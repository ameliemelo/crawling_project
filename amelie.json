[{
    "id": "761b42cfff120aac30045f7a110d0256",
    "title": "Posterior Meta-Replay for Continual Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/761b42cfff120aac30045f7a110d0256-Paper.pdf",
    "abstract": "Learning a sequence of tasks without access to i.i.d. observations is a widely studied form of continual learning (CL) that remains challenging. In principle, Bayesian learning directly applies to this setting, since recursive and one-off Bayesian updates yield the same result. In practice, however, recursive updating often leads to poor trade-off solutions across tasks because approximate inference is necessary for most models of interest. Here, we describe an alternative Bayesian approach where task-conditioned parameter distributions are continually inferred from data. We offer a practical deep learning implementation of our framework based on probabilistic task-conditioned hypernetworks, an approach we term posterior meta-replay. Experiments on standard benchmarks show that our probabilistic hypernetworks compress sequences of posterior parameter distributions with virtually no forgetting. We obtain considerable performance gains compared to existing Bayesian CL methods, and identify task inference as our major limiting factor. This limitation has several causes that are independent of the considered sequential setting, opening up new avenues for progress in CL.",
    "authors": [
      "Henning, Christian",
      "Cervera, Maria",
      "D'Angelo, Francesco",
      "von Oswald, Johannes",
      "Traber, Regina",
      "Ehret, Benjamin",
      "Kobayashi, Seijin",
      "Grewe, Benjamin F.",
      "Sacramento, Jo\u00e3o"
    ]
  },
  {
    "id": "761e6675f9e54673cc778e7fdb2823d2",
    "title": "Optimizing Reusable Knowledge for Continual Learning via Metalearning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/761e6675f9e54673cc778e7fdb2823d2-Paper.pdf",
    "abstract": "When learning tasks over time, artificial neural networks suffer from a problem known as Catastrophic Forgetting (CF). This happens when the weights of a network are overwritten during the training of a new task causing forgetting of old information. To address this issue, we propose MetA Reusable Knowledge or MARK, a new method that fosters weight reusability instead of overwriting when learning a new task. Specifically, MARK keeps a set of shared weights among tasks. We envision these shared weights as a common Knowledge Base (KB) that is not only used to learn new tasks, but also enriched with new knowledge as the model learns new tasks. Key components behind MARK are two-fold. On the one hand, a metalearning approach provides the key mechanism to incrementally enrich the KB with new knowledge and to foster weight reusability among tasks. On the other hand, a set of trainable masks provides the key mechanism to selectively choose from the KB relevant weights to solve each task. By using MARK, we achieve state of the art results in several popular benchmarks, surpassing the best performing methods in terms of average accuracy by over 10% on the 20-Split-MiniImageNet dataset, while achieving almost zero forgetfulness using 55% of the number of parameters. Furthermore, an ablation study provides evidence that, indeed, MARK is learning reusable knowledge that is selectively used by each task.",
    "authors": [
      "Hurtado, Julio",
      "Raymond, Alain",
      "Soto, Alvaro"
    ]
  },
  {
    "id": "76444b3132fda0e2aca778051d776f1c",
    "title": "A sampling-based circuit for optimal decision making",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/76444b3132fda0e2aca778051d776f1c-Paper.pdf",
    "abstract": "Many features of human and animal behavior can be understood in the framework of Bayesian inference and optimal decision making, but the biological substrate of such processes is not fully understood. Neural sampling provides a flexible code for probabilistic inference in high dimensions and explains key features of sensory responses under experimental manipulations of uncertainty. However, since it encodes uncertainty implicitly, across time and neurons, it remains unclear how such representations can be used for decision making. Here we propose a spiking network model that maps neural samples of a task-specific marginal distribution into an instantaneous representation of uncertainty via a procedure inspired by online  kernel density estimation, so that its output can be readily used for decision making. Our model is consistent with experimental results at the level of single neurons and populations, and makes predictions for how neural responses and decisions could be modulated by uncertainty and prior biases. More generally, our work brings together conflicting perspectives on probabilistic brain computation.",
    "authors": [
      "Rull\u00e1n Bux\u00f3, Camille",
      "Savin, Cristina"
    ]
  },
  {
    "id": "7647966b7343c29048673252e490f736",
    "title": "Compressed Video Contrastive Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7647966b7343c29048673252e490f736-Paper.pdf",
    "abstract": "This work concerns self-supervised video representation learning (SSVRL), one topic that has received much attention recently. Since videos are storage-intensive and contain a rich source of visual content, models designed for SSVRL are expected to be storage- and computation-efficient, as well as effective. However, most existing methods only focus on one of the two objectives, failing to consider both at the same time. In this work, for the first time, the seemingly contradictory goals are simultaneously achieved by exploiting compressed videos and capturing mutual information between two input streams. Specifically, a novel Motion Vector based Cross Guidance Contrastive learning approach (MVCGC) is proposed. For storage and computation efficiency, we choose to directly decode RGB frames and motion vectors (that resemble low-resolution optical flows) from compressed videos on-the-fly. To enhance the representation ability of the motion vectors, hence the effectiveness of our method, we design a cross guidance contrastive learning algorithm based on multi-instance InfoNCE loss, where motion vectors can take supervision signals from RGB frames and vice versa. Comprehensive experiments on two downstream tasks show that our MVCGC yields new state-of-the-art while being significantly more efficient than its competitors.",
    "authors": [
      "Huo, Yuqi",
      "Ding, Mingyu",
      "Lu, Haoyu",
      "Fei, Nanyi",
      "Lu, Zhiwu",
      "Wen, Ji-Rong",
      "Luo, Ping"
    ]
  },
  {
    "id": "7695ea769f021803c508817dd374bb27",
    "title": "Uniform-PAC Bounds for Reinforcement Learning with Linear Function Approximation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7695ea769f021803c508817dd374bb27-Paper.pdf",
    "abstract": "We study reinforcement learning (RL) with linear function approximation. Existing algorithms for this problem only have high-probability regret and/or Probably Approximately Correct (PAC) sample complexity guarantees, which cannot guarantee the convergence to the optimal policy. In this paper, in order to overcome the limitation of existing algorithms, we propose a new algorithm called FLUTE, which enjoys uniform-PAC convergence to the optimal policy with high probability. The uniform-PAC guarantee is the strongest possible guarantee for reinforcement learning in the literature, which can directly imply both PAC and high probability regret bounds, making our algorithm superior to all existing algorithms with linear function approximation. At the core of our algorithm is a novel minimax value function estimator and a multi-level partition scheme to select the training samples from historical observations. Both of these techniques are new and of independent interest. ",
    "authors": [
      "He, Jiafan",
      "Zhou, Dongruo",
      "Gu, Quanquan"
    ]
  },
  {
    "id": "76ba9f564ebbc35b1014ac498fafadd0",
    "title": "Attention Bottlenecks for Multimodal Fusion",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/76ba9f564ebbc35b1014ac498fafadd0-Paper.pdf",
    "abstract": "Humans perceive the world by concurrently processing and fusing high-dimensional inputs from multiple modalities such as vision and audio.  Machine perception models, in stark contrast, are typically modality-specific and optimised for unimodal benchmarks.A common approach for building multimodal models is to simply combine multiple of these modality-specific architectures using late-stage fusion of final representations or predictions ('late-fusion').Instead, we introduce a novel transformer based architecture that uses 'attention bottlenecks' for modality fusion at multiple layers. Compared to traditional pairwise self-attention,  these bottlenecks force information between different modalities to pass through a small number of '`bottleneck' latent units, requiring the model to collate and condense the most relevant information in each modality and only share what is necessary. We find that such a strategy improves fusion performance, at the same time reducing computational cost. We conduct thorough ablation studies, and achieve state-of-the-art results on multiple audio-visual classification benchmarks including Audioset, Epic-Kitchens and VGGSound. All code and models will be released.",
    "authors": [
      "Nagrani, Arsha",
      "Yang, Shan",
      "Arnab, Anurag",
      "Jansen, Aren",
      "Schmid, Cordelia",
      "Sun, Chen"
    ]
  },
  {
    "id": "76c073d8a82d9ddaf993300be03ac70f",
    "title": "Convergence of adaptive algorithms for constrained weakly convex optimization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/76c073d8a82d9ddaf993300be03ac70f-Paper.pdf",
    "abstract": "We analyze the adaptive first order algorithm AMSGrad, for solving a constrained stochastic optimization problem with a weakly convex objective. We prove the $\\mathcal{\\tilde O}(t^{-1/2})$ rate of convergence for the squared norm of the gradient of Moreau envelope, which is the standard stationarity measure for this class of problems. It matches the known rates that adaptive algorithms enjoy for the specific case of unconstrained smooth nonconvex stochastic optimization. Our analysis works with mini-batch size of $1$, constant first and second order moment parameters, and possibly unbounded optimization domains. Finally, we illustrate the applications and extensions of our results to specific problems and algorithms.",
    "authors": [
      "Alacaoglu, Ahmet",
      "Malitsky, Yura",
      "Cevher, Volkan"
    ]
  },
  {
    "id": "76c538125fc5c9ec6ad1d05650a57de5",
    "title": "On the Convergence of Step Decay Step-Size for Stochastic Optimization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/76c538125fc5c9ec6ad1d05650a57de5-Paper.pdf",
    "abstract": "The convergence of stochastic gradient descent is highly dependent on the step-size, especially on non-convex problems such as neural network training. Step decay step-size schedules (constant and then cut) are widely used in practice because of their excellent convergence and generalization qualities, but their theoretical properties are not yet well understood. We provide convergence results for step decay in the non-convex regime, ensuring that the gradient norm vanishes at an $\\mathcal{O}(\\ln T/\\sqrt{T})$ rate. We also provide near-optimal (and sometimes provably tight) convergence guarantees for general, possibly non-smooth, convex and strongly convex problems. The practical efficiency of the step decay step-size is demonstrated in several large-scale deep neural network training tasks.",
    "authors": [
      "Wang, Xiaoyu",
      "Magn\u00fasson, Sindri",
      "Johansson, Mikael"
    ]
  },
  {
    "id": "76f1cfd7754a6e4fc3281bcccb3d0902",
    "title": "BernNet: Learning Arbitrary Graph Spectral Filters via Bernstein Approximation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/76f1cfd7754a6e4fc3281bcccb3d0902-Paper.pdf",
    "abstract": "Many representative graph neural networks, $e.g.$, GPR-GNN and ChebNet, approximate graph convolutions with graph spectral filters. However, existing work either applies predefined filter weights or learns them without necessary constraints, which may lead to oversimplified or ill-posed filters. To overcome these issues, we propose $\\textit{BernNet}$, a novel graph neural network with theoretical support that provides a simple but effective scheme for designing and learning arbitrary graph spectral filters. In particular, for any filter over the normalized Laplacian spectrum of a graph, our BernNet estimates it by an order-$K$ Bernstein polynomial approximation and designs its spectral property by setting the coefficients of the Bernstein basis. Moreover, we can learn the coefficients (and the corresponding filter weights) based on observed graphs and their associated signals and thus achieve the BernNet specialized for the data. Our experiments demonstrate that BernNet can learn arbitrary spectral filters, including complicated band-rejection and comb filters, and it achieves superior performance in real-world graph modeling tasks. Code is available at https://github.com/ivam-he/BernNet.",
    "authors": [
      "He, Mingguo",
      "Wei, Zhewei",
      "Huang, zengfeng",
      "Xu, Hongteng"
    ]
  },
  {
    "id": "770f8e448d07586afbf77bb59f698587",
    "title": "Co-evolution Transformer for Protein Contact Prediction",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/770f8e448d07586afbf77bb59f698587-Paper.pdf",
    "abstract": "Proteins are the main machinery of life and protein functions are largely determined by their 3D structures. The measurement of the pairwise proximity between amino acids of a protein, known as inter-residue contact map, well characterizes the structural information of a protein. Protein contact prediction (PCP) is an essential building block of many protein structure related applications.  The prevalent approach to contact prediction is based on estimating the inter-residue contacts using hand-crafted coevolutionary features derived from multiple sequence alignments (MSAs). To mitigate the information loss caused by hand-crafted features, some recently proposed methods try to learn residue co-evolutions directly from MSAs. These methods generally derive coevolutionary features by aggregating the learned residue representations from individual sequences with equal weights, which is inconsistent with the premise that residue co-evolutions are a reflection of collective covariation patterns of numerous homologous proteins.  Moreover, non-homologous residues and gaps commonly exist in MSAs. By aggregating features from all homologs equally, the non-homologous information may cause misestimation of the residue co-evolutions.  To overcome these issues, we propose an attention-based architecture, Co-evolution Transformer (CoT), for PCP. CoT jointly considers the information from all homologous sequences in the MSA to better capture global coevolutionary patterns. To mitigate the influence of the non-homologous information, CoT selectively aggregates the features from different homologs by assigning smaller weights to non-homologous sequences or residue pairs.  Extensive experiments on two rigorous benchmark datasets demonstrate the effectiveness of CoT. In particular, CoT achieves a $51.6\\%$ top-L long-range precision score for the Free Modeling (FM) domains on the CASP14 benchmark, which outperforms the winner group of CASP14 contact prediction challenge by $9.8\\%$.",
    "authors": [
      "Zhang, He",
      "Ju, Fusong",
      "Zhu, Jianwei",
      "He, Liang",
      "Shao, Bin",
      "Zheng, Nanning",
      "Liu, Tie-Yan"
    ]
  },
  {
    "id": "77369e37b2aa1404f416275183ab055f",
    "title": "Unsupervised Foreground Extraction via Deep Region Competition",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/77369e37b2aa1404f416275183ab055f-Paper.pdf",
    "abstract": "We present Deep Region Competition (DRC), an algorithm designed to extract foreground objects from images in a fully unsupervised manner. Foreground extraction can be viewed as a special case of generic image segmentation that focuses on identifying and disentangling objects from the background. In this work, we rethink the foreground extraction by reconciling energy-based prior with generative image modeling in the form of Mixture of Experts (MoE), where we further introduce the learned pixel re-assignment as the essential inductive bias to capture the regularities of background regions. With this modeling, the foreground-background partition can be naturally found through Expectation-Maximization (EM). We show that the proposed method effectively exploits the interaction between the mixture components during the partitioning process, which closely connects to region competition, a seminal approach for generic image segmentation. Experiments demonstrate that DRC exhibits more competitive performances on complex real-world data and challenging multi-object scenes compared with prior methods. Moreover, we show empirically that DRC can potentially generalize to novel foreground objects even from categories unseen during training.",
    "authors": [
      "Yu, Peiyu",
      "Xie, Sirui",
      "Ma, Xiaojian",
      "Zhu, Yixin",
      "Wu, Ying Nian",
      "Zhu, Song-Chun"
    ]
  },
  {
    "id": "77b88288ebae7b17b7c8610a48c40dd1",
    "title": "Leveraging Spatial and Temporal Correlations in Sparsified Mean Estimation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/77b88288ebae7b17b7c8610a48c40dd1-Paper.pdf",
    "abstract": "We study the problem of estimating at a central server the mean of a set of vectors distributed across several nodes (one vector per node). When the vectors are high-dimensional, the communication cost of sending entire vectors may be prohibitive, and it may be imperative for them to use sparsification techniques. While most existing work on sparsified mean estimation is agnostic to the characteristics of the data vectors, in many practical applications such as federated learning, there may be spatial correlations (similarities in the vectors sent by different nodes) or temporal correlations (similarities in the data sent by a single node over different iterations of the algorithm) in the data vectors. We leverage these correlations by simply modifying the decoding method used by the server to estimate the mean. We provide an analysis of the resulting estimation error as well as experiments for PCA, K-Means and Logistic Regression, which show that our estimators consistently outperform more sophisticated and expensive sparsification methods.",
    "authors": [
      "Jhunjhunwala, Divyansh",
      "Mallick, Ankur",
      "Gadhikar, Advait",
      "Kadhe, Swanand",
      "Joshi, Gauri"
    ]
  },
  {
    "id": "77bb14f6132ea06dea456584b7d5581e",
    "title": "Last-iterate Convergence in Extensive-Form Games",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/77bb14f6132ea06dea456584b7d5581e-Paper.pdf",
    "abstract": "Regret-based algorithms are highly efficient at finding approximate Nash equilibria in sequential games such as poker games. However, most regret-based algorithms, including counterfactual regret minimization (CFR) and its variants, rely on iterate averaging to achieve convergence.  Inspired by recent advances on last-iterate convergence of optimistic algorithms in zero-sum normal-form games, we study this phenomenon in sequential games, and provide a comprehensive study of last-iterate convergence for zero-sum extensive-form games with perfect recall (EFGs), using various optimistic regret-minimization algorithms over treeplexes. This includes algorithms using the vanilla entropy or squared Euclidean norm regularizers, as well as their dilated versions which admit more efficient implementation. In contrast to CFR, we show that all of these algorithms enjoy last-iterate convergence, with some of them even converging exponentially fast. We also provide experiments to further support our theoretical results.",
    "authors": [
      "Lee, Chung-Wei",
      "Kroer, Christian",
      "Luo, Haipeng"
    ]
  },
  {
    "id": "77ee3bc58ce560b86c2b59363281e914",
    "title": "Class-Incremental Learning via Dual Augmentation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/77ee3bc58ce560b86c2b59363281e914-Paper.pdf",
    "abstract": "Deep learning systems typically suffer from catastrophic forgetting of past knowledge when acquiring new skills continually. In this paper, we emphasize two dilemmas, representation bias and classifier bias in class-incremental learning, and present a simple and novel approach that employs explicit class augmentation (classAug) and implicit semantic augmentation (semanAug) to address the two biases, respectively. On the one hand, we propose to address the representation bias by learning transferable and diverse representations. Specifically, we investigate the feature representations in incremental learning based on spectral analysis and present a simple technique called classAug, to let the model see more classes during training for learning representations transferable across classes. On the other hand, to overcome the classifier bias, semanAug implicitly involves the simultaneous generating of an infinite number of instances of old classes in the deep feature space, which poses tighter constraints to maintain the decision boundary of previously learned classes. Without storing any old samples, our method can perform comparably with representative data replay based approaches.",
    "authors": [
      "Zhu, Fei",
      "Cheng, Zhen",
      "Zhang, Xu-yao",
      "Liu, Cheng-lin"
    ]
  },
  {
    "id": "7806689d934e610d660caf5536fea0b2",
    "title": "Robust and Fully-Dynamic Coreset for Continuous-and-Bounded Learning (With Outliers) Problems",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7806689d934e610d660caf5536fea0b2-Paper.pdf",
    "abstract": "In many machine learning tasks, a common approach for dealing with large-scale data is to build a small summary, {\\em e.g.,} coreset,  that can efficiently represent the original input. However, real-world datasets usually contain outliers and most existing coreset construction methods are not resilient against outliers (in particular, an outlier can be located arbitrarily in the space by an adversarial attacker). In this paper, we propose a novel robust coreset method for the {\\em continuous-and-bounded learning} problems (with outliers) which includes a broad range of popular optimization objectives in machine learning, {\\em e.g.,} logistic regression and $ k $-means clustering. Moreover, our robust coreset  can be efficiently maintained in fully-dynamic environment. To the best of our knowledge, this is the first robust and fully-dynamic coreset construction method for these optimization problems. Another highlight is that our coreset size can depend on the doubling dimension of the parameter space, rather than the VC dimension of the objective function which could be very large or even challenging to compute. Finally, we conduct the experiments on real-world datasets to evaluate the effectiveness of our proposed robust coreset method.",
    "authors": [
      "Wang, Zixiu",
      "Guo, Yiwen",
      "Ding, Hu"
    ]
  },
  {
    "id": "781397bc0630d47ab531ea850bddcf63",
    "title": "Rethinking and Reweighting the Univariate Losses for Multi-Label Ranking: Consistency and Generalization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/781397bc0630d47ab531ea850bddcf63-Paper.pdf",
    "abstract": "The (partial) ranking loss is a commonly used evaluation measure for multi-label classification, which is usually optimized with convex surrogates for computational efficiency. Prior theoretical efforts on multi-label ranking mainly focus on (Fisher) consistency analyses. However, there is a gap between existing theory and practice --- some inconsistent pairwise losses can lead to promising performance, while some consistent univariate losses usually have no clear superiority in practice. To take a step towards filling up this gap, this paper presents a systematic study from two complementary perspectives of consistency and generalization error bounds of learning algorithms. We theoretically find two key factors of the distribution (or dataset) that affect the learning guarantees of algorithms: the instance-wise class imbalance and the label size $c$. Specifically, in an extremely imbalanced case, the algorithm with the consistent univariate loss has an error bound of $O(c)$, while the one with the inconsistent pairwise loss depends on $O(\\sqrt{c})$ as shown in prior work. This may shed light on the superior performance of pairwise methods in practice, where real datasets are usually highly imbalanced. Moreover, we present an inconsistent reweighted univariate loss-based algorithm that enjoys an error bound of $O(\\sqrt{c})$ for promising performance as well as the computational efficiency of univariate losses. Finally, experimental results confirm our theoretical findings.",
    "authors": [
      "Wu, Guoqiang",
      "LI, Chongxuan",
      "Xu, Kun",
      "Zhu, Jun"
    ]
  },
  {
    "id": "781877bda0783aac5f1cf765c128b437",
    "title": "Fair Clustering Under a Bounded Cost",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/781877bda0783aac5f1cf765c128b437-Paper.pdf",
    "abstract": "Clustering is a fundamental unsupervised learning problem where a dataset is partitioned into clusters that consist of nearby points in a metric space. A recent variant, fair clustering, associates a color with each point representing its group membership and requires that each color has (approximately) equal representation in each cluster to satisfy group fairness. In this model, the cost of the clustering objective increases due to enforcing fairness in the algorithm. The relative increase in the cost, the ```````''price of fairness,'' can indeed be unbounded. Therefore, in this paper we propose to treat an upper bound on the clustering objective as a constraint on the clustering problem, and to maximize equality of representation subject to it. We consider two fairness objectives: the group utilitarian objective and the group egalitarian objective, as well as the group leximin objective which generalizes the group egalitarian objective. We derive fundamental lower bounds on the approximation of the utilitarian and egalitarian objectives and introduce algorithms with provable guarantees for them. For the leximin objective we introduce an effective heuristic algorithm. We further derive impossibility results for other natural fairness objectives. We conclude with experimental results on real-world datasets that demonstrate the validity of our algorithms. ",
    "authors": [
      "Esmaeili, Seyed",
      "Brubach, Brian",
      "Srinivasan, Aravind",
      "Dickerson, John"
    ]
  },
  {
    "id": "78421a2e0e1168e5cd1b7a8d23773ce6",
    "title": "Improving Calibration through the Relationship with Adversarial Robustness",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/78421a2e0e1168e5cd1b7a8d23773ce6-Paper.pdf",
    "abstract": "Neural networks lack adversarial robustness, i.e., they are vulnerable to adversarial examples that through small perturbations to inputs cause incorrect predictions. Further, trust is undermined when models give miscalibrated predictions, i.e.,  the predicted probability is not a good indicator of how much we should trust our model. In this paper, we study the connection between adversarial robustness and calibration and find that the inputs for which the model is sensitive to small perturbations (are easily attacked) are more likely to have poorly calibrated predictions. Based on this insight, we examine if calibration can be improved by addressing those adversarially unrobust inputs. To this end, we propose Adversarial Robustness based Adaptive Label Smoothing (AR-AdaLS) that integrates the correlations of adversarial robustness and calibration into training by adaptively softening labels for an example based on how easily it can be attacked by an adversary. We find that our method, taking the adversarial robustness of the in-distribution data into consideration, leads to better calibration over the model even under distributional shifts. In addition, AR-AdaLS can also be applied to an ensemble model to further improve model calibration. ",
    "authors": [
      "Qin, Yao",
      "Wang, Xuezhi",
      "Beutel, Alex",
      "Chi, Ed"
    ]
  },
  {
    "id": "7866c91c59f8bffc92a79a7cd09f9af9",
    "title": "Credal Self-Supervised Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7866c91c59f8bffc92a79a7cd09f9af9-Paper.pdf",
    "abstract": "Self-training is an effective approach to semi-supervised learning. The key idea is to let the learner itself iteratively generate \"pseudo-supervision\" for unlabeled instances based on its current hypothesis. In combination with consistency regularization, pseudo-labeling has shown promising performance in various domains, for example in computer vision. To account for the hypothetical nature of the pseudo-labels, these are commonly provided in the form of probability distributions. Still, one may argue that even a probability distribution represents an excessive level of informedness, as it suggests that the learner precisely knows the ground-truth conditional probabilities. In our approach, we therefore allow the learner to label instances in the form of credal sets, that is, sets of (candidate) probability distributions. Thanks to this increased expressiveness, the learner is able to represent uncertainty and a lack of knowledge in a more flexible and more faithful manner. To learn from weakly labeled data of that kind, we leverage methods that have recently been proposed in the realm of so-called superset learning. In an exhaustive empirical evaluation, we compare our methodology to state-of-the-art self-supervision approaches, showing competitive to superior performance especially in low-label scenarios incorporating a high degree of uncertainty.",
    "authors": [
      "Lienen, Julian",
      "H\u00fcllermeier, Eyke"
    ]
  },
  {
    "id": "7867d6557b82ed3b5d61e6591a2a2fd3",
    "title": "Spot the Difference: Detection of Topological Changes via Geometric Alignment",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7867d6557b82ed3b5d61e6591a2a2fd3-Paper.pdf",
    "abstract": "Geometric alignment appears in a variety of applications, ranging from domain adaptation, optimal transport, and normalizing flows in machine learning; optical flow and learned augmentation in computer vision and deformable registration within biomedical imaging. A recurring challenge is the alignment of domains whose topology is not the same; a problem that is routinely ignored, potentially introducing bias in downstream analysis. As a first step towards solving such alignment problems, we propose an unsupervised algorithm for the detection of changes in image topology. The model is based on a conditional variational auto-encoder and detects topological changes between two images during the registration step. We account for both topological changes in the image under spatial variation and unexpected transformations. Our approach is validated on two tasks and datasets: detection of topological changes in microscopy images of cells, and unsupervised anomaly detection brain imaging.",
    "authors": [
      "Czolbe, Per Steffen",
      "Feragen, Aasa",
      "Krause, Oswin"
    ]
  },
  {
    "id": "788d986905533aba051261497ecffcbb",
    "title": "Rethinking the Variational Interpretation of Accelerated Optimization Methods",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/788d986905533aba051261497ecffcbb-Paper.pdf",
    "abstract": "The continuous-time model of Nesterov's momentum provides a thought-provoking perspective for understanding the nature of the acceleration phenomenon in convex optimization. One of the main ideas in this line of research comes from the field of classical mechanics and proposes to link Nesterov's trajectory to the solution of a set of Euler-Lagrange equations relative to the so-called Bregman Lagrangian. In the last years, this approach led to the discovery of many new (stochastic) accelerated algorithms and provided a solid theoretical foundation for the design of structure-preserving accelerated methods. In this work, we revisit this idea and provide an in-depth analysis of the action relative to the Bregman Lagrangian from the point of view of calculus of variations. Our main finding is that, while Nesterov's method is a stationary point for the action, it is often not a minimizer but instead a saddle point for this functional in the space of differentiable curves. This finding challenges the main intuition behind the variational interpretation of Nesterov's method and provides additional insights into the intriguing geometry of accelerated paths.",
    "authors": [
      "Zhang, Peiyuan",
      "Orvieto, Antonio",
      "Daneshmand, Hadi"
    ]
  },
  {
    "id": "78ccad7da4c2fc2646d1848e965794c5",
    "title": "Linear and Kernel Classification in the Streaming Model: Improved Bounds for Heavy Hitters",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/78ccad7da4c2fc2646d1848e965794c5-Paper.pdf",
    "abstract": "We study linear and kernel classification in the streaming model. For linear classification, we improve upon the algorithm of (Tai, et al. 2018), which solves the $\\ell_1$ point query problem on the optimal weight vector $w_* \\in \\mathbb{R}^d$ in sublinear space. We first give an algorithm solving the more difficult $\\ell_2$ point query problem on $w_*$, also in sublinear space. We also give an algorithm which solves the $\\ell_2$ heavy hitter problem on $w_*$, in sublinear space and running time. Finally, we give an algorithm which can $\\textit{deterministically}$ solve the $\\ell_1$ point query problem on $w_*$, with sublinear space improving upon that of (Tai, et al. 2018). For kernel classification, if $w_* \\in \\mathbb{R}^{d^p}$ is the optimal weight vector classifying points in the stream according to their $p^{th}$-degree polynomial kernel, then we give an algorithm solving the $\\ell_2$ point query problem on $w_*$ in $\\text{poly}(\\frac{p \\log d}{\\varepsilon})$ space, and an algorithm solving the $\\ell_2$ heavy hitter problem in $\\text{poly}(\\frac{p \\log d}{\\varepsilon})$ space and running time. Note that our space and running time are polynomial in $p$, making our algorithms well-suited to high-degree polynomial kernels and the Gaussian kernel (approximated by the polynomial kernel of degree $p = \\Theta(\\log T)$).",
    "authors": [
      "Mahankali, Arvind",
      "Woodruff, David"
    ]
  },
  {
    "id": "78e8dffe65a2898eef68a33b8db35b78",
    "title": "A PAC-Bayes Analysis of Adversarial Robustness",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/78e8dffe65a2898eef68a33b8db35b78-Paper.pdf",
    "abstract": "We propose the first general PAC-Bayesian generalization bounds for adversarial robustness, that estimate, at test time, how much a model will be invariant to imperceptible perturbations in the input. Instead of deriving a worst-case analysis of the risk of a hypothesis over all the possible perturbations, we leverage the PAC-Bayesian framework to bound the averaged risk on the perturbations for majority votes (over the whole class of hypotheses). Our theoretically founded analysis has the advantage to provide general bounds (i) that are valid for any kind of attacks (i.e., the adversarial attacks), (ii) that are tight thanks to the PAC-Bayesian framework, (iii) that can be directly minimized during the learning phase to obtain a robust model on different attacks at test time.",
    "authors": [
      "Viallard, Paul",
      "VIDOT, Eric Guillaume",
      "Habrard, Amaury",
      "Morvant, Emilie"
    ]
  },
  {
    "id": "78f1893678afbeaa90b1fa01b9cfb860",
    "title": "SE(3)-equivariant prediction of molecular wavefunctions and electronic densities",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/78f1893678afbeaa90b1fa01b9cfb860-Paper.pdf",
    "abstract": "Machine learning has enabled the prediction of quantum chemical properties with high accuracy and efficiency, allowing to bypass computationally costly ab initio calculations. Instead of training on a fixed set of properties, more recent approaches attempt to learn the electronic wavefunction (or density) as a central quantity of atomistic systems, from which all other observables can be derived. This is complicated by the fact that wavefunctions transform non-trivially under molecular rotations, which makes them a challenging prediction target. To solve this issue, we introduce general SE(3)-equivariant operations and building blocks for constructing deep learning architectures for geometric point cloud data and apply them to reconstruct wavefunctions of atomistic systems with unprecedented accuracy. Our model achieves speedups of over three orders of magnitude compared to ab initio methods and reduces prediction errors by up to two orders of magnitude compared to the previous state-of-the-art. This accuracy makes it possible to derive properties such as energies and forces directly from the wavefunction in an end-to-end manner. We demonstrate the potential of our approach in a transfer learning application, where a model trained on low accuracy reference wavefunctions implicitly learns to correct for electronic many-body interactions from observables computed at a higher level of theory. Such machine-learned wavefunction surrogates pave the way towards novel semi-empirical methods, offering resolution at an electronic level while drastically decreasing computational cost. Additionally, the predicted wavefunctions can serve as initial guess in conventional ab initio methods, decreasing the number of iterations required to arrive at a converged solution, thus leading to significant speedups without any loss of accuracy or robustness. While we focus on physics applications in this contribution, the proposed equivariant framework for deep learning on point clouds is promising also beyond, say, in computer vision or graphics. ",
    "authors": [
      "Unke, Oliver",
      "Bogojeski, Mihail",
      "Gastegger, Michael",
      "Geiger, Mario",
      "Smidt, Tess",
      "M\u00fcller, Klaus-Robert"
    ]
  },
  {
    "id": "79121bb953a3bd47c076f20234bafd2e",
    "title": "Modified Frank Wolfe in Probability Space",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/79121bb953a3bd47c076f20234bafd2e-Paper.pdf",
    "abstract": "We propose a novel Frank-Wolfe (FW) procedure for the optimization of infinite-dimensional functionals of probability measures - a task which arises naturally in a wide range of areas including statistical learning (e.g. variational inference) and artificial intelligence (e.g. generative adversarial networks). Our FW procedure takes advantage of Wasserstein gradient flows and strong duality results recently developed in Distributionally Robust Optimization so that gradient steps (in the Wasserstein space) can be efficiently computed using finite-dimensional, convex optimization methods. We show how to choose the step sizes in order to guarantee exponentially fast iteration convergence, under mild assumptions on the functional to optimize. We apply our algorithm to a range of functionals arising from applications in nonparametric estimation.  ",
    "authors": [
      "Kent, Carson",
      "Li, Jiajin",
      "Blanchet, Jose",
      "Glynn, Peter W"
    ]
  },
  {
    "id": "792c7b5aae4a79e78aaeda80516ae2ac",
    "title": "Bayesian Optimization of Function Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/792c7b5aae4a79e78aaeda80516ae2ac-Paper.pdf",
    "abstract": "We consider Bayesian optimization of the output of a network of functions, where each function takes as input the output of its parent nodes, and where the network takes significant time to evaluate. Such problems arise, for example, in reinforcement learning, engineering design, and manufacturing.  While the standard Bayesian optimization approach observes only the final output, our approach delivers greater query efficiency by leveraging information that the former ignores: intermediate output within the network. This is achieved by modeling the nodes of the network using Gaussian processes and choosing the points to evaluate using, as our acquisition function, the expected improvement computed with respect to the implied posterior on the objective. Although the non-Gaussian nature of this posterior prevents computing our acquisition function in closed form, we show that it can be efficiently maximized via sample average approximation. In addition, we prove that our method is asymptotically consistent, meaning that it finds a globally optimal solution as the number of evaluations grows to infinity, thus generalizing previously known convergence results for the expected improvement. Notably, this holds even though our method might not evaluate the domain densely, instead leveraging problem structure to leave regions unexplored. Finally, we show that our approach dramatically outperforms standard Bayesian optimization methods in several synthetic and real-world problems.",
    "authors": [
      "Astudillo, Raul",
      "Frazier, Peter"
    ]
  },
  {
    "id": "792dd774336314c3c27a04bb260cf2cf",
    "title": "Look at What I\u2019m Doing: Self-Supervised Spatial Grounding of Narrations in Instructional Videos",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/792dd774336314c3c27a04bb260cf2cf-Paper.pdf",
    "abstract": "We introduce the task of spatially localizing narrated interactions in videos. Key to our approach is the ability to learn to spatially localize interactions with self-supervision on a large corpus of videos with accompanying transcribed narrations. To achieve this goal, we propose a multilayer cross-modal attention network that enables effective optimization of a contrastive loss during training. We introduce a divided strategy that alternates between computing inter- and intra-modal attention across the visual and natural language modalities, which allows effective training via directly contrasting the two modalities' representations. We demonstrate the effectiveness of our approach by self-training on the HowTo100M instructional video dataset and evaluating on a newly collected dataset of localized described interactions in the YouCook2 dataset. We show that our approach outperforms alternative baselines, including shallow co-attention and full cross-modal attention. We also apply our approach to grounding phrases in images with weak supervision on Flickr30K and show that stacking multiple attention layers is effective and, when combined with a word-to-region loss, achieves state of the art on recall-at-one and pointing hand accuracies.",
    "authors": [
      "Tan, Reuben",
      "Plummer, Bryan",
      "Saenko, Kate",
      "Jin, Hailin",
      "Russell, Bryan"
    ]
  },
  {
    "id": "793bc52a941b3951dfdb85fb04f9fd06",
    "title": "RETRIEVE: Coreset Selection for Efficient and Robust Semi-Supervised Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/793bc52a941b3951dfdb85fb04f9fd06-Paper.pdf",
    "abstract": "Semi-supervised learning (SSL) algorithms have had great success in recent years in limited labeled data regimes. However, the current state-of-the-art SSL algorithms are computationally expensive and entail significant compute time and energy requirements. This can prove to be a huge limitation for many smaller companies and academic groups. Our main insight is that training on a subset of unlabeled data instead of entire unlabeled data enables the current SSL algorithms to converge faster, significantly reducing computational costs. In this work, we propose RETRIEVE, a coreset selection framework for efficient and robust semi-supervised learning. RETRIEVE selects the coreset by solving a mixed discrete-continuous bi-level optimization problem such that the selected coreset minimizes the labeled set loss. We use a one-step gradient approximation and show that the discrete optimization problem is approximately submodular, enabling simple greedy algorithms to obtain the coreset. We empirically demonstrate on several real-world datasets that existing SSL algorithms like VAT, Mean-Teacher, FixMatch, when used with RETRIEVE, achieve a) faster training times,  b) better performance when unlabeled data consists of Out-of-Distribution (OOD) data and imbalance. More specifically, we show that with minimal accuracy degradation, RETRIEVE achieves a speedup of around $3\\times$ in the traditional SSL setting and achieves a speedup of $5\\times$ compared to state-of-the-art (SOTA) robust SSL algorithms in the case of imbalance and OOD data. RETRIEVE is available as a part of the CORDS toolkit: https://github.com/decile-team/cords.",
    "authors": [
      "Killamsetty, Krishnateja",
      "Zhao, Xujiang",
      "Chen, Feng",
      "Iyer, Rishabh"
    ]
  },
  {
    "id": "797134c3e42371bb4979a462eb2f042a",
    "title": "Collaborating with Humans without Human Data",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/797134c3e42371bb4979a462eb2f042a-Paper.pdf",
    "abstract": "Collaborating with humans requires rapidly adapting to their individual strengths, weaknesses, and preferences. Unfortunately, most standard multi-agent reinforcement learning techniques, such as self-play (SP) or population play (PP), produce agents that overfit to their training partners and do not generalize well to humans. Alternatively, researchers can collect human data, train a human model using behavioral cloning, and then use that model to train \"human-aware\" agents (\"behavioral cloning play\", or BCP). While such an approach can improve the generalization of agents to new human co-players, it involves the onerous and expensive step of collecting large amounts of human data first. Here, we study the problem of how to train agents that collaborate well with human partners without using human data. We argue that the crux of the problem is to produce a diverse set of training partners. Drawing inspiration from successful multi-agent approaches in competitive domains, we find that a surprisingly simple approach is highly effective. We train our agent partner as the best response to a population of self-play agents and their past checkpoints taken throughout training, a method we call Fictitious Co-Play (FCP). Our experiments focus on a two-player collaborative cooking simulator that has recently been proposed as a challenge problem for coordination with humans. We find that FCP agents score significantly higher than SP, PP, and BCP when paired with novel agent and human partners. Furthermore, humans also report a strong subjective preference to partnering with FCP agents over all baselines.",
    "authors": [
      "Strouse, DJ",
      "McKee, Kevin",
      "Botvinick, Matt",
      "Hughes, Edward",
      "Everett, Richard"
    ]
  },
  {
    "id": "79a49b3e3762632813f9e35f4ba53d6c",
    "title": "Training Feedback Spiking Neural Networks by Implicit Differentiation on the Equilibrium State",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/79a49b3e3762632813f9e35f4ba53d6c-Paper.pdf",
    "abstract": "Spiking neural networks (SNNs) are brain-inspired models that enable energy-efficient implementation on neuromorphic hardware. However, the supervised training of SNNs remains a hard problem due to the discontinuity of the spiking neuron model. Most existing methods imitate the backpropagation framework and feedforward architectures for artificial neural networks, and use surrogate derivatives or compute gradients with respect to the spiking time to deal with the problem. These approaches either accumulate approximation errors or only propagate information limitedly through existing spikes, and usually require information propagation along time steps with large memory costs and biological implausibility. In this work, we consider feedback spiking neural networks, which are more brain-like, and propose a novel training method that does not rely on the exact reverse of the forward computation. First, we show that the average firing rates of SNNs with feedback connections would gradually evolve to an equilibrium state along time, which follows a fixed-point equation. Then by viewing the forward computation of feedback SNNs as a black-box solver for this equation, and leveraging the implicit differentiation on the equation, we can compute the gradient for parameters without considering the exact forward procedure. In this way, the forward and backward procedures are decoupled and therefore the problem of non-differentiable spiking functions is avoided. We also briefly discuss the biological plausibility of implicit differentiation, which only requires computing another equilibrium. Extensive experiments on MNIST, Fashion-MNIST, N-MNIST, CIFAR-10, and CIFAR-100 demonstrate the superior performance of our method for feedback models with fewer neurons and parameters in a small number of time steps. Our code is available at https://github.com/pkuxmq/IDE-FSNN.",
    "authors": [
      "Xiao, Mingqing",
      "Meng, Qingyan",
      "Zhang, Zongpeng",
      "Wang, Yisen",
      "Lin, Zhouchen"
    ]
  },
  {
    "id": "79b6245ff93841eb8c120cec9bf8be14",
    "title": "Online Selective Classification with Limited Feedback",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/79b6245ff93841eb8c120cec9bf8be14-Paper.pdf",
    "abstract": "Motivated by applications to resource-limited and safety-critical domains, we study selective classification in the online learning model, wherein a predictor may abstain from classifying an instance. For example, this may model an adaptive decision to invoke more resources on this instance. Two salient aspects of the setting we consider are that the data may be non-realisable, due to which abstention may be a valid long-term action, and that feedback is only received when the learner abstains, which models the fact that reliable labels are only available when the resource intensive processing is invoked.Within this framework, we explore strategies that make few mistakes, while not abstaining too many times more than the best-in-hindsight error-free classifier from a given class. That is, the one that makes no mistakes, while abstaining the fewest number of times. We construct simple versioning-based schemes for any $\\mu \\in (0,1],$ that make most $T^\\mu$ mistakes while incurring $\\tilde{O}(T^{1-\\mu})$ excess abstention against adaptive adversaries. We further show that this dependence on $T$ is tight, and provide illustrative experiments on realistic datasets.",
    "authors": [
      "Gangrade, Aditya",
      "Kag, Anil",
      "Cutkosky, Ashok",
      "Saligrama, Venkatesh"
    ]
  },
  {
    "id": "79ec2a4246feb2126ecf43c4a4418002",
    "title": "Controlled Text Generation as Continuous Optimization with Multiple Constraints",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/79ec2a4246feb2126ecf43c4a4418002-Paper.pdf",
    "abstract": "As large-scale language model pretraining pushes the state-of-the-art in text generation, recent work has turned to controlling attributes of the text such models generate. While modifying the pretrained models via fine-tuning remains the popular approach, it incurs a significant computational cost and can be infeasible due to a lack of appropriate data. As an alternative, we propose \\textsc{MuCoCO}---a flexible and modular algorithm for controllable inference from pretrained models. We formulate the decoding process as an optimization problem that allows for multiple attributes we aim to control to be easily incorporated as differentiable constraints. By relaxing this discrete optimization to a continuous one, we make use of Lagrangian multipliers and gradient-descent-based techniques to generate the desired text. We evaluate our approach on controllable machine translation and style transfer with multiple sentence-level attributes and observe significant improvements over baselines.",
    "authors": [
      "Kumar, Sachin",
      "Malmi, Eric",
      "Severyn, Aliaksei",
      "Tsvetkov, Yulia"
    ]
  },
  {
    "id": "7a1d9028a78f418cb8f01909a348d9b2",
    "title": "S$^3$: Sign-Sparse-Shift Reparametrization for Effective Training of Low-bit Shift Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7a1d9028a78f418cb8f01909a348d9b2-Paper.pdf",
    "abstract": "Shift neural networks reduce computation complexity by removing expensive multiplication operations and quantizing continuous weights into low-bit discrete values, which are fast and energy-efficient compared to conventional neural networks. However, existing shift networks are sensitive to the weight initialization and yield a degraded performance caused by vanishing gradient and weight sign freezing problem. To address these issues, we propose S$^3$ re-parameterization, a novel technique for training low-bit shift networks. Our method decomposes a discrete parameter in a sign-sparse-shift 3-fold manner. This way, it efficiently learns a low-bit network with weight dynamics similar to full-precision networks and insensitive to weight initialization. Our proposed training method pushes the boundaries of shift neural networks and shows 3-bit shift networks compete with their full-precision counterparts in terms of top-1 accuracy on ImageNet. ",
    "authors": [
      "Li, Xinlin",
      "Liu, Bang",
      "Yu, Yaoliang",
      "Liu, Wulong",
      "XU, Chunjing",
      "Partovi Nia, Vahid"
    ]
  },
  {
    "id": "7a430339c10c642c4b2251756fd1b484",
    "title": "Implicit MLE: Backpropagating Through Discrete Exponential Family Distributions",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7a430339c10c642c4b2251756fd1b484-Paper.pdf",
    "abstract": "Combining discrete probability distributions and combinatorial optimization problems with neural network components has numerous applications but poses several challenges. We propose Implicit Maximum Likelihood Estimation (I-MLE), a framework for end-to-end learning of models combining discrete exponential family distributions and differentiable neural components. I-MLE is widely applicable as it only requires the ability to compute the most probable states and does not rely on smooth relaxations. The framework encompasses several approaches such as perturbation-based implicit differentiation and recent methods to differentiate through black-box combinatorial solvers. We introduce a novel class of noise distributions for approximating marginals via perturb-and-MAP. Moreover, we show that I-MLE simplifies to maximum likelihood estimation when used in some recently studied learning settings that involve combinatorial solvers. Experiments on several datasets suggest that I-MLE is competitive with and often outperforms existing approaches which rely on problem-specific relaxations.",
    "authors": [
      "Niepert, Mathias",
      "Minervini, Pasquale",
      "Franceschi, Luca"
    ]
  },
  {
    "id": "7a50d83a1e70e9d96c3357438aed7a44",
    "title": "Scaling up Continuous-Time Markov Chains Helps Resolve Underspecification",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7a50d83a1e70e9d96c3357438aed7a44-Paper.pdf",
    "abstract": "Modeling the time evolution of discrete sets of items (e.g., genetic mutations) is a fundamental problem in many biomedical applications. We approach this problem through the lens of continuous-time Markov chains, and show that the resulting learning task is generally underspecified in the usual setting of cross-sectional data. We explore a perhaps surprising remedy: including a number of additional independent items can help determine time order, and hence resolve underspecification. This is in sharp contrast to the common practice of limiting the analysis to a small subset of relevant items, which is followed largely due to poor scaling of existing methods. To put our theoretical insight into practice, we develop an approximate likelihood maximization method for learning continuous-time Markov chains, which can scale to hundreds of items and is orders of magnitude faster than previous methods. We demonstrate the effectiveness of our approach on synthetic and real cancer data.",
    "authors": [
      "Gotovos, Alkis",
      "Burkholz, Rebekka",
      "Quackenbush, John",
      "Jegelka, Stefanie"
    ]
  },
  {
    "id": "7a6a6127ff85640ec69691fb0f7cb1a2",
    "title": "Do Neural Optimal Transport Solvers Work? A Continuous Wasserstein-2 Benchmark",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7a6a6127ff85640ec69691fb0f7cb1a2-Paper.pdf",
    "abstract": "Despite the recent popularity of neural network-based solvers for optimal transport (OT), there is no standard quantitative way to evaluate their performance. In this paper, we address this issue for quadratic-cost transport---specifically, computation of the Wasserstein-2 distance, a commonly-used formulation of optimal transport in machine learning. To overcome the challenge of computing ground truth transport maps between continuous measures needed to assess these solvers, we use input-convex neural networks (ICNN) to construct pairs of measures whose ground truth OT maps can be obtained analytically. This strategy yields pairs of continuous benchmark measures in high-dimensional spaces such as spaces of images. We thoroughly evaluate existing optimal transport solvers using these benchmark measures. Even though these solvers perform well in downstream tasks, many do not faithfully recover optimal transport maps. To investigate the cause of this discrepancy, we further test the solvers in a setting of image generation. Our study reveals crucial limitations of existing solvers and shows that increased OT accuracy does not necessarily correlate to better results downstream.",
    "authors": [
      "Korotin, Alexander",
      "Li, Lingxiao",
      "Genevay, Aude",
      "Solomon, Justin M.",
      "Filippov, Alexander",
      "Burnaev, Evgeny"
    ]
  },
  {
    "id": "7a6bda9ad6ffdac035c752743b7e9d0e",
    "title": "Linear Convergence in Federated Learning: Tackling Client Heterogeneity and Sparse Gradients",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7a6bda9ad6ffdac035c752743b7e9d0e-Paper.pdf",
    "abstract": "We consider a standard federated learning (FL) setup where a group of clients periodically coordinate with a central server to train a statistical model. We develop a general algorithmic framework called FedLin to tackle some of the key challenges intrinsic to FL, namely objective heterogeneity, systems heterogeneity, and infrequent and imprecise communication. Our framework is motivated by the observation that under these challenges, various existing FL algorithms suffer from a fundamental speed-accuracy conflict: they either guarantee linear convergence but to an incorrect point, or convergence to the global minimum but at a sub-linear rate, i.e., fast convergence comes at the expense of accuracy. In contrast, when the clients' local loss functions are smooth and strongly convex, we show that FedLin guarantees linear convergence to the global minimum, despite arbitrary objective and systems heterogeneity. We then establish matching upper and lower bounds on the convergence rate of FedLin that highlight the effects of infrequent, periodic communication. Finally, we show that FedLin preserves linear convergence rates under aggressive gradient sparsification, and quantify the effect of the compression level on the convergence rate. Notably, our work is the first to provide tight linear convergence rate guarantees, and constitutes the first comprehensive analysis of gradient sparsification in FL.  ",
    "authors": [
      "Mitra, Aritra",
      "Jaafar, Rayana",
      "Pappas, George J.",
      "Hassani, Hamed"
    ]
  },
  {
    "id": "7aaece81f2d731fbf8ee0ad3521002ac",
    "title": "On the Convergence of Prior-Guided Zeroth-Order Optimization Algorithms",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7aaece81f2d731fbf8ee0ad3521002ac-Paper.pdf",
    "abstract": "Zeroth-order (ZO) optimization is widely used to handle challenging tasks, such as query-based black-box adversarial attacks and reinforcement learning. Various attempts have been made to integrate prior information into the gradient estimation procedure based on finite differences, with promising empirical results. However, their convergence properties are not well understood. This paper makes an attempt to fill up this gap by analyzing the convergence of prior-guided ZO algorithms under a greedy descent framework with various gradient estimators. We provide a convergence guarantee for the prior-guided random gradient-free (PRGF) algorithms. Moreover, to further accelerate over greedy descent methods, we present a new accelerated random search (ARS) algorithm that incorporates prior information, together with a convergence analysis. Finally, our theoretical results are confirmed by experiments on several numerical benchmarks as well as adversarial attacks.",
    "authors": [
      "Cheng, Shuyu",
      "Wu, Guoqiang",
      "Zhu, Jun"
    ]
  },
  {
    "id": "7b3403f79b478699224bb449509694cf",
    "title": "Revisit Multimodal Meta-Learning through the Lens of Multi-Task Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7b3403f79b478699224bb449509694cf-Paper.pdf",
    "abstract": "Multimodal meta-learning is a recent problem that extends conventional few-shot meta-learning by generalizing its setup to diverse multimodal task distributions. This setup makes a step towards mimicking how humans make use of a diverse set of prior skills to learn new skills. Previous work has achieved encouraging performance. In particular, in spite of the diversity of the multimodal tasks, previous work claims that a single meta-learner trained on a multimodal distribution can sometimes outperform multiple specialized meta-learners trained on individual unimodal distributions. The improvement is attributed to knowledge transfer between different modes of task distributions. However, there is no deep investigation to verify and understand the knowledge transfer between multimodal tasks. Our work makes two contributions to multimodal meta-learning. First, we propose a method to quantify knowledge transfer between tasks of different modes at a micro-level. Our quantitative, task-level analysis is inspired by the recent transference idea from multi-task learning. Second, inspired by hard parameter sharing in multi-task learning and a new interpretation of related work, we propose a new multimodal meta-learner that outperforms existing work by considerable margins. While the major focus is on multimodal meta-learning, our work also attempts to shed light on task interaction in conventional meta-learning. The code for this project is available at https://miladabd.github.io/KML.",
    "authors": [
      "Abdollahzadeh, Milad",
      "Malekzadeh, Touba",
      "Cheung, Ngai-Man (Man)"
    ]
  },
  {
    "id": "7b5b23f4aadf9513306bcd59afb6e4c9",
    "title": "Dynamic Sasvi: Strong Safe Screening for Norm-Regularized Least Squares",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7b5b23f4aadf9513306bcd59afb6e4c9-Paper.pdf",
    "abstract": "A recently introduced technique, called safe screening,'' for a sparse optimization problem allows us to identify irrelevant variables in the early stages of optimization. In this paper, we first propose a flexible framework for safe screening based on the Fenchel--Rockafellar duality and then derive a strong safe screening rule for norm-regularized least squares using the proposed framework. We refer to the proposed screening rule for norm-regularized least squares asdynamic Sasvi'' because it can be interpreted as a generalization of Sasvi. Unlike the original Sasvi, it does not require the exact solution of a more strongly regularized problem; hence, it works safely in practice. We show that our screening rule always eliminates more features compared with the existing state-of-the-art methods.",
    "authors": [
      "Yamada, Hiroaki",
      "Yamada, Makoto"
    ]
  },
  {
    "id": "7b647a7d88f4d6319bf0d600d168dbeb",
    "title": "What Matters for Adversarial Imitation Learning?",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7b647a7d88f4d6319bf0d600d168dbeb-Paper.pdf",
    "abstract": "Adversarial imitation learning has become a popular framework for imitation in continuous control. Over the years, several variations of its components were proposed to enhance the performance of the learned policies as well as the sample complexity of the algorithm. In practice, these choices are rarely tested all together in rigorous empirical studies.It is therefore difficult to discuss and understand what choices, among the high-level algorithmic options as well as  low-level implementation details, matter. To tackle this issue, we implement more than 50 of these choices in a generic adversarial imitation learning frameworkand investigate their impacts in a large-scale study (>500k trained agents) with both synthetic and human-generated demonstrations. We analyze the key results and highlight the most surprising findings.",
    "authors": [
      "Orsini, Manu",
      "Raichuk, Anton",
      "Hussenot, Leonard",
      "Vincent, Damien",
      "Dadashi, Robert",
      "Girgin, Sertan",
      "Geist, Matthieu",
      "Bachem, Olivier",
      "Pietquin, Olivier",
      "Andrychowicz, Marcin"
    ]
  },
  {
    "id": "7b670d553471ad0fd7491c75bad587ff",
    "title": "Sequential Causal Imitation Learning with Unobserved Confounders",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7b670d553471ad0fd7491c75bad587ff-Paper.pdf",
    "abstract": "\"Monkey see monkey do\" is an age-old adage, referring to naive imitation without a deep understanding of a system's underlying mechanics. Indeed, if a demonstrator has access to information unavailable to the imitator (monkey), such as a different set of sensors, then no matter how perfectly the imitator models its perceived environment (See), attempting to directly reproduce the demonstrator's behavior (Do) can lead to poor outcomes. Imitation learning in the presence of a mismatch between demonstrator and imitator has been studied in the literature under the rubric of causal imitation learning  (Zhang et. al. 2020), but existing solutions are limited to single-stage decision-making. This paper investigates the problem of causal imitation learning in sequential settings, where the imitator must make multiple decisions per episode. We develop a graphical criterion that is both necessary and sufficient for determining the feasibility of causal imitation, providing conditions when an imitator can match a demonstrator's performance despite differing capabilities. Finally, we provide an efficient algorithm for determining imitability, and corroborate our theory with simulations.",
    "authors": [
      "Kumor, Daniel",
      "Zhang, Junzhe",
      "Bareinboim, Elias"
    ]
  },
  {
    "id": "7b6982e584636e6a1cda934f1410299c",
    "title": "Topic Modeling Revisited: A Document Graph-based Neural Network Perspective",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7b6982e584636e6a1cda934f1410299c-Paper.pdf",
    "abstract": "Most topic modeling approaches are based on the bag-of-words assumption, where each word is required to be conditionally independent in the same document. As a result, both of the generative story and the topic formulation have totally ignored the semantic dependency among words, which is important for improving the semantic comprehension and model interpretability. To this end, in this paper, we revisit the task of topic modeling by transforming each document into a directed graph with word dependency as edges between word nodes, and develop a novel approach, namely Graph Neural Topic Model (GNTM). Specifically, in GNTM, a well-defined probabilistic generative story is designed to model both the graph structure and word sets with multinomial distributions on the vocabulary and word dependency edge set as the topics. Meanwhile, a Neural Variational Inference (NVI) approach is proposed to learn our model with graph neural networks to encode the document graphs. Besides, we theoretically demonstrate that Latent Dirichlet Allocation (LDA) can be derived from GNTM as a special case with similar objective functions. Finally, extensive experiments on four benchmark datasets have clearly demonstrated the effectiveness and interpretability of GNTM compared with state-of-the-art baselines.",
    "authors": [
      "Shen, Dazhong",
      "Qin, Chuan",
      "Wang, Chao",
      "Dong, Zheng",
      "Zhu, Hengshu",
      "Xiong, Hui"
    ]
  },
  {
    "id": "7b7916dd2de56297aa29cccb2bbf48d4",
    "title": "Hard-Attention for Scalable Image Classification",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7b7916dd2de56297aa29cccb2bbf48d4-Paper.pdf",
    "abstract": "Can we leverage high-resolution information without the unsustainable quadratic complexity to input scale? We propose Traversal Network (TNet), a novel multi-scale hard-attention architecture, which traverses image scale-space in a top-down fashion, visiting only the most informative image regions along the way. TNet offers an adjustable trade-off between accuracy and complexity, by changing the number of attended image locations. We compare our model against hard-attention baselines on ImageNet, achieving higher accuracy with less resources (FLOPs, processing time and memory). We further test our model on fMoW dataset, where we process satellite images of size up to $896 \\times 896$ px, getting up to $2.5$x faster processing compared to baselines operating on the same resolution, while achieving higher accuracy as well. TNet is modular, meaning that most classification models could be adopted as its backbone for feature extraction, making the reported performance gains orthogonal to benefits offered by existing optimized deep models. Finally, hard-attention guarantees a degree of interpretability to our model's predictions, without any extra cost beyond inference.",
    "authors": [
      "Papadopoulos, Athanasios",
      "Korus, Pawel",
      "Memon, Nasir"
    ]
  },
  {
    "id": "7b86f36d139d8581d4b5a4f155ba431c",
    "title": "Fast Routing under Uncertainty: Adaptive Learning in Congestion Games via Exponential Weights",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7b86f36d139d8581d4b5a4f155ba431c-Paper.pdf",
    "abstract": "We examine an adaptive learning framework for nonatomic congestion games where the players' cost functions may be subject to exogenous fluctuations (e.g., due to disturbances in the network, variations in the traffic going through a link). In this setting, the popular multiplicative/ exponential weights algorithm enjoys an $\\mathcal{O}(1/\\sqrt{T})$ equilibrium convergence rate; however, this rate is suboptimal in static environments---i.e., when the network is not subject to randomness. In this static regime, accelerated algorithms achieve an $\\mathcal{O}(1/T^{2})$ convergence speed, but they fail to converge altogether in stochastic problems. To fill this gap, we propose a novel,  adaptive exponential weights method---dubbed AdaWeight---that seamlessly interpolates between the $\\mathcal{O}(1/T^{2})$  and $\\mathcal{O}(1/\\sqrt{T})$ rates in the static and stochastic regimes respectively. Importantly, this \"best-of-both-worlds\" guarantee does not require any prior knowledge of the problem's parameters or tuning by the optimizer; in addition, the method's convergence speed depends subquadratically on the size of the network (number of vertices and edges), so it scales gracefully to large, real-life urban networks.",
    "authors": [
      "Vu, Dong Quan",
      "Antonakopoulos, Kimon",
      "Mertikopoulos, Panayotis"
    ]
  },
  {
    "id": "7bb16972da003e87724f048d76b7e0e1",
    "title": "Profiling Pareto Front With Multi-Objective Stein Variational  Gradient Descent",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7bb16972da003e87724f048d76b7e0e1-Paper.pdf",
    "abstract": "Finding diverse and representative Pareto solutions from the Pareto front is a key challenge in multi-objective optimization (MOO). In this work, we propose a novel gradient-based algorithm for profiling Pareto front by using Stein variational gradient descent (SVGD). We also provide a counterpart of our method based on Langevin dynamics. Our methods iteratively update a set of points in a parallel fashion to push them towards the Pareto front using multiple gradient descent, while encouraging the diversity between the particles by using the repulsive force mechanism in SVGD, or diffusion noise in Langevin dynamics. Compared with existing gradient-based methods that require predefined preference functions, our method can work efficiently in high dimensional problems, and can obtain more diverse solutions evenly distributed in the Pareto front. Moreover, our methods are theoretically guaranteed to converge to the Pareto front. We demonstrate the effectiveness of our method, especially the SVGD algorithm, through extensive experiments, showing its superiority over existing gradient-based algorithms.",
    "authors": [
      "Liu, Xingchao",
      "Tong, Xin",
      "Liu, Qiang"
    ]
  },
  {
    "id": "7c05147f3029c97ce26c0cb0b2469fca",
    "title": "MAP Propagation Algorithm: Faster Learning with a Team of Reinforcement Learning Agents",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7c05147f3029c97ce26c0cb0b2469fca-Paper.pdf",
    "abstract": "Nearly all state-of-the-art deep learning algorithms rely on error backpropagation, which is generally regarded as biologically implausible. An alternative way of training an artificial neural network is through treating each unit in the network as a reinforcement learning agent, and thus the network is considered as a team of agents. As such, all units can be trained by REINFORCE, a local learning rule modulated by a global signal that is more consistent with biologically observed forms of synaptic plasticity. Although this learning rule follows the gradient of return in expectation, it suffers from high variance and thus the low speed of learning, rendering it impractical to train deep networks. We therefore propose a novel algorithm called MAP propagation to reduce this variance significantly while retaining the local property of the learning rule. Experiments demonstrated that MAP propagation could solve common reinforcement learning tasks at a similar speed to backpropagation when applied to an actor-critic network. Our work thus allows for the broader application of teams of agents in deep reinforcement learning. ",
    "authors": [
      "Chung, Stephen"
    ]
  },
  {
    "id": "7c220a2091c26a7f5e9f1cfb099511e3",
    "title": "TransGAN: Two Pure Transformers Can Make One Strong GAN, and That Can Scale Up",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7c220a2091c26a7f5e9f1cfb099511e3-Paper.pdf",
    "abstract": "The recent explosive interest on transformers has suggested their potential to become powerful ``universal\" models for computer vision tasks, such as classification, detection, and segmentation. While those attempts mainly study the discriminative models, we explore transformers on some more notoriously difficult vision tasks, e.g., generative adversarial networks (GANs).  Our goal is to conduct the first pilot study in building a GAN \\textit{completely free of convolutions}, using only pure transformer-based architectures. Our vanilla GAN architecture, dubbed \\textbf{TransGAN}, consists of a memory-friendly transformer-based generator that progressively increases feature resolution, and correspondingly a multi-scale discriminator to capture simultaneously semantic contexts and low-level textures. On top of them, we introduce the new module of grid self-attention for alleviating the memory bottleneck further, in order to scale up TransGAN to high-resolution generation. We also develop a unique training recipe including a series of techniques that can mitigate the training instability issues of TransGAN, such as data augmentation, modified normalization, and relative position encoding. Our best architecture achieves highly competitive performance compared to current state-of-the-art GANs using convolutional backbones. Specifically, TransGAN sets \\textbf{new state-of-the-art} inception score of 10.43 and FID of 18.28 on STL-10. It also reaches the inception score of 9.02 and FID of 9.26  on CIFAR-10, and 5.28 FID on CelebA $\\mathbf{128} \\times \\mathbf{128}$, respectively: both on par with the current best results and outperforming StyleGAN-V2. When it comes to higher-resolution (e.g. $\\mathbf{256} \\times \\mathbf{256}$) generation tasks, such as on CelebA-HQ and LSUN-Church, TransGAN continues to produce diverse visual examples with high fidelity and impressive texture details. In addition, we dive deep into the transformer-based generation models to understand how their behaviors differ from convolutional ones, by visualizing training dynamics. The code is available at: https://github.com/VITA-Group/TransGAN.",
    "authors": [
      "Jiang, Yifan",
      "Chang, Shiyu",
      "Wang, Zhangyang"
    ]
  },
  {
    "id": "7c2c48a32443ad8f805e48520f3b26a4",
    "title": "A Central Limit Theorem for Differentially Private Query Answering",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7c2c48a32443ad8f805e48520f3b26a4-Paper.pdf",
    "abstract": "Perhaps the single most important use case for differential privacy is to privately answer numerical queries, which is usually achieved by adding noise to the answer vector. The central question is, therefore, to understand which noise distribution optimizes the privacy-accuracy trade-off, especially when the dimension of the answer vector is high. Accordingly, an extensive literature has been dedicated to the question and the upper and lower bounds have been successfully matched up to constant factors (Bun et al.,2018; Steinke & Ullman, 2017). In this paper, we take a novel approach to address this important optimality question. We first demonstrate an intriguing central limit theorem phenomenon in the high-dimensional regime. More precisely, we prove that a mechanism is approximately Gaussian Differentially Private (Dong et al., 2021) if the added noise satisfies certain conditions. In particular, densities proportional to $\\mathrm{e}^{-\\|x\\|_p^\\alpha}$, where $\\|x\\|_p$ is the standard $\\ell_p$-norm, satisfies the conditions. Taking this perspective, we make use of the Cramer--Rao inequality and show an \"uncertainty principle\"-style result: the product of privacy parameter and the $\\ell_2$-loss of the mechanism is lower bounded by the dimension. Furthermore, the Gaussian mechanism achieves the constant-sharp optimal privacy-accuracy trade-off among all such noises. Our findings are corroborated by numerical experiments.",
    "authors": [
      "Dong, Jinshuo",
      "Su, Weijie",
      "Zhang, Linjun"
    ]
  },
  {
    "id": "7c6c1a7bfde175bed616b39247ccace1",
    "title": "Differential Privacy Dynamics of Langevin Diffusion and Noisy Gradient Descent",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7c6c1a7bfde175bed616b39247ccace1-Paper.pdf",
    "abstract": "What is the information leakage of an iterative randomized learning algorithm about its training data, when the internal state of the algorithm is \\emph{private}? How much is the contribution of each specific training epoch to the information leakage through the released model? We study this problem for noisy gradient descent algorithms, and model the \\emph{dynamics} of R\\'enyi differential privacy loss throughout the training process.  Our analysis traces a provably \\emph{tight} bound on the R\\'enyi divergence between the pair of probability distributions over parameters of models trained on neighboring datasets.  We prove that the privacy loss converges exponentially fast, for smooth and strongly convex loss functions, which is a significant improvement over composition theorems (which over-estimate the privacy loss by upper-bounding its total value over all intermediate gradient computations). For Lipschitz, smooth, and strongly convex loss functions, we prove optimal utility with a small gradient complexity for noisy gradient descent algorithms.",
    "authors": [
      "Chourasia, Rishav",
      "Ye, Jiayuan",
      "Shokri, Reza"
    ]
  },
  {
    "id": "7c93ebe873ef213123c8af4b188e7558",
    "title": "Data driven semi-supervised learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7c93ebe873ef213123c8af4b188e7558-Paper.pdf",
    "abstract": "We consider a novel data driven approach for designing semi-supervised learning algorithms that can effectively learn with only a small number of labeled examples. We focus on graph-based techniques, where the unlabeled examples are connected in a graph  under the implicit assumption that similar nodes likely have similar labels. Over the past two decades, several elegant graph-based semi-supervised learning algorithms for inferring the labels of the unlabeled examples given the graph and a few labeled examples have been proposed. However, the problem of how to create the graph (which impacts the practical usefulness of these methods significantly) has been relegated to heuristics and domain-specific art, and no general principles have been proposed. In this work we present a  novel data driven approach for learning the graph and provide strong formal guarantees in both the distributional and online learning formalizations. We show how to leverage problem instances coming from an underlying problem domain to learn the graph hyperparameters for commonly used parametric families of graphs that provably perform well on new instances from the same domain. We obtain low regret and efficient algorithms in the online setting, and generalization guarantees in the distributional setting. We also show how to combine several very different similarity metrics and learn multiple  hyperparameters, our results hold for large classes of problems. We expect some of the tools and techniques we develop along the way to be of independent interest, for data driven algorithms more generally.",
    "authors": [
      "Balcan, Maria-Florina F.",
      "Sharma, Dravyansh"
    ]
  },
  {
    "id": "7c9e9afa5a9dc68ccaf27d9effeb9383",
    "title": "Online Meta-Learning via Learning with Layer-Distributed Memory",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7c9e9afa5a9dc68ccaf27d9effeb9383-Paper.pdf",
    "abstract": "We demonstrate that efficient meta-learning can be achieved via end-to-end training of deep neural networks with memory distributed across layers.  The persistent state of this memory assumes the entire burden of guiding task adaptation.  Moreover, its distributed nature is instrumental in orchestrating adaptation.  Ablation experiments demonstrate that providing relevant feedback to memory units distributed across the depth of the network enables them to guide adaptation throughout the entire network.  Our results show that this is a successful strategy for simplifying meta-learning -- often cast as a bi-level optimization problem -- to standard end-to-end training, while outperforming gradient-based, prototype-based, and other memory-based meta-learning strategies.  Additionally, our adaptation strategy naturally handles online learning scenarios with a significant delay between observing a sample and its corresponding label -- a setting in which other approaches struggle.  Adaptation via distributed memory is effective across a wide range of learning tasks, ranging from classification to online few-shot semantic segmentation.",
    "authors": [
      "Babu, Sudarshan",
      "Savarese, Pedro",
      "Maire, Michael"
    ]
  },
  {
    "id": "7ca57a9f85a19a6e4b9a248c1daca185",
    "title": "Physics-Integrated Variational Autoencoders for Robust and Interpretable Generative Modeling",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7ca57a9f85a19a6e4b9a248c1daca185-Paper.pdf",
    "abstract": "Integrating physics models within machine learning models holds considerable promise toward learning robust models with improved interpretability and abilities to extrapolate. In this work, we focus on the integration of incomplete physics models into deep generative models. In particular, we introduce an architecture of variational autoencoders (VAEs) in which a part of the latent space is grounded by physics. A key technical challenge is to strike a balance between the incomplete physics and trainable components such as neural networks for ensuring that the physics part is used in a meaningful manner. To this end, we propose a regularized learning method that controls the effect of the trainable components and preserves the semantics of the physics-based latent variables as intended. We not only demonstrate generative performance improvements over a set of synthetic and real-world datasets, but we also show that we learn robust models that can consistently extrapolate beyond the training distribution in a meaningful manner. Moreover, we show that we can control the generative process in an interpretable manner.",
    "authors": [
      "Takeishi, Naoya",
      "Kalousis, Alexandros"
    ]
  },
  {
    "id": "7caf5e22ea3eb8175ab518429c8589a4",
    "title": "Characterizing the risk of fairwashing",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7caf5e22ea3eb8175ab518429c8589a4-Paper.pdf",
    "abstract": "Fairwashing refers to the risk that an unfair black-box model can be explained by a fairer model through post-hoc explanation manipulation. In this paper, we investigate the capability of fairwashing attacks by analyzing their fidelity-unfairness trade-offs. In particular, we show that fairwashed explanation models can generalize beyond the suing group (i.e., data points that are being explained), meaning that a fairwashed explainer can be used to rationalize subsequent unfair decisions of a black-box model. We also demonstrate that fairwashing attacks can transfer across black-box models, meaning that other black-box models can perform fairwashing without explicitly using their predictions. This generalization and transferability of fairwashing attacks imply that their detection will be difficult in practice. Finally, we propose an approach to quantify the risk of fairwashing, which is based on the computation of the range of the unfairness of high-fidelity explainers.",
    "authors": [
      "A\u00efvodji, Ulrich",
      "Arai, Hiromi",
      "Gambs, S\u00e9bastien",
      "Hara, Satoshi"
    ]
  },
  {
    "id": "7cc234202e98d2722580858573fd0817",
    "title": "Qimera: Data-free Quantization with Synthetic Boundary Supporting Samples",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7cc234202e98d2722580858573fd0817-Paper.pdf",
    "abstract": "Model quantization is known as a promising method to compress deep neural networks, especially for inferences on lightweight mobile or edge devices. However, model quantization usually requires access to the original training data to maintain the accuracy of the full-precision models, which is often infeasible in real-world scenarios for security and privacy issues.A popular approach to perform quantization without access to the original data is to use synthetically generated samples, based on batch-normalization statistics or adversarial learning.However, the drawback of such approaches is that they primarily rely on random noise input to the generator to attain diversity of the synthetic samples. We find that this is often insufficient to capture the distribution of the original data, especially around the decision boundaries.To this end, we propose Qimera, a method that uses superposed latent embeddings to generate synthetic boundary supporting samples.For the superposed embeddings to better reflect the original distribution, we also propose using an additional disentanglement mapping layer and extracting information from the full-precision model.The experimental results show that Qimera achieves state-of-the-art performances for various settings on data-free quantization. Code is available at https://github.com/iamkanghyunchoi/qimera.",
    "authors": [
      "Choi, Kanghyun",
      "Hong, Deokki",
      "Park, Noseong",
      "Kim, Youngsok",
      "Lee, Jinho"
    ]
  },
  {
    "id": "7cc532d783a7461f227a5da8ea80bfe1",
    "title": "Embedding Principle of Loss Landscape of Deep Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7cc532d783a7461f227a5da8ea80bfe1-Paper.pdf",
    "abstract": "Understanding the structure of loss landscape of deep neural networks (DNNs) is obviously important. In this work, we prove an embedding principle that the loss landscape of a DNN \"contains\" all the critical points of all the narrower DNNs. More precisely, we propose a critical embedding such that any critical point, e.g., local or global minima, of a narrower DNN can be embedded to a critical point/affine subspace of the target DNN with higher degeneracy and preserving the DNN output function. Note that, given any training data, differentiable loss function and differentiable activation function, this embedding structure of critical points holds.This general structure of DNNs is starkly different from other nonconvex problems such as protein-folding.Empirically, we find that a wide DNN is often attracted by highly-degenerate critical points that are embedded from narrow DNNs. The embedding principle provides a new perspective to study the general easy optimization of wide DNNs and unravels a potential implicit low-complexity regularization during the training.Overall, our work provides a skeleton for the study of loss landscape of DNNs and its implication, by which a more exact and comprehensive understanding can be anticipated in the near future. ",
    "authors": [
      "Zhang, Yaoyu",
      "Zhang, Zhongwang",
      "Luo, Tao",
      "Xu, Zhiqin J"
    ]
  },
  {
    "id": "7ce3284b743aefde80ffd9aec500e085",
    "title": "Adversarial Reweighting for Partial Domain Adaptation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7ce3284b743aefde80ffd9aec500e085-Paper.pdf",
    "abstract": "Partial domain adaptation (PDA) has gained much attention due to its practical setting. The current PDA methods usually adapt the feature extractor by aligning the target and reweighted source domain distributions. In this paper, we experimentally find that the feature adaptation by the reweighted distribution alignment in some state-of-the-art PDA methods is not robust to the ``noisy'' weights of source domain data, leading to negative domain transfer on some challenging benchmarks. To tackle the challenge of negative domain transfer, we propose a novel Adversarial Reweighting (AR) approach that adversarially learns the weights of source domain data to align the source and target domain distributions, and the transferable deep recognition network is learned on the reweighted source domain data. Based on this idea, we propose a training algorithm that alternately updates the parameters of the network and optimizes the weights of source domain data. Extensive experiments show that our method achieves state-of-the-art results on the benchmarks of ImageNet-Caltech, Office-Home, VisDA-2017, and DomainNet. Ablation studies also confirm the effectiveness of our approach.",
    "authors": [
      "Gu, Xiang",
      "Yu, Xi",
      "yang, yan",
      "Sun, Jian",
      "Xu, Zongben"
    ]
  },
  {
    "id": "7cfd5df443b4eb0d69886a583b33de4c",
    "title": "M-FAC: Efficient Matrix-Free Approximations of Second-Order Information",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7cfd5df443b4eb0d69886a583b33de4c-Paper.pdf",
    "abstract": "Efficiently approximating local curvature information of the loss function is a useful tool for the optimization and compression of deep neural networks. Yet, most existing methods to approximate second-order information have high computational or storage costs, limiting their practicality. In this work, we investigate matrix-free approaches for estimating Inverse-Hessian Vector Products (IHVPs) for the case when the Hessian can be approximated as a sum of rank-one matrices, as in the classic approximation of the Hessian by the empirical Fisher matrix. The first algorithm we propose is tailored towards network compression and can compute the IHVP for dimension $d$ given a fixed set of $m$ rank-one matrices using $O(dm^2)$ precomputation, $O(dm)$ cost for computing the IHVP and query cost $O(m)$ for computing any single element of the inverse Hessian approximation. The second algorithm targets an optimization setting, where we wish to compute the product between the inverse Hessian, estimated over a sliding  window of optimization steps, and a given gradient direction. We give an algorithm with cost $O(dm + m^2)$ for computing the IHVP and $O(dm + m^3)$ for adding or removing any gradient from the sliding window. We show that both algorithms yield competitive results for network pruning and optimization, respectively, with significantly lower computational overhead relative to existing second-order methods. ",
    "authors": [
      "Frantar, Elias",
      "Kurtic, Eldar",
      "Alistarh, Dan"
    ]
  },
  {
    "id": "7d3010c11d08cf990b7614d2c2ca9098",
    "title": "Graph Adversarial Self-Supervised Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7d3010c11d08cf990b7614d2c2ca9098-Paper.pdf",
    "abstract": "This paper studies a long-standing problem of learning the representations of a whole graph without human supervision. The recent self-supervised learning methods train models to be invariant to the transformations (views) of the inputs. However, designing these views requires the experience of human experts. Inspired by adversarial training, we propose an adversarial self-supervised learning (\\texttt{GASSL}) framework for learning unsupervised representations of graph data without any handcrafted views. \\texttt{GASSL} automatically generates challenging views by adding perturbations to the input and are adversarially trained with respect to the encoder. Our method optimizes the min-max problem and utilizes a gradient accumulation strategy to accelerate the training process. Experimental on ten graph classification datasets show that the proposed approach is superior to state-of-the-art self-supervised learning baselines, which are competitive with supervised models.",
    "authors": [
      "Yang, Longqi",
      "Zhang, Liangliang",
      "Yang, Wenjing"
    ]
  },
  {
    "id": "7d38b1e9bd793d3f45e0e212a729a93c",
    "title": "Anti-Backdoor Learning: Training Clean Models on Poisoned Data",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7d38b1e9bd793d3f45e0e212a729a93c-Paper.pdf",
    "abstract": "Backdoor attack has emerged as a major security threat to deep neural networks (DNNs). While existing defense methods have demonstrated promising results on detecting or erasing backdoors, it is still not clear whether robust training methods can be devised to prevent the backdoor triggers being injected into the trained model in the first place. In this paper, we introduce the concept of \\emph{anti-backdoor learning}, aiming to train \\emph{clean} models given backdoor-poisoned data. We frame the overall learning process as a dual-task of learning the \\emph{clean} and the \\emph{backdoor} portions of data. From this view, we identify two inherent characteristics of backdoor attacks as their weaknesses: 1) the models learn backdoored data much faster than learning with clean data, and the stronger the attack the faster the model converges on backdoored data; 2) the backdoor task is tied to a specific class (the backdoor target class). Based on these two weaknesses, we propose a general learning scheme, Anti-Backdoor Learning (ABL), to automatically prevent backdoor attacks during training. ABL introduces a two-stage \\emph{gradient ascent} mechanism for standard training to 1) help isolate backdoor examples at an early training stage, and 2) break the correlation between backdoor examples and the target class at a later training stage. Through extensive experiments on multiple benchmark datasets against 10 state-of-the-art attacks, we empirically show that ABL-trained models on backdoor-poisoned data achieve the same performance as they were trained on purely clean data. Code is available at \\url{https://github.com/bboylyg/ABL}.",
    "authors": [
      "Li, Yige",
      "Lyu, Xixiang",
      "Koren, Nodens",
      "Lyu, Lingjuan",
      "Li, Bo",
      "Ma, Xingjun"
    ]
  },
  {
    "id": "7d3e28d14440d6c07f73b7557e3d9602",
    "title": "Locally Most Powerful Bayesian Test for Out-of-Distribution Detection using Deep Generative Models",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7d3e28d14440d6c07f73b7557e3d9602-Paper.pdf",
    "abstract": "Several out-of-distribution (OOD) detection scores have been recently proposed for deep generative models because the direct use of the likelihood threshold for OOD detection has been shown to be problematic. In this paper, we propose a new OOD score based on a Bayesian hypothesis test called the locally most powerful Bayesian test (LMPBT). The LMPBT is locally most powerful in that the alternative hypothesis (the representative parameter for the OOD sample) is specified to maximize the probability that the Bayes factor exceeds the evidence threshold in favor of the alternative hypothesis provided that the parameter specified under the alternative hypothesis is in the neighborhood of the parameter specified under the null hypothesis. That is, under this neighborhood parameter condition, the test with the proposed alternative hypothesis maximizes the probability of correct detection of OOD samples. We also propose numerical strategies for more efficient and reliable computation of the LMPBT for practical application to deep generative models. Evaluations conducted of the OOD detection performance of the LMPBT on various benchmark datasets demonstrate its superior performance over existing OOD detection methods.",
    "authors": [
      "Kim, Keunseo",
      "Shin, JunCheol",
      "Kim, Heeyoung"
    ]
  },
  {
    "id": "7d5430cf85f78c4b7aa09813b14bce0d",
    "title": "Stable Neural ODE with Lyapunov-Stable Equilibrium Points for Defending Against Adversarial Attacks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7d5430cf85f78c4b7aa09813b14bce0d-Paper.pdf",
    "abstract": "Deep neural networks (DNNs) are well-known to be vulnerable to adversarial attacks, where malicious human-imperceptible perturbations are included in the input to the deep network to fool it into making a wrong classification. Recent studies have demonstrated that neural Ordinary Differential Equations (ODEs) are intrinsically more robust against adversarial attacks compared to vanilla DNNs. In this work, we propose a neural ODE with Lyapunov-stable equilibrium points for defending against adversarial attacks (SODEF). By ensuring that the equilibrium points of the ODE solution used as part of SODEF are Lyapunov-stable, the ODE solution for an input with a small perturbation converges to the same solution as the unperturbed input. We provide theoretical results that give insights into the stability of SODEF as well as the choice of regularizers to ensure its stability. Our analysis suggests that our proposed regularizers force the extracted feature points to be within a neighborhood of the Lyapunov-stable equilibrium points of the SODEF ODE. SODEF is compatible with many defense methods and can be applied to any neural network's final regressor layer to enhance its stability against adversarial attacks. ",
    "authors": [
      "Kang, Qiyu",
      "Song, Yang",
      "Ding, Qinxu",
      "Tay, Wee Peng"
    ]
  },
  {
    "id": "7d6044e95a16761171b130dcb476a43e",
    "title": "Robust Compressed Sensing MRI with Deep Generative Priors",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7d6044e95a16761171b130dcb476a43e-Paper.pdf",
    "abstract": "The CSGM framework (Bora-Jalal-Price-Dimakis'17) has shown that deepgenerative priors can be powerful tools for solving inverse problems.However, to date this framework has been empirically successful only oncertain datasets (for example, human faces and MNIST digits), and itis known to perform poorly on out-of-distribution samples. In thispaper, we present the first successful application of the CSGMframework on clinical MRI data. We train a generative prior on brainscans from the fastMRI dataset, and show that posterior sampling viaLangevin dynamics achieves high quality reconstructions. Furthermore,our experiments and theory show that posterior sampling is robust tochanges in the ground-truth distribution and measurement process.Our code and models are available at: \\url{https://github.com/utcsilab/csgm-mri-langevin}.",
    "authors": [
      "Jalal, Ajil",
      "Arvinte, Marius",
      "Daras, Giannis",
      "Price, Eric",
      "Dimakis, Alexandros G.",
      "Tamir, Jon"
    ]
  },
  {
    "id": "7d62a275027741d98073d42b8f735c68",
    "title": "H-NeRF: Neural Radiance Fields for Rendering and Temporal Reconstruction of Humans in Motion",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7d62a275027741d98073d42b8f735c68-Paper.pdf",
    "abstract": "We present neural radiance fields for rendering and temporal (4D) reconstruction of humans in motion (H-NeRF), as captured by a sparse set of cameras or even from a monocular video. Our approach combines ideas from neural scene representation, novel-view synthesis, and implicit statistical geometric human representations, coupled using novel loss functions. Instead of learning a radiance field with a uniform occupancy prior, we constrain it by a structured implicit human body model, represented using signed distance functions. This allows us to robustly fuse information from sparse views and generalize well beyond the poses or views observed in training. Moreover, we apply geometric constraints to co-learn the structure of the observed subject -- including both body and clothing -- and to regularize the radiance field to geometrically plausible solutions. Extensive experiments on multiple datasets demonstrate the robustness and the accuracy of our approach, its generalization capabilities significantly outside a small training set of poses and views, and statistical extrapolation beyond the observed shape.",
    "authors": [
      "Xu, Hongyi",
      "Alldieck, Thiemo",
      "Sminchisescu, Cristian"
    ]
  },
  {
    "id": "7d6548bdc0082aacc950ed35e91fcccb",
    "title": "DOBF: A Deobfuscation Pre-Training Objective for Programming Languages",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7d6548bdc0082aacc950ed35e91fcccb-Paper.pdf",
    "abstract": "Recent advances in self-supervised learning have dramatically improved the state of the art on a wide variety of tasks. However, research in language model pre-training has mostly focused on natural languages, and it is unclear whether models like BERT and its variants provide the best pre-training when applied to other modalities, such as source code. In this paper, we introduce a new pre-training objective, DOBF, that leverages the structural aspect of programming languages and pre-trains a model to recover the original version of obfuscated source code. We show that models pre-trained with DOBF significantly outperform existing approaches on multiple downstream tasks, providing relative improvements of up to 12.2% in unsupervised code translation, and 5.3% in natural language code search. Incidentally, we found that our pre-trained model is able to deobfuscate fully obfuscated source files, and to suggest descriptive variable names.",
    "authors": [
      "Lachaux, Marie-Anne",
      "Roziere, Baptiste",
      "Szafraniec, Marc",
      "Lample, Guillaume"
    ]
  },
  {
    "id": "7dd3ed2e12d7967b656d156d50308263",
    "title": "Detecting Errors and Estimating Accuracy on Unlabeled Data with Self-training  Ensembles",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7dd3ed2e12d7967b656d156d50308263-Paper.pdf",
    "abstract": "When a deep learning model is deployed in the wild, it can encounter test data drawn from distributions different from the training data distribution and suffer drop in performance. For safe deployment, it is essential to estimate the accuracy of the pre-trained model on the test data. However, the labels for the test inputs are usually not immediately available in practice, and obtaining them can be expensive. This observation leads to two challenging tasks: (1) unsupervised accuracy estimation, which aims to estimate the accuracy of a pre-trained classifier on a set of unlabeled test inputs; (2) error detection, which aims to identify mis-classified test inputs. In this paper, we propose a principled and practically effective framework that simultaneously addresses the two tasks. The proposed framework iteratively learns an ensemble of models to identify mis-classified data points and performs self-training to improve the ensemble with the identified points. Theoretical analysis demonstrates that our framework enjoys provable guarantees for both accuracy estimation and error detection under mild conditions readily satisfied by practical deep learning models. Along with the framework, we proposed and experimented with two instantiations and achieved state-of-the-art results on 59 tasks. For example, on iWildCam, one instantiation reduces the estimation error for unsupervised accuracy estimation by at least 70% and improves the F1 score for error detection by at least 4.7% compared to existing methods.  ",
    "authors": [
      "Chen, Jiefeng",
      "Liu, Frederick",
      "Avci, Besim",
      "Wu, Xi",
      "Liang, Yingyu",
      "Jha, Somesh"
    ]
  },
  {
    "id": "7e0ff37942c2de60cbcbd27041196ce3",
    "title": "Exploiting Chain Rule and Bayes' Theorem to Compare Probability Distributions",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7e0ff37942c2de60cbcbd27041196ce3-Paper.pdf",
    "abstract": "To measure the difference between two probability distributions, referred to as the source and target, respectively, we exploit both the chain rule and Bayes' theorem to construct conditional transport (CT), which is constituted by both a forward component and a backward one. The forward CT is the expected cost of moving a source data point to a target one, with their joint distribution defined by the product of the source probability density function (PDF) and a source-dependent conditional distribution, which is related to the target PDF via Bayes' theorem. The backward CT is defined by reversing the direction. The CT cost can be approximated by replacing the source and target PDFs with their discrete empirical distributions supported on mini-batches, making it amenable to implicit distributions and stochastic gradient descent-based optimization. When applied to train a generative model, CT is shown to strike a good balance between mode-covering and mode-seeking behaviors and strongly resist mode collapse. On a wide variety of benchmark datasets for generative modeling, substituting the default statistical distance of an existing generative adversarial network with CT is shown to consistently improve the performance. PyTorch code is provided.",
    "authors": [
      "Zheng, Huangjie",
      "Zhou, Mingyuan"
    ]
  },
  {
    "id": "7e7e69ea3384874304911625ac34321c",
    "title": "Actively Identifying Causal Effects with Latent Variables Given Only Response Variable Observable",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7e7e69ea3384874304911625ac34321c-Paper.pdf",
    "abstract": "In many real tasks, it is generally desired to study the causal effect on a specific target (response variable) only, with no need to identify the thorough causal effects involving all variables. In this paper, we attempt to identify such effects by a few active interventions where only the response variable is observable. This task is challenging because the causal graph is unknown and even there may exist latent confounders. To learn the necessary structure for identifying the effects, we provide the graphical characterization that allows us to efficiently estimate all possible causal effects in a partially mixed ancestral graph (PMAG) by generalized back-door criterion. The characterization guides learning a local structure with the interventional data. Theoretical analysis and empirical studies validate the effectiveness and efficiency of our proposed approach.",
    "authors": [
      "Wang, Tian-Zuo",
      "Zhou, Zhi-Hua"
    ]
  },
  {
    "id": "7eb7eabbe9bd03c2fc99881d04da9cbd",
    "title": "Interventional Sum-Product Networks: Causal Inference with Tractable Probabilistic Models",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7eb7eabbe9bd03c2fc99881d04da9cbd-Paper.pdf",
    "abstract": "While probabilistic models are an important tool for studying causality, doing so suffers from the intractability of inference. As a step towards tractable causal models, we consider the problem of learning interventional distributions using sum-product networks (SPNs) that are over-parameterized by gate functions, e.g., neural networks. Providing an arbitrarily intervened causal graph as input, effectively subsuming Pearl's do-operator, the gate function predicts the parameters of the SPN. The resulting interventional SPNs are motivated and illustrated by a structural causal model themed around personal health. Our empirical evaluation against competing methods from both generative and causal modelling demonstrates that interventional SPNs indeed are both expressive and causally adequate.",
    "authors": [
      "Ze\u010devi\u0107, Matej",
      "Dhami, Devendra",
      "Karanam, Athresh",
      "Natarajan, Sriraam",
      "Kersting, Kristian"
    ]
  },
  {
    "id": "7ed2d3454c5eea71148b11d0c25104ff",
    "title": "PettingZoo: Gym for Multi-Agent Reinforcement Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7ed2d3454c5eea71148b11d0c25104ff-Paper.pdf",
    "abstract": "This paper introduces the PettingZoo library and the accompanying Agent Environment Cycle (\"AEC\") games model. PettingZoo is a library of diverse sets of multi-agent environments with a universal, elegant Python API. PettingZoo was developed with the goal of accelerating research in Multi-Agent Reinforcement Learning (\"MARL\"), by making work more interchangeable, accessible and reproducible akin to what OpenAI's Gym library did for single-agent reinforcement learning. PettingZoo's API, while inheriting many features of Gym, is unique amongst MARL APIs in that it's based around the novel AEC games model. We argue, in part through case studies on major problems in popular MARL environments, that the popular game models are poor conceptual models of the games commonly used with MARL, that they promote severe bugs that are hard to detect, and that the AEC games model addresses these problems.",
    "authors": [
      "Terry, J",
      "Black, Benjamin",
      "Grammel, Nathaniel",
      "Jayakumar, Mario ",
      "Hari, Ananth ",
      "Sullivan, Ryan",
      "Santos, Luis S",
      "Dieffendahl, Clemens",
      "Horsch, Caroline",
      "Perez-Vicente, Rodrigo",
      "Williams, Niall ",
      "Lokesh, Yashas ",
      "Ravi , Praveen "
    ]
  },
  {
    "id": "7edccc661418aeb5761dbcdc06ad490c",
    "title": "Parametric Complexity Bounds for Approximating PDEs with Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7edccc661418aeb5761dbcdc06ad490c-Paper.pdf",
    "abstract": "Recent experiments have shown that deep networks can approximate solutions to high-dimensional PDEs, seemingly escaping the curse of dimensionality. However, questions regarding the theoretical basis for such approximations, including the required network size remain open. In this paper, we investigate the representational power of neural networks for approximating solutions to linear elliptic PDEs with Dirichlet boundary conditions. We prove that when a PDE's coefficients are representable by small neural networks, the parameters required to approximate its solution scale polynomially with the input dimension $d$ and proportionally to the parameter counts of the coefficient networks. To this end, we develop a proof technique that simulates gradient descent (in an appropriate Hilbert space) by growing a neural network architecture whose iterates each participate as sub-networks in their (slightly larger) successors, and converge to the solution of the PDE.",
    "authors": [
      "Marwah, Tanya",
      "Lipton, Zachary",
      "Risteski, Andrej"
    ]
  },
  {
    "id": "7ee6f2b3b68a212d3b7a4f6557eb8cc7",
    "title": "Learning-to-learn non-convex piecewise-Lipschitz functions",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7ee6f2b3b68a212d3b7a4f6557eb8cc7-Paper.pdf",
    "abstract": "We analyze the meta-learning of the initialization and step-size of learning algorithms for piecewise-Lipschitz functions, a non-convex setting with applications to both machine learning and algorithms. Starting from recent regret bounds for the exponential forecaster on losses with dispersed discontinuities, we generalize them to be initialization-dependent and then use this result to propose a practical meta-learning procedure that learns both the initialization and the step-size of the algorithm from multiple online learning tasks. Asymptotically, we guarantee that the average regret across tasks scales with a natural notion of task-similarity that measures the amount of overlap between near-optimal regions of different tasks. Finally, we instantiate the method and its guarantee in two important settings: robust meta-learning and multi-task data-driven algorithm design.",
    "authors": [
      "Balcan, Maria-Florina F.",
      "Khodak, Mikhail",
      "Sharma, Dravyansh",
      "Talwalkar, Ameet"
    ]
  },
  {
    "id": "7f141cf8e7136ce8701dc6636c2a6fe4",
    "title": "Uncertain Decisions Facilitate Better Preference Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7f141cf8e7136ce8701dc6636c2a6fe4-Paper.pdf",
    "abstract": "Existing observational approaches for learning human preferences, such as inverse reinforcement learning, usually make strong assumptions about the observability of the human's environment. However, in reality, people make many important decisions under uncertainty. To better understand preference learning in these cases, we study the setting of inverse decision theory (IDT), a previously proposed framework where a human is observed making non-sequential binary decisions under uncertainty. In IDT, the human's preferences are conveyed through their loss function, which expresses a tradeoff between different types of mistakes. We give the first statistical analysis of IDT, providing conditions necessary to identify these preferences and characterizing the sample complexity\u2014the number of decisions that must be observed to learn the tradeoff the human is making to a desired precision. Interestingly, we show that it is actually easier to identify preferences when the decision problem is more uncertain. Furthermore, uncertain decision problems allow us to relax the unrealistic assumption that the human is an optimal decision maker but still identify their exact preferences; we give sample complexities in this suboptimal case as well. Our analysis contradicts the intuition that partial observability should make preference learning more difficult. It also provides a first step towards understanding and improving preference learning methods for uncertain and suboptimal humans.",
    "authors": [
      "Laidlaw, Cassidy",
      "Russell, Stuart"
    ]
  },
  {
    "id": "7f489f642a0ddb10272b5c31057f0663",
    "title": "Decision Transformer: Reinforcement Learning via Sequence Modeling",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7f489f642a0ddb10272b5c31057f0663-Paper.pdf",
    "abstract": "We introduce a framework that abstracts Reinforcement Learning (RL) as a sequence modeling problem. This allows us to draw upon the simplicity and scalability of the Transformer architecture, and associated advances in language modeling such as GPT-x and BERT. In particular, we present Decision Transformer, an architecture that casts the problem of RL as conditional sequence modeling. Unlike prior approaches to RL that fit value functions or compute policy gradients, Decision Transformer simply outputs the optimal actions by leveraging a causally masked Transformer. By conditioning an autoregressive model on the desired return (reward), past states, and actions, our Decision Transformer model can generate future actions that achieve the desired return. Despite its simplicity, Decision Transformer matches or exceeds the performance of state-of-the-art model-free offline RL baselines on Atari, OpenAI Gym, and Key-to-Door tasks.",
    "authors": [
      "Chen, Lili",
      "Lu, Kevin",
      "Rajeswaran, Aravind",
      "Lee, Kimin",
      "Grover, Aditya",
      "Laskin, Misha",
      "Abbeel, Pieter",
      "Srinivas, Aravind",
      "Mordatch, Igor"
    ]
  },
  {
    "id": "7f53f8c6c730af6aeb52e66eb74d8507",
    "title": "Probability Paths and the Structure of Predictions over Time",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7f53f8c6c730af6aeb52e66eb74d8507-Paper.pdf",
    "abstract": "In settings ranging from weather forecasts to political prognostications to financial projections, probability estimates of future binary outcomes often evolve over time. For example, the estimated likelihood of rain on a specific day changes by the hour as new information becomes available. Given a collection of such probability paths, we introduce a Bayesian framework -- which we call the Gaussian latent information martingale, or GLIM -- for modeling the structure of dynamic predictions over time. Suppose, for example, that the likelihood of rain in a week is 50%, and consider two hypothetical scenarios. In the first, one expects the forecast to be equally likely to become either 25% or 75% tomorrow; in the second, one expects the forecast to stay constant for the next several days. A time-sensitive decision-maker might select a course of action immediately in the latter scenario, but may postpone their decision in the former, knowing that new information is imminent. We model these trajectories by assuming predictions update according to a latent process of information flow, which is inferred from historical data. In contrast to general methods for time series analysis, this approach preserves important properties of probability paths such as the martingale structure and appropriate amount of volatility and better quantifies future uncertainties around probability paths. We show that GLIM outperforms three popular baseline methods, producing better estimated posterior probability path distributions measured by three different metrics. By elucidating the dynamic structure of predictions over time, we hope to help individuals make more informed choices.",
    "authors": [
      "Lin, Zhiyuan Jerry",
      "Sheng, Hao",
      "Goel, Sharad"
    ]
  },
  {
    "id": "7f6caf1f0ba788cd7953d817724c2b6e",
    "title": "Deep Extended Hazard Models for Survival Analysis",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7f6caf1f0ba788cd7953d817724c2b6e-Paper.pdf",
    "abstract": "Unlike standard prediction tasks, survival analysis requires modeling right censored data, which must be treated with care. While deep neural networks excel in traditional supervised learning, it remains unclear how to best utilize these models in survival analysis. A key question asks which data-generating assumptions of traditional survival models should be retained and which should be made more flexible via the function-approximating capabilities of neural networks. Rather than estimating the survival function targeted by most existing methods, we introduce a Deep Extended Hazard (DeepEH) model to provide a flexible and general framework for deep survival analysis. The extended hazard model includes the conventional Cox proportional hazards  and accelerated failure time models as special cases, so DeepEH subsumes the popular Deep Cox proportional hazard (DeepSurv) and Deep Accelerated Failure Time (DeepAFT) models. We additionally provide theoretical support for the proposed DeepEH model by establishing consistency and convergence rate of the survival function estimator, which underscore the attractive feature that deep learning is able to detect low-dimensional structure of data in high-dimensional space. Numerical experiments also provide evidence that the proposed methods outperform existing statistical and deep learning approaches to survival analysis.",
    "authors": [
      "Zhong, Qixian",
      "Mueller, Jonas W.",
      "Wang, Jane-Ling"
    ]
  },
  {
    "id": "7fa1575cbd7027c9a799983a485c3c2f",
    "title": "TNASP: A Transformer-based NAS Predictor with a Self-evolution Framework",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7fa1575cbd7027c9a799983a485c3c2f-Paper.pdf",
    "abstract": "Predictor-based Neural Architecture Search (NAS) continues to be an important topic because it aims to mitigate the time-consuming search procedure of traditional NAS methods. A promising performance predictor determines the quality of final searched models in predictor-based NAS methods. Most existing predictor-based methodologies train model-based predictors under a proxy dataset setting, which may suffer from the accuracy decline and the generalization problem, mainly due to their poor abilities to represent spatial topology information of the graph structure data. Besides the poor encoding for spatial topology information, these works did not take advantage of the temporal information such as historical evaluations during training. Thus, we propose a Transformer-based NAS performance predictor, associated with a Laplacian matrix based positional encoding strategy, which better represents topology information and achieves better performance than previous state-of-the-art methods on NAS-Bench-101, NAS-Bench-201, and DARTS search space. Furthermore, we also propose a self-evolution framework that can fully utilize temporal information as guidance. This framework iteratively involves the evaluations of previously predicted results as constraints into current optimization iteration, thus further improving the performance of our predictor. Such framework is model-agnostic, thus can enhance performance on various backbone structures for the prediction task. Our proposed method helped us rank 2nd among all teams in CVPR 2021 NAS Competition Track 2: Performance Prediction Track.",
    "authors": [
      "Lu, Shun",
      "Li, Jixiang",
      "Tan, Jianchao",
      "Yang, Sen",
      "Liu, Ji"
    ]
  },
  {
    "id": "7ffb4e0ece07869880d51662a2234143",
    "title": "Automorphic Equivalence-aware Graph Neural Network",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/7ffb4e0ece07869880d51662a2234143-Paper.pdf",
    "abstract": "Distinguishing the automorphic equivalence of nodes in a graph plays an essential role in many scientific domains, e.g., computational biologist and social network analysis. However, existing graph neural networks (GNNs) fail to capture such an important property. To make GNN aware of automorphic equivalence, we first introduce a localized variant of this concept --- ego-centered automorphic equivalence (Ego-AE). Then, we design a novel variant of GNN, i.e., GRAPE, that uses learnable AE-aware aggregators to explicitly differentiate the Ego-AE of each node's neighbors with the aids of various subgraph templates. While the design of subgraph templates can be hard, we further propose a genetic algorithm to automatically search them from graph data. Moreover, we theoretically prove that GRAPE is expressive in terms of generating distinct representations for nodes with different Ego-AE features, which fills in a fundamental gap of existing GNN variants. Finally, we empirically validate our model on eight real-world graph data, including social network, e-commerce co-purchase network, and citation network, and show that it consistently outperforms existing GNNs. The source code is public available at https://github.com/tsinghua-fib-lab/GRAPE.",
    "authors": [
      "Xu, Fengli",
      "Yao, Quanming",
      "Hui, Pan",
      "Li, Yong"
    ]
  },
  {
    "id": "803ef56843860e4a48fc4cdb3065e8ce",
    "title": "Random Shuffling Beats SGD Only After Many Epochs on Ill-Conditioned Problems",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/803ef56843860e4a48fc4cdb3065e8ce-Paper.pdf",
    "abstract": "Recently, there has been much interest in studying the convergence rates of without-replacement SGD, and proving that it is faster than with-replacement SGD in the worst case. However, known lower bounds ignore the problem's geometry, including its condition number, whereas the upper bounds explicitly depend on it. Perhaps surprisingly, we prove that when the condition number is taken into account, without-replacement SGD \\emph{does not} significantly improve on with-replacement SGD in terms of worst-case bounds, unless the number of epochs (passes over the data) is larger than the condition number. Since many problems in machine learning and other areas are both ill-conditioned and involve large datasets, this indicates that without-replacement does not necessarily improve over with-replacement sampling for realistic iteration budgets. We show this by providing new lower and upper bounds which are tight (up to log factors), for quadratic problems with commuting quadratic terms, precisely quantifying the dependence on the problem parameters.",
    "authors": [
      "Safran, Itay",
      "Shamir, Ohad"
    ]
  },
  {
    "id": "806d926414ce19d907700e23177ab4ff",
    "title": "Analytic Study of Families of Spurious Minima in Two-Layer ReLU Neural Networks: A Tale of Symmetry II",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/806d926414ce19d907700e23177ab4ff-Paper.pdf",
    "abstract": "We study the optimization problem associated with fitting two-layer ReLU neural networks with respect to the squared loss, where labels are generated by a target network. We make use of the rich symmetry structure to develop a novel set of tools for studying families of spurious minima. In contrast to existing approaches which operate in limiting regimes, our technique directly addresses the nonconvex loss landscape for finite number of inputs $d$ and neurons $k$, and provides analytic, rather than heuristic, information. In particular, we derive analytic estimates for the loss at different minima, and prove that, modulo $O(d^{-1/2})$-terms, the Hessian spectrum concentrates near small positive constants, with the exception of $\\Theta(d)$ eigenvalues which grow linearly with~$d$. We further show that the Hessian spectrum at global and spurious minima coincide to $O(d^{-1/2})$-order, thus challenging our ability to argue about statistical generalization through local curvature. Lastly, our technique provides the exact \\emph{fractional} dimensionality at which families of critical points turn from saddles into spurious minima. This makes possible the study of the creation and the annihilation of spurious minima using powerful tools from equivariant bifurcation theory. ",
    "authors": [
      "Arjevani, Yossi",
      "Field, Michael"
    ]
  },
  {
    "id": "8073bd4ed0fe0c330290c58056a2cd5e",
    "title": "CAM-GAN: Continual Adaptation Modules for Generative Adversarial Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8073bd4ed0fe0c330290c58056a2cd5e-Paper.pdf",
    "abstract": "We present a continual learning approach for generative adversarial networks (GANs), by designing and leveraging parameter-efficient feature map transformations. Our approach is based on learning a set of global and task-specific parameters. The global parameters are fixed across tasks whereas the task-specific parameters act as local adapters for each task, and help in efficiently obtaining task-specific feature maps. Moreover, we propose an element-wise addition of residual bias in the transformed feature space, which further helps stabilize GAN training in such settings. Our approach also leverages task similarities based on the Fisher information matrix. Leveraging this knowledge from previous tasks significantly improves the model performance. In addition, the similarity measure also helps reduce the parameter growth in continual adaptation and helps to learn a compact model. In contrast to the recent approaches for continually-learned GANs, the proposed approach provides a memory-efficient way to perform effective continual data generation. Through extensive experiments on challenging and diverse datasets, we show that the feature-map-transformation approach outperforms state-of-the-art methods for continually-learned GANs, with substantially fewer parameters. The proposed method generates high-quality samples that can also improve the generative-replay-based continual learning for discriminative tasks.",
    "authors": [
      "Varshney, Sakshi",
      "Verma, Vinay Kumar",
      "Srijith, P. K.",
      "Carin, Lawrence",
      "Rai, Piyush"
    ]
  },
  {
    "id": "80a160ff31266be2f93012a2a3eca713",
    "title": "Structured Dropout Variational Inference for Bayesian Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/80a160ff31266be2f93012a2a3eca713-Paper.pdf",
    "abstract": "Approximate inference in Bayesian deep networks exhibits a dilemma of how to yield high fidelity posterior approximations while maintaining computational efficiency and scalability. We tackle this challenge by introducing a novel variational structured approximation inspired by the Bayesian interpretation of Dropout regularization. Concretely, we focus on the inflexibility of the factorized structure in Dropout posterior and then propose an improved method called Variational Structured Dropout (VSD). VSD employs an orthogonal transformation to learn a structured representation on the variational Gaussian noise with plausible complexity, and consequently induces statistical dependencies in the approximate posterior. Theoretically, VSD successfully addresses the pathologies of previous Variational Dropout methods and thus offers a standard Bayesian justification. We further show that VSD induces an adaptive regularization term with several desirable properties which contribute to better generalization. Finally, we conduct extensive experiments on standard benchmarks to demonstrate the effectiveness of VSD over state-of-the-art variational methods on predictive accuracy, uncertainty estimation, and out-of-distribution detection.",
    "authors": [
      "Nguyen, Son",
      "Nguyen, Duong",
      "Nguyen, Khai",
      "Than, Khoat",
      "Bui, Hung",
      "Ho, Nhat"
    ]
  },
  {
    "id": "80f24ef493982c552b6943f1411f7e2c",
    "title": "Neural Relightable Participating Media Rendering",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/80f24ef493982c552b6943f1411f7e2c-Paper.pdf",
    "abstract": "Learning neural radiance fields of a scene has recently allowed realistic novel view synthesis of the scene, but they are limited to synthesize images under the original fixed lighting condition. Therefore, they are not flexible for the eagerly desired tasks like relighting, scene editing and scene composition. To tackle this problem, several recent methods propose to disentangle reflectance and illumination from the radiance field. These methods can cope with solid objects with opaque surfaces but participating media are neglected. Also, they take into account only direct illumination or at most one-bounce indirect illumination, thus suffer from energy loss due to ignoring the high-order indirect illumination. We propose to learn neural representations for participating media with a complete simulation of global illumination. We estimate direct illumination via ray tracing and compute indirect illumination with spherical harmonics. Our approach avoids computing the lengthy indirect bounces and does not suffer from energy loss. Our experiments on multiple scenes show that our approach achieves superior visual quality and numerical performance compared to state-of-the-art methods, and it can generalize to deal with solid objects with opaque surfaces as well.",
    "authors": [
      "Zheng, Quan",
      "Singh, Gurprit",
      "Seidel, Hans-peter"
    ]
  },
  {
    "id": "80f2f15983422987ea30d77bb531be86",
    "title": "Efficient Neural Network Training via Forward and Backward Propagation Sparsification",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/80f2f15983422987ea30d77bb531be86-Paper.pdf",
    "abstract": "Sparse training is a natural idea to accelerate the training speed of deep neural networks and save the memory usage, especially since large modern neural networks are significantly over-parameterized.  However, most of the existing methods cannot achieve this goal in practice because the chain rule based gradient (w.r.t. structure parameters) estimators adopted by previous methods require dense computation at least in the backward propagation step.  This paper solves this problem by proposing an efficient sparse training method with completely sparse forward and backward passes. We first formulate the training process as a continuous minimization problem under global sparsity constraint. We then separate the optimization process into two steps, corresponding to weight update and structure parameter update. For the former step, we use the conventional chain rule, which can be sparse via exploiting the sparse structure.  For the latter step, instead of using the chain rule based gradient estimators as in existing methods, we propose a variance reduced policy gradient estimator, which only requires two forward passes without backward propagation, thus achieving completely sparse training. We prove that the variance of our gradient estimator is bounded. Extensive experimental results on real-world datasets demonstrate that compared to previous methods, our algorithm is much more effective in accelerating the training process, up to an order of magnitude faster. ",
    "authors": [
      "Zhou, Xiao",
      "Zhang, Weizhong",
      "Chen, Zonghao",
      "DIAO, SHIZHE",
      "Zhang, Tong"
    ]
  },
  {
    "id": "80fee67c8a4c4989bf8a580b4bbb0cd2",
    "title": "Learning to Ground Multi-Agent Communication with Autoencoders",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/80fee67c8a4c4989bf8a580b4bbb0cd2-Paper.pdf",
    "abstract": "Communication requires having a common language, a lingua franca, between agents. This language could emerge via a consensus process, but it may require many generations of trial and error. Alternatively, the lingua franca can be given by the environment, where agents ground their language in representations of the observed world. We demonstrate a simple way to ground language in learned representations, which facilitates decentralized multi-agent communication and coordination. We find that a standard representation learning algorithm -- autoencoding -- is sufficient for arriving at a grounded common language. When agents broadcast these representations, they learn to understand and respond to each other's utterances and achieve surprisingly strong task performance across a variety of multi-agent communication environments.",
    "authors": [
      "Lin, Toru",
      "Huh, Jacob",
      "Stauffer, Christopher",
      "Lim, Ser Nam",
      "Isola, Phillip"
    ]
  },
  {
    "id": "810dfbbebb17302018ae903e9cb7a483",
    "title": "Large-Scale Wasserstein Gradient Flows",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/810dfbbebb17302018ae903e9cb7a483-Paper.pdf",
    "abstract": "Wasserstein gradient flows provide a powerful means of understanding and solving many diffusion equations. Specifically, Fokker-Planck equations, which model the diffusion of probability measures, can be understood as gradient descent over entropy functionals in Wasserstein space. This equivalence, introduced by Jordan, Kinderlehrer and Otto, inspired the so-called JKO scheme to approximate these diffusion processes via an implicit discretization of the gradient flow in Wasserstein space. Solving the optimization problem associated with each JKO step, however, presents serious computational challenges. We introduce a scalable method to approximate Wasserstein gradient flows, targeted to machine learning applications. Our approach relies on input-convex neural networks (ICNNs) to discretize the JKO steps, which can be optimized by stochastic gradient descent. Contrarily to previous work, our method does not require domain discretization or particle simulation.  As a result, we can sample from the measure at each time step of the diffusion and compute its probability density. We demonstrate the performance of our algorithm by computing diffusions following the Fokker-Planck equation and apply it to unnormalized density sampling as well as nonlinear filtering. ",
    "authors": [
      "Mokrov, Petr",
      "Korotin, Alexander",
      "Li, Lingxiao",
      "Genevay, Aude",
      "Solomon, Justin M.",
      "Burnaev, Evgeny"
    ]
  },
  {
    "id": "812214fb8e7066bfa6e32c626c2c688b",
    "title": "Who Leads and Who Follows in Strategic Classification?",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/812214fb8e7066bfa6e32c626c2c688b-Paper.pdf",
    "abstract": "As predictive models are deployed into the real world, they must increasingly contend with strategic behavior. A growing body of work on strategic classification treats this problem as a Stackelberg game: the decision-maker \"leads\" in the game by deploying a model, and the strategic agents \"follow\" by playing their best response to the deployed model. Importantly, in this framing, the burden of learning is placed solely on the decision-maker, while the agents\u2019 best responses are implicitly treated as instantaneous. In this work, we argue that the order of play in strategic classification is fundamentally determined by the relative frequencies at which the decision-maker and the agents adapt to each other\u2019s actions. In particular, by generalizing the standard model to allow both players to learn over time, we show that a decision-maker that makes updates faster than the agents can reverse the order of play, meaning that the agents lead and the decision-maker follows. We observe in standard learning settings that such a role reversal can be desirable for both the decision-maker and the strategic agents. Finally, we show that a decision-maker with the freedom to choose their update frequency can induce learning dynamics that converge to Stackelberg equilibria with either order of play.",
    "authors": [
      "Zrnic, Tijana",
      "Mazumdar, Eric",
      "Sastry, Shankar",
      "Jordan, Michael"
    ]
  },
  {
    "id": "816a6db41f0e44644bc65808b6db5ca4",
    "title": "Unadversarial Examples: Designing Objects for Robust Vision",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/816a6db41f0e44644bc65808b6db5ca4-Paper.pdf",
    "abstract": "We study a class of computer vision settings wherein one can modify the design of the objects being recognized. We develop a framework that leverages this capability---and deep networks' unusual sensitivity to input perturbations---to design ``robust objects,'' i.e., objects that are explicitly optimized to be confidently classified. Our framework yields improved performance on standard benchmarks, a simulated robotics environment, and physical-world experiments. ",
    "authors": [
      "Salman, Hadi",
      "Ilyas, Andrew",
      "Engstrom, Logan",
      "Vemprala, Sai",
      "Madry, Aleksander",
      "Kapoor, Ashish"
    ]
  },
  {
    "id": "816b112c6105b3ebd537828a39af4818",
    "title": "Deep Jump Learning for Off-Policy Evaluation in Continuous Treatment Settings",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/816b112c6105b3ebd537828a39af4818-Paper.pdf",
    "abstract": "We consider off-policy evaluation (OPE) in continuous treatment settings, such as personalized dose-finding. In OPE, one aims to estimate the mean outcome under a new treatment decision rule using historical data generated by a different decision rule. Most existing works on OPE focus on discrete treatment settings. To handle continuous treatments, we develop a novel estimation method for OPE using deep jump learning. The key ingredient of our method lies in adaptively discretizing the treatment space using deep discretization, by leveraging deep learning and multi-scale change point detection. This allows us to apply existing OPE methods in discrete treatments to handle continuous treatments. Our method is further justified by theoretical results, simulations, and a real application to Warfarin Dosing.",
    "authors": [
      "Cai, Hengrui",
      "Shi, Chengchun",
      "Song, Rui",
      "Lu, Wenbin"
    ]
  },
  {
    "id": "8171ac2c5544a5cb54ac0f38bf477af4",
    "title": "Attention Approximates Sparse Distributed Memory",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8171ac2c5544a5cb54ac0f38bf477af4-Paper.pdf",
    "abstract": "While Attention has come to be an important mechanism in deep learning, there remains limited intuition for why it works so well. Here, we show that Transformer Attention can be closely related under certain data conditions to Kanerva's Sparse Distributed Memory (SDM), a biologically plausible associative memory model. We confirm that these conditions are satisfied in pre-trained GPT2 Transformer models. We discuss the implications of the Attention-SDM map and provide new computational and biological interpretations of Attention.",
    "authors": [
      "Bricken, Trenton",
      "Pehlevan, Cengiz"
    ]
  },
  {
    "id": "818f4654ed39a1c147d1e51a00ffb4cb",
    "title": "Augmented Shortcuts for Vision Transformers",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/818f4654ed39a1c147d1e51a00ffb4cb-Paper.pdf",
    "abstract": "Transformer models have achieved great progress on computer vision tasks recently. The rapid development of vision transformers is mainly contributed by their high representation ability for extracting informative features from input images. However, the mainstream transformer models are designed with deep architectures, and the feature diversity will be continuously reduced as the depth increases, \\ie, feature collapse. In this paper, we theoretically analyze the feature collapse phenomenon and study the relationship between shortcuts and feature diversity in these transformer models. Then, we present an augmented shortcut scheme, which inserts additional paths with learnable parameters in parallel on the original shortcuts. To save the computational costs, we further explore an efficient approach that uses the block-circulant projection to implement augmented shortcuts. Extensive experiments conducted on benchmark datasets demonstrate the effectiveness of the proposed method, which brings about 1% accuracy increase of the state-of-the-art visual transformers without obviously increasing their parameters and FLOPs.",
    "authors": [
      "Tang, Yehui",
      "Han, Kai",
      "Xu, Chang",
      "Xiao, An",
      "Deng, Yiping",
      "Xu, Chao",
      "Wang, Yunhe"
    ]
  },
  {
    "id": "81930c54e08b6d26d9638dd2e4656dc1",
    "title": "Finding Regions of Heterogeneity in Decision-Making via Expected Conditional Covariance",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/81930c54e08b6d26d9638dd2e4656dc1-Paper.pdf",
    "abstract": "Individuals often make different decisions when faced with the same context, due to personal preferences and background.  For instance, judges may vary in their leniency towards certain drug-related offenses, and doctors may vary in their preference for how to start treatment for certain types of patients.  With these examples in mind, we present an algorithm for identifying types of contexts (e.g., types of cases or patients) with high inter-decision-maker disagreement.  We formalize this as a causal inference problem, seeking a region where the assignment of decision-maker has a large causal effect on the decision.  Our algorithm finds such a region by maximizing an empirical objective, and we give a generalization bound for its performance. In a semi-synthetic experiment, we show that our algorithm recovers the correct region of heterogeneity accurately compared to baselines. Finally, we apply our algorithm to real-world healthcare datasets, recovering variation that aligns with existing clinical knowledge.",
    "authors": [
      "Lim, Justin",
      "Ji, Christina X",
      "Oberst, Michael",
      "Blecker, Saul",
      "Horwitz, Leora",
      "Sontag, David"
    ]
  },
  {
    "id": "81c2f886f91e18fe16d6f4e865877cb6",
    "title": "Identifying and Benchmarking Natural Out-of-Context Prediction Problems",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/81c2f886f91e18fe16d6f4e865877cb6-Paper.pdf",
    "abstract": "Deep learning systems frequently fail at out-of-context (OOC) prediction, the problem of making reliable predictions on uncommon or unusual inputs or subgroups of the training distribution. To this end, a number of benchmarks for measuring OOC performance have been recently introduced.  In this work, we introduce a framework unifying the literature on OOC performance measurement, and demonstrate how rich auxiliary information can be leveraged to identify candidate sets of OOC examples in existing datasets.  We present NOOCh: a suite of naturally-occurring \"challenge sets\", and show how varying notions of context can be used to probe specific OOC failure modes. Experimentally, we explore the tradeoffs between various learning approaches on these challenge sets and demonstrate how the choices made in designing OOC benchmarks can yield varying conclusions.",
    "authors": [
      "Madras, David",
      "Zemel, Richard"
    ]
  },
  {
    "id": "81c8727c62e800be708dbf37c4695dff",
    "title": "Label Disentanglement in Partition-based Extreme Multilabel Classification",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/81c8727c62e800be708dbf37c4695dff-Paper.pdf",
    "abstract": "Partition-based methods are increasingly-used in extreme multi-label classification (XMC) problems due to their scalability to large output spaces (e.g., millions or more). However, existing methods partition the large label space into mutually exclusive clusters, which is sub-optimal when labels have multi-modality and rich semantics. For instance, the label \u201cApple\u201d can be the fruit or the brand name, which leads to the following research question: can we disentangle these multi-modal labels with non-exclusive clustering tailored for downstream XMC tasks? In this paper, we show that the label assignment problem in partition-based XMC can be formulated as an optimization problem, with the objective of maximizing precision rates. This leads to an efficient algorithm to form  flexible and overlapped label clusters, and a method that can alternatively optimizes the cluster assignments and the model parameters for partition-based XMC. Experimental results on synthetic and real datasets show that our method can successfully disentangle multi-modal labels, leading to state-of-the-art (SOTA) results on four XMC benchmarks.",
    "authors": [
      "Liu, Xuanqing",
      "Chang, Wei-Cheng",
      "Yu, Hsiang-Fu",
      "Hsieh, Cho-Jui",
      "Dhillon, Inderjit"
    ]
  },
  {
    "id": "81e74d678581a3bb7a720b019f4f1a93",
    "title": "Leveraging SE(3) Equivariance for Self-supervised Category-Level Object  Pose Estimation from Point Clouds",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/81e74d678581a3bb7a720b019f4f1a93-Paper.pdf",
    "abstract": "Category-level object pose estimation aims to find 6D object poses of previously unseen object instances from known categories without access to object CAD models. To reduce the huge amount of pose annotations needed for category-level learning, we propose for the first time a self-supervised learning framework to estimate category-level 6D object pose from single 3D point clouds. During training, our method assumes no ground-truth pose annotations, no CAD models, and no multi-view supervision. The key to our method is to disentangle shape and pose through an invariant shape reconstruction module and an equivariant pose estimation module, empowered by SE(3) equivariant point cloud networks. The invariant shape reconstruction module learns to perform aligned reconstructions, yielding a category-level reference frame without using any annotations. In addition, the equivariant pose estimation module achieves category-level pose estimation accuracy that is comparable to some fully supervised methods. Extensive experiments demonstrate the effectiveness of our approach on both complete and partial depth point clouds from the ModelNet40 benchmark, and on real depth point clouds from the NOCS-REAL 275 dataset. The project page with code and visualizations can be found at: dragonlong.github.io/equi-pose.",
    "authors": [
      "Li, Xiaolong",
      "Weng, Yijia",
      "Yi, Li",
      "Guibas, Leonidas J.",
      "Abbott, A.",
      "Song, Shuran",
      "Wang, He"
    ]
  },
  {
    "id": "82039d16dce0aab3913b6a7ac73deff7",
    "title": "A Theoretical Analysis of Fine-tuning with Linear Teachers",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/82039d16dce0aab3913b6a7ac73deff7-Paper.pdf",
    "abstract": "Fine-tuning is a common practice in deep learning, achieving excellent generalization results on downstream tasks using relatively little training data. Although widely used in practice, it is not well understood theoretically. Here we analyze the sample complexity of this scheme for regression with linear teachers in several settings. Intuitively, the success of fine-tuning depends on the similarity between the source tasks and the target task. But what is the right way of measuring this similarity? We show that the relevant measure has to do with the relation between the source task, the target task and the covariance structure of the target data. In the setting of linear regression, we show that under realistic settings there can be substantial sample complexity reduction when the above measure is low. For deep linear regression, we propose a novel result regarding the inductive bias of gradient-based training when the network is initialized with pretrained weights. Using this result we show that the similarity measure for this setting is also affected by the depth of the network. We conclude with results on shallow ReLU models, and analyze the dependence of sample complexity there on source and target tasks. We empirically demonstrate our results for both synthetic and realistic data.",
    "authors": [
      "Shachaf, Gal",
      "Brutzkus, Alon",
      "Globerson, Amir"
    ]
  },
  {
    "id": "8217bb4e7fa0541e0f5e04fea764ab91",
    "title": "Overinterpretation reveals image classification model pathologies",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8217bb4e7fa0541e0f5e04fea764ab91-Paper.pdf",
    "abstract": "Image classifiers are typically scored on their test set accuracy, but high accuracy can mask a subtle type of model failure. We find that high scoring convolutional neural networks (CNNs) on popular benchmarks exhibit troubling pathologies that allow them to display high accuracy even in the absence of semantically salient features. When a model provides a high-confidence decision without salient supporting input features, we say the classifier has overinterpreted its input, finding too much class-evidence in patterns that appear nonsensical to humans. Here, we demonstrate that neural networks trained on CIFAR-10 and ImageNet suffer from overinterpretation, and we find models on CIFAR-10 make confident predictions even when 95% of input images are masked and humans cannot discern salient features in the remaining pixel-subsets. We introduce Batched Gradient SIS, a new method for discovering sufficient input subsets for complex datasets, and use this method to show the sufficiency of border pixels in ImageNet for training and testing. Although these patterns portend potential model fragility in real-world deployment, they are in fact valid statistical patterns of the benchmark that alone suffice to attain high test accuracy. Unlike adversarial examples, overinterpretation relies upon unmodified image pixels.  We find ensembling and input dropout can each help mitigate overinterpretation.",
    "authors": [
      "Carter, Brandon",
      "Jain, Siddhartha",
      "Mueller, Jonas W.",
      "Gifford, David"
    ]
  },
  {
    "id": "8230bea7d54bcdf99cdfe85cb07313d5",
    "title": "Neural Circuit Synthesis from Specification Patterns",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8230bea7d54bcdf99cdfe85cb07313d5-Paper.pdf",
    "abstract": "We train hierarchical Transformers on the task of synthesizing hardware circuits directly out of high-level logical speci\ufb01cations in linear-time temporal logic (LTL). The LTL synthesis problem is a well-known algorithmic challenge with a long history and an annual competition is organized to track the improvement of algorithms and tooling over time. New approaches using machine learning might open a lot of possibilities in this area, but suffer from the lack of suf\ufb01cient amounts of training data. In this paper, we consider a method to generate large amounts of additional training data, i.e., pairs of speci\ufb01cations and circuits implementing them. We ensure that this synthetic data is suf\ufb01ciently close to human-written speci\ufb01cations by mining common patterns from the speci\ufb01cations used in the synthesis competitions. We show that hierarchical Transformers trained on this synthetic data solve a signi\ufb01cant portion of problems from the synthesis competitions, and even out-of-distribution examples from a recent case study.",
    "authors": [
      "Schmitt, Frederik",
      "Hahn, Christopher",
      "Rabe, Markus N",
      "Finkbeiner, Bernd"
    ]
  },
  {
    "id": "82489c9737cc245530c7a6ebef3753ec",
    "title": "Directional Message Passing on Molecular Graphs via Synthetic Coordinates",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/82489c9737cc245530c7a6ebef3753ec-Paper.pdf",
    "abstract": "Graph neural networks that leverage coordinates via directional message passing have recently set the state of the art on multiple molecular property prediction tasks. However, they rely on atom position information that is often unavailable, and obtaining it is usually prohibitively expensive or even impossible. In this paper we propose synthetic coordinates that enable the use of advanced GNNs without requiring the true molecular configuration. We propose two distances as synthetic coordinates: Distance bounds that specify the rough range of molecular configurations, and graph-based distances using a symmetric variant of personalized PageRank. To leverage both distance and angular information we propose a method of transforming normal graph neural networks into directional MPNNs. We show that with this transformation we can reduce the error of a normal graph neural network by 55% on the ZINC benchmark. We furthermore set the state of the art on ZINC and coordinate-free QM9 by incorporating synthetic coordinates in the SMP and DimeNet++ models. Our implementation is available online.",
    "authors": [
      "Gasteiger, Johannes",
      "Yeshwanth, Chandan",
      "G\u00fcnnemann, Stephan"
    ]
  },
  {
    "id": "82599a4ec94aca066873c99b4c741ed8",
    "title": "Federated Multi-Task Learning under a Mixture of Distributions",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/82599a4ec94aca066873c99b4c741ed8-Paper.pdf",
    "abstract": "The increasing size of data generated by smartphones and IoT devices motivated the development of Federated Learning (FL), a framework for on-device collaborative training of machine learning models. First efforts in FL focused on learning a single global model with good average performance across clients, but the global model may be arbitrarily bad for a given client, due to the inherent heterogeneity of local data distributions. Federated multi-task learning (MTL) approaches can learn personalized models by formulating an opportune penalized optimization problem. The penalization term can capture complex relations among personalized models, but eschews clear statistical assumptions about local data distributions. In this work, we propose to study federated MTL under the flexible assumption that each local data distribution is a mixture of unknown underlying distributions. This assumption encompasses most of the existing personalized FL approaches and leads to federated EM-like algorithms for both client-server and fully decentralized settings. Moreover, it  provides a principled way to serve personalized models to clients not seen at training time. The algorithms' convergence is analyzed through a novel federated surrogate optimization framework, which can be of general interest. Experimental results on FL benchmarks show that our approach provides models with higher accuracy and fairness than state-of-the-art methods.",
    "authors": [
      "Marfoq, Othmane",
      "Neglia, Giovanni",
      "Bellet, Aur\u00e9lien",
      "Kameni, Laetitia",
      "Vidal, Richard"
    ]
  },
  {
    "id": "8289889263db4a40463e3f358bb7c7a1",
    "title": "Learning Generative Vision Transformer with Energy-Based Latent Space for Saliency Prediction",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8289889263db4a40463e3f358bb7c7a1-Paper.pdf",
    "abstract": "Vision transformer networks have shown superiority in many computer vision tasks. In this paper, we take a step further by proposing a novel generative vision transformer with latent variables following an informative energy-based prior for salient object detection. Both the vision transformer network and the energy-based prior model are jointly trained via Markov chain Monte Carlo-based maximum likelihood estimation, in which the sampling from the intractable posterior and prior distributions of the latent variables are performed by Langevin dynamics. Further, with the generative vision transformer, we can easily obtain a pixel-wise uncertainty map from an image, which indicates the model confidence in predicting saliency from the image. Different from the existing generative models which define the prior distribution of the latent variables as a simple isotropic Gaussian distribution, our model uses an energy-based informative prior which can be more expressive to capture the latent space of the data. We apply the proposed framework to both RGB and RGB-D salient object detection tasks. Extensive experimental results show that our framework can achieve not only accurate saliency predictions but also meaningful uncertainty maps that are consistent with the human perception. ",
    "authors": [
      "Zhang, Jing",
      "Xie, Jianwen",
      "Barnes, Nick",
      "Li, Ping"
    ]
  },
  {
    "id": "82ba9d6eee3f026be339bb287651c3d8",
    "title": "Regularization in ResNet with Stochastic Depth",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/82ba9d6eee3f026be339bb287651c3d8-Paper.pdf",
    "abstract": "Regularization plays a major role in modern deep learning. From classic techniques such as L1, L2 penalties to other noise-based methods such as Dropout, regularization often yields better generalization properties by avoiding overfitting. Recently, Stochastic Depth (SD) has emerged as an alternative regularization technique for residual neural networks (ResNets) and has proven to boost the performance of ResNet on many tasks [Huang et al., 2016]. Despite the recent success of SD, little is known about this technique from a theoretical perspective. This paper provides a hybrid analysis combining perturbation analysis and signal propagation to shed light on different regularization effects of SD. Our analysis allows us to derive principled guidelines for choosing the survival rates used for training with SD.",
    "authors": [
      "Hayou, Soufiane",
      "Ayed, Fadhel"
    ]
  },
  {
    "id": "82c2559140b95ccda9c6ca4a8b981f1e",
    "title": "ResT: An Efficient Transformer for Visual Recognition",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/82c2559140b95ccda9c6ca4a8b981f1e-Paper.pdf",
    "abstract": "This paper presents an efficient multi-scale vision Transformer, called ResT, that capably served as a general-purpose backbone for image recognition. Unlike existing Transformer methods, which employ standard Transformer blocks to tackle raw images with a fixed resolution, our ResT have several advantages: (1) A memory-efficient multi-head self-attention is built, which compresses the memory by a simple depth-wise convolution, and projects the interaction across the attention-heads dimension while keeping the diversity ability of multi-heads; (2) Positional encoding is constructed as spatial attention, which is more flexible and can tackle with input images of arbitrary size without interpolation or fine-tune; (3) Instead of the straightforward tokenization at the beginning of each stage, we design the patch embedding as a stack of overlapping convolution operation with stride on the token map. We comprehensively validate ResT on image classification and downstream tasks. Experimental results show that the proposed ResT can outperform the recently state-of-the-art backbones by a large margin, demonstrating the potential of ResT as strong backbones. The code and models will be made publicly available at https://github.com/wofmanaf/ResT.",
    "authors": [
      "Zhang, Qinglong",
      "Yang, Yu-Bin"
    ]
  },
  {
    "id": "82ca5dd156cc926b2992f73c2896f761",
    "title": "Adversarial Examples for k-Nearest Neighbor Classifiers Based on Higher-Order Voronoi Diagrams",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/82ca5dd156cc926b2992f73c2896f761-Paper.pdf",
    "abstract": "Adversarial examples are a widely studied phenomenon in machine learning models. While most of the attention has been focused on neural networks, other practical models also suffer from this issue. In this work, we propose an algorithm for evaluating the adversarial robustness of $k$-nearest neighbor classification, i.e., finding a minimum-norm adversarial example. Diverging from previous proposals, we propose the first geometric approach by performing a search that expands outwards from a given input point. On a high level, the search radius expands to the nearby higher-order Voronoi cells until we find a cell that classifies differently from the input point. To scale the algorithm to a large $k$, we introduce approximation steps that find perturbation with smaller norm, compared to the baselines, in a variety of datasets. Furthermore, we analyze the structural properties of a dataset where our approach outperforms the competition.",
    "authors": [
      "Sitawarin, Chawin",
      "Kornaropoulos, Evgenios",
      "Song, Dawn",
      "Wagner, David"
    ]
  },
  {
    "id": "82cadb0649a3af4968404c9f6031b233",
    "title": "Adversarially Robust 3D Point Cloud Recognition Using Self-Supervisions",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/82cadb0649a3af4968404c9f6031b233-Paper.pdf",
    "abstract": "3D point cloud data is increasingly used in safety-critical applications such as autonomous driving. Thus, the robustness of 3D deep learning models against adversarial attacks becomes a major consideration. In this paper, we systematically study the impact of various self-supervised learning proxy tasks on different architectures and threat models for 3D point clouds with adversarial training. Specifically, we study MLP-based (PointNet), convolution-based (DGCNN), and transformer-based (PCT) 3D architectures. Through extensive experimentation, we demonstrate that appropriate applications of self-supervision can significantly enhance the robustness in 3D point cloud recognition, achieving considerable improvements compared to the standard adversarial training baseline. Our analysis reveals that local feature learning is desirable for adversarial robustness in point clouds since it limits the adversarial propagation between the point-level input perturbations and the model's final output. This insight also explains the success of DGCNN and the jigsaw proxy task in achieving stronger 3D adversarial robustness.",
    "authors": [
      "Sun, Jiachen",
      "Cao, Yulong",
      "Choy, Christopher B",
      "Yu, Zhiding",
      "Anandkumar, Anima",
      "Mao, Zhuoqing Morley",
      "Xiao, Chaowei"
    ]
  },
  {
    "id": "82debd8a12b498e765a11a8e51159440",
    "title": "Tuning Mixed Input Hyperparameters on the Fly for Efficient Population Based AutoRL",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/82debd8a12b498e765a11a8e51159440-Paper.pdf",
    "abstract": "Despite a series of recent successes in reinforcement learning (RL), many RL algorithms remain sensitive to hyperparameters. As such, there has recently been interest in the field of AutoRL, which seeks to automate design decisions to create more general algorithms. Recent work suggests that population based approaches may be effective AutoRL algorithms, by learning hyperparameter schedules on the fly. In particular, the PB2 algorithm is able to achieve strong performance in RL tasks by formulating online hyperparameter optimization as time varying GP-bandit problem, while also providing theoretical guarantees. However, PB2 is only designed to work for \\emph{continuous} hyperparameters, which severely limits its utility in practice. In this paper we introduce a new (provably) efficient hierarchical approach for optimizing \\emph{both continuous and categorical} variables, using a new time-varying bandit algorithm specifically designed for the population based training regime. We evaluate our approach on the challenging Procgen benchmark, where we show that explicitly modelling dependence between data augmentation and other hyperparameters improves generalization.",
    "authors": [
      "Parker-Holder, Jack",
      "Nguyen, Vu",
      "Desai, Shaan",
      "Roberts, Stephen J"
    ]
  },
  {
    "id": "82e9e7a12665240d13d0b928be28f230",
    "title": "Neural Algorithmic Reasoners are Implicit Planners",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/82e9e7a12665240d13d0b928be28f230-Paper.pdf",
    "abstract": "Implicit planning has emerged as an elegant technique for combining learned models of the world with end-to-end model-free reinforcement learning. We study the class of implicit planners inspired by value iteration, an algorithm that is guaranteed to yield perfect policies in fully-specified tabular environments. We find that prior approaches either assume that the environment is provided in such a tabular form---which is highly restrictive---or infer \"local neighbourhoods\" of states to run value iteration over---for which we discover an algorithmic bottleneck effect. This effect is caused by explicitly running the planning algorithm based on scalar predictions in every state, which can be harmful to data efficiency if such scalars are improperly predicted. We propose eXecuted Latent Value Iteration Networks (XLVINs), which alleviate the above limitations. Our method performs all planning computations in a high-dimensional latent space, breaking the algorithmic bottleneck. It maintains alignment with value iteration by carefully leveraging neural graph-algorithmic reasoning and contrastive self-supervised learning. Across seven low-data settings---including classical control, navigation and Atari---XLVINs provide significant improvements to data efficiency against value iteration-based implicit planners, as well as relevant model-free baselines. Lastly, we empirically verify that XLVINs can closely align with value iteration.",
    "authors": [
      "Deac, Andreea-Ioana",
      "Veli\u010dkovi\u0107, Petar",
      "Milinkovic, Ognjen",
      "Bacon, Pierre-Luc",
      "Tang, Jian",
      "Nikolic, Mladen"
    ]
  },
  {
    "id": "83004190b1793d7aa15f8d0d49a13eba",
    "title": "Self-Supervised Learning with Kernel Dependence Maximization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/83004190b1793d7aa15f8d0d49a13eba-Paper.pdf",
    "abstract": "We approach self-supervised learning of image representations from a statistical dependence perspective, proposing Self-Supervised Learning with the Hilbert-Schmidt Independence Criterion (SSL-HSIC). SSL-HSIC maximizes dependence between representations of transformations of an image and the image identity, while minimizing the kernelized variance of those representations. This framework yields a new understanding of InfoNCE, a variational lower bound on the mutual information (MI) between different transformations. While the MI itself is known to have pathologies which can result in learning meaningless representations, its bound is much better behaved: we show that it implicitly approximates SSL-HSIC (with a slightly different regularizer).Our approach also gives us insight into BYOL, a negative-free SSL method, since SSL-HSIC similarly learns local neighborhoods of samples. SSL-HSIC allows us to directly optimize statistical dependence in time linear in the batch size, without restrictive data assumptions or indirect mutual information estimators. Trained with or without a target network, SSL-HSIC matches the current state-of-the-art for standard linear evaluation on ImageNet, semi-supervised learning and transfer to other classification and vision tasks such as semantic segmentation, depth estimation and object recognition. Code is available at https://github.com/deepmind/ssl_hsic.",
    "authors": [
      "Li, Yazhe",
      "Pogodin, Roman",
      "Sutherland, Danica J.",
      "Gretton, Arthur"
    ]
  },
  {
    "id": "8303a79b1e19a194f1875981be5bdb6f",
    "title": "CROCS: Clustering and Retrieval of Cardiac Signals Based on Patient Disease Class, Sex, and Age",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8303a79b1e19a194f1875981be5bdb6f-Paper.pdf",
    "abstract": "The process of manually searching for relevant instances in, and extracting information from, clinical databases underpin a multitude of clinical tasks. Such tasks include disease diagnosis, clinical trial recruitment, and continuing medical education. This manual search-and-extract process, however, has been hampered by the growth of large-scale clinical databases and the increased prevalence of unlabelled instances. To address this challenge, we propose a supervised contrastive learning framework, CROCS, where representations of cardiac signals associated with a set of patient-specific attributes (e.g., disease class, sex, age) are attracted to learnable embeddings entitled clinical prototypes. We exploit such prototypes for both the clustering and retrieval of unlabelled cardiac signals based on multiple patient attributes. We show that CROCS outperforms the state-of-the-art method, DTC, when clustering and also retrieves relevant cardiac signals from a large database. We also show that clinical prototypes adopt a semantically meaningful arrangement based on patient attributes and thus confer a high degree of interpretability.",
    "authors": [
      "Kiyasseh, Dani",
      "Zhu, Tingting",
      "Clifton, David"
    ]
  },
  {
    "id": "832353270aacb6e3322f493a66aaf5b9",
    "title": "Representing Hyperbolic Space Accurately using Multi-Component Floats",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/832353270aacb6e3322f493a66aaf5b9-Paper.pdf",
    "abstract": "Hyperbolic space is particularly useful for embedding data with hierarchical structure; however, representing hyperbolic space with ordinary floating-point numbers greatly affects the performance due to its \\emph{ineluctable} numerical errors. Simply increasing the precision of floats fails to solve the problem and incurs a high computation cost for simulating greater-than-double-precision floats on hardware such as GPUs, which does not support them. In this paper, we propose a simple, feasible-on-GPUs, and easy-to-understand solution for numerically accurate learning on hyperbolic space. We do this with a new approach to represent hyperbolic space using multi-component floating-point (MCF) in the Poincar{\\'e} upper-half space model. Theoretically and experimentally we show our model has small numerical error, and on embedding tasks across various datasets, models represented by multi-component floating-points gain more capacity and run significantly faster on GPUs than prior work. ",
    "authors": [
      "Yu, Tao",
      "De Sa, Christopher M."
    ]
  },
  {
    "id": "8346db44a721fa863ca38180638bad3d",
    "title": "Dimensionality Reduction for Wasserstein Barycenter",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8346db44a721fa863ca38180638bad3d-Paper.pdf",
    "abstract": "The Wasserstein barycenter is a geometric construct which captures the notion of centrality among probability distributions, and which has found many applications in machine learning. However, most algorithms for finding even an approximate barycenter suffer an exponential dependence on the dimension $d$ of the underlying space of the distributions. In order to cope with this ``curse of dimensionality,'' we study dimensionality reduction techniques for the Wasserstein barycenter problem. When the barycenter is restricted to support of size $n$, we show that randomized dimensionality reduction can be used to map the problem to a space of dimension $O(\\log n)$ independent of both $d$ and $k$, and that \\emph{any} solution found in the reduced dimension will have its cost preserved up to arbitrary small error in the original space. We provide matching upper and lower bounds on the size of the reduced dimension, showing that our methods are optimal up to constant factors. We also provide a coreset construction for the Wasserstein barycenter problem that significantly decreases the number of input distributions. The coresets can be used in conjunction with random projections and thus further improve computation time. Lastly, our experimental results validate the speedup provided by dimensionality reduction while maintaining solution quality.",
    "authors": [
      "Izzo, Zachary",
      "Silwal, Sandeep",
      "Zhou, Samson"
    ]
  },
  {
    "id": "8383f931b0cefcc631f070480ef340e1",
    "title": "Neural Population Geometry Reveals the Role of Stochasticity in Robust Perception",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8383f931b0cefcc631f070480ef340e1-Paper.pdf",
    "abstract": "Adversarial examples are often cited by neuroscientists and machine learning researchers as an example of how computational models diverge from biological sensory systems. Recent work has proposed adding biologically-inspired components to visual neural networks as a way to improve their adversarial robustness. One surprisingly effective component for reducing adversarial vulnerability is response stochasticity, like that exhibited by biological neurons. Here, using recently developed geometrical techniques from computational neuroscience, we investigate how adversarial perturbations influence the internal representations of standard, adversarially trained, and biologically-inspired stochastic networks. We find distinct geometric signatures for each type of network, revealing different mechanisms for achieving robust representations. Next, we generalize these results to the auditory domain, showing that neural stochasticity also makes auditory models more robust to adversarial perturbations. Geometric analysis of the stochastic networks reveals overlap between representations of clean and adversarially perturbed stimuli, and quantitatively demonstrate that competing geometric effects of stochasticity mediate a tradeoff between adversarial and clean performance. Our results shed light on the strategies of robust perception utilized by adversarially trained and stochastic networks, and help explain how stochasticity may be beneficial to machine and biological computation.",
    "authors": [
      "Dapello, Joel",
      "Feather, Jenelle",
      "Le, Hang",
      "Marques, Tiago",
      "Cox, David",
      "McDermott, Josh",
      "DiCarlo, James J",
      "Chung, Sueyeon"
    ]
  },
  {
    "id": "838aac83e00e8c5ca0f839c96d6cb3be",
    "title": "Unsupervised Learning of Compositional Energy Concepts",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/838aac83e00e8c5ca0f839c96d6cb3be-Paper.pdf",
    "abstract": "Humans are able to rapidly understand scenes by utilizing concepts extracted from prior experience. Such concepts are diverse, and include global scene descriptors, such as the weather or lighting, as well as local scene descriptors, such as the color or size of a particular object. So far, unsupervised discovery of concepts has focused on either modeling the global scene-level or the local object-level factors of variation, but not both. In this work, we propose COMET, which discovers and represents concepts as separate energy functions, enabling us to represent both global concepts as well as objects under a unified framework.  COMET discovers energy functions through recomposing the input image, which we find captures independent factors without additional supervision. Sample generation in COMET is formulated as an optimization process on underlying energy functions, enabling us to generate images with permuted and composed concepts.  Finally, discovered visual concepts in COMET generalize well, enabling us to compose concepts between separate modalities of images as well as with other concepts discovered by a separate instance of COMET trained on a different dataset. Code and data available at https://energy-based-model.github.io/comet/.",
    "authors": [
      "Du, Yilun",
      "Li, Shuang",
      "Sharma, Yash",
      "Tenenbaum, Josh",
      "Mordatch, Igor"
    ]
  },
  {
    "id": "8396b14c5dff55d13eea57487bf8ed26",
    "title": "Nearly Horizon-Free Offline Reinforcement Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8396b14c5dff55d13eea57487bf8ed26-Paper.pdf",
    "abstract": "We revisit offline reinforcement learning on episodic time-homogeneous Markov Decision Processes (MDP). For tabular MDP with $S$ states and $A$ actions, or linear MDP with anchor points and feature dimension $d$, given the collected $K$ episodes data with minimum visiting probability of (anchor) state-action pairs $d_m$, we obtain nearly horizon $H$-free sample complexity bounds for offline reinforcement learning when the total reward is upper bounded by 1. Specifically:\u2022 For offline policy evaluation, we obtain an $\\tilde{O}\\left(\\sqrt{\\frac{1}{Kd_m}} \\right)$ error bound for the plug-in estimator, which matches the lower bound up to logarithmic factors and does not have additional dependency on $\\mathrm{poly}(H, S, A, d)$ in higher-order term.\u2022 For offline policy optimization, we obtain an $\\tilde{O}\\left(\\sqrt{\\frac{1}{Kd_m}} + \\frac{\\min(S, d)}{Kd_m}\\right)$ sub-optimality gap for the empirical optimal policy, which approaches the lower bound up to logarithmic factors and a high-order term, improving upon the best known result by [Cui and Yang 2020] that has additional $\\mathrm{poly} (H, S, d)$ factors in the main term.To the best of our knowledge, these are the first set of nearly horizon-free bounds for episodic time-homogeneous offline tabular MDP and linear MDP with anchor points. Central to our analysis is a simple yet effective recursion based method to bound a \"total variance\" term in the offline scenarios, which could be of individual interest.",
    "authors": [
      "Ren, Tongzheng",
      "Li, Jialian",
      "Dai, Bo",
      "Du, Simon S.",
      "Sanghavi, Sujay"
    ]
  },
  {
    "id": "83a368f54768f506b833130584455df4",
    "title": "Combinatorial Optimization for Panoptic Segmentation: A Fully Differentiable Approach",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/83a368f54768f506b833130584455df4-Paper.pdf",
    "abstract": "We propose a fully differentiable architecture for simultaneous semantic and instance segmentation (a.k.a. panoptic segmentation) consisting of a convolutional neural network and an asymmetric multiway cut problem solver. The latter solves a combinatorial optimization problem that elegantly incorporates semantic and boundary predictions to produce a panoptic labeling. Our formulation allows to directly maximize a smooth surrogate of the panoptic quality metric by backpropagating the gradient through the optimization problem. Experimental evaluation shows improvement by backpropagating through the optimization problem w.r.t. comparable approaches on Cityscapes and COCO datasets. Overall, our approach of combinatorial optimization for panoptic segmentation (COPS) shows the utility of using optimization in tandem with deep learning in a challenging large scale real-world problem and showcases benefits and insights into training such an architecture.",
    "authors": [
      "Abbas, Ahmed",
      "Swoboda, Paul"
    ]
  },
  {
    "id": "83e8fe6279ad25f15b23c6298c6a3584",
    "title": "Reinforcement Learning with State Observation Costs in Action-Contingent Noiselessly Observable Markov Decision Processes ",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/83e8fe6279ad25f15b23c6298c6a3584-Paper.pdf",
    "abstract": "Many real-world problems that require making optimal sequences of decisions under uncertainty involve costs when the agent wishes to obtain information about its environment. We design and analyze algorithms for reinforcement learning (RL) in Action-Contingent Noiselessly Observable MDPs (ACNO-MDPs), a special class of POMDPs in which the agent can choose to either (1) fully observe the state at a cost and then act; or (2) act without any immediate observation information, relying on past observations to infer the underlying state. ACNO-MDPs arise frequently in important real-world application domains like healthcare, in which clinicians must balance the value of information gleaned from medical tests (e.g., blood-based biomarkers) with the costs of gathering that information (e.g., the costs of labor and materials required to administer such tests). We develop a PAC RL algorithm for tabular ACNO-MDPs that provides substantially tighter bounds, compared to generic POMDP-RL algorithms, on the total number of episodes exhibiting worse than near-optimal performance. For continuous-state ACNO-MDPs, we propose a novel method of incorporating observation information that, when coupled with modern RL algorithms, yields significantly faster learning compared to other POMDP-RL algorithms in several simulated environments.",
    "authors": [
      "Nam, HyunJi Alex",
      "Fleming, Scott",
      "Brunskill, Emma"
    ]
  },
  {
    "id": "83fa5a432ae55c253d0e60dbfa716723",
    "title": "Iterative Amortized Policy Optimization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/83fa5a432ae55c253d0e60dbfa716723-Paper.pdf",
    "abstract": "Policy networks are a central feature of deep reinforcement learning (RL) algorithms for continuous control, enabling the estimation and sampling of high-value actions. From the variational inference perspective on RL, policy networks, when used with entropy or KL regularization, are a form of amortized optimization, optimizing network parameters rather than the policy distributions directly. However, direct amortized mappings can yield suboptimal policy estimates and restricted distributions, limiting performance and exploration. Given this perspective, we consider the more flexible class of iterative amortized optimizers. We demonstrate that the resulting technique, iterative amortized policy optimization, yields performance improvements over direct amortization on benchmark continuous control tasks.",
    "authors": [
      "Marino, Joseph",
      "Piche, Alexandre",
      "Ialongo, Alessandro Davide",
      "Yue, Yisong"
    ]
  },
  {
    "id": "8420d359404024567b5aefda1231af24",
    "title": "Revisiting the Calibration of Modern Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8420d359404024567b5aefda1231af24-Paper.pdf",
    "abstract": "Accurate estimation of predictive uncertainty (model calibration) is essential for the safe application of neural networks. Many instances of miscalibration in modern neural networks have been reported, suggesting a trend that newer, more accurate models produce poorly calibrated predictions. Here, we revisit this question for recent state-of-the-art image classification models. We systematically relate model calibration and accuracy, and find that the most recent models, notably those not using convolutions, are among the best calibrated. Trends observed in prior model generations, such as decay of calibration with distribution shift or model size, are less pronounced in recent architectures. We also show that model size and amount of pretraining do not fully explain these differences, suggesting that architecture is a major determinant of calibration properties.",
    "authors": [
      "Minderer, Matthias",
      "Djolonga, Josip",
      "Romijnders, Rob",
      "Hubis, Frances",
      "Zhai, Xiaohua",
      "Houlsby, Neil",
      "Tran, Dustin",
      "Lucic, Mario"
    ]
  },
  {
    "id": "842424a1d0595b76ec4fa03c46e8d755",
    "title": "The decomposition of the higher-order homology embedding constructed from the $k$-Laplacian",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/842424a1d0595b76ec4fa03c46e8d755-Paper.pdf",
    "abstract": "The null space of the $k$-th order Laplacian $\\mathbf{\\mathcal L}_k$, known as the {\\em $k$-th homology vector space}, encodes the non-trivial topology of a manifold or a network. Understanding the structure of the homology embedding can thus disclose geometric or topological information from the data. The study of the null space embedding of the graph Laplacian $\\mathbf{\\mathcal L}_0$ has spurred new research and applications, such as spectral clustering algorithms with theoretical guarantees and estimators of the Stochastic Block Model. In this work, we investigate the geometry of the $k$-th homology embedding and focus on cases reminiscent of spectral clustering. Namely, we analyze the {\\em connected sum} of manifolds as a perturbation to the direct sum of their homology embeddings. We propose an algorithm to factorize the homology embedding into subspaces corresponding to a manifold's simplest topological components. The proposed framework is applied to the {\\em shortest homologous loop detection} problem, a problem known to be NP-hard in general. Our spectral loop detection algorithm scales better than existing methods and is effective on diverse data such as point clouds and images. ",
    "authors": [
      "Chen, Yu-Chia",
      "Meila, Marina"
    ]
  },
  {
    "id": "843a4d7fb5b1641b0bb8e3c2b2e75231",
    "title": "Breaking the Moments Condition Barrier: No-Regret Algorithm for Bandits with Super Heavy-Tailed Payoffs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/843a4d7fb5b1641b0bb8e3c2b2e75231-Paper.pdf",
    "abstract": "Despite a large amount of effort in dealing with heavy-tailed error in machine learning, little is known when moments of the error can become non-existential: the random noise $\\eta$ satisfies Pr$\\left[|\\eta| > |y|\\right] \\le 1/|y|^{\\alpha}$ for some $\\alpha > 0$. We make the first attempt to actively handle such super heavy-tailed noise in bandit learning problems:  We propose a novel robust statistical estimator, mean of medians, which estimates a random variable by computing the empirical mean of a sequence of empirical medians. We then present a generic reductionist algorithmic framework for solving bandit learning problems (including multi-armed and linear bandit problem): the mean of medians estimator can be applied to nearly any bandit learning algorithm as a black-box filtering for its reward signals and obtain similar regret bound as if the reward is sub-Gaussian. We show that the regret bound is near-optimal even with very heavy-tailed noise. We also empirically demonstrate the effectiveness of the proposed algorithm, which further corroborates our theoretical results. ",
    "authors": [
      "Zhong, Han",
      "Huang, Jiayi",
      "Yang, Lin",
      "Wang, Liwei"
    ]
  },
  {
    "id": "8452a95c40e2b232acd9b8a8712935d7",
    "title": "A nonparametric method for gradual change problems with statistical guarantees",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8452a95c40e2b232acd9b8a8712935d7-Paper.pdf",
    "abstract": "We consider the detection and localization of gradual changes in the distribution of a sequence of time-ordered observations. Existing literature focuses mostly on the simpler abrupt setting which assumes a discontinuity jump in distribution, and is unrealistic for some applied settings. We propose a general method for detecting and localizing gradual changes that does not require any specific data generating model, any particular data type, or any prior knowledge about which features of the distribution are subject to change. Despite relaxed assumptions, the proposed method possesses proven theoretical guarantees for both detection and localization. ",
    "authors": [
      "Nie, Lizhen",
      "Nicolae, Dan"
    ]
  },
  {
    "id": "8462a7c229aea03dde69da754c3bbcc4",
    "title": "Nested Graph Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8462a7c229aea03dde69da754c3bbcc4-Paper.pdf",
    "abstract": "Graph neural network (GNN)'s success in graph classification is closely related to the Weisfeiler-Lehman (1-WL) algorithm. By iteratively aggregating neighboring node features to a center node, both 1-WL and GNN obtain a node representation that encodes a rooted subtree around the center node. These rooted subtree representations are then pooled into a single representation to represent the whole graph. However, rooted subtrees are of limited expressiveness to represent a non-tree graph. To address it, we propose Nested Graph Neural Networks (NGNNs). NGNN represents a graph with rooted subgraphs instead of rooted subtrees, so that two graphs sharing many identical subgraphs (rather than subtrees) tend to have similar representations. The key is to make each node representation encode a subgraph around it more than a subtree. To achieve this, NGNN extracts a local subgraph around each node and applies a base GNN to each subgraph to learn a subgraph representation. The whole-graph representation is then obtained by pooling these subgraph representations. We provide a rigorous theoretical analysis showing that NGNN is strictly more powerful than 1-WL. In particular, we proved that NGNN can discriminate almost all r-regular graphs, where 1-WL always fails. Moreover, unlike other more powerful GNNs, NGNN only introduces a constant-factor higher time complexity than standard GNNs. NGNN is a plug-and-play framework that can be combined with various base GNNs. We test NGNN with different base GNNs on several benchmark datasets. NGNN uniformly improves their performance and shows highly competitive performance on all datasets.",
    "authors": [
      "Zhang, Muhan",
      "Li, Pan"
    ]
  },
  {
    "id": "8466f9ace6a9acbe71f75762ffc890f1",
    "title": "Multimodal and Multilingual Embeddings for Large-Scale Speech Mining",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8466f9ace6a9acbe71f75762ffc890f1-Paper.pdf",
    "abstract": "We present an approach to encode a speech signal into a fixed-size representation which minimizes the cosine loss with the existing massively multilingual LASER text embedding space. Sentences are close in this embedding space, independently of their language and modality, either text or audio. Using a similarity metric in that multimodal embedding space, we perform mining of audio in German, French, Spanish and English from Librivox against billions of sentences from Common Crawl. This yielded more than twenty thousand hours of aligned speech translations.  To evaluate the automatically mined speech/text corpora, we train neural speech translation systems for several languages pairs. Adding the mined data, achieves significant improvements in the BLEU score on the CoVoST2 and the MUST-C test sets with respect to a very competitive baseline. Our approach can also be used to directly perform speech-to-speech mining, without the need to first transcribe or translate the data. We obtain more than one thousand three hundred hours of aligned speech in French, German, Spanish and English. This speech corpus has the potential to boost research in speech-to-speech translation which suffers from scarcity of natural end-to-end training data. All the mined multimodal corpora will be made freely available.",
    "authors": [
      "Duquenne, Paul-Ambroise",
      "Gong, Hongyu",
      "Schwenk, Holger"
    ]
  },
  {
    "id": "8485ae387a981d783f8764e508151cd9",
    "title": "Necessary and sufficient graphical conditions for optimal adjustment sets in causal graphical models with hidden variables",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8485ae387a981d783f8764e508151cd9-Paper.pdf",
    "abstract": "The problem of selecting optimal backdoor adjustment sets to estimate causal effects in graphical models with hidden and conditioned variables is addressed. Previous work has defined optimality as achieving the smallest asymptotic estimation variance and derived an optimal set for the case without hidden variables. For the case with hidden variables there can be settings where no optimal set exists and currently only a sufficient graphical optimality criterion of limited applicability has been derived. In the present work optimality is characterized as maximizing a certain adjustment information which allows to derive a necessary and sufficient graphical criterion for the existence of an optimal adjustment set and a definition and algorithm to construct it. Further, the optimal set is valid if and only if a valid adjustment set exists and has higher (or equal) adjustment information than the Adjust-set proposed in Perkovi{\\'c} et~al. [Journal of Machine Learning Research, 18: 1--62, 2018] for any graph. The results translate to minimal asymptotic estimation variance for a class of estimators whose asymptotic variance follows a certain information-theoretic relation. Numerical experiments indicate that the asymptotic results also hold for relatively small sample sizes and that the optimal adjustment set or minimized variants thereof often yield better variance also beyond that estimator class. Surprisingly, among the randomly created setups more than 90\\% fulfill the optimality conditions indicating that also in many real-world scenarios graphical optimality may hold.",
    "authors": [
      "Runge, Jakob"
    ]
  },
  {
    "id": "848c4965359e617d5e16c924b4a85fd9",
    "title": "On Blame Attribution for Accountable Multi-Agent Sequential Decision Making",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/848c4965359e617d5e16c924b4a85fd9-Paper.pdf",
    "abstract": "Blame attribution is one of the key aspects of accountable decision making, as it provides means to quantify the responsibility of an agent for a decision making outcome. In this paper, we study blame attribution in the context of cooperative multi-agent sequential decision making. As a particular setting of interest, we focus on cooperative decision making formalized by Multi-Agent Markov Decision Processes (MMDPs), and we analyze different blame attribution methods derived from or inspired by existing concepts in cooperative game theory. We formalize desirable properties of blame attribution in the setting of interest, and we analyze the relationship between these properties and the studied blame attribution methods. Interestingly, we show that some of the well known blame attribution methods, such as Shapley value, are not performance-incentivizing, while others, such as Banzhaf index, may over-blame agents. To mitigate these value misalignment and fairness issues, we introduce a novel blame attribution method, unique in the set of properties it satisfies, which trade-offs explanatory power (by under-blaming agents) for the aforementioned properties.  We further show how to account for uncertainty about agents' decision making policies, and we experimentally: a) validate the qualitative properties of the studied blame attribution methods, and b) analyze their robustness to uncertainty. ",
    "authors": [
      "Triantafyllou, Stelios",
      "Singla, Adish",
      "Radanovic, Goran"
    ]
  },
  {
    "id": "8493eeaccb772c0878f99d60a0bd2bb3",
    "title": "FLEX: Unifying Evaluation for Few-Shot NLP",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8493eeaccb772c0878f99d60a0bd2bb3-Paper.pdf",
    "abstract": "Few-shot NLP research is highly active, yet conducted in disjoint research threads with evaluation suites that lack challenging-yet-realistic testing setups and fail to employ careful experimental design. Consequently, the community does not know which techniques perform best or even if they outperform simple baselines. In response, we formulate the FLEX Principles, a set of requirements and best practices for unified, rigorous, valid, and cost-sensitive few-shot NLP evaluation. These principles include Sample Size Design, a novel approach to benchmark design that optimizes statistical accuracy and precision while keeping evaluation costs manageable. Following the principles, we release the FLEX benchmark, which includes four few-shot transfer settings, zero-shot evaluation, and a public leaderboard that covers diverse NLP tasks. In addition, we present UniFew, a prompt-based model for few-shot learning that unifies pretraining and finetuning prompt formats, eschewing complex machinery of recent prompt-based approaches in adapting downstream task formats to language model pretraining objectives. We demonstrate that despite simplicity, UniFew achieves results competitive with both popular meta-learning and prompt-based approaches.",
    "authors": [
      "Bragg, Jonathan",
      "Cohan, Arman",
      "Lo, Kyle",
      "Beltagy, Iz"
    ]
  },
  {
    "id": "84a529a92de322be42dd3365afd54f91",
    "title": "A flow-based latent state generative model of neural population responses to natural images",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/84a529a92de322be42dd3365afd54f91-Paper.pdf",
    "abstract": "We present a joint deep neural system identification model for two major sources of neural variability: stimulus-driven and stimulus-conditioned fluctuations. To this end, we combine (1) state-of-the-art deep networks for stimulus-driven activity and (2) a flexible, normalizing flow-based generative model to capture the stimulus-conditioned variability including noise correlations. This allows us to train the model end-to-end without the need for sophisticated probabilistic approximations associated with many latent state models for stimulus-conditioned fluctuations. We train the model on the responses of thousands of neurons from multiple areas of the mouse visual cortex to natural images. We show that our model outperforms previous state-of-the-art models in predicting the distribution of neural population responses to novel stimuli, including shared stimulus-conditioned variability. Furthermore, it successfully learns known latent factors of the population responses that are related to behavioral variables such as pupil dilation, and other factors that vary systematically with brain area or retinotopic location. Overall, our model accurately accounts for two critical sources of neural variability while avoiding several complexities associated with many existing latent state models. It thus provides a useful tool for uncovering the interplay between different factors that contribute to variability in neural activity.",
    "authors": [
      "Bashiri, Mohammad",
      "Walker, Edgar",
      "Lurz, Konstantin-Klemens",
      "Jagadish, Akshay",
      "Muhammad, Taliah",
      "Ding, Zhiwei",
      "Ding, Zhuokun",
      "Tolias, Andreas",
      "Sinz, Fabian"
    ]
  },
  {
    "id": "84c2d4860a0fc27bcf854c444fb8b400",
    "title": "Learnable Fourier Features for Multi-dimensional Spatial Positional Encoding",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/84c2d4860a0fc27bcf854c444fb8b400-Paper.pdf",
    "abstract": "Attentional mechanisms are order-invariant. Positional encoding is a crucial component to allow attention-based deep model architectures such as Transformer to address sequences or images where the position of information matters. In this paper, we propose a novel positional encoding method based on learnable Fourier features. Instead of hard-coding each position as a token or a vector, we represent each position, which can be multi-dimensional, as a trainable encoding based on learnable Fourier feature mapping, modulated  with  a  multi-layer perceptron. The representation is particularly advantageous for a spatial multi-dimensional position, e.g., pixel positions on an image, where $L_2$ distances or more complex positional relationships need to be captured. Our experiments based on several public benchmark tasks show that our learnable Fourier feature representation for multi-dimensional positional encoding outperforms existing methods by both improving the accuracy and allowing faster convergence.",
    "authors": [
      "Li, Yang",
      "Si, Si",
      "Li, Gang",
      "Hsieh, Cho-Jui",
      "Bengio, Samy"
    ]
  },
  {
    "id": "84d5711e9bf5547001b765878e7b0157",
    "title": "Doubly Robust Thompson Sampling with Linear Payoffs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/84d5711e9bf5547001b765878e7b0157-Paper.pdf",
    "abstract": "A challenging aspect of the bandit problem is that a stochastic reward is observed only for the chosen arm and the rewards of other arms remain missing.    The dependence of the arm choice on the past context and reward pairs compounds the complexity of regret analysis.We propose a novel multi-armed contextual bandit algorithm called Doubly Robust Thompson Sampling (DRTS) employing the doubly-robust estimator used in missing data literature to Thompson Sampling with contexts (\\texttt{LinTS}).Different from previous works relying on missing data techniques (Dimakopoulou et al. [2019], Kim and Paik [2019]), the proposed algorithm is designed to allow a novel additive regret decomposition leading to an improved regret bound with the order of $\\tilde{O}(\\phi^{-2}\\sqrt{T})$, where $\\phi^2$ is the minimum eigenvalue of the covariance matrix of contexts.This is the first regret bound of \\texttt{LinTS} using $\\phi^2$ without $d$,  where $d$ is the dimension of the context.Applying the relationship between $\\phi^2$ and $d$, the regret bound of the proposed algorithm is $\\tilde{O}(d\\sqrt{T})$ in many practical scenarios, improving the bound of \\texttt{LinTS} by a factor of $\\sqrt{d}$.A benefit of the proposed method is that it uses all the context data, chosen or not chosen, thus allowing to circumvent the technical definition of unsaturated arms used in theoretical analysis of \\texttt{LinTS}.Empirical studies show the advantage of the proposed algorithm over \\texttt{LinTS}.",
    "authors": [
      "Kim, Wonyoung",
      "Kim, Gi-Soo",
      "Paik, Myunghee Cho"
    ]
  },
  {
    "id": "84f7e69969dea92a925508f7c1f9579a",
    "title": "A Computationally Efficient Method for Learning Exponential Family Distributions",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/84f7e69969dea92a925508f7c1f9579a-Paper.pdf",
    "abstract": "We consider the question of learning the natural parameters of a $k$ parameter \\textit{minimal} exponential family from i.i.d. samples in a computationally and statistically efficient manner. We focus on the setting where the support as well as the natural parameters are appropriately bounded. While the traditional maximum likelihood estimator for this class of exponential family is consistent, asymptotically normal, and asymptotically efficient, evaluating it is computationally hard. In this work, we propose a computationally efficient estimator that is consistent as well as asymptotically normal under mild conditions. We provide finite sample guarantees to achieve an ($\\ell_2$) error of $\\alpha$ in the parameter estimation  with sample complexity $O(\\mathrm{poly}(k/\\alpha))$ and computational complexity ${O}(\\mathrm{poly}(k/\\alpha))$. To establish these results, we show that, at the population level, our method can be viewed as the maximum likelihood estimation of a re-parameterized distribution belonging to the same class of exponential family. ",
    "authors": [
      "Shah, Abhin",
      "Shah, Devavrat",
      "Wornell, Gregory"
    ]
  },
  {
    "id": "84fdbc3ac902561c00871c9b0c226756",
    "title": "Rethinking Neural Operations for Diverse Tasks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/84fdbc3ac902561c00871c9b0c226756-Paper.pdf",
    "abstract": "An important goal of AutoML is to automate-away the design of neural networks on new tasks in under-explored domains. Motivated by this goal, we study the problem of enabling users to discover the right neural operations given data from their specific domain. We introduce a search space of operations called XD-Operations that mimic the inductive bias of standard multi-channel convolutions while being much more expressive: we prove that it includes many named operations across multiple application areas. Starting with any standard backbone such as ResNet, we show how to transform it into a search space over XD-operations and how to traverse the space using a simple weight sharing scheme. On a diverse set of tasks\u2014solving PDEs, distance prediction for protein folding, and music modeling\u2014our approach consistently yields models with lower error than baseline networks and often even lower error than expert-designed domain-specific approaches.",
    "authors": [
      "Roberts, Nicholas",
      "Khodak, Mikhail",
      "Dao, Tri",
      "Li, Liam",
      "R\u00e9, Christopher",
      "Talwalkar, Ameet"
    ]
  },
  {
    "id": "85267d349a5e647ff0a9edcb5ffd1e02",
    "title": "Motif-based Graph Self-Supervised Learning for Molecular Property Prediction",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/85267d349a5e647ff0a9edcb5ffd1e02-Paper.pdf",
    "abstract": "Predicting molecular properties with data-driven methods has drawn much attention in recent years. Particularly, Graph Neural Networks (GNNs) have demonstrated remarkable success in various molecular generation and prediction tasks. In cases where labeled data is scarce, GNNs can be pre-trained on unlabeled molecular data to first learn the general semantic and structural information before being finetuned for specific tasks. However, most existing self-supervised pretraining frameworks for GNNs only focus on node-level or graph-level tasks. These approaches cannot capture the rich information in subgraphs or graph motifs. For example, functional groups (frequently-occurred subgraphs in molecular graphs)  often carry indicative information about the molecular properties. To bridge this gap, we propose Motif-based Graph Self-supervised Learning (MGSSL) by introducing a novel self-supervised motif generation framework for GNNs. First, for motif extraction from molecular graphs, we design a molecule fragmentation method that leverages a retrosynthesis-based algorithm BRICS and additional rules for controlling the size of motif vocabulary. Second, we design a general motif-based generative pretraining framework in which GNNs are asked to make topological and label predictions. This generative framework can be implemented in two different ways, i.e., breadth-first or depth-first. Finally, to take the multi-scale information in molecular graphs into consideration, we introduce a multi-level self-supervised pre-training. Extensive experiments on various downstream benchmark tasks show that our methods outperform all state-of-the-art baselines.",
    "authors": [
      "ZHANG, ZAIXI",
      "Liu, Qi",
      "Wang, Hao",
      "Lu, Chengqiang",
      "Lee, Chee-Kong"
    ]
  },
  {
    "id": "8526e0962a844e4a2f158d831d5fddf7",
    "title": "On Inductive Biases for Heterogeneous Treatment Effect Estimation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8526e0962a844e4a2f158d831d5fddf7-Paper.pdf",
    "abstract": "We investigate how to exploit structural similarities of an individual's potential outcomes (POs) under different treatments to obtain better estimates of conditional average treatment effects in finite samples. Especially when it is unknown whether a treatment has an effect at all, it is natural to hypothesize that the POs are similar -- yet, some existing strategies for treatment effect estimation employ regularization schemes that implicitly encourage heterogeneity even when it does not exist and fail to fully make use of shared structure. In this paper, we investigate and compare three end-to-end learning strategies to overcome this problem -- based on regularization, reparametrization and a flexible multi-task architecture -- each encoding inductive bias favoring shared behavior across POs. To build understanding of their relative strengths, we implement all strategies using neural networks and conduct a wide range of semi-synthetic experiments. We observe that all three approaches can lead to substantial improvements upon numerous baselines and gain insight into performance differences across various experimental settings. ",
    "authors": [
      "Curth, Alicia",
      "van der Schaar, Mihaela"
    ]
  },
  {
    "id": "854d6fae5ee42911677c739ee1734486",
    "title": "DP-SSL: Towards Robust Semi-supervised Learning with A Few Labeled Samples",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/854d6fae5ee42911677c739ee1734486-Paper.pdf",
    "abstract": "The scarcity of labeled data is a critical obstacle to deep learning. Semi-supervised learning (SSL) provides a promising way to leverage unlabeled data by pseudo labels. However, when the size of labeled data is very small (say a few labeled samples per class), SSL performs poorly and unstably, possibly due to the low quality of learned pseudo labels. In this paper, we propose a new SSL method called DP-SSL that adopts an innovative data programming (DP) scheme to generate probabilistic labels for unlabeled data. Different from existing DP methods that rely on human experts to provide initial labeling functions (LFs), we develop a multiple-choice learning~(MCL) based approach to automatically generate LFs from scratch in SSL style. With the noisy labels produced by the LFs, we design a label model to resolve the conflict and overlap among the noisy labels, and finally infer probabilistic labels for unlabeled samples. Extensive experiments on four standard SSL benchmarks show that DP-SSL can provide reliable labels for unlabeled data and achieve better classification performance on test sets than existing SSL methods, especially when only a small number of labeled samples are available. Concretely, for CIFAR-10 with only 40 labeled samples, DP-SSL achieves 93.82% annotation accuracy on unlabeled data and 93.46% classification accuracy on test data, which are higher than the SOTA results.",
    "authors": [
      "Xu, Yi",
      "Ding, Jiandong",
      "Zhang, Lu",
      "Zhou, Shuigeng"
    ]
  },
  {
    "id": "854d9fca60b4bd07f9bb215d59ef5561",
    "title": "Transformer in Transformer",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/854d9fca60b4bd07f9bb215d59ef5561-Paper.pdf",
    "abstract": "Transformer is a new kind of neural architecture which encodes the input data as powerful features via the attention mechanism. Basically, the visual transformers first divide the input images into several local patches and then calculate both representations and their relationship. Since natural images are of high complexity with abundant detail and color information, the granularity of the patch dividing is not fine enough for excavating features of objects in different scales and locations. In this paper, we point out that the attention inside these local patches are also essential for building visual transformers with high performance and we explore a new architecture, namely, Transformer iN Transformer (TNT). Specifically, we regard the local patches (\\eg, 16$\\times$16) as \u201cvisual sentences\u201d and present to further divide them into smaller patches (\\eg, 4$\\times$4) as \u201cvisual words\u201d. The attention of each word will be calculated with other words in the given visual sentence with negligible computational costs. Features of both words and sentences will be aggregated to enhance the representation ability. Experiments on several benchmarks demonstrate the effectiveness of the proposed TNT architecture, \\eg, we achieve an 81.5\\% top-1 accuracy on the ImageNet, which is about 1.7\\% higher than that of the state-of-the-art visual transformer with similar computational cost. The PyTorch code is available at \\url{https://github.com/huawei-noah/CV-Backbones}, and the MindSpore code is available at \\url{https://gitee.com/mindspore/models/tree/master/research/cv/TNT}.",
    "authors": [
      "Han, Kai",
      "Xiao, An",
      "Wu, Enhua",
      "Guo, Jianyuan",
      "XU, Chunjing",
      "Wang, Yunhe"
    ]
  },
  {
    "id": "854f1fb6f65734d9e49f708d6cd84ad6",
    "title": "Adversarial Graph Augmentation to Improve Graph Contrastive Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/854f1fb6f65734d9e49f708d6cd84ad6-Paper.pdf",
    "abstract": "Self-supervised learning of graph neural networks (GNN) is in great need because of the widespread label scarcity issue in real-world graph/network data. Graph contrastive learning (GCL), by training GNNs to maximize the correspondence between the representations of the same graph in its different augmented forms, may yield robust and transferable GNNs even without using labels. However, GNNs trained by traditional GCL often risk capturing redundant graph features and thus may be brittle and provide sub-par performance in downstream tasks. Here, we propose a novel principle, termed adversarial-GCL (\\textit{AD-GCL}), which enables GNNs to avoid capturing redundant information during the training by optimizing adversarial graph augmentation strategies used in GCL. We pair AD-GCL with theoretical explanations and design a practical instantiation based on trainable edge-dropping graph augmentation. We experimentally validate AD-GCL by comparing with the state-of-the-art GCL methods and achieve performance gains of up-to~14\\% in unsupervised, ~6\\% in transfer and~3\\% in semi-supervised learning settings overall with 18 different benchmark datasets for the tasks of molecule property regression and classification, and social network classification.",
    "authors": [
      "Suresh, Susheel",
      "Li, Pan",
      "Hao, Cong",
      "Neville, Jennifer"
    ]
  },
  {
    "id": "856b503e276cc491e7e6e0ac1b9f4b17",
    "title": "Online Control of Unknown Time-Varying Dynamical Systems",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/856b503e276cc491e7e6e0ac1b9f4b17-Paper.pdf",
    "abstract": "We study online control of time-varying linear systems with unknown dynamics in the nonstochastic control model. At a high level, we demonstrate that this setting is \\emph{qualitatively harder} than that of either unknown time-invariant or known time-varying dynamics, and complement our negative results with algorithmic upper bounds in regimes where sublinear regret is possible. More specifically, we study regret bounds with respect to common classes of policies: Disturbance Action (SLS), Disturbance Response (Youla), and linear feedback policies. While these three classes are essentially equivalent for LTI systems, we demonstrate that these equivalences break down for time-varying systems. We prove a lower bound that no algorithm can obtain sublinear regret with respect to the first two classes unless a certain measure of system variability also scales sublinearly in the horizon. Furthermore, we show that offline planning over the state linear feedback policies is NP-hard, suggesting hardness of the online learning problem. On the positive side, we give an efficient algorithm that attains a sublinear regret bound against the class of Disturbance Response policies up to the aforementioned system variability term. In fact, our algorithm enjoys sublinear \\emph{adaptive} regret bounds, which is a strictly stronger metric than standard regret and is more appropriate for time-varying systems. We sketch extensions to Disturbance Action policies and partial observation, and propose an inefficient algorithm for regret against linear state feedback policies.",
    "authors": [
      "Minasyan, Edgar",
      "Gradu, Paula",
      "Simchowitz, Max",
      "Hazan, Elad"
    ]
  },
  {
    "id": "859555c74e9afd45ab771c615c1e49a6",
    "title": "Contrastive Reinforcement Learning of Symbolic Reasoning Domains",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/859555c74e9afd45ab771c615c1e49a6-Paper.pdf",
    "abstract": "Abstract symbolic reasoning, as required in domains such as mathematics and logic, is a key component of human intelligence. Solvers for these domains have important applications, especially to computer-assisted education. But learning to solve symbolic problems is challenging for machine learning algorithms. Existing models either learn from human solutions or use hand-engineered features, making them expensive to apply in new domains. In this paper, we instead consider symbolic domains as simple environments where states and actions are given as unstructured text, and binary rewards indicate whether a problem is solved. This flexible setup makes it easy to specify new domains, but search and planning become challenging. We introduce five environments inspired by the Mathematics Common Core Curriculum, and observe that existing Reinforcement Learning baselines perform poorly. We then present a novel learning algorithm, Contrastive Policy Learning (ConPoLe) that explicitly optimizes the InfoNCE loss, which lower bounds the mutual information between the current state and next states that continue on a path to the solution. ConPoLe successfully solves all four domains. Moreover, problem representations learned by ConPoLe enable accurate prediction of the categories of problems in a real mathematics curriculum. Our results suggest new directions for reinforcement learning in symbolic domains, as well as applications to mathematics education.",
    "authors": [
      "Poesia, Gabriel",
      "Dong, WenXin",
      "Goodman, Noah"
    ]
  },
  {
    "id": "8597a6cfa74defcbde3047c891d78f90",
    "title": "Spatial Ensemble: a Novel Model Smoothing Mechanism for Student-Teacher Framework",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8597a6cfa74defcbde3047c891d78f90-Paper.pdf",
    "abstract": "Model smoothing is of central importance for obtaining a reliable teacher model in the student-teacher framework, where the teacher generates surrogate supervision signals to train the student. A popular model smoothing method is the Temporal Moving Average (TMA), which continuously averages the teacher parameters with the up-to-date student parameters. In this paper, we propose ''Spatial Ensemble'', a novel model smoothing mechanism in parallel with TMA. Spatial Ensemble randomly picks up a small fragment of the student model to directly replace the corresponding fragment of the teacher model. Consequentially, it stitches different fragments of historical student models into a unity, yielding the ''Spatial Ensemble'' effect. Spatial Ensemble obtains comparable student-teacher learning performance by itself and demonstrates valuable complementarity with temporal moving average. Their integration, named Spatial-Temporal Smoothing, brings general (sometimes significant) improvement to the student-teacher learning framework on a variety of state-of-the-art methods. For example, based on the self-supervised method BYOL, it yields +0.9% top-1 accuracy improvement on ImageNet, while based on the semi-supervised approach FixMatch, it increases the top-1 accuracy by around +6% on CIFAR-10 when only few training labels are available. Codes and models are available at: https://github.com/tengteng95/Spatial_Ensemble.",
    "authors": [
      "Huang, Tengteng",
      "Sun, Yifan",
      "Wang, Xun",
      "Yao, Haotian",
      "Zhang, Chi"
    ]
  },
  {
    "id": "859b755563f548d008f936906a959c8f",
    "title": "Probabilistic Tensor Decomposition of Neural Population Spiking Activity",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/859b755563f548d008f936906a959c8f-Paper.pdf",
    "abstract": "The firing of neural populations is coordinated across cells, in time, and across experimentalconditions or repeated experimental trials; and so a full understanding of the computationalsignificance of neural responses must be based on a separation of these different contributions tostructured activity.Tensor decomposition is an approach to untangling the influence of multiple factors in data that iscommon in many fields.  However, despite some recent interest in neuroscience, wider applicabilityof the approach is hampered by the lack of a full probabilistic treatment allowing principledinference of a decomposition from non-Gaussian spike-count data.Here, we extend the P\u00f3lya-Gamma (PG) augmentation, previously used in sampling-based Bayesianinference, to implement scalable variational inference in non-conjugate spike-count models.Using this new approach, we develop techniques related to automatic relevance determination to inferthe most appropriate tensor rank, as well as to incorporate priors based on known brain anatomy suchas the segregation of cell response properties by brain area.We apply the model to neural recordings taken under conditions of visual-vestibular sensoryintegration, revealing how the encoding of self- and visual-motion signals is modulated by thesensory information available to the animal.",
    "authors": [
      "Soulat, Hugo",
      "Keshavarzi, Sepiedeh",
      "Margrie, Troy",
      "Sahani, Maneesh"
    ]
  },
  {
    "id": "859bf1416b8b8761c5d588dee78dc65f",
    "title": "Recurrent Bayesian Classifier Chains for Exact Multi-Label Classification",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/859bf1416b8b8761c5d588dee78dc65f-Paper.pdf",
    "abstract": "Exact multi-label classification is the task of assigning each datapoint a set of class labels such that the assigned set exactly matches the ground truth. Optimizing for exact multi-label classification is important in domains where missing a single label can be especially costly, such as in object detection for autonomous vehicles or symptom classification for disease diagnosis. Recurrent Classifier Chains (RCCs), a recurrent neural network extension of ensemble-based classifier chains, are the state-of-the-art exact multi-label classification method for maximizing subset accuracy. However, RCCs iteratively predict classes with an unprincipled ordering, and therefore indiscriminately condition class probabilities. These disadvantages make RCCs prone to predicting inaccurate label sets. In this work we propose Recurrent Bayesian Classifier Chains (RBCCs), which learn a Bayesian network of class dependencies and leverage this network in order to condition the prediction of child nodes only on their parents. By conditioning predictions in this way, we perform principled and non-noisy class prediction.  We demonstrate the effectiveness of our RBCC method on a variety of real-world multi-label datasets, where we routinely outperform the state of the art methods for exact multi-label classification. ",
    "authors": [
      "Gerych, Walter",
      "Hartvigsen, Tom",
      "Buquicchio, Luke",
      "Agu, Emmanuel",
      "Rundensteiner, Elke A."
    ]
  },
  {
    "id": "85a4413ecea7122bcc399cf0a53bba26",
    "title": "Wasserstein Flow Meets Replicator Dynamics: A Mean-Field Analysis of Representation Learning in Actor-Critic",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/85a4413ecea7122bcc399cf0a53bba26-Paper.pdf",
    "abstract": "Actor-critic  (AC) algorithms, empowered by neural networks, have had significant empirical success in recent years. However, most of the existing theoretical support for AC algorithms focuses on the case of linear function approximations, or linearized neural networks, where the feature representation is fixed throughout training. Such a limitation fails to capture the key aspect of representation learning in neural AC, which is pivotal in practical problems. In this work, we take a mean-field perspective on the evolution and convergence of feature-based neural AC. Specifically, we consider a version of  AC where the actor and critic are represented by overparameterized two-layer neural networks and are updated with two-timescale learning rates. The critic is updated by temporal-difference (TD) learning with a larger stepsize while the actor is updated via proximal policy optimization (PPO) with a smaller stepsize. In the continuous-time and infinite-width limiting regime, when the timescales are properly separated, we prove that neural AC finds the globally optimal policy at a sublinear rate. Additionally,  we prove that the feature representation induced by the critic network is allowed to evolve within a neighborhood of the initial one. ",
    "authors": [
      "Zhang, Yufeng",
      "Chen, Siyu",
      "Yang, Zhuoran",
      "Jordan, Michael",
      "Wang, Zhaoran"
    ]
  },
  {
    "id": "85dca1d270f7f9aef00c9d372f114482",
    "title": "Assessing Fairness in the Presence of Missing Data",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/85dca1d270f7f9aef00c9d372f114482-Paper.pdf",
    "abstract": "Missing data are prevalent and present daunting challenges in real data analysis. While there is a growing body of literature on fairness in analysis of fully observed data, there has been little theoretical work on investigating fairness in analysis of incomplete data. In practice, a popular analytical approach for dealing with missing data is to use only the set of complete cases, i.e., observations with all features fully observed to train a prediction algorithm. However, depending on the missing data mechanism, the distribution of complete cases and the distribution of the complete data may be substantially different. When the goal is to develop a fair algorithm in the complete data domain where there are no missing values, an algorithm that is fair in the complete case domain may show disproportionate bias towards some marginalized groups in the complete data domain. To fill this significant gap, we study the problem of estimating fairness in the complete data domain for an arbitrary model evaluated merely using complete cases. We provide upper and lower bounds on the fairness estimation error and conduct numerical experiments to assess our theoretical results. Our work provides the first known theoretical results on fairness guarantee in analysis of incomplete data.",
    "authors": [
      "Zhang, Yiliang",
      "Long, Qi"
    ]
  },
  {
    "id": "85e5526a360b0bcf082d8d42e7bf100b",
    "title": "Adversarial Attack Generation Empowered by Min-Max Optimization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/85e5526a360b0bcf082d8d42e7bf100b-Paper.pdf",
    "abstract": "The worst-case training principle that minimizes the maximal adversarial loss, also known as adversarial training (AT), has shown to be a state-of-the-art approach for enhancing adversarial robustness. Nevertheless, min-max optimization beyond the purpose of AT has not been rigorously explored in the adversarial context. In this paper, we show how a general notion of min-max optimization over multiple domains can be leveraged to the design of different types of adversarial attacks. In particular, given a set of risk sources, minimizing the worst-case attack loss can be reformulated as a min-max problem by introducing domain weights that are maximized over the probability simplex of the domain set. We showcase this unified framework in three attack generation problems -- attacking model ensembles, devising universal perturbation under multiple inputs, and crafting attacks resilient to data transformations. Extensive experiments demonstrate that our approach leads to substantial attack improvement over the existing heuristic strategies as well as robustness improvement over state-of-the-art defense methods against multiple perturbation types. Furthermore, we find that the self-adjusted domain weights learned from min-max optimization can provide a holistic tool to explain the difficulty level of attack across domains.",
    "authors": [
      "Wang, Jingkang",
      "Zhang, Tianyun",
      "Liu, Sijia",
      "Chen, Pin-Yu",
      "Xu, Jiacen",
      "Fardad, Makan",
      "Li, Bo"
    ]
  },
  {
    "id": "85ea6fd7a2ca3960d0cf5201933ac998",
    "title": "Safe Pontryagin Differentiable Programming",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/85ea6fd7a2ca3960d0cf5201933ac998-Paper.pdf",
    "abstract": "We propose a Safe Pontryagin Differentiable Programming (Safe PDP) methodology, which establishes a theoretical and algorithmic  framework to solve a broad class of safety-critical learning and control tasks---problems that require the guarantee of safety constraint satisfaction at any stage of the learning and control progress.  In the spirit of interior-point methods,   Safe PDP handles different types of system  constraints on states and inputs by incorporating them into the cost or loss through barrier functions. We prove three fundamentals  of the proposed  Safe PDP:  first, both the  solution and its gradient in the backward pass can be approximated by solving their  more efficient unconstrained counterparts;  second,   the approximation for both the  solution and its gradient can be controlled for arbitrary accuracy by a  barrier parameter;   and third,   importantly, all intermediate results throughout the approximation and optimization  strictly respect the  constraints,  thus guaranteeing safety throughout the entire learning and control process. We demonstrate the capabilities of   Safe PDP in solving various safety-critical tasks,  including safe policy optimization, safe motion planning, and learning MPCs from demonstrations, on different challenging systems such as 6-DoF maneuvering quadrotor and 6-DoF rocket powered landing.",
    "authors": [
      "Jin, Wanxin",
      "Mou, Shaoshuai",
      "Pappas, George J."
    ]
  },
  {
    "id": "8606f35ec6c77858dfb80a385d0d1151",
    "title": "Class-Disentanglement and Applications in Adversarial Detection and Defense",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8606f35ec6c77858dfb80a385d0d1151-Paper.pdf",
    "abstract": "What is the minimum necessary information required by a neural net $D(\\cdot)$ from an image $x$ to accurately predict its class? Extracting such information in the input space from $x$ can allocate the areas $D(\\cdot)$ mainly attending to and shed novel insights to the detection and defense of adversarial attacks. In this paper, we propose ''class-disentanglement'' that trains a variational autoencoder $G(\\cdot)$ to extract this class-dependent information as $x - G(x)$ via a trade-off between reconstructing $x$ by $G(x)$ and classifying $x$ by $D(x-G(x))$, where the former competes with the latter in decomposing $x$ so the latter retains only necessary information for classification in $x-G(x)$. We apply it to both clean images and their adversarial images and discover that the perturbations generated by adversarial attacks mainly lie in the class-dependent part $x-G(x)$. The decomposition results also provide novel interpretations to classification and attack models. Inspired by these observations, we propose to conduct adversarial detection and adversarial defense respectively on $x - G(x)$ and $G(x)$, which consistently outperform the results on the original $x$. In experiments, this simple approach substantially improves the detection and defense against different types of adversarial attacks.",
    "authors": [
      "Yang, Kaiwen",
      "Zhou, Tianyi",
      "Zhang, Yonggang",
      "Tian, Xinmei",
      "Tao, Dacheng"
    ]
  },
  {
    "id": "8635b5fd6bc675033fb72e8a3ccc10a0",
    "title": "Active 3D Shape Reconstruction from Vision and Touch",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8635b5fd6bc675033fb72e8a3ccc10a0-Paper.pdf",
    "abstract": "Humans build 3D understandings of the world through active object exploration, using jointly their senses of vision and touch. However, in 3D shape reconstruction, most recent progress has relied on static datasets of limited sensory data such as RGB images, depth maps or haptic readings, leaving the active exploration of the shape largely unexplored. In active touch sensing for 3D reconstruction, the goal is to actively select the tactile readings that maximize the improvement in shape reconstruction accuracy. However, the development of deep learning-based active touch models is largely limited by the lack of frameworks for shape exploration. In this paper, we focus on this problem and introduce a system composed of: 1) a haptic simulator leveraging high spatial resolution vision-based tactile sensors for active touching of 3D objects; 2) a mesh-based 3D shape reconstruction model that relies on tactile or visuotactile signals; and 3) a set of data-driven solutions with either tactile or visuotactile priors to guide the shape exploration. Our framework enables the development of the first fully data-driven solutions to active touch on top of learned models for object understanding. Our experiments show the benefits of such solutions in the task of 3D shape understanding where our models consistently outperform natural baselines. We provide our framework as a tool to foster future research in this direction.",
    "authors": [
      "Smith, Edward",
      "Meger, David",
      "Pineda, Luis",
      "Calandra, Roberto",
      "Malik, Jitendra",
      "Romero Soriano, Adriana",
      "Drozdzal, Michal"
    ]
  },
  {
    "id": "865bf46435bd84fa5d89f64cf3ba7347",
    "title": "CAPE: Encoding Relative Positions with Continuous Augmented Positional Embeddings",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/865bf46435bd84fa5d89f64cf3ba7347-Paper.pdf",
    "abstract": "Without positional information, attention-based Transformer neural networks are permutation-invariant. Absolute or relative positional embeddings are the most popular ways to feed Transformer models with positional information. Absolute positional embeddings are simple to implement, but suffer from generalization issues when evaluating on sequences longer than seen at training time. Relative positions are more robust to input length change, but are more complex to implement and yield inferior model throughput due to extra computational and memory costs. In this paper, we propose an augmentation-based approach (CAPE) for absolute positional embeddings, which keeps the advantages of both absolute (simplicity and speed) and relative positional embeddings (better generalization). In addition, our empirical evaluation on state-of-the-art models in machine translation, image and speech recognition demonstrates that CAPE leads to better generalization performance as well as increased stability with respect to training hyper-parameters.",
    "authors": [
      "Likhomanenko, Tatiana",
      "Xu, Qiantong",
      "Synnaeve, Gabriel",
      "Collobert, Ronan",
      "Rogozhnikov, Alex"
    ]
  },
  {
    "id": "865dfbde8a344b44095495f3591f7407",
    "title": "Multi-armed Bandit Requiring Monotone Arm Sequences",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/865dfbde8a344b44095495f3591f7407-Paper.pdf",
    "abstract": "In many online learning or multi-armed bandit problems, the taken actions or pulled arms are ordinal and required to be monotone over time. Examples include dynamic pricing, in which the firms use markup pricing policies to please early adopters and deter strategic waiting, and clinical trials, in which the dose allocation usually follows the dose escalation principle to prevent dose limiting toxicities. We consider the continuum-armed bandit problem when the arm sequence is required to be monotone. We show that when the unknown objective function is Lipschitz continuous, the regret is $O(T)$. When in addition the objective function is unimodal or quasiconcave, the regret is $\\tilde O(T^{3/4})$ under the proposed algorithm, which is also shown to be the optimal rate. This deviates from the optimal rate $\\tilde O(T^{2/3})$ in the continuous-armed bandit literature and demonstrates the cost to the learning efficiency brought by the monotonicity requirement.",
    "authors": [
      "Chen, Ningyuan"
    ]
  },
  {
    "id": "8682cc30db9c025ecd3fee433f8ab54c",
    "title": "Gradient Driven Rewards to Guarantee Fairness in Collaborative Machine Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8682cc30db9c025ecd3fee433f8ab54c-Paper.pdf",
    "abstract": "In collaborative machine learning(CML), multiple agents pool their resources(e.g., data) together for a common learning task. In realistic CML settings where the agents are self-interested and not altruistic, they may be unwilling to share data or model information without adequate rewards. Furthermore, as the data/model information shared by the agents may differ in quality, designing rewards which are fair to them is important so that they would not feel exploited nor discouraged from sharing. In this paper, we adopt federated learning as the CML paradigm, propose a novel cosine gradient Shapley value(CGSV) to fairly evaluate the expected marginal contribution of each agent\u2019s uploaded model parameter update/gradient without needing an auxiliary validation dataset, and based on the CGSV, design a novel training-time gradient reward mechanism with a fairness guarantee by sparsifying the aggregated parameter update/gradient downloaded from the server as reward to each agent such that its resulting quality is commensurate to that of the agent\u2019s uploaded parameter update/gradient. We empirically demonstrate the effectiveness of our fair gradient reward mechanism on multiple benchmark datasets in terms of fairness, predictive performance, and time overhead.",
    "authors": [
      "Xu, Xinyi",
      "Lyu, Lingjuan",
      "Ma, Xingjun",
      "Miao, Chenglin",
      "Foo, Chuan Sheng",
      "Low, Bryan Kian Hsiang"
    ]
  },
  {
    "id": "868b7df964b1af24c8c0a9e43a330c6a",
    "title": "Generalizable Imitation Learning from Observation via Inferring Goal Proximity",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/868b7df964b1af24c8c0a9e43a330c6a-Paper.pdf",
    "abstract": "Task progress is intuitive and readily available task information that can guide an agent closer to the desired goal. Furthermore, a task progress estimator can generalize to new situations. From this intuition, we propose a simple yet effective imitation learning from observation method for a goal-directed task using a learned goal proximity function as a task progress estimator for better generalization to unseen states and goals. We obtain this goal proximity function from expert demonstrations and online agent experience, and then use the learned goal proximity as a dense reward for policy training. We demonstrate that our proposed method can robustly generalize compared to prior imitation learning methods on a set of goal-directed tasks in navigation, locomotion, and robotic manipulation, even with demonstrations that cover only a part of the states.",
    "authors": [
      "Lee, Youngwoon",
      "Szot, Andrew",
      "Sun, Shao-Hua",
      "Lim, Joseph J."
    ]
  },
  {
    "id": "86a1fa88adb5c33bd7a68ac2f9f3f96b",
    "title": "DualNet: Continual Learning, Fast and Slow",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/86a1fa88adb5c33bd7a68ac2f9f3f96b-Paper.pdf",
    "abstract": "According to Complementary Learning Systems (CLS) theory~\\cite{mcclelland1995there} in neuroscience, humans do effective \\emph{continual learning} through two complementary systems: a fast learning system centered on the hippocampus for rapid learning of the specifics and individual experiences, and a slow learning system located in the neocortex for the gradual acquisition of structured knowledge about the environment. Motivated by this theory, we propose a novel continual learning framework named ``DualNet\", which comprises a fast learning system for supervised learning of pattern-separated representation from specific tasks and a slow learning system for unsupervised representation learning of task-agnostic general representation via a Self-Supervised Learning (SSL) technique. The two fast and slow learning systems are complementary and work seamlessly in a holistic continual learning framework. Our extensive experiments on two challenging continual learning benchmarks of CORE50 and miniImageNet show that DualNet outperforms state-of-the-art continual learning methods by a large margin. We further conduct ablation studies of different SSL objectives to validate DualNet's efficacy, robustness, and scalability. Code is publicly available at \\url{https://github.com/phquang/DualNet}.",
    "authors": [
      "Pham, Quang",
      "Liu, Chenghao",
      "Hoi, Steven"
    ]
  },
  {
    "id": "86b122d4358357d834a87ce618a55de0",
    "title": "Deformable Butterfly: A Highly Structured and Sparse Linear Transform",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/86b122d4358357d834a87ce618a55de0-Paper.pdf",
    "abstract": "We introduce a new kind of linear transform named Deformable Butterfly (DeBut) that generalizes the conventional butterfly matrices and can be adapted to various input-output dimensions. It inherits the fine-to-coarse-grained learnable hierarchy of traditional butterflies and when deployed to neural networks, the prominent structures and sparsity in a DeBut layer constitutes a new way for network compression. We apply DeBut as a drop-in replacement of standard fully connected and convolutional layers, and demonstrate its superiority in homogenizing a neural network and rendering it favorable properties such as light weight and low inference complexity, without compromising accuracy. The natural complexity-accuracy tradeoff arising from the myriad deformations of a DeBut layer also opens up new rooms for analytical and practical research. The codes and Appendix are publicly available at: https://github.com/ruilin0212/DeBut.",
    "authors": [
      "Lin, Rui",
      "Ran, Jie",
      "Chiu, King Hung",
      "Chesi, Graziano",
      "Wong, Ngai"
    ]
  },
  {
    "id": "86b3e165b8154656a71ffe8a327ded7d",
    "title": "Why Do Pretrained Language Models Help in Downstream Tasks? An Analysis of Head and Prompt Tuning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/86b3e165b8154656a71ffe8a327ded7d-Paper.pdf",
    "abstract": "Pretrained language models have achieved state-of-the-art performance when adapted to a downstream NLP task. However, theoretical analysis of these models is scarce and challenging since the pretraining and downstream tasks can be very different. We propose an analysis framework that links the pretraining and downstream tasks with an underlying latent variable generative model of text -- the downstream classifier must recover a function of the posterior distribution over the latent variables. We analyze head tuning (learning a classifier on top of the frozen pretrained model) and prompt tuning in this setting. The generative model in our analysis is either a Hidden Markov Model (HMM) or an HMM augmented with a latent memory component, motivated by long-term dependencies in natural language. We show that 1) under certain non-degeneracy conditions on the HMM, simple classification heads can solve the downstream task, 2) prompt tuning obtains downstream guarantees with weaker non-degeneracy conditions, and 3) our recovery guarantees for the memory-augmented HMM are stronger than for the vanilla HMM because task-relevant information is easier to recover from the long-term memory. Experiments on synthetically generated data from HMMs back our theoretical findings.",
    "authors": [
      "Wei, Colin",
      "Xie, Sang Michael",
      "Ma, Tengyu"
    ]
  },
  {
    "id": "86dba86754c0ad93997a11fa947d97b2",
    "title": "Learning Diverse Policies in MOBA Games via Macro-Goals",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/86dba86754c0ad93997a11fa947d97b2-Paper.pdf",
    "abstract": "Recently, many researchers have made successful progress in building the AI systems for MOBA-game-playing with deep reinforcement learning, such as on Dota 2 and Honor of Kings. Even though these AI systems have achieved or even exceeded human-level performance, they still suffer from the lack of policy diversity. In this paper, we propose a novel Macro-Goals Guided framework, called MGG, to learn diverse policies in MOBA games. MGG abstracts strategies as macro-goals from human demonstrations and trains a Meta-Controller to predict these macro-goals. To enhance policy diversity, MGG samples macro-goals from the Meta-Controller prediction and guides the training process towards these goals. Experimental results on the typical MOBA game Honor of Kings demonstrate that MGG can execute diverse policies in different matches and lineups, and also outperform the state-of-the-art methods over 102 heroes.",
    "authors": [
      "Gao, Yiming",
      "Shi, Bei",
      "Du, Xueying",
      "Wang, Liang",
      "Chen, Guangwei",
      "Lian, Zhenjie",
      "Qiu, Fuhao",
      "HAN, GUOAN",
      "Wang, Weixuan",
      "Ye, Deheng",
      "Fu, Qiang",
      "Yang, Wei",
      "Huang, Lanxiao"
    ]
  },
  {
    "id": "86e8f7ab32cfd12577bc2619bc635690",
    "title": "Evaluation of Human-AI Teams for Learned and Rule-Based Agents in Hanabi",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/86e8f7ab32cfd12577bc2619bc635690-Paper.pdf",
    "abstract": "Deep reinforcement learning has generated superhuman AI in competitive games such as Go and StarCraft. Can similar learning techniques create a superior AI teammate for human-machine collaborative games? Will humans prefer AI teammates that improve objective team performance or those that improve subjective metrics of trust? In this study, we perform a single-blind evaluation of teams of humans and AI agents in the cooperative card game Hanabi, with both rule-based and learning-based agents. In addition to the game score, used as an objective metric of the human-AI team performance, we also quantify subjective measures of the human's perceived performance, teamwork, interpretability, trust, and overall preference of AI teammate. We find that humans have a clear preference toward a rule-based AI teammate (SmartBot) over a state-of-the-art learning-based AI teammate (Other-Play) across nearly all subjective metrics, and generally view the learning-based agent negatively, despite no statistical difference in the game score. This result has implications for future AI design and reinforcement learning benchmarking, highlighting the need to incorporate subjective metrics of human-AI teaming rather than a singular focus on objective task performance.",
    "authors": [
      "Siu, Ho Chit",
      "Pe\u00f1a, Jaime",
      "Chen, Edenna",
      "Zhou, Yutai",
      "Lopez, Victor",
      "Palko, Kyle",
      "Chang, Kimberlee",
      "Allen, Ross"
    ]
  },
  {
    "id": "8710ef761bbb29a6f9d12e4ef8e4379c",
    "title": "Counterfactual Invariance to Spurious Correlations in Text Classification",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8710ef761bbb29a6f9d12e4ef8e4379c-Paper.pdf",
    "abstract": "Informally, a 'spurious correlation' is the dependence of a model on some aspect of the input data that an analyst thinks shouldn't matter. In machine learning, these have a know-it-when-you-see-it character; e.g., changing the gender of a sentence's subject changes a sentiment predictor's output. To check for spurious correlations, we can 'stress test' models by perturbing irrelevant parts of input data and seeing if model predictions change. In this paper, we study stress testing using the tools of causal inference. We introduce counterfactual invariance as a formalization of the requirement that changing irrelevant parts of the input shouldn't change model predictions. We connect counterfactual invariance to out-of-domain model performance, and provide practical schemes for learning (approximately) counterfactual invariant predictors (without access to counterfactual examples). It turns out that both the means and implications of counterfactual invariance depend fundamentally on the true underlying causal structure of the data---in particular, whether the label causes the features or the features cause the label. Distinct causal structures require distinct regularization schemes to induce counterfactual invariance. Similarly, counterfactual invariance implies different domain shift guarantees depending on the underlying causal structure. This theory is supported by empirical results on text classification.",
    "authors": [
      "Veitch, Victor",
      "D'Amour, Alexander",
      "Yadlowsky, Steve",
      "Eisenstein, Jacob"
    ]
  },
  {
    "id": "8726bb30dc7ce15023daa8ff8402bcfd",
    "title": "Better Safe Than Sorry: Preventing Delusive Adversaries with Adversarial Training",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8726bb30dc7ce15023daa8ff8402bcfd-Paper.pdf",
    "abstract": "Delusive attacks aim to substantially deteriorate the test accuracy of the learning model by slightly perturbing the features of correctly labeled training examples. By formalizing this malicious attack as finding the worst-case training data within a specific $\\infty$-Wasserstein ball, we show that minimizing adversarial risk on the perturbed data is equivalent to optimizing an upper bound of natural risk on the original data. This implies that adversarial training can serve as a principled defense against delusive attacks. Thus, the test accuracy decreased by delusive attacks can be largely recovered by adversarial training. To further understand the internal mechanism of the defense, we disclose that adversarial training can resist the delusive perturbations by preventing the learner from overly relying on non-robust features in a natural setting. Finally, we complement our theoretical findings with a set of experiments on popular benchmark datasets, which show that the defense withstands six different practical attacks. Both theoretical and empirical results vote for adversarial training when confronted with delusive adversaries.",
    "authors": [
      "Tao, Lue",
      "Feng, Lei",
      "Yi, Jinfeng",
      "Huang, Sheng-Jun",
      "Chen, Songcan"
    ]
  },
  {
    "id": "8744cf92c88433f8cb04a02e6db69a0d",
    "title": "Determinantal point processes based on orthogonal polynomials for sampling minibatches in SGD",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8744cf92c88433f8cb04a02e6db69a0d-Paper.pdf",
    "abstract": "Stochastic gradient descent (SGD) is a cornerstone of machine learning. When the number $N$ of data items is large, SGD relies on constructing an unbiased estimator of the gradient of the empirical risk using a small subset of the original dataset, called a minibatch. Default minibatch construction involves uniformly sampling a subset of the desired size, but alternatives have been explored for variance reduction. In particular, experimental evidence suggests drawing minibatches from determinantal point processes (DPPs), tractable distributions over minibatches that favour diversity among selected items. However, like in recent work on DPPs for coresets, providing a systematic and principled understanding of how and why DPPs help has been difficult. In this work, we contribute an orthogonal polynomial-based determinantal point process paradigm for performing minibatch sampling in SGD. Our approach leverages the specific data distribution at hand, which endows it with greater sensitivity and power over existing data-agnostic methods. We substantiate our method via a detailed theoretical analysis of its convergence properties, interweaving between the discrete data set and the underlying continuous domain. In particular, we show how specific DPPs and a string of controlled approximations can lead to gradient estimators with a variance that decays faster with the batchsize than under uniform sampling. Coupled with existing finite-time guarantees for SGD on convex objectives, this entails that, for a large enough batchsize and a fixed budget of item-level gradients to evaluate, DPP minibatches lead to a smaller bound on the mean square approximation error than uniform minibatches. Moreover, our estimators are amenable to a recent algorithm that directly samples linear statistics of DPPs (i.e., the gradient estimator) without sampling the underlying DPP (i.e., the minibatch), thereby reducing computational overhead. We provide detailed synthetic as well as real data experiments to substantiate our theoretical claims.",
    "authors": [
      "Bardenet, R\u00e9mi",
      "Ghosh, Subhroshekhar",
      "LIN, Meixia"
    ]
  },
  {
    "id": "8757150decbd89b0f5442ca3db4d0e0e",
    "title": "Revisiting Contrastive Methods for Unsupervised Learning of Visual Representations",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8757150decbd89b0f5442ca3db4d0e0e-Paper.pdf",
    "abstract": "Contrastive self-supervised learning has outperformed supervised pretraining on many downstream tasks like segmentation and object detection. However, current methods are still primarily applied to curated datasets like ImageNet. In this paper, we first study how biases in the dataset affect existing methods. Our results show that an approach like MoCo works surprisingly well across: (i) object- versus scene-centric, (ii) uniform versus long-tailed and (iii) general versus domain-specific datasets. Second, given the generality of the approach, we try to realize further gains with minor modifications. We show that learning additional invariances - through the use of multi-scale cropping, stronger augmentations and nearest neighbors - improves the representations. Finally, we observe that MoCo learns spatially structured representations when trained with a multi-crop strategy. The representations can be used for semantic segment retrieval and video instance segmentation without finetuning. Moreover, the results are on par with specialized models. We hope this work will serve as a useful study for other researchers.",
    "authors": [
      "Van Gansbeke, Wouter",
      "Vandenhende, Simon",
      "Georgoulis, Stamatios",
      "Gool, Luc V"
    ]
  },
  {
    "id": "87682805257e619d49b8e0dfdc14affa",
    "title": "Neural Analysis and Synthesis: Reconstructing Speech from Self-Supervised Representations",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/87682805257e619d49b8e0dfdc14affa-Paper.pdf",
    "abstract": "We present a neural analysis and synthesis (NANSY) framework that can manipulate the voice, pitch, and speed of an arbitrary speech signal.  Most of the previous works have focused on using information bottleneck to disentangle analysis features for controllable synthesis, which usually results in poor reconstruction quality. We address this issue by proposing a novel training strategy based on information perturbation. The idea is to perturb information in the original input signal (e.g., formant, pitch, and frequency response), thereby letting synthesis networks selectively take essential attributes to reconstruct the input signal. Because NANSY does not need any bottleneck structures, it enjoys both high reconstruction quality and controllability. Furthermore, NANSY does not require any labels associated with speech data such as text and speaker information, but rather uses a new set of analysis features, i.e., wav2vec feature and newly proposed pitch feature, Yingram, which allows for fully self-supervised training. Taking advantage of fully self-supervised training, NANSY can be easily extended to a multilingual setting by simply training it with a multilingual dataset. The experiments show that NANSY can achieve significant improvement in performance in several applications such as zero-shot voice conversion, pitch shift, and time-scale modification.",
    "authors": [
      "Choi, Hyeong-Seok",
      "Lee, Juheon",
      "Kim, Wansoo",
      "Lee, Jie",
      "Heo, Hoon",
      "Lee, Kyogu"
    ]
  },
  {
    "id": "876e1c59023b1a0e95808168e1a8ff89",
    "title": "Auto-Encoding Knowledge Graph for Unsupervised Medical Report Generation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/876e1c59023b1a0e95808168e1a8ff89-Paper.pdf",
    "abstract": "Medical report generation, which aims to automatically generate a long and coherent report of a given medical image, has been receiving growing research interests. Existing approaches mainly adopt a supervised manner and heavily rely on coupled image-report pairs. However, in the medical domain, building a large-scale image-report paired dataset is both time-consuming and expensive. To relax the dependency on paired data, we propose an unsupervised model Knowledge Graph Auto-Encoder (KGAE) which accepts independent sets of images and reports in training. KGAE consists of a pre-constructed knowledge graph, a knowledge-driven encoder and a knowledge-driven decoder. The knowledge graph works as the shared latent space to bridge the visual and textual domains; The knowledge-driven encoder projects medical images and reports to the corresponding coordinates in this latent space and the knowledge-driven decoder generates a medical report given a coordinate in this space. Since the knowledge-driven encoder and decoder can be trained with independent sets of images and reports, KGAE is unsupervised. The experiments show that the unsupervised KGAE generates desirable medical reports without using any image-report training pairs. Moreover, KGAE can also work in both semi-supervised and supervised settings, and accept paired images and reports in training. By further fine-tuning with image-report pairs, KGAE consistently outperforms the current state-of-the-art models on two datasets.",
    "authors": [
      "Liu, Fenglin",
      "You, Chenyu",
      "Wu, Xian",
      "Ge, Shen",
      "wang, Sheng",
      "Sun, Xu"
    ]
  },
  {
    "id": "876f1f9954de0aa402d91bb988d12cd4",
    "title": "Diffusion Normalizing Flow",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/876f1f9954de0aa402d91bb988d12cd4-Paper.pdf",
    "abstract": "We present a novel generative modeling method called diffusion normalizing flow based on stochastic differential equations (SDEs). The algorithm consists of two neural SDEs: a forward SDE that gradually adds noise to the data to transform the data into Gaussian random noise, and a backward SDE that gradually removes the noise to sample from the data distribution. By jointly training the two neural SDEs to minimize a common cost function that quantifies the difference between the two, the backward SDE converges to a diffusion process the starts with a Gaussian distribution and ends with the desired data distribution. Our method is closely related to normalizing flow and diffusion probabilistic models, and can be viewed as a combination of the two. Compared with normalizing flow, diffusion normalizing flow is able to learn distributions with sharp boundaries. Compared with diffusion probabilistic models, diffusion normalizing flow requires fewer discretization steps and thus has better sampling efficiency. Our algorithm demonstrates competitive performance in both high-dimension data density estimation and image generation tasks.",
    "authors": [
      "Zhang, Qinsheng",
      "Chen, Yongxin"
    ]
  },
  {
    "id": "878d5691c824ee2aaf770f7d36c151d6",
    "title": "Introspective Distillation for Robust Question Answering",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/878d5691c824ee2aaf770f7d36c151d6-Paper.pdf",
    "abstract": "Question answering (QA) models are well-known to exploit data bias, e.g., the language prior in visual QA and the position bias in reading comprehension. Recent debiasing methods achieve good out-of-distribution (OOD) generalizability with a considerable sacrifice of the in-distribution (ID) performance. Therefore, they are only applicable in domains where the test distribution is known in advance. In this paper, we present a novel debiasing method called Introspective Distillation (IntroD) to make the best of both worlds for QA. Our key technical contribution is to blend the inductive bias of OOD and ID by introspecting whether a training sample fits in the factual ID world or the counterfactual OOD one. Experiments on visual QA datasets VQA v2, VQA-CP, and reading comprehension dataset SQuAD demonstrate that our proposed IntroD maintains the competitive OOD performance compared to other debiasing methods, while sacrificing little or even achieving better ID performance compared to the non-debiasing ones.",
    "authors": [
      "Niu, Yulei",
      "Zhang, Hanwang"
    ]
  },
  {
    "id": "87ae6fb631f7c8a627e8e28785d9992d",
    "title": "Rethinking the Pruning Criteria for Convolutional Neural Network",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/87ae6fb631f7c8a627e8e28785d9992d-Paper.pdf",
    "abstract": "Channel pruning is a popular technique for compressing convolutional neural networks (CNNs), where various pruning criteria have been proposed to remove the redundant filters. From our comprehensive experiments, we found two blind spots of pruning criteria: (1) Similarity: There are some strong similarities among several primary pruning criteria that are widely cited and compared. According to these criteria, the ranks of filters\u2019 Importance Score are almost identical, resulting in similar pruned structures. (2) Applicability: The filters' Importance Score measured by some pruning criteria are too close to distinguish the network redundancy well. In this paper, we analyze the above blind spots on different types of pruning criteria with layer-wise pruning or global pruning. We also break some stereotypes, such as that the results of $\\ell_1$ and $\\ell_2$ pruning are not always similar. These analyses are based on the empirical experiments and our assumption (Convolutional Weight Distribution Assumption) that the well-trained convolutional filters in each layer approximately follow a Gaussian-alike distribution. This assumption has been verified through systematic and extensive statistical tests.",
    "authors": [
      "Huang, Zhongzhan",
      "Shao, Wenqi",
      "Wang, Xinjiang",
      "Lin, Liang",
      "Luo, Ping"
    ]
  },
  {
    "id": "87f7ee4fdb57bdfd52179947211b7ebb",
    "title": "Adaptive Machine Unlearning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/87f7ee4fdb57bdfd52179947211b7ebb-Paper.pdf",
    "abstract": "Data deletion algorithms aim to remove the influence of deleted data points from trained models at a cheaper computational cost than fully retraining those models. However, for sequences of deletions, most prior work in the non-convex setting gives valid guarantees only for sequences that are chosen independently of the models that are published. If people choose to delete their data as a function of the published models (because they don\u2019t like what the models reveal about them, for example), then the update sequence is adaptive. In this paper, we give a general reduction from deletion guarantees against adaptive sequences to deletion guarantees against non-adaptive sequences, using differential privacy and its connection to max information. Combined with ideas from prior work which give guarantees for non-adaptive deletion sequences, this leads to extremely flexible algorithms able to handle arbitrary model classes and training methodologies, giving strong provable deletion guarantees for adaptive deletion sequences. We show in theory how prior work for non-convex models fails against adaptive deletion sequences, and use this intuition to design a practical attack against the SISA algorithm of Bourtoule et al. [2021] on CIFAR-10, MNIST, Fashion-MNIST.",
    "authors": [
      "Gupta, Varun",
      "Jung, Christopher",
      "Neel, Seth",
      "Roth, Aaron",
      "Sharifi-Malvajerdi, Saeed",
      "Waites, Chris"
    ]
  },
  {
    "id": "880610aa9f9de9ea7c545169c716f477",
    "title": "EditGAN: High-Precision Semantic Image Editing",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/880610aa9f9de9ea7c545169c716f477-Paper.pdf",
    "abstract": "Generative adversarial networks (GANs) have recently found applications in image editing. However, most GAN-based image editing methods often require large-scale datasets with semantic segmentation annotations for training, only provide high-level control, or merely interpolate between different images. Here, we propose EditGAN, a novel method for high-quality, high-precision semantic image editing, allowing users to edit images by modifying their highly detailed part segmentation masks, e.g., drawing a new mask for the headlight of a car. EditGAN builds on a GAN framework that jointly models images and their semantic segmentation, requiring only a handful of labeled examples \u2013 making it a scalable tool for editing. Specifically, we embed an image into the GAN\u2019s latent space and perform conditional latent code optimization according to the segmentation edit, which effectively also modifies the image. To amortize optimization, we find \u201cediting vectors\u201d in latent space that realize the edits. The framework allows us to learn an arbitrary number of editing vectors, which can then be directly applied on other images at interactive rates. We experimentally show that EditGAN can manipulate images with an unprecedented level of detail and freedom while preserving full image quality. We can also easily combine multiple edits and perform plausible edits beyond EditGAN\u2019s training data. We demonstrate EditGAN on a wide variety of image types and quantitatively outperform several previous editing methods on standard editing benchmark tasks.",
    "authors": [
      "Ling, Huan",
      "Kreis, Karsten",
      "Li, Daiqing",
      "Kim, Seung Wook",
      "Torralba, Antonio",
      "Fidler, Sanja"
    ]
  },
  {
    "id": "884d247c6f65a96a7da4d1105d584ddd",
    "title": "Deep Molecular Representation Learning via Fusing Physical and Chemical Information",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/884d247c6f65a96a7da4d1105d584ddd-Paper.pdf",
    "abstract": "Molecular representation learning is the first yet vital step in combining deep learning and molecular science. To push the boundaries of molecular representation learning, we present PhysChem, a novel neural architecture that learns molecular representations via fusing physical and chemical information of molecules. PhysChem is composed of a physicist network (PhysNet) and a chemist network (ChemNet). PhysNet is a neural physical engine that learns molecular conformations through simulating molecular dynamics with parameterized forces; ChemNet implements geometry-aware deep message-passing to learn chemical / biomedical properties of molecules. Two networks specialize in their own tasks and cooperate by providing expertise to each other. By fusing physical and chemical information, PhysChem achieved state-of-the-art performances on MoleculeNet, a standard molecular machine learning benchmark. The effectiveness of PhysChem was further corroborated on cutting-edge datasets of SARS-CoV-2.",
    "authors": [
      "Yang, Shuwen",
      "Li, Ziyao",
      "Song, Guojie",
      "Cai, Lingsheng"
    ]
  },
  {
    "id": "88591b4d3219675bdeb33584b755f680",
    "title": "Neural optimal feedback control with local learning rules",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/88591b4d3219675bdeb33584b755f680-Paper.pdf",
    "abstract": "A major problem in motor control is understanding how the brain plans and executes proper movements in the face of delayed and noisy stimuli. A prominent framework for addressing such control problems is Optimal Feedback Control (OFC). OFC generates control actions that optimize behaviorally relevant criteria by integrating noisy sensory stimuli and the predictions of an internal model using the Kalman filter or its extensions. However, a satisfactory neural model of Kalman filtering and control is lacking because existing proposals have the following  limitations: not considering the delay of sensory feedback, training in alternating phases, requiring knowledge of the noise covariance matrices, as well as that of systems dynamics. Moreover, the majority of these studies considered Kalman filtering in isolation, and not jointly with control. To address these shortcomings, we introduce a novel online algorithm which combines adaptive Kalman filtering with a model free control approach  (i.e., policy gradient algorithm). We implement this algorithm in a biologically plausible neural network with local synaptic plasticity rules. This network, with local synaptic plasticity rules, performs system identification, Kalman filtering and control with delayed noisy sensory feedback. This network performs system identification and Kalman filtering, without the need for multiple phases with distinct update rules or the knowledge of the noise covariances. It can perform state estimation  with delayed sensory feedback, with the help of an internal model. It learns the control policy without requiring any knowledge of the dynamics, thus avoiding the need for weight transport. In this way, our implementation of OFC solves the credit assignment problem needed to produce the appropriate sensory-motor control in the presence of stimulus delay.",
    "authors": [
      "Friedrich, Johannes",
      "Golkar, Siavash",
      "Farashahi, Shiva",
      "Genkin, Alexander",
      "Sengupta, Anirvan",
      "Chklovskii, Dmitri"
    ]
  },
  {
    "id": "8860e834a67da41edd6ffe8a1c58fa55",
    "title": "Reinforcement Learning in Linear MDPs: Constant Regret and Representation Selection",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8860e834a67da41edd6ffe8a1c58fa55-Paper.pdf",
    "abstract": "We study the role of the representation of state-action value functions in regret minimization in finite-horizon Markov Decision Processes (MDPs) with linear structure. We first derive a necessary condition on the representation, called universally spanning optimal features (UNISOFT), to achieve constant regret in any MDP with linear reward function. This result encompasses the well-known settings of low-rank MDPs and, more generally, zero inherent Bellman error (also known as the Bellman closure assumption). We then demonstrate that this condition is also sufficient for these classes of problems by deriving a constant regret bound for two optimistic algorithms (LSVI-UCB and ELEANOR). Finally, we propose an algorithm for representation selection and we prove that it achieves constant regret when one of the given representations, or a suitable combination of them, satisfies the UNISOFT condition.",
    "authors": [
      "Papini, Matteo",
      "Tirinzoni, Andrea",
      "Pacchiano, Aldo",
      "Restelli, Marcello",
      "Lazaric, Alessandro",
      "Pirotta, Matteo"
    ]
  },
  {
    "id": "886ad506e0c115cf590d18ebb6c26561",
    "title": "Noether Networks: meta-learning useful conserved quantities",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/886ad506e0c115cf590d18ebb6c26561-Paper.pdf",
    "abstract": "Progress in machine learning (ML) stems from a combination of data availability, computational resources, and an appropriate encoding of inductive biases. Useful biases often exploit symmetries in the prediction problem, such as convolutional networks relying on translation equivariance. Automatically discovering these useful symmetries holds the potential to greatly improve the performance of ML systems, but still remains a challenge. In this work, we focus on sequential prediction problems and take inspiration from Noether's theorem to reduce the problem of finding inductive biases to meta-learning useful conserved quantities. We propose Noether Networks: a new type of architecture where a meta-learned conservation loss is optimized inside the prediction function. We show, theoretically and experimentally, that Noether Networks improve prediction quality, providing a general framework for discovering inductive biases in sequential problems.",
    "authors": [
      "Alet, Ferran",
      "Doblar, Dylan",
      "Zhou, Allan",
      "Tenenbaum, Josh",
      "Kawaguchi, Kenji",
      "Finn, Chelsea"
    ]
  },
  {
    "id": "88a199611ac2b85bd3f76e8ee7e55650",
    "title": "Uncertainty-Driven Loss for Single Image Super-Resolution",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/88a199611ac2b85bd3f76e8ee7e55650-Paper.pdf",
    "abstract": "In low-level vision such as single image super-resolution (SISR), traditional MSE or L1 loss function treats every pixel equally with the assumption that the importance of all pixels is the same. However, it has been long recognized that texture and edge areas carry more important visual information than smooth areas in photographic images. How to achieve such spatial adaptation in a principled manner has been an open problem in both traditional model-based and modern learning-based approaches toward SISR. In this paper, we propose a new adaptive weighted loss for SISR to train deep networks focusing on challenging situations such as textured and edge pixels with high uncertainty. Specifically, we introduce variance estimation characterizing the uncertainty on a pixel-by-pixel basis into SISR solutions so the targeted pixels in a high-resolution image (mean) and their corresponding uncertainty (variance) can be learned simultaneously. Moreover, uncertainty estimation allows us to leverage conventional wisdom such as sparsity prior for regularizing SISR solutions. Ultimately, pixels with large certainty (e.g., texture and edge pixels) will be prioritized for SISR according to their importance to visual quality. For the first time, we demonstrate that such uncertainty-driven loss can achieve better results than MSE or L1 loss for a wide range of network architectures. Experimental results on three popular SISR networks show that our proposed uncertainty-driven loss has achieved better PSNR performance than traditional loss functions without any increased computation during testing. The code is available at https://see.xidian.edu.cn/faculty/wsdong/Projects/UDL-SR.htm",
    "authors": [
      "Ning, Qian",
      "Dong, Weisheng",
      "Li, Xin",
      "Wu, Jinjian",
      "Shi, GUANGMING"
    ]
  },
  {
    "id": "88ae6372cfdc5df69a976e893f4d554b",
    "title": "GradInit: Learning to Initialize Neural Networks for Stable and Efficient Training",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/88ae6372cfdc5df69a976e893f4d554b-Paper.pdf",
    "abstract": "Innovations in neural architectures have fostered significant breakthroughs in language modeling and computer vision. Unfortunately, novel architectures often result in challenging hyper-parameter choices and training instability if the network parameters are not properly initialized. A number of architecture-specific initialization schemes have been proposed, but these schemes are not always portable to new architectures. This paper presents GradInit, an automated and architecture agnostic method for initializing neural networks. GradInit is based on a simple heuristic; the norm of each network layer is adjusted so that a single step of SGD or Adam with prescribed hyperparameters results in the smallest possible loss value. This adjustment is done by introducing a scalar multiplier variable in front of each parameter block, and then optimizing these variables using a simple numerical scheme. GradInit accelerates the convergence and test performance of many convolutional architectures, both with or without skip connections, and even without normalization layers. It also improves the stability of the original Transformer architecture for machine translation, enabling training it without learning rate warmup using either Adam or SGD under a wide range of learning rates and momentum coefficients. Code is available at https://github.com/zhuchen03/gradinit.",
    "authors": [
      "Zhu, Chen",
      "Ni, Renkun",
      "Xu, Zheng",
      "Kong, Kezhi",
      "Huang, W. Ronny",
      "Goldstein, Tom"
    ]
  },
  {
    "id": "88d25099b103efd638163ecb40a55589",
    "title": "Capacity and Bias of Learned Geometric Embeddings for Directed Graphs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/88d25099b103efd638163ecb40a55589-Paper.pdf",
    "abstract": "A wide variety of machine learning tasks such as knowledge base completion, ontology alignment, and multi-label classification can benefit from incorporating into learning differentiable representations of graphs or taxonomies.  While vectors in Euclidean space can theoretically represent any graph, much recent work shows that alternatives such as complex, hyperbolic, order, or box embeddings have geometric properties better suited to modeling real-world graphs. Experimentally these gains are seen only in lower dimensions, however, with performance benefits diminishing in higher dimensions. In this work, we introduce a novel variant of box embeddings that uses a learned smoothing parameter to achieve better representational capacity than vector models in low dimensions, while also avoiding performance saturation common to other geometric models in high dimensions. Further, we present theoretical results that prove box embeddings can represent any DAG. We perform rigorous empirical evaluations of vector, hyperbolic, and region-based geometric representations on several families of synthetic and real-world directed graphs. Analysis of these results exposes correlations between different families of graphs, graph characteristics, model size, and embedding geometry, providing useful insights into the inductive biases of various differentiable graph representations.",
    "authors": [
      "Boratko, Michael",
      "Zhang, Dongxu",
      "Monath, Nicholas",
      "Vilnis, Luke",
      "Clarkson, Kenneth L",
      "McCallum, Andrew"
    ]
  },
  {
    "id": "88e1ce84f9feef5a08d0df0334c53468",
    "title": "Online Learning Of Neural Computations From Sparse Temporal Feedback",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/88e1ce84f9feef5a08d0df0334c53468-Paper.pdf",
    "abstract": "Neuronal computations depend on synaptic connectivity and intrinsic electrophysiological properties. Synaptic connectivity determines which inputs from presynaptic neurons are integrated, while cellular properties determine how inputs are filtered over time. Unlike their biological counterparts, most computational approaches to learning in simulated neural networks are limited to changes in synaptic connectivity. However, if intrinsic parameters change, neural computations are altered drastically. Here, we include the parameters that determine the intrinsic properties, e.g., time constants and reset potential, into the learning paradigm. Using sparse feedback signals that indicate target spike times, and gradient-based parameter updates, we show that the intrinsic parameters can be learned along with the synaptic weights to produce specific input-output functions. Specifically, we use  a teacher-student paradigm in which a randomly initialised leaky integrate-and-fire or resonate-and-fire neuron must recover the parameters of a teacher neuron. We show that complex temporal functions can be learned online and without backpropagation through time, relying on event-based updates only. Our results are a step towards online learning of neural computations from ungraded and unsigned sparse feedback signals with a biologically inspired learning mechanism.",
    "authors": [
      "Braun, Lukas",
      "Vogels, Tim"
    ]
  },
  {
    "id": "8929c70f8d710e412d38da624b21c3c8",
    "title": "Self-Supervised Learning with Data Augmentations Provably Isolates Content from Style",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8929c70f8d710e412d38da624b21c3c8-Paper.pdf",
    "abstract": "Self-supervised representation learning has shown remarkable success in a number of domains. A common practice is to perform data augmentation via hand-crafted transformations intended to leave the semantics of the data invariant. We seek to understand the empirical success of this approach from a theoretical perspective. We formulate the augmentation process as a latent variable model by postulating a partition of the latent representation into a content component, which is assumed invariant to augmentation, and a style component, which is allowed to change. Unlike prior work on disentanglement and independent component analysis, we allow for both nontrivial statistical and causal dependencies in the latent space. We study the identifiability of the latent representation based on pairs of views of the observations and prove sufficient conditions that allow us to identify the invariant content partition up to an invertible mapping in both generative and discriminative settings. We find numerical simulations with dependent latent variables are consistent with our theory. Lastly, we introduce Causal3DIdent, a dataset of high-dimensional, visually complex images with rich causal dependencies, which we use to study the effect of data augmentations performed in practice.",
    "authors": [
      "von K\u00fcgelgen, Julius",
      "Sharma, Yash",
      "Gresele, Luigi",
      "Brendel, Wieland",
      "Sch\u00f6lkopf, Bernhard",
      "Besserve, Michel",
      "Locatello, Francesco"
    ]
  },
  {
    "id": "892c91e0a653ba19df81a90f89d99bcd",
    "title": "Instance-Conditional Knowledge Distillation for Object Detection",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/892c91e0a653ba19df81a90f89d99bcd-Paper.pdf",
    "abstract": "Knowledge distillation has shown great success in classification, however, it is still challenging for detection. In a typical image for detection, representations from different locations may have different contributions to detection targets, making the distillation hard to balance. In this paper, we propose a conditional distillation framework to distill the desired knowledge, namely knowledge that is beneficial in terms of both classification and localization for every instance. The framework introduces a learnable conditional decoding module, which retrieves information given each target instance as query. Specifically, we encode the condition information as query and use the teacher's representations as key. The attention between query and key is used to measure the contribution of different features, guided by a localization-recognition-sensitive auxiliary task. Extensive experiments demonstrate the efficacy of our method: we observe impressive improvements under various settings. Notably, we boost RetinaNet with ResNet-50 backbone from $37.4$ to $40.7$ mAP ($+3.3$) under $1\\times$ schedule, that even surpasses the teacher ($40.4$ mAP) with ResNet-101 backbone under $3\\times$ schedule. Code has been released on https://github.com/megvii-research/ICD.",
    "authors": [
      "Kang, Zijian",
      "Zhang, Peizhen",
      "Zhang, Xiangyu",
      "Sun, Jian",
      "Zheng, Nanning"
    ]
  },
  {
    "id": "89562dccfeb1d0394b9ae7e09544dc70",
    "title": "Self-Supervised Representation Learning on Neural Network Weights for Model Characteristic Prediction",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/89562dccfeb1d0394b9ae7e09544dc70-Paper.pdf",
    "abstract": "Self-Supervised Learning (SSL) has been shown to learn useful and information-preserving representations. Neural Networks (NNs) are widely applied, yet their weight space is still not fully understood. Therefore, we propose to use SSL to learn hyper-representations of the weights of populations of NNs. To that end, we introduce domain specific data augmentations and an adapted attention architecture.  Our empirical evaluation demonstrates that self-supervised representation learning in this domain is able to recover diverse NN model characteristics. Further, we show that the proposed learned representations outperform prior work for predicting hyper-parameters, test accuracy, and generalization gap as well as transfer to out-of-distribution settings.",
    "authors": [
      "Sch\u00fcrholt, Konstantin",
      "Kostadinov, Dimche",
      "Borth, Damian"
    ]
  },
  {
    "id": "895daa408f494ad58006c47a30f51c1f",
    "title": "Multimodal Virtual Point 3D Detection",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/895daa408f494ad58006c47a30f51c1f-Paper.pdf",
    "abstract": "Lidar-based sensing drives current autonomous vehicles. Despite rapid progress, current Lidar sensors still lag two decades behind traditional color cameras in terms of resolution and cost. For autonomous driving, this means that large objects close to the sensors are easily visible, but far-away or small objects comprise only one measurement or two. This is an issue, especially when these objects turn out to be driving hazards. On the other hand, these same objects are clearly visible in onboard RGB sensors. In this work, we present an approach to seamlessly fuse RGB sensors into Lidar-based 3D recognition. Our approach takes a set of 2D detections to generate dense 3D virtual points to augment an otherwise sparse 3D point cloud. These virtual points naturally integrate into any standard Lidar-based 3D detectors along with regular Lidar measurements. The resulting multi-modal detector is simple and effective. Experimental results on the large-scale nuScenes dataset show that our framework improves a strong CenterPoint baseline by a significant $6.6$ mAP, and outperforms competing fusion approaches. Code and more visualizations are available at https://tianweiy.github.io/mvp/",
    "authors": [
      "Yin, Tianwei",
      "Zhou, Xingyi",
      "Kr\u00e4henb\u00fchl, Philipp"
    ]
  },
  {
    "id": "898aef0932f6aaecda27aba8e9903991",
    "title": "On Joint Learning for Solving Placement and Routing in Chip Design",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/898aef0932f6aaecda27aba8e9903991-Paper.pdf",
    "abstract": "For its advantage in GPU acceleration and less dependency on human experts, machine learning has been an emerging tool for solving the placement and routing problems, as two critical steps in modern chip design flow. Being still in its early stage, there are several fundamental issues unresolved: scalability, reward design, and end-to-end learning paradigm etc. To achieve end-to-end placement learning, we first propose a joint learning method for the placement of macros and standard cells, by the integration of reinforcement learning with a gradient based optimization scheme. To further bridge the placement with the subsequent routing task, we also develop a joint learning approach via reinforcement learning. One key design in our (reinforcement) learning paradigm involves a multi-view embedding model to encode both global graph level and local node level information of the input macros. Moreover, the random network distillation is devised to encourage exploration. Experiments on public chip design benchmarks show that our method can effectively learn from experience and also provide high-quality intermediate placement for the post standard cell placement, within few hours for training.",
    "authors": [
      "Cheng, Ruoyu",
      "Yan, Junchi"
    ]
  },
  {
    "id": "89ae0fe22c47d374bc9350ef99e01685",
    "title": "Learning with Algorithmic Supervision via Continuous Relaxations",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/89ae0fe22c47d374bc9350ef99e01685-Paper.pdf",
    "abstract": "The integration of algorithmic components into neural architectures has gained increased attention recently, as it allows training neural networks with new forms of supervision such as ordering constraints or silhouettes instead of using ground truth labels. Many approaches in the field focus on the continuous relaxation of a specific task and show promising results in this context. But the focus on single tasks also limits the applicability of the proposed concepts to a narrow range of applications. In this work, we build on those ideas to propose an approach that allows to integrate algorithms into end-to-end trainable neural network architectures based on a general approximation of discrete conditions. To this end, we relax these conditions in control structures such as conditional statements, loops, and indexing, so that resulting algorithms are smoothly differentiable. To obtain meaningful gradients, each relevant variable is perturbed via logistic distributions and the expectation value under this perturbation is approximated. We evaluate the proposed continuous relaxation model on four challenging tasks and show that it can keep up with relaxations specifically designed for each individual task.",
    "authors": [
      "Petersen, Felix",
      "Borgelt, Christian",
      "Kuehne, Hilde",
      "Deussen, Oliver"
    ]
  },
  {
    "id": "89b9c689a57b82e59074c6ba09aa394d",
    "title": "Differentiable Multiple Shooting Layers",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/89b9c689a57b82e59074c6ba09aa394d-Paper.pdf",
    "abstract": "We detail a novel class of implicit neural models. Leveraging time-parallel methods for differential equations, Multiple Shooting Layers  (MSLs) seek solutions of initial value problems via parallelizable root-finding algorithms. MSLs broadly serve as drop-in replacements for neural ordinary differential equations  (Neural ODEs) with improved efficiency in number of function evaluations (NFEs) and wall-clock inference time. We develop the algorithmic framework of MSLs, analyzing the different choices of solution methods from a theoretical and computational perspective. MSLs are showcased in long horizon optimal control of ODEs and PDEs and as latent models for sequence generation. Finally, we investigate the speedups obtained through application of MSL inference in neural controlled differential equations (Neural CDEs) for time series classification of medical data.",
    "authors": [
      "Massaroli, Stefano",
      "Poli, Michael",
      "Sonoda, Sho",
      "Suzuki, Taiji",
      "Park, Jinkyoo",
      "Yamashita, Atsushi",
      "Asama, Hajime"
    ]
  },
  {
    "id": "89d4402dc03d3b7318bbac10203034ab",
    "title": "Global-aware Beam Search for Neural Abstractive Summarization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/89d4402dc03d3b7318bbac10203034ab-Paper.pdf",
    "abstract": "This study develops a calibrated beam-based algorithm with awareness of the global attention distribution for neural abstractive summarization, aiming to improve the local optimality problem of the original beam search in a rigorous way. Specifically, a novel global protocol is proposed based on the attention distribution to stipulate how a global optimal hypothesis should attend to the source. A global scoring mechanism is then developed to regulate beam search to generate summaries in a near-global optimal fashion. This novel design enjoys a distinctive property, i.e., the global attention distribution could be predicted before inference, enabling step-wise improvements on the beam search through the global scoring mechanism. Extensive experiments on nine datasets show that the global (attention)-aware inference significantly improves state-of-the-art summarization models even using empirical hyper-parameters. The algorithm is also proven robust as it remains to generate meaningful texts with corrupted attention distributions. The codes and a comprehensive set of examples are available.",
    "authors": [
      "Ma, Ye",
      "Lan, Zixun",
      "Zong, Lu",
      "Huang, Kaizhu"
    ]
  },
  {
    "id": "89fcd07f20b6785b92134bd6c1d0fa42",
    "title": "DROID-SLAM: Deep Visual SLAM for Monocular, Stereo, and RGB-D Cameras",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/89fcd07f20b6785b92134bd6c1d0fa42-Paper.pdf",
    "abstract": "We introduce DROID-SLAM, a new deep learning based SLAM system. DROID-SLAM consists of recurrent iterative updates of camera pose and pixelwise depth through a Dense Bundle Adjustment layer. DROID-SLAM is accurate, achieving large improvements over prior work, and robust, suffering from substantially fewer catastrophic failures. Despite training on monocular video, it can leverage stereo or RGB-D video to achieve improved performance at test time. The URL to our open source code is https://github.com/princeton-vl/DROID-SLAM.",
    "authors": [
      "Teed, Zachary",
      "Deng, Jia"
    ]
  },
  {
    "id": "8a1e808b55fde9455cb3d8857ed88389",
    "title": "Few-Shot Object Detection via Association and DIscrimination",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8a1e808b55fde9455cb3d8857ed88389-Paper.pdf",
    "abstract": "Object detection has achieved substantial progress in the last decade. However, detecting novel classes with only few samples remains challenging, since deep learning under low data regime usually leads to a degraded feature space. Existing works employ a holistic fine-tuning paradigm to tackle this problem, where the model is first pre-trained on all base classes with abundant samples, and then it is used to carve the novel class feature space. Nonetheless, this paradigm is still imperfect. Durning fine-tuning, a novel class may implicitly leverage the knowledge of multiple base classes to construct its feature space, which induces a scattered feature space, hence violating the inter-class separability. To overcome these obstacles, we propose a two-step fine-tuning framework, Few-shot object detection via Association and DIscrimination (FADI), which builds up a discriminative feature space for each novel class with two integral steps. 1) In the association step, in contrast to implicitly leveraging multiple base classes, we construct a compact novel class feature space via explicitly imitating a specific base class feature space. Specifically, we associate each novel class with a base class according to their semantic similarity. After that, the feature space of a novel class can readily imitate the well-trained feature space of the associated base class. 2) In the discrimination step, to ensure the separability between the novel classes and associated base classes, we disentangle the classification branches for base and novel classes. To further enlarge the inter-class separability between all classes, a set-specialized margin loss is imposed. Extensive experiments on standard Pascal VOC and MS-COCO datasets demonstrate that FADI achieves new state-of-the-art performance, significantly improving the baseline in any shot/split by +18.7. Notably, the advantage of FADI is most announced on extremely few-shot scenarios (e.g. 1- and 3- shot).",
    "authors": [
      "Cao, Yuhang",
      "Wang, Jiaqi",
      "Jin, Ying",
      "Wu, Tong",
      "Chen, Kai",
      "Liu, Ziwei",
      "Lin, Dahua"
    ]
  },
  {
    "id": "8a9c8ac001d3ef9e4ce39b1177295e03",
    "title": "Neural Dubber: Dubbing for Videos According to Scripts",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8a9c8ac001d3ef9e4ce39b1177295e03-Paper.pdf",
    "abstract": "Dubbing is a post-production process of re-recording actors\u2019 dialogues, which is extensively used in filmmaking and video production. It is usually performed manually by professional voice actors who read lines with proper prosody, and in synchronization with the pre-recorded videos. In this work, we propose Neural Dubber, the first neural network model to solve a novel automatic video dubbing (AVD) task: synthesizing human speech synchronized with the given video from the text. Neural Dubber is a multi-modal text-to-speech (TTS) model that utilizes the lip movement in the video to control the prosody of the generated speech. Furthermore, an image-based speaker embedding (ISE) module is developed for the multi-speaker setting, which enables Neural Dubber to generate speech with a reasonable timbre according to the speaker\u2019s face. Experiments on the chemistry lecture single-speaker dataset and LRS2 multi-speaker dataset show that Neural Dubber can generate speech audios on par with state-of-the-art TTS models in terms of speech quality. Most importantly, both qualitative and quantitative evaluations show that Neural Dubber can control the prosody of synthesized speech by the video, and generate high-fidelity speech temporally synchronized with the video.",
    "authors": [
      "Hu, Chenxu",
      "Tian, Qiao",
      "Li, Tingle",
      "Yuping, Wang",
      "Wang, Yuxuan",
      "Zhao, Hang"
    ]
  },
  {
    "id": "8abfe8ac9ec214d68541fcb888c0b4c3",
    "title": "Neural Bootstrapper",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8abfe8ac9ec214d68541fcb888c0b4c3-Paper.pdf",
    "abstract": "Bootstrapping has been a primary tool for ensemble and uncertainty quantification in machine learning and statistics. However, due to its nature of multiple training and resampling, bootstrapping deep neural networks is computationally burdensome; hence it has difficulties in practical application to the uncertainty estimation and related tasks. To overcome this computational bottleneck, we propose a novel approach called Neural Bootstrapper (NeuBoots), which learns to generate bootstrapped neural networks through single model training. NeuBoots injects the bootstrap weights into the high-level feature layers of the backbone network and outputs the bootstrapped predictions of the target, without additional parameters and the repetitive computations from scratch. We apply NeuBoots to various machine learning tasks related to uncertainty quantification, including prediction calibrations in image classification and semantic segmentation, active learning, and detection of out-of-distribution samples. Our empirical results show that NeuBoots outperforms other bagging based methods under a much lower computational cost without losing the validity of bootstrapping.",
    "authors": [
      "Shin, Minsuk",
      "Cho, Hyungjoo",
      "Min, Hyun-seok",
      "Lim, Sungbin"
    ]
  },
  {
    "id": "8b0bb3eff8c1e5bf7f206125959921d7",
    "title": "An Axiomatic Theory of Provably-Fair Welfare-Centric Machine Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8b0bb3eff8c1e5bf7f206125959921d7-Paper.pdf",
    "abstract": "We address an inherent difficulty in welfare-theoretic fair machine learning (ML), by proposing an equivalently-axiomatically justified alternative setting, and studying the resulting computational and statistical learning questions. Welfare metrics quantify overall wellbeing across a population of groups, and welfare-based objectives and constraints have recently been proposed to incentivize fair ML methods to satisfy their diverse needs. However, many ML problems are cast as loss minimization tasks, rather than utility maximization, and thus require nontrivial modeling to construct utility functions. We define a complementary metric, termed malfare, measuring overall societal harm, with axiomatic justification via the standard axioms of cardinal welfare, and cast fair ML as malfare minimization over the risk values (expected losses) of each group. Surprisingly, the axioms of cardinal welfare (malfare) dictate that this is not equivalent to simply defining utility as negative loss and maximizing welfare. Building upon these concepts, we define fair-PAC learning, where a fair-PAC learner is an algorithm that learns an \u03b5-\u03b4 malfare-optimal model with bounded sample complexity, for any data distribution and (axiomatically justified) malfare concept. Finally, we show conditions under which many standard PAC-learners may be converted to fair-PAC learners, which places fair-PAC learning on firm theoretical ground, as it yields statistical \u2014 and in some cases computational \u2014 efficiency guarantees for many well-studied ML models. Fair-PAC learning is also practically relevant, as it democratizes fair ML by providing concrete training algorithms with rigorous generalization guarantees.",
    "authors": [
      "Cousins, Cyrus"
    ]
  },
  {
    "id": "8b0d268963dd0cfb808aac48a549829f",
    "title": "HSVA: Hierarchical Semantic-Visual Adaptation for Zero-Shot Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8b0d268963dd0cfb808aac48a549829f-Paper.pdf",
    "abstract": "Zero-shot learning (ZSL) tackles the unseen class recognition problem,  transferring semantic knowledge from seen classes to unseen ones. Typically, to guarantee desirable knowledge transfer, a common (latent) space is adopted for associating the visual and semantic domains in ZSL.  However, existing common space learning methods align the semantic and visual domains by merely mitigating distribution disagreement through one-step adaptation. This strategy is usually ineffective due to the heterogeneous nature of the feature representations in the two domains, which intrinsically contain both distribution and structure variations. To address this and advance ZSL, we propose a novel hierarchical semantic-visual adaptation (HSVA) framework. Specifically, HSVA aligns the semantic and visual domains by adopting a hierarchical two-step adaptation, i.e., structure adaptation and distribution adaptation. In the structure adaptation step, we take two task-specific encoders to encode the source data (visual domain) and the target data (semantic domain) into a structure-aligned common space. To this end, a  supervised adversarial discrepancy (SAD)  module is proposed to adversarially minimize the discrepancy between the predictions of two task-specific classifiers, thus making the visual and semantic feature manifolds more closely aligned. In the distribution adaptation step, we directly minimize the Wasserstein distance between the latent multivariate Gaussian distributions to align the visual and semantic distributions using a common encoder. Finally, the structure and distribution adaptation are derived in a unified framework under two partially-aligned variational autoencoders. Extensive experiments on four benchmark datasets demonstrate that HSVA achieves superior performance on both conventional and generalized ZSL. The code is available at \\url{https://github.com/shiming-chen/HSVA}.",
    "authors": [
      "Chen, Shiming",
      "Xie, Guosen",
      "Liu, Yang",
      "Peng, Qinmu",
      "Sun, Baigui",
      "Li, Hao",
      "You, Xinge",
      "Shao, Ling"
    ]
  },
  {
    "id": "8b2dfbe0c1d43f9537dae01e96458ff1",
    "title": "Higher Order Kernel Mean Embeddings to Capture Filtrations of Stochastic Processes",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8b2dfbe0c1d43f9537dae01e96458ff1-Paper.pdf",
    "abstract": "Stochastic processes are random variables with values in some space of paths. However, reducing a stochastic process to a path-valued random variable ignores its filtration, i.e. the flow of information carried by the process through time. By conditioning the process on its filtration, we introduce a family of higher order kernel mean embeddings (KMEs) that generalizes the notion of KME to capture additional information related to the filtration. We derive empirical estimators for the associated higher order maximum mean discrepancies (MMDs) and prove consistency. We then construct a filtration-sensitive kernel two-sample test able to capture information that gets missed by the standard MMD test. In addition, leveraging our higher order MMDs we construct a family of universal kernels on stochastic processes that allows to solve real-world calibration and optimal stopping problems in quantitative finance (such as the pricing of American options) via classical kernel-based regression methods. Finally, adapting existing tests for conditional independence to the case of stochastic processes, we design a causal-discovery algorithm to recover the causal graph of structural dependencies among interacting bodies solely from observations of their multidimensional trajectories.",
    "authors": [
      "Salvi, Cristopher",
      "Lemercier, Maud",
      "Liu, Chong",
      "Horvath, Blanka",
      "Damoulas, Theodoros",
      "Lyons, Terry"
    ]
  },
  {
    "id": "8b4066554730ddfaa0266346bdc1b202",
    "title": "Low-Rank Subspaces in GANs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8b4066554730ddfaa0266346bdc1b202-Paper.pdf",
    "abstract": "The latent space of a Generative Adversarial Network (GAN) has been shown to encode rich semantics within some subspaces. To identify these subspaces, researchers typically analyze the statistical information from a collection of synthesized data, and the identified subspaces tend to control image attributes globally (i.e., manipulating an attribute causes the change of an entire image). By contrast, this work introduces low-rank subspaces that enable more precise control of GAN generation. Concretely, given an arbitrary image and a region of interest (e.g., eyes of face images), we manage to relate the latent space to the image region with the Jacobian matrix and then use low-rank factorization to discover steerable latent subspaces. There are three distinguishable strengths of our approach that can be aptly called LowRankGAN. First, compared to analytic algorithms in prior work, our low-rank factorization of Jacobians is able to find the low-dimensional representation of attribute manifold, making image editing more precise and controllable.  Second, low-rank factorization naturally yields a null space of attributes such that moving the latent code within it only affects the outer region of interest. Therefore, local image editing can be simply achieved by projecting an attribute vector into the null space without relying on a spatial mask as existing methods do. Third, our method can robustly work with a local region from one image for analysis yet well generalize to other images, making it much easy to use in practice. Extensive experiments on state-of-the-art GAN models (including StyleGAN2 and BigGAN) trained on various datasets demonstrate the effectiveness of our LowRankGAN.",
    "authors": [
      "Zhu, Jiapeng",
      "Feng, Ruili",
      "Shen, Yujun",
      "Zhao, Deli",
      "Zha, Zheng-Jun",
      "Zhou, Jingren",
      "Chen, Qifeng"
    ]
  },
  {
    "id": "8b519f198dd26772e3e82874826b04aa",
    "title": "Neural Symplectic Form: Learning Hamiltonian Equations on General Coordinate Systems",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8b519f198dd26772e3e82874826b04aa-Paper.pdf",
    "abstract": "In recent years, substantial research on the methods for learning Hamiltonian equations has been conducted. Although these approaches are very promising, the commonly used representation of the Hamilton equation uses the generalized momenta, which are generally unknown. Therefore, the training data must be represented in this unknown coordinate system, and this causes difficulty in applying the model to real data. Meanwhile, Hamiltonian equations also have a coordinate-free expression that is expressed by using the symplectic 2-form. In this study, we propose a model that learns the symplectic form from data using neural networks, thereby providing a method for learning Hamiltonian equations from data represented in general coordinate systems, which are not limited to the generalized coordinates and the generalized momenta. Consequently, the proposed method is capable not only of modeling target equations of both Hamiltonian and Lagrangian formalisms but also of extracting unknown Hamiltonian structures hidden in the data. For example, many polynomial ordinary differential equations such as the Lotka-Volterra equation are known to admit non-trivial Hamiltonian structures, and our numerical experiments show that such structures can be certainly learned from data. Technically, each symplectic 2-form is associated with a skew-symmetric matrix, but not all skew-symmetric matrices define the symplectic 2-form. In the proposed method, using the fact that symplectic 2-forms are derived as the exterior derivative of certain differential 1-forms, we model the differential 1-form by neural networks, thereby improving the efficiency of learning.",
    "authors": [
      "Chen, Yuhan",
      "Matsubara, Takashi",
      "Yaguchi, Takaharu"
    ]
  },
  {
    "id": "8b5700012be65c9da25f49408d959ca0",
    "title": "Sample-Efficient Reinforcement Learning Is Feasible for Linearly Realizable MDPs with Limited Revisiting",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8b5700012be65c9da25f49408d959ca0-Paper.pdf",
    "abstract": "Low-complexity models such as linear function representation play a pivotal role in enabling sample-efficient reinforcement learning (RL). The current paper pertains to a scenario with value-based linear representation, which postulates linear realizability of the optimal Q-function (also called the ``linear $Q^{\\star}$ problem''). While linear realizability alone does not allow for sample-efficient solutions in general, the presence of a large sub-optimality gap is a potential game changer, depending on the sampling mechanism in use.  Informally, sample efficiency is achievable with a large sub-optimality gap when a generative model is available, but is unfortunately infeasible when we turn to standard online RL settings.  We make progress towards understanding this linear $Q^{\\star}$ problem by investigating a new sampling protocol, which draws samples in an online/exploratory fashion but allows one to backtrack and revisit previous states. This protocol is more flexible than the standard online RL setting, while being practically relevant and far more restrictive than the generative model. We develop an algorithm tailored to this setting, achieving a sample complexity that scales polynomially with the feature dimension, the horizon, and the inverse sub-optimality gap, but not the size of the state/action space. Our findings underscore the fundamental interplay between sampling protocols and low-complexity function representation in RL.  ",
    "authors": [
      "Li, Gen",
      "Chen, Yuxin",
      "Chi, Yuejie",
      "Gu, Yuantao",
      "Wei, Yuting"
    ]
  },
  {
    "id": "8b5c8441a8ff8e151b191c53c1842a38",
    "title": "Self-Paced Contrastive Learning for Semi-supervised Medical Image Segmentation with Meta-labels",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8b5c8441a8ff8e151b191c53c1842a38-Paper.pdf",
    "abstract": "The contrastive pre-training of a recognition model on a large dataset of unlabeled data often boosts the model\u2019s performance on downstream tasks like image classification. However, in domains such as medical imaging, collecting unlabeled data can be challenging and expensive. In this work, we consider the task of medical image segmentation and adapt contrastive learning with meta-label annotations to scenarios where no additional unlabeled data is available. Meta-labels, such as the location of a 2D slice in a 3D MRI scan, often come for free during the acquisition process. We use these meta-labels to pre-train the image encoder, as well as in a semi-supervised learning step that leverages a reduced set of annotated data. A self-paced learning strategy exploiting the weak annotations is proposed to furtherhelp the learning process and discriminate useful labels from noise. Results on five medical image segmentation datasets show that our approach: i) highly boosts the performance of a model trained on a few scans, ii) outperforms previous contrastive and semi-supervised approaches, and iii) reaches close to the performance of a model trained on the full data.",
    "authors": [
      "Peng, Jizong",
      "Wang, Ping",
      "Desrosiers, Christian",
      "Pedersoli, Marco"
    ]
  },
  {
    "id": "8b77b4b5156dc11dec152c6c71481565",
    "title": "Reverse engineering recurrent neural networks with Jacobian switching linear dynamical systems",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8b77b4b5156dc11dec152c6c71481565-Paper.pdf",
    "abstract": "Recurrent neural networks (RNNs) are powerful models for processing time-series data, but it remains challenging to understand how they function. Improving this understanding is of substantial interest to both the machine learning and neuroscience communities. The framework of reverse engineering a trained RNN by linearizing around its fixed points has provided insight, but the approach has significant challenges. These include difficulty choosing which fixed point to expand around when studying RNN dynamics and error accumulation when reconstructing the nonlinear dynamics with the linearized dynamics. We present a new model that overcomes these limitations by co-training an RNN with a novel switching linear dynamical system (SLDS) formulation. A first-order Taylor series expansion of the co-trained RNN and an auxiliary function trained to pick out the RNN's fixed points govern the SLDS dynamics. The results are a trained SLDS variant that closely approximates the RNN, an auxiliary function that can produce a fixed point for each point in state-space, and a trained nonlinear RNN whose dynamics have been regularized such that its first-order terms perform the computation, if possible. This model removes the post-training fixed point optimization and allows us to unambiguously study the learned dynamics of the SLDS at any point in state-space.  It also generalizes SLDS models to continuous manifolds of switching points while sharing parameters across switches. We validate the utility of the model on two synthetic tasks relevant to previous work reverse engineering RNNs. We then show that our model can be used as a drop-in in more complex architectures, such as LFADS, and apply this LFADS hybrid to analyze single-trial spiking activity from the motor system of a non-human primate.",
    "authors": [
      "Smith, Jimmy",
      "Linderman, Scott",
      "Sussillo, David"
    ]
  },
  {
    "id": "8b8388180314a337c9aa3c5aa8e2f37a",
    "title": "Learning-Augmented Dynamic Power Management with Multiple States via New Ski Rental Bounds",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8b8388180314a337c9aa3c5aa8e2f37a-Paper.pdf",
    "abstract": "We study the online problem of minimizing power consumption in systems with multiple power-saving states. During idle periods of unknown lengths, an algorithm has to choose between power-saving states of different energy consumption and wake-up costs. We develop a learning-augmented online algorithm that makes decisions based on (potentially inaccurate) predicted lengths of the idle periods. The algorithm's performance is near-optimal when predictions are accurate and degrades gracefully with increasing prediction error, with a worst-case guarantee almost identical to the optimal classical online algorithm for the problem. A key ingredient in our approach is a new algorithm for the online ski-rental problem in the learning augmented setting with tight dependence on the prediction error. We support our theoretical findings with experiments.",
    "authors": [
      "Antoniadis, Antonios",
      "Coester, Christian",
      "Elias, Marek",
      "Polak, Adam",
      "Simon, Bertrand"
    ]
  },
  {
    "id": "8b9e7ab295e87570551db122a04c6f7c",
    "title": "Learning Equivariant Energy Based Models with Equivariant Stein Variational Gradient Descent",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8b9e7ab295e87570551db122a04c6f7c-Paper.pdf",
    "abstract": "We focus on the problem of efficient sampling and learning of probability densities by incorporating symmetries in probabilistic models. We first introduce Equivariant Stein Variational Gradient Descent algorithm -- an equivariant sampling method based on Stein's identity for sampling from densities with symmetries. Equivariant SVGD explicitly incorporates symmetry information in a density through equivariant kernels which makes the resultant sampler efficient both in terms of sample complexity and the quality of generated samples. Subsequently, we define equivariant energy based models to model invariant densities that are learned using contrastive divergence. By utilizing our equivariant SVGD for training equivariant EBMs, we propose new ways of improving and scaling up training of energy based models. We apply these equivariant energy models for modelling joint densities in regression and classification tasks for image datasets, many-body particle systems and molecular structure generation.  ",
    "authors": [
      "Jaini, Priyank",
      "Holdijk, Lars",
      "Welling, Max"
    ]
  },
  {
    "id": "8ba6c657b03fc7c8dd4dff8e45defcd2",
    "title": "Information Directed Sampling for Sparse Linear Bandits",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8ba6c657b03fc7c8dd4dff8e45defcd2-Paper.pdf",
    "abstract": "Stochastic sparse linear bandits offer a practical model for high-dimensional online decision-making problems and have a rich information-regret structure. In this work we explore the use of information-directed sampling (IDS), which naturally balances the information-regret trade-off. We develop a class of information-theoretic Bayesian regret bounds that nearly match existing lower bounds on a variety of problem instances, demonstrating the adaptivity of IDS. To efficiently implement sparse IDS, we propose an empirical Bayesian approach for sparse posterior sampling using a spike-and-slab Gaussian-Laplace prior.  Numerical results demonstrate significant regret reductions by sparse IDS relative to several baselines.",
    "authors": [
      "Hao, Botao",
      "Lattimore, Tor",
      "Deng, Wei"
    ]
  },
  {
    "id": "8be627bc543fd91be4d7f26ee86f5ee9",
    "title": "Linear Convergence of Gradient Methods for Estimating Structured Transition Matrices in High-dimensional Vector Autoregressive Models",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8be627bc543fd91be4d7f26ee86f5ee9-Paper.pdf",
    "abstract": "In this paper, we present non-asymptotic optimization guarantees of gradient descent methods for estimating structured transition matrices in high-dimensional vector autoregressive (VAR) models. We adopt the projected gradient descent (PGD) for single-structured transition matrices and the alternating projected gradient descent (AltPGD) for superposition-structured ones. Our analysis demonstrates that both gradient algorithms converge linearly to the statistical error even though the strong convexity of the objective function is absent under the high-dimensional settings. Moreover our result is sharp (up to a constant factor) in the sense of matching the phase transition theory of the corresponding  model with independent samples. To the best of our knowledge, this analysis constitutes first non-asymptotic optimization guarantees of the linear rate for regularized estimation in  high-dimensional VAR models. Numerical results are provided to support our theoretical analysis.",
    "authors": [
      "Lv, Xiao",
      "Cui, Wei",
      "Liu, Yulong"
    ]
  },
  {
    "id": "8bf1211fd4b7b94528899de0a43b9fb3",
    "title": "Large-Scale Unsupervised Object Discovery",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8bf1211fd4b7b94528899de0a43b9fb3-Paper.pdf",
    "abstract": "Existing approaches to unsupervised object discovery (UOD) do not scale up to large datasets without approximations that compromise their performance. We propose a novel formulation of UOD as a ranking problem, amenable to the arsenal of distributed methods available for eigenvalue problems and link analysis. Through the use of self-supervised features, we also demonstrate the first  effective fully unsupervised pipeline for UOD. Extensive experiments on COCO~\\cite{Lin2014cocodataset} and OpenImages~\\cite{openimages} show that, in the single-object discovery setting where a single prominent object is sought in each image, the proposed LOD (Large-scale Object Discovery) approach is on par with, or better than the state of the art for medium-scale datasets (up to 120K images), and over 37\\% better than the only other algorithms capable of scaling up to 1.7M images. In the multi-object discovery setting where multiple objects are sought in each image, the proposed LOD is over 14\\% better in average precision (AP) than all other methods for datasets ranging from 20K to 1.7M images. Using self-supervised features, we also show that the proposed method obtains state-of-the-art UOD performance on OpenImages.",
    "authors": [
      "Vo, Van Huy",
      "Sizikova, Elena",
      "Schmid, Cordelia",
      "P\u00e9rez, Patrick",
      "Ponce, Jean"
    ]
  },
  {
    "id": "8c1b6fa97c4288a4514365198566c6fa",
    "title": "Sparse Steerable Convolutions: An Efficient Learning of SE(3)-Equivariant Features for Estimation and Tracking of Object Poses in 3D Space",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8c1b6fa97c4288a4514365198566c6fa-Paper.pdf",
    "abstract": "As a basic component of SE(3)-equivariant deep feature learning, steerable convolution has recently demonstrated its advantages for 3D semantic analysis. The advantages are, however, brought by expensive computations on dense, volumetric data, which prevent its practical use for efficient processing of 3D data that are inherently sparse. In this paper, we propose a novel design of Sparse Steerable Convolution (SS-Conv) to address the shortcoming; SS-Conv greatly accelerates steerable convolution with sparse tensors, while strictly preserving the property of SE(3)-equivariance. Based on SS-Conv, we propose a general pipeline for precise estimation of object poses, wherein a key design is a Feature-Steering module that  takes the full advantage of SE(3)-equivariance and is able to conduct an efficient pose refinement. To verify our designs, we conduct thorough experiments on three tasks of 3D object semantic analysis, including instance-level 6D pose estimation, category-level 6D pose and size estimation, and category-level 6D pose tracking. Our proposed pipeline based on SS-Conv outperforms existing methods on almost all the metrics evaluated by the three tasks. Ablation studies also show the superiority of our SS-Conv over alternative convolutions in terms of both accuracy and efficiency. Our code is released publicly at https://github.com/Gorilla-Lab-SCUT/SS-Conv.",
    "authors": [
      "Lin, Jiehong",
      "Li, Hongyang",
      "Chen, Ke",
      "Lu, Jiangbo",
      "Jia, Kui"
    ]
  },
  {
    "id": "8c249675aea6c3cbd91661bbae767ff1",
    "title": "Noisy Adaptation Generates L\u00e9vy Flights in Attractor Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8c249675aea6c3cbd91661bbae767ff1-Paper.pdf",
    "abstract": "L\u00e9vy flights describe a special class of random walks whose step sizes satisfy a power-law tailed distribution. As being an efficientsearching strategy in unknown environments, L\u00e9vy flights are widely observed in animal foraging behaviors. Recent studies further showed that human cognitive functions also exhibit the characteristics of L\u00e9vy flights.  Despite being a general phenomenon, the neural mechanism at the circuit level for generating L\u00e9vy flights remains unresolved. Here, we investigate how L\u00e9vy flights can be achieved in attractor neural networks. To elucidate the underlying mechanism clearly, we first study continuous attractor neural networks (CANNs), and find that noisy neural adaptation, exemplified by spike frequency adaptation (SFA) in this work,  can generate L\u00e9vy flights representing transitions of the network state in the attractor space. Specifically, the strength of SFA defines a travelling wave boundary, below which the network state displays local Brownian motion, and above which the network state displays long-jump motion. Noises in neural adaptation causes the network state to intermittently switch between these two motion modes, manifesting the characteristics of L\u00e9vy flights. We further extend the study to a general attractor neural network, and demonstrate that our model can explain the L\u00e9vy-flight phenomenon observed during free memory retrieval of humans. We hope that this study will give us insight into understanding the neural mechanism for optimal information processing in the brain.",
    "authors": [
      "Dong, Xingsi",
      "Chu, Tianhao",
      "Huang, Tiejun",
      "Ji, Zilong",
      "Wu, Si"
    ]
  },
  {
    "id": "8c26d2fad09dc76f3ff36b6ea752b0e1",
    "title": "On Linear Stability of SGD and Input-Smoothness of Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8c26d2fad09dc76f3ff36b6ea752b0e1-Paper.pdf",
    "abstract": "The multiplicative structure of parameters and input data in the first layer of neural networks is explored to build connection between the landscape of the loss function with respect to parameters and the landscape of the model function with respect to input data. By this connection, it is shown that flat minima regularize the gradient of the model function, which explains the good generalization performance of flat minima. Then, we go beyond the flatness and consider high-order moments of the gradient noise, and show that Stochastic Gradient Dascent (SGD) tends to impose constraints on these moments by a linear stability analysis of SGD around global minima. Together with the multiplicative structure, we identify the Sobolev regularization effect of SGD, i.e. SGD regularizes the Sobolev seminorms of the model function with respect to the input data. Finally, bounds for generalization error and adversarial robustness are provided for solutions found by SGD under assumptions of the data distribution. ",
    "authors": [
      "Ma, Chao",
      "Ying, Lexing"
    ]
  },
  {
    "id": "8c3c27ac7d298331a1bdfd0a5e8703d3",
    "title": "Joint inference and input optimization in equilibrium networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8c3c27ac7d298331a1bdfd0a5e8703d3-Paper.pdf",
    "abstract": "Many tasks in deep learning involve optimizing over the inputs to a network to minimize or maximize some objective; examples include optimization over latent spaces in a generative model to match a target image, or adversarially perturbing an input to worsen classifier performance.  Performing such optimization, however, is traditionally quite costly, as it involves a complete forward and backward pass through the network for each gradient step.  In a separate line of work, a recent thread of research has developed the deep equilibrium (DEQ) model, a class of models that foregoes traditional network depth and instead computes the output of a network by finding the fixed point of a single nonlinear layer. In this paper, we show that there is a natural synergy between these two settings. Although, naively using DEQs for these optimization problems is expensive (owing to the time needed to compute a fixed point for each gradient step), we can leverage the fact that gradient-based optimization can itself be cast as a fixed point iteration to substantially improve the overall speed. That is, we simultaneously both solve for the DEQ fixed point and optimize over network inputs, all within a single \"augmented\" DEQ model that jointly encodes both the original network and the optimization process.  Indeed, the procedure is fast enough that it allows us to efficiently train DEQ models for tasks traditionally relying on an \"inner\" optimization loop.  We demonstrate this strategy on various tasks such as training generative models while optimizing over latent codes, training models for inverse problems like denoising and inpainting, adversarial training and gradient based meta-learning.",
    "authors": [
      "Gurumurthy, Swaminathan",
      "Bai, Shaojie",
      "Manchester, Zachary",
      "Kolter, J. Zico"
    ]
  },
  {
    "id": "8c460674cd61bf189e62b4da4bd9d7c1",
    "title": "A unified framework for bandit multiple testing",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8c460674cd61bf189e62b4da4bd9d7c1-Paper.pdf",
    "abstract": "In bandit multiple hypothesis testing, each arm corresponds to a different null hypothesis that we wish to test, and the goal is to design adaptive algorithms that correctly identify large set of interesting arms (true discoveries), while only mistakenly identifying a few uninteresting ones (false discoveries). One common metric in non-bandit multiple testing is the false discovery rate (FDR). We propose a unified, modular framework for bandit FDR control that emphasizes the decoupling of exploration and summarization of evidence. We utilize the powerful martingale-based concept of \"e-processes\" to ensure FDR control for arbitrary composite nulls, exploration rules and stopping times in generic problem settings. In particular, valid FDR control holds even if the reward distributions of the arms could be dependent, multiple arms may be queried simultaneously, and multiple (cooperating or competing) agents may be querying arms, covering combinatorial semi-bandit type settings as well. Prior work has considered in great detail the setting where each arm's reward distribution is independent and sub-Gaussian, and a single arm is queried at each step. Our framework recovers matching sample complexity guarantees in this special case, and performs comparably or better in practice. For other settings, sample complexities will depend on the finer details of the problem (composite nulls being tested, exploration algorithm, data dependence structure, stopping rule) and we do not explore these; our contribution is to show that the FDR guarantee is clean and entirely agnostic to these details. ",
    "authors": [
      "Xu, Ziyu",
      "Wang, Ruodu",
      "Ramdas, Aaditya"
    ]
  },
  {
    "id": "8c6744c9d42ec2cb9e8885b54ff744d0",
    "title": "Recovering Latent Causal Factor for Generalization to Distributional Shifts",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8c6744c9d42ec2cb9e8885b54ff744d0-Paper.pdf",
    "abstract": "Distributional shifts between training and target domains may degrade the prediction accuracy of learned models, mainly because these models often learn features that possess only correlation rather than causal relation with the output. Such a correlation, which is known as ``spurious correlation'' statistically, is domain-dependent hence may fail to generalize to unseen domains. To avoid such a spurious correlation, we propose \\textbf{La}tent \\textbf{C}ausal \\textbf{I}nvariance \\textbf{M}odels (LaCIM) that specifies the underlying causal structure of the data and the source of distributional shifts, guiding us to pursue only causal factor for prediction. Specifically, the LaCIM introduces a pair of correlated latent factors: (a) causal factor and (b) others, while the extent of this correlation is governed by a domain variable that characterizes the distributional shifts. On the basis of this, we prove that the distribution of observed variables conditioning on latent variables is shift-invariant. Equipped with such an invariance, we prove that the causal factor can be recovered without mixing information from others, which induces the ground-truth predicting mechanism. We propose a Variational-Bayesian-based method to learn this invariance for prediction. The utility of our approach is verified by improved generalization to distributional shifts on various real-world data. Our code is freely available at \\url{https://github.com/wubotong/LaCIM}.",
    "authors": [
      "Sun, Xinwei",
      "Wu, Botong",
      "Zheng, Xiangyu",
      "Liu, Chang",
      "Chen, Wei",
      "Qin, Tao",
      "Liu, Tie-Yan"
    ]
  },
  {
    "id": "8c9f32e03aeb2e3000825c8c875c4edd",
    "title": "Graph Differentiable Architecture Search with Structure Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8c9f32e03aeb2e3000825c8c875c4edd-Paper.pdf",
    "abstract": "Discovering ideal Graph Neural Networks (GNNs) architectures for different tasks is labor intensive and time consuming. To save human efforts, Neural Architecture Search (NAS) recently has been used to automatically discover adequate GNN architectures for certain tasks in order to achieve competitive or even better performance compared with manually designed architectures. However, existing works utilizing NAS to search GNN structures fail to answer the question: how NAS is able to select the desired GNN architectures? In this paper, we investigate this question to solve the problem, for the first time. We conduct a measurement study with experiments to discover that gradient based NAS methods tend to select proper architectures based on the usefulness of different types of information with respect to the target task. Our explorations further show that gradient based NAS also suffers from noises hidden in the graph, resulting in searching suboptimal GNN architectures. Based on our findings, we propose a Graph differentiable Architecture Search model with Structure Optimization (GASSO), which allows differentiable search of the architecture with gradient descent and is able to discover graph neural architectures with better performance through employing graph structure learning as a denoising process in the search procedure. The proposed GASSO model is capable of simultaneously searching the optimal architecture and adaptively adjusting graph structure by jointly optimizing graph architecture search and graph structure denoising. Extensive experiments on real-world graph datasets demonstrate that our proposed GASSO model is able to achieve state-of-the-art performance compared with existing baselines.",
    "authors": [
      "Qin, Yijian",
      "Wang, Xin",
      "Zhang, Zeyang",
      "Zhu, Wenwu"
    ]
  },
  {
    "id": "8ca01ea920679a0fe3728441494041b9",
    "title": "Designing Counterfactual Generators using Deep Model Inversion",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8ca01ea920679a0fe3728441494041b9-Paper.pdf",
    "abstract": "Explanation techniques that synthesize small, interpretable changes to a given image while producing desired changes in the model prediction have become popular for introspecting black-box models. Commonly referred to as counterfactuals, the synthesized explanations are required to contain discernible changes (for easy interpretability) while also being realistic (consistency to the data manifold). In this paper, we focus on the case where we have access only to the trained deep classifier and not the actual training data. While the problem of inverting deep models to synthesize images from the training distribution has been explored, our goal is to develop a deep inversion approach to generate counterfactual explanations for a given query image. Despite their effectiveness in conditional image synthesis, we show that existing deep inversion methods are insufficient for producing meaningful counterfactuals. We propose DISC (Deep Inversion for Synthesizing Counterfactuals) that improves upon deep inversion by utilizing (a) stronger image priors, (b) incorporating a novel manifold consistency objective and (c) adopting a progressive optimization strategy. We find that, in addition to producing visually meaningful explanations, the counterfactuals from DISC are effective at learning classifier decision boundaries and are robust to unknown test-time corruptions.",
    "authors": [
      "Thiagarajan, Jayaraman",
      "Narayanaswamy, Vivek Sivaraman",
      "Rajan, Deepta",
      "Liang, Jia",
      "Chaudhari, Akshay",
      "Spanias, Andreas"
    ]
  },
  {
    "id": "8ca696ca160520b1cf5a569b4be525e8",
    "title": "A Faster Maximum Cardinality Matching Algorithm with Applications in Machine Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8ca696ca160520b1cf5a569b4be525e8-Paper.pdf",
    "abstract": "Maximum cardinality bipartite matching is an important graph optimization problem with several applications. For instance, maximum cardinality matching in a $\\delta$-disc graph can be used in the computation of the bottleneck matching as well as the $\\infty$-Wasserstein and the L\u00e9vy-Prokhorov distances between probability distributions. For any point sets $A, B \\subset \\mathbb{R}^2$, the $\\delta$-disc graph is a bipartite graph formed by connecting every pair of points $(a,b) \\in A\\times B$ by an edge if the Euclidean distance between them is at most $\\delta$. Using the classical Hopcroft-Karp algorithm, a maximum-cardinality matching on any $\\delta$-disc graph can be found in $\\tilde{O}(n^{3/2})$ time.~\\footnote{We use $\\tilde{O}(\\cdot)$ to suppress poly-logarithmic terms in the complexity.} In this paper, we present a simplification of a recent algorithm (Lahn and Raghvendra, JoCG 2021) for the maximum cardinality matching problem and describe how a maximum cardinality matching in a $\\delta$-disc graph can be computed asymptotically faster than $O(n^{3/2})$ time for any moderately dense point set. As applications, we show that if $A$ and $B$ are point sets drawn uniformly at random from a unit square, an exact bottleneck matching can be computed in $\\tilde{O}(n^{4/3})$ time. On the other hand, experiments suggest that the Hopcroft-Karp algorithm seems to take roughly $\\Theta (n^{3/2})$ time for this case. This translates to substantial improvements in execution time for larger inputs.",
    "authors": [
      "Lahn, Nathaniel",
      "Raghvendra, Sharath",
      "Ye, Jiacheng"
    ]
  },
  {
    "id": "8caa38721906c1a0bb95c80fab33a893",
    "title": "Dynamic population-based meta-learning for multi-agent communication with natural language",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8caa38721906c1a0bb95c80fab33a893-Paper.pdf",
    "abstract": "In this work, our goal is to train agents that can coordinate with seen, unseen as well as human partners in a multi-agent communication environment involving natural language. Previous work using a single set of agents has shown great progress in generalizing to known partners, however it struggles when coordinating with unfamiliar agents. To mitigate that, recent work explored the use of population-based approaches, where multiple agents interact with each other with the goal of learning more generic protocols. These methods, while able to result in good coordination between unseen partners, still only achieve so in cases of simple languages, thus failing to adapt to human partners using natural language. We attribute this to the use of static populations and instead propose a dynamic population-based meta-learning approach that builds such a population in an iterative manner. We perform a holistic evaluation of our method on two different referential games, and show that our agents outperform all prior work when communicating with seen partners and humans. Furthermore, we analyze the natural language generation skills of our agents, where we find that our agents also outperform strong baselines. Finally, we test the robustness of our agents when communicating with out-of-population agents and carefully test the importance of each component of our method through ablation studies.  ",
    "authors": [
      "Gupta, Abhinav",
      "Lanctot, Marc",
      "Lazaridou, Angeliki"
    ]
  },
  {
    "id": "8cbe9ce23f42628c98f80fa0fac8b19a",
    "title": "Adversarial Neuron Pruning Purifies Backdoored Deep Models",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8cbe9ce23f42628c98f80fa0fac8b19a-Paper.pdf",
    "abstract": "As deep neural networks (DNNs) are growing larger, their requirements for computational resources become huge, which makes outsourcing training more popular. Training in a third-party platform, however, may introduce potential risks that a malicious trainer will return backdoored DNNs, which behave normally on clean samples but output targeted misclassifications whenever a trigger appears at the test time. Without any knowledge of the trigger, it is difficult to distinguish or recover benign DNNs from backdoored ones. In this paper, we first identify an unexpected sensitivity of backdoored DNNs, that is, they are much easier to collapse and tend to predict the target label on clean samples when their neurons are adversarially perturbed. Based on these observations, we propose a novel model repairing method, termed Adversarial Neuron Pruning (ANP), which prunes some sensitive neurons to purify the injected backdoor. Experiments show, even with only an extremely small amount of clean data (e.g., 1%), ANP effectively removes the injected backdoor without causing obvious performance degradation.",
    "authors": [
      "Wu, Dongxian",
      "Wang, Yisen"
    ]
  },
  {
    "id": "8ccfb1140664a5fa63177fb6e07352f0",
    "title": "Towards Robust and Reliable Algorithmic Recourse",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8ccfb1140664a5fa63177fb6e07352f0-Paper.pdf",
    "abstract": "As predictive models are increasingly being deployed in high-stakes decision making (e.g., loan approvals), there has been growing interest in post-hoc techniques which provide recourse to affected individuals.  These techniques generate recourses under the assumption that the underlying predictive model does not change. However, in practice, models are often regularly updated for a variety of reasons (e.g., dataset shifts), thereby rendering previously prescribed recourses ineffective.To address this problem, we propose a novel framework, RObust Algorithmic Recourse (ROAR), that leverages adversarial training for finding recourses that are robust to model shifts. To the best of our knowledge, this work proposes the first ever solution to this critical problem. We also carry out theoretical analysis which underscores the importance of constructing recourses that are robust to model shifts: 1) We quantify the probability of invalidation for recourses generated without accounting for model shifts. 2) We prove that the additional cost incurred due to the robust recourses output by our framework is bounded. Experimental evaluation on multiple synthetic and real-world datasets demonstrates the efficacy of the proposed framework.",
    "authors": [
      "Upadhyay, Sohini",
      "Joshi, Shalmali",
      "Lakkaraju, Himabindu"
    ]
  },
  {
    "id": "8ce241e1ed84937ee48322b170b9b18c",
    "title": "Neural Rule-Execution Tracking Machine For Transformer-Based Text Generation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8ce241e1ed84937ee48322b170b9b18c-Paper.pdf",
    "abstract": "Sequence-to-Sequence (Seq2Seq) neural text generation models, especially the pre-trained ones (e.g., BART and T5), have exhibited compelling performance on various natural language generation tasks. However, the black-box nature of these models limits their application in tasks where specific rules (e.g., controllable constraints, prior knowledge) need to be executed. Previous works either design specific model structures (e.g., Copy Mechanism corresponding to the rule \"the generated output should include certain words in the source input'') or implement specialized inference algorithms (e.g., Constrained Beam Search) to execute particular rules through the text generation. These methods require the careful design case-by-case and are difficult to support multiple rules concurrently. In this paper, we propose a novel module named Neural Rule-Execution Tracking Machine (NRETM) that can be equipped into various transformer-based generators to leverage multiple rules simultaneously to guide the neural generation model for superior generation performance in an unified and scalable way. Extensive experiments on several benchmarks verify the effectiveness of our proposed model in both controllable and general text generation tasks.",
    "authors": [
      "Wang, Yufei",
      "Xu, Can",
      "Hu, Huang",
      "Tao, Chongyang",
      "Wan, Stephen",
      "Dras, Mark",
      "Johnson, Mark",
      "Jiang, Daxin"
    ]
  },
  {
    "id": "8ce8b102d40392a688f8c04b3cd6cae0",
    "title": "Scalable Online Planning via Reinforcement Learning Fine-Tuning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8ce8b102d40392a688f8c04b3cd6cae0-Paper.pdf",
    "abstract": "Lookahead search has been a critical component of recent AI successes, such as in the games of chess, go, and poker. However, the search methods used in these games, and in many other settings, are tabular. Tabular search methods do not scale well with the size of the search space, and this problem is exacerbated by stochasticity and partial observability. In this work we replace tabular search with online model-based fine-tuning of a policy neural network via reinforcement learning, and show that this approach outperforms state-of-the-art search algorithms in benchmark settings. In particular, we use our search algorithm to achieve a new state-of-the-art result in self-play Hanabi, and show the generality of our algorithm by also showing that it outperforms tabular search in the Atari game Ms. Pacman.",
    "authors": [
      "Fickinger, Arnaud",
      "Hu, Hengyuan",
      "Amos, Brandon",
      "Russell, Stuart",
      "Brown, Noam"
    ]
  },
  {
    "id": "8cfef17bee2b7a75a3ce09d40b497f6b",
    "title": "Adversarial Regression with Doubly Non-negative Weighting Matrices",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8cfef17bee2b7a75a3ce09d40b497f6b-Paper.pdf",
    "abstract": "Many machine learning tasks that involve predicting an output response can be solved by training a weighted regression model. Unfortunately, the predictive power of this type of models may severely deteriorate under low sample sizes or under covariate perturbations. Reweighting the training samples has aroused as an effective mitigation strategy to these problems. In this paper, we propose a novel and coherent scheme for kernel-reweighted regression by reparametrizing the sample weights using a doubly non-negative matrix. When the weighting matrix is confined in an uncertainty set using either the log-determinant divergence or the Bures-Wasserstein distance, we show that the adversarially reweighted estimate can be solved efficiently using first-order methods. Numerical experiments show that our reweighting strategy delivers promising results on numerous datasets.",
    "authors": [
      "Le, Tam",
      "Nguyen, Truyen",
      "Yamada, Makoto",
      "Blanchet, Jose",
      "Nguyen, Viet Anh"
    ]
  },
  {
    "id": "8d2355364e9a2ba1f82f975414937b43",
    "title": "Learned Robust PCA: A Scalable Deep Unfolding Approach for High-Dimensional Outlier Detection",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8d2355364e9a2ba1f82f975414937b43-Paper.pdf",
    "abstract": "Robust principal component analysis (RPCA) is a critical tool in modern machine learning, which detects outliers in the task of low-rank matrix reconstruction. In this paper, we propose a scalable and learnable non-convex approach for high-dimensional RPCA problems, which we call Learned Robust PCA (LRPCA). LRPCA is highly efficient, and its free parameters can be effectively learned to optimize via deep unfolding. Moreover, we extend deep unfolding from finite iterations to infinite iterations via a novel feedforward-recurrent-mixed neural network model. We establish the recovery guarantee of LRPCA under mild assumptions for RPCA. Numerical experiments show that LRPCA outperforms the state-of-the-art RPCA algorithms, such as ScaledGD and AltProj, on both synthetic datasets and real-world applications. ",
    "authors": [
      "Cai, HanQin",
      "Liu, Jialin",
      "Yin, Wotao"
    ]
  },
  {
    "id": "8d2a5f7d4afa5d0530789d3066945330",
    "title": "Proxy-Normalizing Activations to Match Batch Normalization while Removing Batch Dependence",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8d2a5f7d4afa5d0530789d3066945330-Paper.pdf",
    "abstract": "We investigate the reasons for the performance degradation incurred with batch-independent normalization. We find that the prototypical techniques of layer normalization and instance normalization both induce the appearance of failure modes in the neural network's pre-activations: (i) layer normalization induces a collapse towards channel-wise constant functions; (ii) instance normalization induces a lack of variability in instance statistics, symptomatic of an alteration of the expressivity. To alleviate failure mode (i) without aggravating failure mode (ii), we introduce the technique \"Proxy Normalization\" that normalizes post-activations using a proxy distribution. When combined with layer normalization or group normalization, this batch-independent normalization emulates batch normalization's behavior and consistently matches or exceeds its performance.",
    "authors": [
      "Labatie, Antoine",
      "Masters, Dominic",
      "Eaton-Rosen, Zach",
      "Luschi, Carlo"
    ]
  },
  {
    "id": "8d3369c4c086f236fabf61d614a32818",
    "title": "Dynamic Bottleneck for Robust Self-Supervised Exploration",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8d3369c4c086f236fabf61d614a32818-Paper.pdf",
    "abstract": "Exploration methods based on pseudo-count of transitions or curiosity of dynamics have achieved promising results in solving reinforcement learning with sparse rewards. However, such methods are usually sensitive to environmental dynamics-irrelevant information, e.g., white-noise. To handle such dynamics-irrelevant information, we propose a Dynamic Bottleneck (DB) model, which attains a dynamics-relevant representation based on the information-bottleneck principle. Based on the DB model, we further propose DB-bonus, which encourages the agent to explore state-action pairs with high information gain. We establish theoretical connections between the proposed DB-bonus, the upper confidence bound (UCB) for linear case, and the visiting count for tabular case. We evaluate the proposed method on Atari suits with dynamics-irrelevant noises. Our experiments show that exploration with DB bonus outperforms several state-of-the-art exploration methods in noisy environments.",
    "authors": [
      "Bai, Chenjia",
      "Wang, Lingxiao",
      "Han, Lei",
      "Garg, Animesh",
      "Hao, Jianye",
      "Liu, Peng",
      "Wang, Zhaoran"
    ]
  },
  {
    "id": "8d34201a5b85900908db6cae92723617",
    "title": "ProTo: Program-Guided Transformer for Program-Guided Tasks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8d34201a5b85900908db6cae92723617-Paper.pdf",
    "abstract": "Programs, consisting of semantic and structural information, play an important role in the communication between humans and agents. Towards learning general program executors to unify perception, reasoning, and decision making, we formulate program-guided tasks which require learning to execute a given program on the observed task specification. Furthermore, we propose Program-Guided Transformers (ProTo), which integrates both semantic and structural guidance of a program by leveraging cross-attention and masked self-attention to pass messages between the specification and routines in the program. ProTo executes a program in a learned latent space and enjoys stronger representation ability than previous neural-symbolic approaches. We demonstrate that ProTo significantly outperforms the previous state-of-the-art methods on GQA visual reasoning and 2D Minecraft policy learning datasets. Additionally, ProTo demonstrates better generalization to unseen, complex, and human-written programs.",
    "authors": [
      "Zhao, Zelin",
      "Samel, Karan",
      "Chen, Binghong",
      "song, lee"
    ]
  },
  {
    "id": "8d9a6e908ed2b731fb96151d9bb94d49",
    "title": "An Efficient Transfer Learning Framework for Multiagent Reinforcement Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8d9a6e908ed2b731fb96151d9bb94d49-Paper.pdf",
    "abstract": "Transfer Learning has shown great potential to enhance single-agent Reinforcement Learning (RL) efficiency. Similarly, Multiagent RL (MARL) can also be accelerated if agents can share knowledge with each other. However, it remains a problem of how an agent should learn from other agents. In this paper, we propose a novel Multiagent Policy Transfer Framework (MAPTF) to improve MARL efficiency. MAPTF learns which agent's policy is the best to reuse for each agent and when to terminate it by modeling multiagent policy transfer as the option learning problem. Furthermore, in practice, the option module can only collect all agent's local experiences for update due to the partial observability of the environment. While in this setting, each agent's experience may be inconsistent with each other, which may cause the inaccuracy and oscillation of the option-value's estimation. Therefore, we propose a novel option learning algorithm, the successor representation option learning to solve it by decoupling the environment dynamics from rewards and learning the option-value under each agent's preference. MAPTF can be easily combined with existing deep RL and MARL approaches, and experimental results show it significantly boosts the performance of existing methods in both discrete and continuous state spaces.",
    "authors": [
      "Yang, Tianpei",
      "Wang, Weixun",
      "Tang, Hongyao",
      "Hao, Jianye",
      "Meng, Zhaopeng",
      "Mao, Hangyu",
      "Li, Dong",
      "Liu, Wulong",
      "Chen, Yingfeng",
      "Hu, Yujing",
      "Fan, Changjie",
      "Zhang, Chengwei"
    ]
  },
  {
    "id": "8da57fac3313174128cc5f13328d4573",
    "title": "Learning to Time-Decode in Spiking Neural Networks Through the Information Bottleneck",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8da57fac3313174128cc5f13328d4573-Paper.pdf",
    "abstract": "One of the key challenges in training Spiking Neural Networks (SNNs) is that target outputs typically come in the form of natural signals, such as labels for classification or images for generative models, and need to be encoded into spikes. This is done by handcrafting target spiking signals, which in turn implicitly fixes the mechanisms used to decode spikes into natural signals, e.g., rate decoding. The arbitrary choice of target signals and decoding rule generally impairs the capacity of the SNN to encode and process information in the timing of spikes. To address this problem, this work introduces a hybrid variational autoencoder architecture, consisting of an encoding SNN and a decoding Artificial Neural Network (ANN). The role of the decoding ANN is to learn how to best convert the spiking signals output by the SNN into the target natural signal. A novel end-to-end learning rule is introduced that optimizes a directed information bottleneck training criterion via surrogate gradients. We demonstrate the applicability of the technique in an experimental settings on various tasks, including real-life datasets. ",
    "authors": [
      "Skatchkovsky, Nicolas",
      "Simeone, Osvaldo",
      "Jang, Hyeryung"
    ]
  },
  {
    "id": "8dd291cbea8f231982db0fb1716dfc55",
    "title": "NEO: Non Equilibrium Sampling on the Orbits of a Deterministic Transform",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8dd291cbea8f231982db0fb1716dfc55-Paper.pdf",
    "abstract": "Sampling from a complex distribution $\\pi$ and approximating its intractable normalizing constant $\\mathrm{Z}$ are challenging problems. In this paper, a novel family of importance samplers (IS) and Markov chain Monte Carlo (MCMC) samplers is derived. Given an invertible map $\\mathrm{T}$, these schemes combine (with weights) elements from the forward and backward Orbits   through points sampled from a proposal distribution $\\rho$. The map $\\mathrm{T}$ does not leave the target $\\pi$ invariant, hence the name NEO, standing for Non-Equilibrium Orbits. NEO-IS provides unbiased estimators of the normalizing constant and self-normalized IS estimators of expectations under $\\pi$ while NEO-MCMC combines multiple NEO-IS estimates of the normalizing constant and an iterated sampling-importance resampling mechanism to sample from $\\pi$. For $\\mathrm{T}$ chosen as a discrete-time integrator of a conformal Hamiltonian system, NEO-IS achieves state-of-the art performance on difficult benchmarks and NEO-MCMC is able to explore highly multimodal targets. Additionally, we provide detailed theoretical results for both methods. In particular, we show that NEO-MCMC is uniformly geometrically ergodic and establish explicit mixing time estimates under mild conditions.",
    "authors": [
      "Thin, Achille",
      "Janati El Idrissi, Yazid",
      "Le Corff, Sylvain",
      "Ollion, Charles",
      "Moulines, Eric",
      "Doucet, Arnaud",
      "Durmus, Alain",
      "Robert, Christian X"
    ]
  },
  {
    "id": "8df6a65941e4c9da40a4fb899de65c55",
    "title": "Relaxing Local Robustness",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8df6a65941e4c9da40a4fb899de65c55-Paper.pdf",
    "abstract": "Certifiable local robustness, which rigorously precludes small-norm adversarial examples, has received significant attention as a means of addressing security concerns in deep learning. However, for some classification problems, local robustness is not a natural objective, even in the presence of adversaries; for example, if an image contains two classes of subjects, the correct label for the image may be considered arbitrary between the two, and thus enforcing strict separation between them is unnecessary. In this work, we introduce two relaxed safety properties for classifiers that address this observation: (1) relaxed top-k robustness, which serves as the analogue of top-k accuracy; and (2) affinity robustness, which specifies which sets of labels must be separated by a robustness margin, and which can be $\\epsilon$-close in $\\ell_p$ space. We show how to construct models that can be efficiently certified against each relaxed robustness property, and trained with very little overhead relative to standard gradient descent. Finally, we demonstrate experimentally that these relaxed variants of robustness are well-suited to several significant classification problems, leading to lower rejection rates and higher certified accuracies than can be obtained when certifying \"standard\" local robustness.",
    "authors": [
      "Leino, Klas",
      "Fredrikson, Matt"
    ]
  },
  {
    "id": "8df7c2e3c3c3be098ef7b382bd2c37ba",
    "title": "Tuning Large Neural Networks via Zero-Shot Hyperparameter Transfer",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8df7c2e3c3c3be098ef7b382bd2c37ba-Paper.pdf",
    "abstract": "Hyperparameter (HP) tuning in deep learning is an expensive process, prohibitively so for neural networks (NNs) with billions of parameters.We show that, in the recently discovered Maximal Update Parametrization ($\\mu$P), many optimal HPs remain stable even as model size changes. This leads to a new HP tuning paradigm we call *$\\mu$Transfer*: parametrize the target model in $\\mu$P, tune the HP indirectly on a smaller model, and *zero-shot transfer* them to the full-sized model, i.e., without directly tuning the latter at all.We verify $\\mu$Transfer on Transformer and ResNet. For example, 1) by transferring pretraining HPs from a model of 13M parameters, we outperform published numbers of BERT-large (350M parameters), with a total tuning cost equivalent to pretraining BERT-large once; 2) by transferring from 40M parameters, we outperform published numbers of the 6.7B GPT-3 model, with tuning cost only 7% of total pretraining cost. A Pytorch implementation of our technique can be found at github.com/microsoft/mup. See arxiv.org for the full, up-to-date version of this work.",
    "authors": [
      "Yang, Ge",
      "Hu, Edward",
      "Babuschkin, Igor",
      "Sidor, Szymon",
      "Liu, Xiaodong",
      "Farhi, David",
      "Ryder, Nick",
      "Pachocki, Jakub",
      "Chen, Weizhu",
      "Gao, Jianfeng"
    ]
  },
  {
    "id": "8e036cc193d0af59aa9b22821248292b",
    "title": "Statistical Regeneration Guarantees of the Wasserstein Autoencoder with Latent Space Consistency",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8e036cc193d0af59aa9b22821248292b-Paper.pdf",
    "abstract": "The introduction of Variational Autoencoders (VAE) has been marked as a breakthrough in the history of representation learning models. Besides having several accolades of its own, VAE has successfully flagged off a series of inventions in the form of its immediate successors. Wasserstein Autoencoder (WAE), being an heir to that realm carries with it all of the goodness and heightened generative promises, matching even the generative adversarial networks (GANs). Needless to say, recent years have witnessed a remarkable resurgence in statistical analyses of the GANs. Similar examinations for Autoencoders however, despite their diverse applicability and notable empirical performance, remain largely absent. To close this gap, in this paper, we investigate the statistical properties of WAE. Firstly, we provide statistical guarantees that WAE achieves the target distribution in the latent space, utilizing the Vapnik\u2013Chervonenkis (VC) theory. The main result, consequently ensures the regeneration of the input distribution, harnessing the potential offered by Optimal Transport of measures under the Wasserstein metric. This study, in turn, hints at the class of distributions WAE can reconstruct after suffering a compression in the form of a latent law. ",
    "authors": [
      "Chakrabarty, Anish",
      "Das, Swagatam"
    ]
  },
  {
    "id": "8e08227323cd829e449559bb381484b7",
    "title": "Leveraging the Inductive Bias of Large Language Models for Abstract Textual Reasoning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8e08227323cd829e449559bb381484b7-Paper.pdf",
    "abstract": "Large natural language models (LMs) (such as GPT-3 or T5) demonstrate impressive abilities across a range of general NLP tasks. Here, we show that the knowledge embedded in such models provides a useful inductive bias, not just on traditional NLP tasks, but also in the nontraditional task of training a symbolic reasoning engine. We observe that these engines learn quickly and generalize in a natural way that reflects human intuition. For example, training such a system to model block-stacking might naturally generalize to stacking other types of objects because of structure in the real world that has been partially captured by the language describing it. We study several abstract textual reasoning tasks, such as object manipulation and navigation, and demonstrate multiple types of generalization to novel scenarios and the symbols that comprise them. We also demonstrate the surprising utility of $\\textit{compositional learning}$, where a learner dedicated to mastering a complicated task gains an advantage by training on relevant simpler tasks instead of jumping straight to the complicated task. ",
    "authors": [
      "Rytting, Christopher",
      "Wingate, David"
    ]
  },
  {
    "id": "8e296a067a37563370ded05f5a3bf3ec",
    "title": "Differentiable Simulation of Soft Multi-body Systems",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8e296a067a37563370ded05f5a3bf3ec-Paper.pdf",
    "abstract": "We present a method for differentiable simulation of soft articulated bodies. Our work enables the integration of differentiable physical dynamics into gradient-based pipelines. We develop a top-down matrix assembly algorithm within Projective Dynamics and derive a generalized dry friction model for soft continuum using a new matrix splitting strategy. We derive a differentiable control framework for soft articulated bodies driven by muscles, joint torques, or pneumatic tubes. The experiments demonstrate that our designs make soft body simulation more stable and realistic compared to other frameworks. Our method accelerates the solution of system identification problems by more than an order of magnitude, and enables efficient gradient-based learning of motion control with soft robots.",
    "authors": [
      "Qiao, Yiling",
      "Liang, Junbang",
      "Koltun, Vladlen",
      "Lin, Ming"
    ]
  },
  {
    "id": "8e489b4966fe8f703b5be647f1cbae63",
    "title": "Good Classification Measures and How to Find Them",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8e489b4966fe8f703b5be647f1cbae63-Paper.pdf",
    "abstract": "Several performance measures can be used for evaluating classification results: accuracy, F-measure, and many others. Can we say that some of them are better than others, or, ideally, choose one measure that is best in all situations? To answer this question, we conduct a systematic analysis of classification performance measures: we formally define a list of desirable properties and theoretically analyze which measures satisfy which properties. We also prove an impossibility theorem: some desirable properties cannot be simultaneously satisfied. Finally, we propose a new family of measures satisfying all desirable properties except one. This family includes the Matthews Correlation Coefficient and a so-called Symmetric Balanced Accuracy that was not previously used in classification literature. We believe that our systematic approach gives an important tool to practitioners for adequately evaluating classification results.",
    "authors": [
      "G\u00f6sgens, Martijn",
      "Zhiyanov, Anton",
      "Tikhonov, Aleksey",
      "Prokhorenkova, Liudmila"
    ]
  },
  {
    "id": "8e5e15c4e6d09c8333a17843461041a9",
    "title": "Distilling Robust and Non-Robust Features in Adversarial Examples by Information Bottleneck",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8e5e15c4e6d09c8333a17843461041a9-Paper.pdf",
    "abstract": "Adversarial examples, generated by carefully crafted perturbation, have attracted considerable attention in research fields. Recent works have argued that the existence of the robust and non-robust features is a primary cause of the adversarial examples, and investigated their internal interactions in the feature space. In this paper, we propose a way of explicitly distilling feature representation into the robust and non-robust features, using Information Bottleneck. Specifically, we inject noise variation to each feature unit and evaluate the information flow in the feature representation to dichotomize feature units either robust or non-robust, based on the noise variation magnitude. Through comprehensive experiments, we demonstrate that the distilled features are highly correlated with adversarial prediction, and they have human-perceptible semantic information by themselves. Furthermore, we present an attack mechanism intensifying the gradient of non-robust features that is directly related to the model prediction, and validate its effectiveness of breaking model robustness.",
    "authors": [
      "Kim, Junho",
      "Lee, Byung-Kwan",
      "Ro, Yong Man"
    ]
  },
  {
    "id": "8e7991af8afa942dc572950e01177da5",
    "title": "Vector-valued Gaussian Processes on Riemannian Manifolds via Gauge Independent Projected Kernels",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8e7991af8afa942dc572950e01177da5-Paper.pdf",
    "abstract": "Gaussian processes are machine learning models capable of learning unknown functions in a way that represents uncertainty, thereby facilitating construction of optimal decision-making systems. Motivated by a desire to deploy Gaussian processes in novel areas of science, a rapidly-growing line of research has focused on constructively extending these models to handle non-Euclidean domains, including Riemannian manifolds, such as spheres and tori. We propose techniques that generalize this class to model vector fields on Riemannian manifolds, which are important in a number of application areas in the physical sciences. To do so, we present a general recipe for constructing gauge independent kernels, which induce Gaussian vector fields, i.e. vector-valued Gaussian processes coherent withgeometry, from scalar-valued Riemannian kernels. We extend standard Gaussian process training methods, such as variational inference, to this setting. This enables vector-valued Gaussian processes on Riemannian manifolds to be trained using standard methods and makes them accessible to machine learning practitioners.",
    "authors": [
      "Hutchinson, Michael",
      "Terenin, Alexander",
      "Borovitskiy, Viacheslav",
      "Takao, So",
      "Teh, Yee",
      "Deisenroth, Marc"
    ]
  },
  {
    "id": "8ea1e4f9f24c38f168d538c9cfc50a14",
    "title": "On the Representation Power of Set Pooling Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8ea1e4f9f24c38f168d538c9cfc50a14-Paper.pdf",
    "abstract": "Point clouds and sets are input data-types which pose unique problems to deep learning. Since sets can have variable cardinality and are unchanged by permutation, the input space for these problems naturally form infinite-dimensional non-Euclidean spaces. Despite these mathematical difficulties, PointNet (Qi et al. 2017) and Deep Sets (Zaheer et al. 2017) introduced foundational neural network architectures to address these problems. In this paper we present a unified framework to study the expressive power of such networks as well as their extensions beyond point clouds (partially addressing a conjecture on the extendibility of DeepSets along the way). To this end, we demonstrate the crucial role that the Hausdorff and Wasserstein metrics play and prove new cardinality-agnostic universality results to characterize exactly which functions can be approximated by these models. In particular, these results imply that PointNet generally cannot approximate averages of continuous functions over sets (e.g. center-of-mass or higher moments) implying that DeepSets is strictly more expressive than PointNet in the constant cardinality setting. Moreover, we obtain explicit lower-bounds on the approximation error and present a simple method to produce arbitrarily many examples of this failure-mode. Counterintuitively, we also prove that in the unbounded cardinality setting that any function which can be uniformly approximated by both PointNet and normalized-DeepSets must be constant. Finally, we also prove theorems on the Lipschitz properties of PointNet and normalized-DeepSets which shed insight into exploitable inductive bias in these networks.",
    "authors": [
      "Bueno, Christian",
      "Hylton, Alan"
    ]
  },
  {
    "id": "8ec2ba5e96ec1c050bc631abda80f269",
    "title": "Learning Policies with Zero or Bounded Constraint Violation for Constrained MDPs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8ec2ba5e96ec1c050bc631abda80f269-Paper.pdf",
    "abstract": "We address the issue of safety in reinforcement learning. We pose the problem in an episodic framework of a constrained Markov decision process. Existing results have shown that it is possible to achieve a reward regret of $\\tilde{\\mathcal{O}}(\\sqrt{K})$ while allowing an $\\tilde{\\mathcal{O}}(\\sqrt{K})$ constraint violation in $K$ episodes. A critical question that arises is whether it is possible to keep the constraint violation even smaller. We show that when a strictly safe policy is known, then one can confine the system to zero constraint violation with arbitrarily high probability while keeping the reward regret of order $\\tilde{\\mathcal{O}}(\\sqrt{K})$. The algorithm which does so employs the principle of optimistic pessimism in the face of uncertainty to achieve safe exploration. When no strictly safe policy is known, though one is known to exist, then it is possible to restrict the system to bounded constraint violation with arbitrarily high probability. This is shown to be realized by a primal-dual algorithm with an optimistic primal estimate and a pessimistic dual update.",
    "authors": [
      "Liu, Tao",
      "Zhou, Ruida",
      "Kalathil, Dileep",
      "Kumar, Panganamala",
      "Tian, Chao"
    ]
  },
  {
    "id": "8edd72158ccd2a879f79cb2538568fdc",
    "title": "A Prototype-Oriented Framework for Unsupervised Domain Adaptation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8edd72158ccd2a879f79cb2538568fdc-Paper.pdf",
    "abstract": "Existing methods for unsupervised domain adaptation often rely on minimizing some statistical distance between the source and target samples in the latent space. To avoid the sampling variability, class imbalance, and data-privacy concerns that often plague these methods, we instead provide a memory and computation-efficient probabilistic framework to extract class prototypes and align the target features with them. We demonstrate the general applicability of our method on a wide range of scenarios, including single-source, multi-source, class-imbalance, and source-private domain adaptation. Requiring no additional model parameters and having a moderate increase in computation over the source model alone, the proposed method achieves competitive performance with state-of-the-art methods.",
    "authors": [
      "Tanwisuth, Korawat",
      "Fan, Xinjie",
      "Zheng, Huangjie",
      "Zhang, Shujian",
      "Zhang, Hao",
      "Chen, Bo",
      "Zhou, Mingyuan"
    ]
  },
  {
    "id": "8f1d43620bc6bb580df6e80b0dc05c48",
    "title": "Mining the Benefits of Two-stage and  One-stage HOI Detection",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8f1d43620bc6bb580df6e80b0dc05c48-Paper.pdf",
    "abstract": "Two-stage methods have dominated Human-Object Interaction~(HOI) detection for several years. Recently, one-stage HOI detection methods have become popular. In this paper, we aim to explore the essential pros and cons of two-stage and one-stage methods. With this as the goal, we find that conventional two-stage methods mainly suffer from positioning positive interactive human-object pairs, while one-stage methods are challenging to make an appropriate trade-off on multi-task learning, \\emph{i.e.}, object detection, and interaction classification.  Therefore, a core problem is how to take the essence and discard the dregs from the conventional two types of methods. To this end, we propose a novel one-stage framework with disentangling human-object detection and interaction classification in a cascade manner. In detail, we first design a human-object pair generator based on a state-of-the-art one-stage HOI detector by removing the interaction classification module or head and then design a relatively isolated interaction classifier to classify each human-object pair. Two cascade decoders in our proposed framework can focus on one specific task, detection or interaction classification. In terms of the specific implementation, we adopt a transformer-based HOI detector as our base model. The newly introduced disentangling paradigm outperforms existing methods by a large margin, with a significant relative mAP gain of 9.32% on HICO-Det. The source codes are available at https://github.com/YueLiao/CDN.",
    "authors": [
      "Zhang, Aixi",
      "Liao, Yue",
      "Liu, Si",
      "Lu, Miao",
      "Wang, Yongliang",
      "Gao, Chen",
      "LI, XIAOBO"
    ]
  },
  {
    "id": "8f1fa0193ca2b5d2fa0695827d8270e9",
    "title": "Discerning Decision-Making Process of Deep Neural Networks with Hierarchical Voting Transformation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8f1fa0193ca2b5d2fa0695827d8270e9-Paper.pdf",
    "abstract": "Neural network based deep learning techniques have shown great success for numerous applications. While it is expected to understand their intrinsic decision-making processes, these deep neural networks often work in a black-box way. To this end, in this paper, we aim to discern the decision-making processes of neural networks through a hierarchical voting strategy by developing an explainable deep learning model, namely Voting Transformation-based Explainable Neural Network (VOTEN). Specifically, instead of relying on massive feature combinations, VOTEN creatively models expressive single-valued voting functions between explicitly modeled latent concepts to achieve high fitting ability. Along this line, we first theoretically analyze the major components of VOTEN and prove the relationship and advantages of VOTEN compared with Multi-Layer Perceptron (MLP), the basic structure of deep neural networks. Moreover, we design efficient algorithms to improve the model usability by explicitly showing the decision processes of VOTEN. Finally, extensive experiments on multiple real-world datasets clearly validate the performances and explainability of VOTEN.",
    "authors": [
      "Sun, Ying",
      "Zhu, Hengshu",
      "Qin, Chuan",
      "Zhuang, Fuzhen",
      "He, Qing",
      "Xiong, Hui"
    ]
  },
  {
    "id": "8f97d1d7e02158a83ceb2c14ff5372cd",
    "title": "Risk-averse Heteroscedastic Bayesian Optimization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8f97d1d7e02158a83ceb2c14ff5372cd-Paper.pdf",
    "abstract": "Many black-box optimization tasks arising in high-stakes applications require risk-averse decisions. The standard Bayesian optimization (BO) paradigm, however, optimizes the expected value only.  We generalize BO to trade mean and input-dependent variance of the objective, both of which we assume to be unknown a priori.  In particular, we propose a novel risk-averse heteroscedastic Bayesian optimization algorithm (RAHBO) that aims to identify a solution with high return and low noise variance, while learning the noise distribution on the fly.  To this end, we model both expectation and variance as (unknown) RKHS functions, and propose a novel risk-aware acquisition function.  We bound the regret for our approach and provide a robust rule to report the final decision point for applications where only a single solution must be identified. We demonstrate the effectiveness of RAHBO on synthetic benchmark functions and hyperparameter tuning tasks.",
    "authors": [
      "Makarova, Anastasia",
      "Usmanova, Ilnura",
      "Bogunovic, Ilija",
      "Krause, Andreas"
    ]
  },
  {
    "id": "8fb21ee7a2207526da55a679f0332de2",
    "title": "Invertible DenseNets with Concatenated LipSwish",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8fb21ee7a2207526da55a679f0332de2-Paper.pdf",
    "abstract": "We introduce Invertible Dense Networks (i-DenseNets), a more parameter efficient extension of Residual Flows. The method relies on an analysis of the Lipschitz continuity of the concatenation in DenseNets, where we enforce invertibility of the network by satisfying the Lipschitz constant. Furthermore, we propose a learnable weighted concatenation, which not only improves the model performance but also indicates the importance of the concatenated weighted representation. Additionally, we introduce the Concatenated LipSwish as activation function, for which we show how to enforce the Lipschitz condition and which boosts performance. The new architecture, i-DenseNet, out-performs Residual Flow and other flow-based models on density estimation evaluated in bits per dimension, where we utilize an equal parameter budget. Moreover, we show that the proposed model out-performs Residual Flows when trained as a hybrid model where the model is both a generative and a discriminative model.",
    "authors": [
      "Perugachi-Diaz, Yura",
      "Tomczak, Jakub",
      "Bhulai, Sandjai"
    ]
  },
  {
    "id": "8fd7f981e10b41330b618129afcaab2d",
    "title": "Topological Detection of Trojaned Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8fd7f981e10b41330b618129afcaab2d-Paper.pdf",
    "abstract": "Deep neural networks are known to have security issues. One particular threat is the Trojan attack. It occurs when the attackers stealthily manipulate the model's behavior through Trojaned training samples, which can later be exploited. Guided by basic neuroscientific principles, we discover subtle -- yet critical -- structural deviation characterizing Trojaned models. In our analysis we use topological tools. They allow us to model high-order dependencies in the networks, robustly compare different networks, and localize structural abnormalities. One interesting observation is that Trojaned models develop short-cuts from shallow to deep layers. Inspired by these observations, we devise a strategy for robust detection of Trojaned models. Compared to standard baselines it displays better performance on multiple benchmarks.",
    "authors": [
      "Zheng, Songzhu",
      "Zhang, Yikai",
      "Wagner, Hubert",
      "Goswami, Mayank",
      "Chen, Chao"
    ]
  },
  {
    "id": "8fe04df45a22b63156ebabbb064fcd5e",
    "title": "Provably Strict Generalisation Benefit for Invariance in Kernel Methods",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8fe04df45a22b63156ebabbb064fcd5e-Paper.pdf",
    "abstract": "It is a commonly held belief that enforcing invariance improves generalisation. Although this approach enjoys widespread popularity, it is only very recently that a rigorous theoretical demonstration of this benefit has been established. In this work we build on the function space perspective of Elesedy and Zaidi [8] to derive a strictly non-zero generalisation benefit of incorporating invariance in kernel ridge regression when the target is invariant to the action of a compact group. We study invariance enforced by feature averaging and find that generalisation is governed by a notion of effective dimension that arises from the interplay between the kernel and the group. In building towards this result, we find that the action of the group induces an orthogonal decomposition of both the reproducing kernel Hilbert space and its kernel, which may be of interest in its own right.",
    "authors": [
      "Elesedy, Bryn"
    ]
  },
  {
    "id": "901797aebf0b23ecbab534d61ad33bb1",
    "title": "Formalizing the Generalization-Forgetting Trade-off in Continual Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/901797aebf0b23ecbab534d61ad33bb1-Paper.pdf",
    "abstract": "We formulate the continual learning (CL) problem via dynamic programming and model the trade-off between catastrophic forgetting and generalization as a two-player sequential game. In this approach, player 1 maximizes the cost due to lack of generalization whereas player 2 minimizes the cost due to catastrophic forgetting. We show theoretically that a balance point between the two players exists for each task and that this point is stable (once the balance is achieved, the two players stay at the balance point). Next, we introduce balanced continual learning (BCL), which is designed to attain balance between generalization and forgetting and empirically demonstrate that BCL is comparable to or better than the state of the art.",
    "authors": [
      "Raghavan, Krishnan",
      "Balaprakash, Prasanna"
    ]
  },
  {
    "id": "90610aa0e24f63ec6d2637e06f9b9af2",
    "title": "Risk-Aware Transfer in Reinforcement Learning using Successor Features",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/90610aa0e24f63ec6d2637e06f9b9af2-Paper.pdf",
    "abstract": "Sample efficiency and risk-awareness are central to the development of practical reinforcement learning (RL) for complex decision-making. The former can be addressed by transfer learning, while the latter by optimizing some utility function of the return. However, the problem of transferring skills in a risk-aware manner is not well-understood. In this paper, we address the problem of transferring policies between tasks in a common domain that differ only in their reward functions, in which risk is measured by the variance of reward streams. Our approach begins by extending the idea of generalized policy improvement to maximize entropic utilities, thus extending the dynamic programming's policy improvement operation to sets of policies \\emph{and} levels of risk-aversion. Next, we extend the idea of successor features (SF), a value function representation that decouples the environment dynamics from the rewards, to capture the variance of returns. Our resulting risk-aware successor features (RaSF) integrate seamlessly within the RL framework, inherit the superior task generalization ability of SFs, while incorporating risk into the decision-making. Experiments on a discrete navigation domain and control of a simulated robotic arm demonstrate the ability of RaSFs to outperform alternative methods including SFs, when taking the risk of the learned policies into account. ",
    "authors": [
      "Gimelfarb, Michael",
      "Barreto, Andre",
      "Sanner, Scott",
      "Lee, Chi-Guhn"
    ]
  },
  {
    "id": "9078f2a8254704bd760460f027072e52",
    "title": "Causal Inference for Event Pairs in Multivariate Point Processes",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9078f2a8254704bd760460f027072e52-Paper.pdf",
    "abstract": "Causal inference and discovery from observational data has been extensively studied across multiple fields. However, most prior work has focused on independent and identically distributed (i.i.d.) data. In this paper, we propose a formalization for causal inference between pairs of event variables in multivariate recurrent event streams by extending Rubin's framework for the average treatment effect (ATE) and propensity scores to multivariate point processes. Analogous to a joint probability distribution representing i.i.d. data, a multivariate point process represents data involving asynchronous and irregularly spaced occurrences of various types of events over a common timeline. We theoretically justify our point process causal framework and show how to obtain unbiased estimates of the proposed measure. We conduct an experimental investigation using synthetic and real-world event datasets, where our proposed causal inference framework is shown to exhibit superior performance against a set of baseline pairwise causal association scores.",
    "authors": [
      "Gao, Tian",
      "Subramanian, Dharmashankar",
      "Bhattacharjya, Debarun",
      "Shou, Xiao",
      "Mattei, Nicholas",
      "Bennett, Kristin P"
    ]
  },
  {
    "id": "908075ea2c025c335f4865f7db427062",
    "title": "Evaluating model performance under worst-case subpopulations",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/908075ea2c025c335f4865f7db427062-Paper.pdf",
    "abstract": "The performance of ML models degrades when the training population is different from that seen under operation. Towards assessing distributional robustness, we study the worst-case performance of a model over all subpopulations of a given size, defined with respect to core attributes $Z$. This notion of robustness can consider arbitrary (continuous) attributes $Z$, and automatically accounts for complex intersectionality in disadvantaged groups. We develop a scalable yet principled two-stage estimation procedure that can evaluate the robustness of state-of-the-art models. We prove that our procedure enjoys several finite-sample convergence guarantees, including dimension-free convergence. Instead of overly conservative notions based on Rademacher complexities, our evaluation error depends on the dimension of $Z$ only through the out-of-sample error in estimating the performance conditional on $Z$. On real datasets, we demonstrate that our method certifies the robustness of a model and prevents deployment of unreliable models.",
    "authors": [
      "Li, Mike",
      "Namkoong, Hongseok",
      "Xia, Shangzhou"
    ]
  },
  {
    "id": "9087b0efc7c7acd1ef7e153678809c77",
    "title": "Privately Publishable Per-instance Privacy",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9087b0efc7c7acd1ef7e153678809c77-Paper.pdf",
    "abstract": "We consider how to privately share the personalized privacy losses incurred by objective perturbation, using per-instance differential privacy (pDP). Standard differential privacy (DP) gives us a worst-case bound that might be orders of magnitude larger than the privacy loss to a particular individual relative to a fixed dataset. The pDP framework provides a more fine-grained analysis of the privacy guarantee to a target individual, but the per-instance privacy loss itself might be a function of sensitive data. In this paper, we analyze the per-instance privacy loss of releasing a private empirical risk minimizer learned via objective perturbation, and propose a group of methods to privately and accurately publish the pDP losses at little to no additional privacy cost.  ",
    "authors": [
      "Redberg, Rachel",
      "Wang, Yu-Xiang"
    ]
  },
  {
    "id": "90cc440b1b8caa520c562ac4e4bbcb51",
    "title": "Understanding the Limits of Unsupervised Domain Adaptation via Data Poisoning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/90cc440b1b8caa520c562ac4e4bbcb51-Paper.pdf",
    "abstract": "Unsupervised domain adaptation (UDA) enables cross-domain learning without target domain labels by transferring knowledge from a labeled source domain whose distribution differs from that of the target. However, UDA is not always successful and several accounts of `negative transfer' have been reported in the literature. In this work, we prove a simple lower bound on the target domain error that complements the existing upper bound. Our bound shows the insufficiency of minimizing source domain error and marginal distribution mismatch for a guaranteed reduction in the target domain error, due to the possible increase of induced labeling function mismatch. This insufficiency is further illustrated through simple distributions for which the same UDA approach succeeds, fails, and may succeed or fail with an equal chance. Motivated from this, we propose novel data poisoning attacks to fool UDA methods into learning representations that produce large target domain errors. We evaluate the effect of these attacks on popular UDA methods using benchmark datasets where they have been previously shown to be successful. Our results show that poisoning can significantly decrease the target domain accuracy, dropping it to almost 0% in some cases, with the addition of only 10% poisoned data in the source domain. The failure of these UDA methods demonstrates their limitations at guaranteeing cross-domain generalization consistent with our lower bound. Thus, evaluating UDA methods in adversarial settings such as data poisoning provides a better sense of their robustness to data distributions unfavorable for UDA.",
    "authors": [
      "Mehra, Akshay",
      "Kailkhura, Bhavya",
      "Chen, Pin-Yu",
      "Hamm, Jihun"
    ]
  },
  {
    "id": "90fd4f88f588ae64038134f1eeaa023f",
    "title": "Coresets for Clustering with Missing Values",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/90fd4f88f588ae64038134f1eeaa023f-Paper.pdf",
    "abstract": "We provide the first coreset for clustering points in $\\mathbb{R}^d$ that have multiple missing values (coordinates). Previous coreset constructions only allow one missing coordinate. The challenge in this setting is that objective functions, like \\kMeans, are evaluated only on the set of available (non-missing) coordinates, which varies across points. Recall that an $\\epsilon$-coreset of a large dataset is a small proxy, usually a reweighted subset of points, that $(1+\\epsilon)$-approximates the clustering objective for every possible center set.Our coresets for $k$-Means and $k$-Median clustering have size $(jk)^{O(\\min(j,k))} (\\epsilon^{-1} d \\log n)^2$, where $n$ is the number of data points, $d$ is the dimension and $j$ is the maximum number of missing coordinates for each data point. We further design an algorithm to construct these coresets in near-linear time, and consequently improve a recent quadratic-time PTAS for $k$-Means with missing values [Eiben et al., SODA 2021] to near-linear time.We validate our coreset construction, which is based on importance sampling and is easy to implement, on various real data sets. Our coreset exhibits a flexible tradeoff between coreset size and accuracy, and generally outperforms the uniform-sampling baseline. Furthermore, it significantly speeds up a Lloyd's-style heuristic for $k$-Means with missing values.",
    "authors": [
      "Braverman, Vladimir",
      "Jiang, Shaofeng",
      "Krauthgamer, Robert",
      "Wu, Xuan"
    ]
  },
  {
    "id": "9103820024efb30b451d006dc4ab3370",
    "title": "Boosting with Multiple Sources",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9103820024efb30b451d006dc4ab3370-Paper.pdf",
    "abstract": "We study the problem of learning accurate ensemble predictors, in  particular boosting, in the presence of multiple source domains. We  show that the standard convex combination ensembles in general  cannot succeed in this scenario and adopt instead a domain-weighted  combination. We introduce and analyze a new boosting algorithm,  MULTIBOOST, for this scenario and show that it benefits from  favorable theoretical guarantees. We also report the results of  several experiments with our algorithm demonstrating that it  outperforms natural baselines on multi-source text-based,  image-based and tabular data. We further present an extension of our  algorithm to the federated learning scenario and report favorable  experimental results for that setting as well. Additionally, we  describe in detail an extension of our algorithm to the multi-class  setting, MCMULTIBOOST, for which we also report  experimental results.",
    "authors": [
      "Cortes, Corinna",
      "Mohri, Mehryar",
      "Storcheus, Dmitry",
      "Suresh, Ananda Theertha"
    ]
  },
  {
    "id": "912d2b1c7b2826caf99687388d2e8f7c",
    "title": "Dynamic Neural Representational Decoders for High-Resolution Semantic Segmentation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/912d2b1c7b2826caf99687388d2e8f7c-Paper.pdf",
    "abstract": "Semantic segmentation requires per-pixel prediction for a given image. Typically, the output resolution of a segmentation network is severely reduced due to the downsampling operations in the CNN backbone. Most previous methods employ upsampling decoders to recover the spatial resolution.Various decoders were designed in the literature. Here, we propose a novel decoder, termed dynamic neural representational decoder (NRD), which is simple yet significantly more efficient. As each location on the encoder's output corresponds to a local patch of the semantic labels, in this work, we represent these local patches of labels with compact neural networks. This neural representation enables our decoder to leverage the smoothness prior in the semantic label space, and thus makes our decoder more efficient. Furthermore, these neural representations are dynamically generated and conditioned on the outputs of the encoder networks. The desired semantic labels can be efficiently decoded from the neural representations, resulting in high-resolution semantic segmentation predictions.We empirically show that our proposed decoder can outperform the decoder in DeeplabV3+ with only $\\sim$$30\\%$ computational complexity, and achieve competitive performance with the methods using dilated encoders with only $\\sim$$15\\% $ computation. Experiments on Cityscapes, ADE20K, and Pascal Context demonstrate the effectiveness and efficiency of our proposed method.",
    "authors": [
      "Zhang, Bowen",
      "liu, Yifan",
      "Tian, Zhi",
      "Shen, Chunhua"
    ]
  },
  {
    "id": "914101ec47c52b48a7b6ccc6f5a76f1f",
    "title": "Dense Keypoints via Multiview Supervision",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/914101ec47c52b48a7b6ccc6f5a76f1f-Paper.pdf",
    "abstract": "This paper presents a new end-to-end semi-supervised framework to learn a dense keypoint detector using unlabeled multiview images. A key challenge lies in \ufb01nding the exact correspondences between the dense keypoints in multiple views since the inverse of the keypoint mapping can be neither analytically derived nor differentiated. This limits applying existing multiview supervision approaches used to learn sparse keypoints that rely on the exact correspondences. To address this challenge, we derive a new probabilistic epipolar constraint that encodes the two desired properties. (1) Soft correspondence: we de\ufb01ne a matchability, which measures a likelihood of a point matching to the other image\u2019s corresponding point, thus relaxing the requirement of the exact correspondences. (2) Geometric consistency: every point in the continuous correspondence \ufb01elds must satisfy the multiview consistency collectively. We formulate a probabilistic epipolar constraint using a weighted average of epipolar errors through the matchability thereby generalizing the point-to-point geometric error to the \ufb01eld-to-\ufb01eld geometric error. This generalization facilitates learning a geometrically coherent dense keypoint detection model by utilizing a large number of unlabeled multiview images. Additionally, to prevent degenerative cases, we employ a distillation-based regularization by using a pretrained model. Finally, we design a new neural network architecture, made of twin networks, that effectively minimizes the probabilistic epipolar errors of all possible correspondences between two view images by building af\ufb01nity matrices. Our method shows superior performance compared to existing methods, including non-differentiable bootstrapping in terms of keypoint accuracy, multiview consistency, and 3D reconstruction accuracy.",
    "authors": [
      "Yu, Zhixuan",
      "Yu, Haozheng",
      "Sha, Long",
      "Ganguly, Sujoy",
      "Park, Hyun Soo"
    ]
  },
  {
    "id": "9185f3ec501c674c7c788464a36e7fb3",
    "title": "Scatterbrain: Unifying Sparse and Low-rank Attention",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9185f3ec501c674c7c788464a36e7fb3-Paper.pdf",
    "abstract": "Recent advances in efficient Transformers have exploited either the sparsity or low-rank properties of attention matrices to reduce the computational and memory bottlenecks of modeling long sequences. However, it is still challenging to balance the trade-off between model quality and efficiency to perform a one-size-fits-all approximation for different tasks. To better understand this trade-off, we observe that sparse and low-rank approximations excel in different regimes, determined by the softmax temperature in attention, and sparse + low-rank can outperform each individually. Inspired by the classical robust-PCA algorithm for sparse and low-rank decomposition, we propose Scatterbrain, a novel way to unify sparse (via locality sensitive hashing) and low-rank (via kernel feature map) attention for accurate and efficient approximation. The estimation is unbiased with provably low error. We empirically show that Scatterbrain can achieve $2.1 \\times$ lower error than baselines when serving as a drop-in replacement in BigGAN image generation and pre-trained T2T-ViT. On a pre-trained T2T Vision transformer, even without fine-tuning, Scatterbrain can reduce $98\\%$ of attention memory at the cost of only $1\\%$ drop in accuracy. We demonstrate Scatterbrain for end-to-end training with up to $4$ points better perplexity and 5 points better average accuracy than sparse or low-rank efficient transformers on language modeling and long-range-arena tasks.",
    "authors": [
      "Chen, Beidi",
      "Dao, Tri",
      "Winsor, Eric",
      "Song, Zhao",
      "Rudra, Atri",
      "R\u00e9, Christopher"
    ]
  },
  {
    "id": "918f5cd5a5c0d48671d4d4fc54bab2e9",
    "title": "PTR: A Benchmark for Part-based Conceptual, Relational, and Physical Reasoning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/918f5cd5a5c0d48671d4d4fc54bab2e9-Paper.pdf",
    "abstract": "A critical aspect of human visual perception is the ability to parse visual scenes into individual objects and further into object parts, forming part-whole hierarchies. Such composite structures could induce a rich set of semantic concepts and relations, thus playing an important role in the interpretation and organization of visual signals as well as for the generalization of visual perception and reasoning. However, existing visual reasoning benchmarks mostly focus on objects rather than parts. Visual reasoning based on the full part-whole hierarchy is much more challenging than object-centric reasoning due to finer-grained concepts, richer geometry relations, and more complex physics. Therefore, to better serve for part-based conceptual, relational and physical reasoning, we introduce a new large-scale diagnostic visual reasoning dataset named PTR. PTR contains around 80k RGBD synthetic images with ground truth object and part level annotations regarding semantic instance segmentation, color attributes, spatial and geometric relationships, and certain physical properties such as stability. These images are paired with 800k machine-generated questions covering various types of reasoning types, making them a good testbed for visual reasoning models. We examine several state-of-the-art visual reasoning models on this dataset and observe that they still make many surprising mistakes in situations where humans can easily infer the correct answer. We believe this dataset will open up new opportunities for part-based reasoning. PTR dataset and baseline models are publicly available. ",
    "authors": [
      "Hong, Yining",
      "Yi, Li",
      "Tenenbaum, Josh",
      "Torralba, Antonio",
      "Gan, Chuang"
    ]
  },
  {
    "id": "91bc333f6967019ac47b49ca0f2fa757",
    "title": "Property-Aware Relation Networks for Few-Shot Molecular Property Prediction",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/91bc333f6967019ac47b49ca0f2fa757-Paper.pdf",
    "abstract": "Molecular property prediction plays a fundamental role in drug discovery to identify candidate molecules with target properties. However, molecular property prediction is essentially a few-shot problem, which makes it hard to use regular machine learning models. In this paper, we propose Property-Aware Relation networks (PAR) to handle this problem. In comparison to existing works, we leverage the fact that both relevant substructures and relationships among molecules change across different molecular properties. We first introduce a property-aware embedding function to transform the generic molecular embeddings to substructure-aware space relevant to the target property.  Further, we design an adaptive relation graph learning module to jointly estimate molecular relation graph and refine molecular embeddings w.r.t. the target property, such that the limited labels can be effectively propagated among similar molecules. We adopt a meta-learning strategy where the parameters are selectively updated within tasks in order to model generic and property-aware knowledge separately. Extensive experiments on benchmark molecular property prediction datasets show that PAR consistently outperforms existing methods and can obtain property-aware molecular embeddings and model molecular relation graph properly.  ",
    "authors": [
      "Wang, Yaqing",
      "Abuduweili, Abulikemu",
      "Yao, Quanming",
      "Dou, Dejing"
    ]
  },
  {
    "id": "91cff01af640a24e7f9f7a5ab407889f",
    "title": "Differentially Private Learning with Adaptive Clipping",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/91cff01af640a24e7f9f7a5ab407889f-Paper.pdf",
    "abstract": "Existing approaches for training neural networks with user-level differential privacy (e.g., DP Federated Averaging) in federated learning (FL) settings involve bounding the contribution of each user's model update by {\\em clipping} it to some constant value. However there is no good {\\em a priori} setting of the clipping norm across tasks and learning settings: the update norm distribution depends on the model architecture and loss, the amount of data on each device, the client learning rate, and possibly various other parameters. We propose a method wherein instead of a fixed clipping norm, one clips to a value at a specified quantile of the update norm distribution, where the value at the quantile is itself estimated online, with differential privacy. The method tracks the quantile closely, uses a negligible amount of privacy budget, is compatible with other federated learning technologies such as compression and secure aggregation, and has a straightforward joint DP analysis with DP-FedAvg. Experiments demonstrate that adaptive clipping to the median update norm works well across a range of federated learning tasks, eliminating the need to tune any clipping hyperparameter.",
    "authors": [
      "Andrew, Galen",
      "Thakkar, Om",
      "McMahan, Brendan",
      "Ramaswamy, Swaroop"
    ]
  },
  {
    "id": "91e50fe1e39af2869d3336eaaeebdb43",
    "title": "Can Less be More? When Increasing-to-Balancing Label Noise Rates Considered Beneficial",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/91e50fe1e39af2869d3336eaaeebdb43-Paper.pdf",
    "abstract": "In this paper, we answer the question of when inserting label noise (less informative labels) can instead return us more accurate and fair models. We are primarily inspired by three observations: 1) In contrast to reducing label noise rates, increasing the noise rates is easy to implement; 2) Increasing a certain class of instances' label noise to balance the noise rates (increasing-to-balancing) results in an easier learning problem; 3) Increasing-to-balancing improves fairness guarantees against label bias. In this paper, we first quantify the trade-offs introduced by increasing a certain group of instances' label noise rate w.r.t. the loss of label informativeness and the lowered learning difficulties. We analytically demonstrate when such an increase is beneficial, in terms of either improved generalization power or the fairness guarantees. Then we present a method to insert label noise properly for the task of learning with noisy labels, either without or with a fairness constraint. The primary technical challenge we face is due to the fact that we would not know which data instances are suffering from higher noise, and we would not have the ground truth labels to verify any possible hypothesis. We propose a detection method that informs us which group of labels might suffer from higher noise without using ground truth labels. We formally establish the effectiveness of the proposed solution and demonstrate it with extensive experiments. ",
    "authors": [
      "Liu, Yang",
      "Wang, Jialu"
    ]
  },
  {
    "id": "9219adc5c42107c4911e249155320648",
    "title": "Projected GANs Converge Faster",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9219adc5c42107c4911e249155320648-Paper.pdf",
    "abstract": "Generative Adversarial Networks (GANs) produce high-quality images but are challenging to train. They need careful regularization, vast amounts of compute, and expensive hyper-parameter sweeps. We make significant headway on these issues by projecting generated and real samples into a fixed, pretrained feature space. Motivated by the finding that the discriminator cannot fully exploit features from deeper layers of the pretrained model, we propose a more effective strategy that mixes features across channels and resolutions. Our Projected GAN improves image quality, sample efficiency, and convergence speed. It is further compatible with resolutions of up to one Megapixel and advances the state-of-the-art Fr\u00e9chet Inception Distance (FID) on twenty-two benchmark datasets. Importantly, Projected GANs match the previously lowest FIDs up to 40 times faster, cutting the wall-clock time from 5 days to less than 3 hours given the same computational resources.",
    "authors": [
      "Sauer, Axel",
      "Chitta, Kashyap",
      "M\u00fcller, Jens",
      "Geiger, Andreas"
    ]
  },
  {
    "id": "926ec030f29f83ce5318754fdb631a33",
    "title": "Generating High-Quality Explanations for Navigation in Partially-Revealed Environments",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/926ec030f29f83ce5318754fdb631a33-Paper.pdf",
    "abstract": "We present an approach for generating natural language explanations of high-level behavior of autonomous agents navigating in partially-revealed environments. Our counterfactual explanations communicate changes to interpratable statistics of the belief (e.g., the likelihood an exploratory action will reach the unseen goal) that are estimated from visual input via a deep neural network and used (via a Bellman equation variant) to inform planning far into the future. Additionally, our novel training procedure mimics explanation generation, allowing us to use planning performance as an objective measure of explanation quality. Simulated experiments validate that our explanations are both high quality and can be used in interventions to directly correct bad behavior; agents trained via our training-by-explaining procedure achieve 9.1% lower average cost than a non-learned baseline (12.7% after interventions) in environments derived from real-world floor plans.",
    "authors": [
      "Stein, Gregory"
    ]
  },
  {
    "id": "9271905e840548b8cada6d60c0cfd93b",
    "title": "De-randomizing MCMC dynamics with the diffusion Stein operator",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9271905e840548b8cada6d60c0cfd93b-Paper.pdf",
    "abstract": "Approximate Bayesian inference estimates descriptors of an intractable target distribution - in essence, an optimization problem within a family of distributions. For example, Langevin dynamics (LD) extracts asymptotically exact samples from a diffusion process because the time evolution of its marginal distributions constitutes a curve that minimizes the KL-divergence via steepest descent in the Wasserstein space. Parallel to LD, Stein variational gradient descent (SVGD) similarly minimizes the KL, albeit endowed with a novel Stein-Wasserstein distance, by deterministically transporting a set of particle samples, thus de-randomizes the stochastic diffusion process. We propose de-randomized kernel-based particle samplers to all diffusion-based samplers known as MCMC dynamics. Following previous work in interpreting MCMC dynamics, we equip the Stein-Wasserstein space with a fiber-Riemannian Poisson structure, with the capacity of characterizing a fiber-gradient Hamiltonian flow that simulates MCMC dynamics. Such dynamics discretizes into generalized SVGD (GSVGD), a Stein-type deterministic particle sampler, with particle updates coinciding with applying the diffusion Stein operator to a kernel function. We demonstrate empirically that GSVGD can de-randomize complex MCMC dynamics, which combine the advantages of auxiliary momentum variables and Riemannian structure, while maintaining the high sample quality from an interacting particle system.",
    "authors": [
      "Shen, Zheyang",
      "Heinonen, Markus",
      "Kaski, Samuel"
    ]
  },
  {
    "id": "927b028cfa24b23a09ff20c1a7f9b398",
    "title": "Sparsely Changing Latent States for Prediction and Planning in Partially Observable Domains",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/927b028cfa24b23a09ff20c1a7f9b398-Paper.pdf",
    "abstract": "A common approach to prediction and planning in partially observable domains is to use recurrent neural networks (RNNs), which ideally develop and maintain a latent memory about hidden, task-relevant factors. We hypothesize that many of these hidden factors in the physical world are constant over time, changing only sparsely. To study this hypothesis, we propose Gated $L_0$ Regularized Dynamics (GateL0RD), a novel recurrent architecture that incorporates the inductive bias to maintain stable, sparsely changing latent states.  The bias is implemented by means of a novel internal gating function and a penalty on the $L_0$ norm of latent state changes. We demonstrate that GateL0RD can compete with or outperform state-of-the-art RNNs in a variety of partially observable prediction and control tasks. GateL0RD tends to encode the underlying generative factors of the environment, ignores spurious temporal dependencies, and generalizes better, improving sampling efficiency and overall performance in model-based planning and reinforcement learning tasks. Moreover, we show that the developing latent states can be easily interpreted, which is a step towards better explainability in RNNs.",
    "authors": [
      "Gumbsch, Christian",
      "Butz, Martin V.",
      "Martius, Georg"
    ]
  },
  {
    "id": "92977ae4d2ba21425a59afb269c2a14e",
    "title": "PreferenceNet: Encoding Human Preferences in Auction Design with Deep Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/92977ae4d2ba21425a59afb269c2a14e-Paper.pdf",
    "abstract": "The design of optimal auctions is a problem of interest in economics, game theory and computer science. Despite decades of effort, strategyproof, revenue-maximizing auction designs are still not known outside of restricted settings. However, recent methods using deep learning have shown some success in approximating optimal auctions, recovering several known solutions and outperforming strong baselines when optimal auctions are not known. In addition to maximizing revenue, auction mechanisms may also seek to encourage socially desirable constraints such as allocation fairness or diversity. However, these philosophical notions neither have standardization nor do they have widely accepted formal definitions. In this paper, we propose PreferenceNet, an extension of existing neural-network-based auction mechanisms to encode constraints using (potentially human-provided) exemplars of desirable allocations. In addition, we introduce a new metric to evaluate an auction allocations' adherence to such socially desirable constraints and demonstrate that our proposed method is competitive with current state-of-the-art neural-network based auction designs. We validate our approach through human subject research and show that we are able to effectively capture real human preferences.",
    "authors": [
      "Peri, Neehar",
      "Curry, Michael",
      "Dooley, Samuel",
      "Dickerson, John"
    ]
  },
  {
    "id": "92a08bf918f44ccd961477be30023da1",
    "title": "Large-Scale Learning with Fourier Features and Tensor Decompositions",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/92a08bf918f44ccd961477be30023da1-Paper.pdf",
    "abstract": "Random Fourier features provide a way to tackle large-scale machine learning problems with kernel methods. Their slow Monte Carlo convergence rate has motivated the research of deterministic Fourier features whose approximation error can decrease exponentially in the number of basis functions. However, due to their tensor product extension to multiple dimensions, these methods suffer heavily from the curse of dimensionality, limiting their applicability to one, two or three-dimensional scenarios. In our approach we overcome said curse of dimensionality by exploiting the tensor product structure of deterministic Fourier features, which enables us to represent the model parameters as a low-rank tensor decomposition. We derive a monotonically converging block coordinate descent algorithm with linear complexity in both the sample size and the dimensionality of the inputs for a regularized squared loss function, allowing to learn a parsimonious model in decomposed form using deterministic Fourier features.We demonstrate by means of numerical experiments how our low-rank tensor approach obtains the same performance of the corresponding nonparametric model, consistently outperforming random Fourier features.",
    "authors": [
      "Wesel, Frederiek",
      "Batselier, Kim"
    ]
  },
  {
    "id": "92bf5e6240737e0326ea59846a83e076",
    "title": "Hash Layers For Large Sparse Models",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/92bf5e6240737e0326ea59846a83e076-Paper.pdf",
    "abstract": "We investigate the training of sparse layers that use different parameters for different inputs based on hashing in large Transformer models. Specifically, we modify the feedforward layer to hash to different sets of weights depending on the current token, over all tokens in the sequence. We show that this procedure either outperforms or is competitive with learning-to-route mixture-of-expert methods such as Switch Transformers and BASE Layers, while requiring no routing parameters or extra terms in the objective function such as a load balancing loss, and no sophisticated assignment algorithm. We study the performance of different hashing techniques,  hash sizes and input features,  and  show that  balanced and random hashes focused on the most local features work best, compared to either learning clusters or using longer-range context. We show our approach works well both on large language modeling and dialogue tasks, and on downstream fine-tuning tasks.",
    "authors": [
      "Roller, Stephen",
      "Sukhbaatar, Sainbayar",
      "szlam, arthur",
      "Weston, Jason"
    ]
  },
  {
    "id": "92c4661685bf6681f6a33b78ef729658",
    "title": "Sliced Mutual Information: A Scalable Measure of Statistical Dependence",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/92c4661685bf6681f6a33b78ef729658-Paper.pdf",
    "abstract": "Mutual information (MI) is a fundamental measure of statistical dependence, with a myriad of applications to information theory, statistics, and machine learning. While it possesses many desirable structural properties, the estimation of high-dimensional MI from samples suffers from the curse of dimensionality. Motivated by statistical scalability to high dimensions, this paper proposes sliced MI (SMI) as a surrogate measure of dependence. SMI is defined as an average of MI terms between one-dimensional random projections. We show that it preserves many of the structural properties of classic MI, while gaining scalable computation and efficient estimation from samples. Furthermore, and in contrast to classic MI, SMI can grow as a result of deterministic transformations. This enables leveraging SMI for feature extraction by optimizing it over processing functions of raw data to identify useful representations thereof. Our theory is supported by numerical studies of independence testing and feature extraction, which demonstrate the potential gains SMI offers over classic MI for high-dimensional inference.",
    "authors": [
      "Goldfeld, Ziv",
      "Greenewald, Kristjan"
    ]
  },
  {
    "id": "92dfa194391a59dc65b88b704599dbd6",
    "title": "Emergent Communication under Varying Sizes and Connectivities",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/92dfa194391a59dc65b88b704599dbd6-Paper.pdf",
    "abstract": "Recent advances in deep neural networks allowed artificial agents to derive their own emergent languages that promote interaction, coordination, and collaboration within a group. Just as we humans have succeeded in creating a shared language that allows us to interact within a large group, can the emergent communication within an artificial group converge to a shared, agreed language? This research provides an analytical study of the shared emergent language within the group communication settings of different sizes and connectivities. As the group size increases up to hundreds, agents start to speak dissimilar languages, but the rate at which they successfully communicate is maintained. We observe the emergence of different dialects when we restrict the group communication to have local connectivities only. Finally, we provide optimization results of group communication graphs when the number of agents one can communicate with is restricted or when we penalize communication between distant agent pairs. The optimized communication graphs show superior communication success rates compared to graphs with same number of links as well as the emergence of hub nodes and scale-free networks. ",
    "authors": [
      "Kim, Jooyeon",
      "Oh, Alice"
    ]
  },
  {
    "id": "92fde850d824c2ba9b563cb6fa4078c3",
    "title": "Deep Bandits Show-Off: Simple and Efficient Exploration with Deep Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/92fde850d824c2ba9b563cb6fa4078c3-Paper.pdf",
    "abstract": "Designing efficient exploration is central to Reinforcement Learning due to the fundamental problem posed by the exploration-exploitation dilemma.  Bayesian exploration strategies like Thompson Sampling resolve this trade-off in a principled way by modeling and updating the distribution of the parameters of the action-value function, the outcome model of the environment.However, this technique becomes infeasible for complex environments due to the computational intractability of maintaining probability distributions over parameters of outcome models of corresponding complexity.Moreover, the approximation techniques introduced to mitigate this issue typically result in poor exploration-exploitation trade-offs, as observed in the case of deep neural network models with approximate posterior methods that have been shown to underperform in the deep bandit scenario.In this paper we introduce Sample Average Uncertainty (SAU), a simple and efficient uncertainty measure for contextual bandits.While Bayesian approaches like Thompson Sampling estimate outcomes uncertainty indirectly by first quantifying the variability over the parameters of the outcome model, SAU is a frequentist approach that directly estimates the uncertainty of the outcomes based on the value predictions.Importantly, we show theoretically that the uncertainty measure estimated by SAU asymptotically matches the uncertainty provided by Thompson Sampling, as well as its regret bounds.Because of its simplicity SAU can be seamlessly applied to deep contextual bandits as a very scalable drop-in replacement for epsilon-greedy exploration.We confirm empirically our theory by showing that SAU-based exploration outperforms current state-of-the-art deep Bayesian bandit methods on several real-world datasets at modest computation cost, and make the code to reproduce our results available at \\url{https://github.com/ibm/sau-explore}.",
    "authors": [
      "Zhu, Rong",
      "Rigotti, Mattia"
    ]
  },
  {
    "id": "931af583573227f0220bc568c65ce104",
    "title": "Regret Minimization Experience Replay in Off-Policy Reinforcement Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/931af583573227f0220bc568c65ce104-Paper.pdf",
    "abstract": "In reinforcement learning, experience replay stores past samples for further reuse. Prioritized sampling is a promising technique to better utilize these samples. Previous criteria of prioritization include TD error, recentness and corrective feedback, which are mostly heuristically designed. In this work, we start from the regret minimization objective, and obtain an optimal prioritization strategy for Bellman update that can directly maximize the return of the policy. The theory suggests that data with higher hindsight TD error, better on-policiness and more accurate Q value should be assigned with higher weights during sampling. Thus most previous criteria only consider this strategy partially. We not only provide theoretical justifications for previous criteria, but also propose two new methods to compute the prioritization weight, namely ReMERN and ReMERT. ReMERN learns an error network, while ReMERT exploits the temporal ordering of states. Both methods outperform previous prioritized sampling algorithms in challenging RL benchmarks, including MuJoCo, Atari and Meta-World.",
    "authors": [
      "Liu, Xu-Hui",
      "Xue, Zhenghai",
      "Pang, Jingcheng",
      "Jiang, Shengyi",
      "Xu, Feng",
      "Yu, Yang"
    ]
  },
  {
    "id": "9332c513ef44b682e9347822c2e457ac",
    "title": "Relative Uncertainty Learning for Facial Expression Recognition",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9332c513ef44b682e9347822c2e457ac-Paper.pdf",
    "abstract": "In facial expression recognition (FER), the uncertainties introduced by inherent noises like ambiguous facial expressions and inconsistent labels raise concerns about the credibility of recognition results. To quantify these uncertainties and achieve good performance under noisy data, we regard uncertainty as a relative concept and propose an innovative uncertainty learning method called Relative Uncertainty Learning (RUL). Rather than assuming Gaussian uncertainty distributions for all datasets, RUL builds an extra branch to learn uncertainty from the relative difficulty of samples by feature mixup. Specifically, we use uncertainties as weights to mix facial features and design an add-up loss to encourage uncertainty learning. It is easy to implement and adds little or no extra computation overhead. Extensive experiments show that RUL outperforms state-of-the-art FER uncertainty learning methods in both real-world and synthetic noisy FER datasets. Besides, RUL also works well on other datasets such as CIFAR and Tiny ImageNet. The code is available at https://github.com/zyh-uaiaaaa/Relative-Uncertainty-Learning.",
    "authors": [
      "Zhang, Yuhang",
      "Wang, Chengrui",
      "Deng, Weihong"
    ]
  },
  {
    "id": "93661c10ed346f9692f4d512319799b3",
    "title": "An Information-theoretic Approach to Distribution Shifts",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/93661c10ed346f9692f4d512319799b3-Paper.pdf",
    "abstract": "Safely deploying machine learning models to the real world is often a challenging process. For example, models trained with data obtained from a specific geographic location tend to fail when queried with data obtained elsewhere, agents trained in a simulation can struggle to adapt when deployed in the real world or novel environments, and neural networks that are fit to a subset of the population might carry some selection bias into their decision process.In this work, we describe the problem of data shift from an information-theoretic perspective by (i) identifying and describing the different sources of error, (ii) comparing some of the most promising objectives explored in the recent domain generalization and fair classification literature. From our theoretical analysis and empirical evaluation, we conclude that the model selection procedure needs to be guided by careful considerations regarding the observed data, the factors used for correction, and the structure of the data-generating process.",
    "authors": [
      "Federici, Marco",
      "Tomioka, Ryota",
      "Forr\u00e9, Patrick"
    ]
  },
  {
    "id": "937936029af671cf479fa893db91cbdd",
    "title": "TRS: Transferability Reduced Ensemble via Promoting Gradient Diversity and Model Smoothness",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/937936029af671cf479fa893db91cbdd-Paper.pdf",
    "abstract": "Adversarial Transferability is an intriguing property - adversarial perturbation crafted against one model is also effective against another model, while these models are from different model families or training processes. To better protect ML systems against adversarial attacks, several questions are raised: what are the sufficient conditions for adversarial transferability, and how to bound it? Is there a way to reduce the adversarial transferability in order to improve the robustness of an ensemble ML model? To answer these questions, in this work we first theoretically analyze and outline sufficient conditions for adversarial transferability between models; then propose a practical algorithm to reduce the transferability between base models within an ensemble to improve its robustness. Our theoretical analysis shows that only promoting the orthogonality between gradients of base models is not enough to ensure low transferability; in the meantime, the model smoothness is an important factor to control the transferability. We also provide the lower and upper bounds of adversarial transferability under certain conditions. Inspired by our theoretical analysis, we propose an effective Transferability Reduced Smooth (TRS) ensemble training strategy to train a robust ensemble with low transferability by enforcing both gradient orthogonality and model smoothness between base models. We conduct extensive experiments on TRS and compare with 6 state-of-the-art ensemble baselines against 8 whitebox attacks on different datasets, demonstrating that the proposed TRS outperforms all baselines significantly. ",
    "authors": [
      "Yang, Zhuolin",
      "Li, Linyi",
      "Xu, Xiaojun",
      "Zuo, Shiliang",
      "Chen, Qian",
      "Zhou, Pan",
      "Rubinstein, Benjamin",
      "Zhang, Ce",
      "Li, Bo"
    ]
  },
  {
    "id": "939314105ce8701e67489642ef4d49e8",
    "title": "Towards Sample-Optimal Compressive Phase Retrieval with Sparse and Generative Priors",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/939314105ce8701e67489642ef4d49e8-Paper.pdf",
    "abstract": "Compressive phase retrieval is a popular variant of the standard compressive sensing problem in which the measurements only contain magnitude information. In this paper, motivated by recent advances in deep generative models, we provide recovery guarantees with near-optimal sample complexity for phase retrieval with generative priors. We first show that when using i.i.d. Gaussian measurements and an $L$-Lipschitz continuous generative model with bounded $k$-dimensional inputs, roughly $O(k \\log L)$ samples suffice to guarantee that any signal minimizing an amplitude-based empirical loss function is close to the true signal. Attaining this sample complexity with a practical algorithm remains a difficult challenge, and finding a good initialization for gradient-based methods has been observed to pose a major bottleneck. To partially address this, we further show that roughly $O(k \\log L)$ samples ensure sufficient closeness between the underlying signal and any {\\em globally optimal} solution to an optimization problem designed for spectral initialization (though finding such a solution may still be challenging). We also adapt this result to sparse phase retrieval, and show that $O(s \\log n)$ samples are sufficient for a similar guarantee when the underlying signal is $s$-sparse and $n$-dimensional, matching an information-theoretic lower bound. While these guarantees do not directly correspond to a practical algorithm, we propose a practical spectral initialization method motivated by our findings, and experimentally observe performance gains over various existing spectral initialization methods for sparse phase retrieval.",
    "authors": [
      "Liu, Zhaoqiang",
      "Ghosh, Subhroshekhar",
      "Scarlett, Jonathan"
    ]
  },
  {
    "id": "93a27b0bd99bac3e68a440b48aa421ab",
    "title": "Moser Flow: Divergence-based Generative Modeling on Manifolds",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/93a27b0bd99bac3e68a440b48aa421ab-Paper.pdf",
    "abstract": "We are interested in learning generative models for complex geometries described via manifolds, such as spheres, tori, and other implicit surfaces. Current extensions of existing (Euclidean) generative models are restricted to specific geometries and typically suffer from high computational costs. We introduce Moser Flow (MF), a new class of generative models within the family of continuous normalizing flows (CNF). MF also produces a CNF via a solution to the change-of-variable formula, however differently from other CNF methods, its model (learned) density is parameterized as the source (prior) density minus the divergence of a neural network (NN). The divergence is a local, linear differential operator, easy to approximate and calculate on manifolds. Therefore, unlike other CNFs, MF does not require invoking or backpropagating through an ODE solver during training. Furthermore, representing the model density explicitly as the divergence of a NN rather than as a solution of an ODE facilitates learning high fidelity densities. Theoretically, we prove that MF constitutes a universal density approximator under suitable assumptions. Empirically, we demonstrate for the first time the use of flow models for sampling from general curved surfaces and achieve significant improvements in density estimation, sample quality, and training complexity over existing CNFs on challenging synthetic geometries and real-world benchmarks from the earth and climate sciences. ",
    "authors": [
      "Rozen, Noam",
      "Grover, Aditya",
      "Nickel, Maximilian",
      "Lipman, Yaron"
    ]
  },
  {
    "id": "93da579a65ce84cd1d4c85c2cbb84fc5",
    "title": "Structure-Aware Random Fourier Kernel for Graphs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/93da579a65ce84cd1d4c85c2cbb84fc5-Paper.pdf",
    "abstract": "Gaussian Processes (GPs) define distributions over functions and their generalization capabilities depend heavily on the choice of kernels. In this paper, we propose a novel structure-aware random Fourier (SRF) kernel for GPs that brings several benefits when modeling graph-structured data. First, SRF kernel is defined with a spectral distribution based on the Fourier duality given by the Bochner's theorem, transforming the kernel learning problem to a distribution inference problem. Second, SRF kernel admits a random Fourier feature formulation that makes the kernel scalable for optimization. Third, SRF kernel enables to leverage geometric structures by taking subgraphs as inputs. To effectively optimize GPs with SRF kernel, we develop a variational EM algorithm, which alternates between an inference procedure (E-step) and a learning procedure (M-step). Experimental results on five real-world datasets show that our model can achieve state-of-the-art performance in two typical graph learning tasks, i.e., object classification and link prediction. ",
    "authors": [
      "Fang, Jinyuan",
      "Zhang, Qiang",
      "Meng, Zaiqiao",
      "Liang, Shangsong"
    ]
  },
  {
    "id": "940392f5f32a7ade1cc201767cf83e31",
    "title": "Diffusion Schr\u00f6dinger Bridge with Applications to Score-Based Generative Modeling",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/940392f5f32a7ade1cc201767cf83e31-Paper.pdf",
    "abstract": "Progressively applying Gaussian noise transforms complex data distributions to approximately Gaussian. Reversing this dynamic defines a generative model. When the forward noising process is given by a Stochastic Differential Equation (SDE), Song et al (2021) demonstrate how the time inhomogeneous drift of the associated reverse-time SDE may be estimated using score-matching. A limitation of this approach is that the forward-time SDE must be run for a sufficiently long time for the final distribution to be approximately Gaussian. In contrast, solving the Schr\u00f6dinger Bridge (SB) problem, i.e. an entropy-regularized optimal transport problem on path spaces, yields diffusions which generate samples from the data distribution in finite time. We present Diffusion SB (DSB), an original approximation of the Iterative Proportional Fitting (IPF) procedure to solve the SB problem, and provide theoretical analysis along with generative modeling experiments. The first DSB iteration recovers the methodology proposed by Song et al. (2021), with the flexibility of using shorter time intervals, as subsequent DSB iterations reduce the discrepancy between the final-time marginal of the forward (resp. backward) SDE with respect to the prior (resp. data) distribution. Beyond generative modeling, DSB offers a widely applicable computational optimal transport tool as the continuous state-space analogue of the popular Sinkhorn algorithm (Cuturi, 2013).",
    "authors": [
      "De Bortoli, Valentin",
      "Thornton, James",
      "Heng, Jeremy",
      "Doucet, Arnaud"
    ]
  },
  {
    "id": "94130ea17023c4837f0dcdda95034b65",
    "title": "Improving Transferability of Representations via Augmentation-Aware Self-Supervision",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/94130ea17023c4837f0dcdda95034b65-Paper.pdf",
    "abstract": "Recent unsupervised representation learning methods have shown to be effective in a range of vision tasks by learning representations invariant to data augmentations such as random cropping and color jittering. However, such invariance could be harmful to downstream tasks if they rely on the characteristics of the data augmentations, e.g., location- or color-sensitive. This is not an issue just for unsupervised learning; we found that this occurs even in supervised learning because it also learns to predict the same label for all augmented samples of an instance. To avoid such failures and obtain more generalizable representations, we suggest to optimize an auxiliary self-supervised loss, coined AugSelf, that learns the difference of augmentation parameters (e.g., cropping positions, color adjustment intensities) between two randomly augmented samples. Our intuition is that AugSelf encourages to preserve augmentation-aware information in learned representations, which could be beneficial for their transferability. Furthermore, AugSelf can easily be incorporated into recent state-of-the-art representation learning methods with a negligible additional training cost. Extensive experiments demonstrate that our simple idea consistently improves the transferability of representations learned by supervised and unsupervised methods in various transfer learning scenarios. The code is available at https://github.com/hankook/AugSelf.",
    "authors": [
      "Lee, Hankook",
      "Lee, Kibok",
      "Lee, Kimin",
      "Lee, Honglak",
      "Shin, Jinwoo"
    ]
  },
  {
    "id": "9425be43ba92c2b4454ca7bf602efad8",
    "title": "Long-Short Transformer: Efficient Transformers for Language and Vision",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9425be43ba92c2b4454ca7bf602efad8-Paper.pdf",
    "abstract": "Transformers have achieved success in both language and vision domains. However, it is prohibitively expensive to scale them to long sequences such as long documents or high-resolution images, because self-attention mechanism has quadratic time and memory complexities with respect to the input sequence length. In this paper, we propose Long-Short Transformer (Transformer-LS), an efficient self-attention mechanism for modeling long sequences with linear complexity for both language and vision tasks. It aggregates a novel long-range attention with dynamic projection to model distant correlations and a short-term attention to capture fine-grained local correlations. We propose a dual normalization strategy to account for the scale mismatch between the two attention mechanisms. Transformer-LS can be applied to both autoregressive and bidirectional models without additional complexity. Our method outperforms the state-of-the-art models on multiple tasks in language and vision domains, including the Long Range Arena benchmark, autoregressive language modeling, and ImageNet classification. For instance, Transformer-LS achieves 0.97 test BPC on enwik8 using half the number of parameters than previous method, while being faster and is able to handle 3x as long sequences compared to its full-attention version on the same hardware. On ImageNet, it can obtain the state-of-the-art results (e.g., a moderate size of 55.8M model solely trained on 224x224 ImageNet-1K can obtain Top-1 accuracy 84.1%), while being more scalable on high-resolution images. The source code and models are released at https://github.com/NVIDIA/transformer-ls.",
    "authors": [
      "Zhu, Chen",
      "Ping, Wei",
      "Xiao, Chaowei",
      "Shoeybi, Mohammad",
      "Goldstein, Tom",
      "Anandkumar, Anima",
      "Catanzaro, Bryan"
    ]
  },
  {
    "id": "9431c87f273e507e6040fcb07dcb4509",
    "title": "Post-Training Sparsity-Aware Quantization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9431c87f273e507e6040fcb07dcb4509-Paper.pdf",
    "abstract": "Quantization is a technique used in deep neural networks (DNNs) to increase execution performance and hardware efficiency. Uniform post-training quantization (PTQ) methods are common, since they can be implemented efficiently in hardware and do not require extensive hardware resources or a training set. Mapping FP32 models to INT8 using uniform PTQ yields models with negligible accuracy degradation; however, reducing precision below 8 bits with PTQ is challenging, as accuracy degradation becomes noticeable, due to the increase in quantization noise. In this paper, we propose a sparsity-aware quantization (SPARQ) method, in which the unstructured and dynamic activation sparsity is leveraged in different representation granularities. 4-bit quantization, for example, is employed by dynamically examining the bits of 8-bit values and choosing a window of 4 bits, while first skipping zero-value bits. Moreover, instead of quantizing activation-by-activation to 4 bits, we focus on pairs of 8-bit activations and examine whether one of the two is equal to zero. If one is equal to zero, the second can opportunistically use the other's 4-bit budget; if both do not equal zero, then each is dynamically quantized to 4 bits, as described. SPARQ achieves minor accuracy degradation and a practical hardware implementation.",
    "authors": [
      "Shomron, Gil",
      "Gabbay, Freddy",
      "Kurzum, Samer",
      "Weiser, Uri"
    ]
  },
  {
    "id": "944a5ae3483ed5c1e10bbccb7942a279",
    "title": "The Implicit Bias of Minima Stability: A View from Function Space",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/944a5ae3483ed5c1e10bbccb7942a279-Paper.pdf",
    "abstract": "The loss terrains of over-parameterized neural networks have multiple global minima. However, it is well known that stochastic gradient descent (SGD) can stably converge only to minima that are sufficiently flat w.r.t. SGD's step size. In this paper we study the effect that this mechanism has on the function implemented by the trained model. First, we extend the existing knowledge on minima stability to non-differentiable minima, which are common in ReLU nets. We then use our stability results to study a single hidden layer univariate ReLU network. In this setting, we show that SGD is biased towards functions whose second derivative (w.r.t the input) has a bounded weighted $L_1$ norm, and this is regardless of the initialization. In particular, we show that the function implemented by the network upon convergence gets smoother as the learning rate increases. The weight multiplying the second derivative is larger around the center of the support of the training distribution, and smaller towards its boundaries, suggesting that a trained model tends to be smoother at the center of the training distribution.",
    "authors": [
      "Mulayoff, Rotem",
      "Michaeli, Tomer",
      "Soudry, Daniel"
    ]
  },
  {
    "id": "94739e5a5164b4d2396e253a11d57044",
    "title": "Breaking the Sample Complexity Barrier to Regret-Optimal Model-Free Reinforcement Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/94739e5a5164b4d2396e253a11d57044-Paper.pdf",
    "abstract": "Achieving sample efficiency in online episodic reinforcement learning (RL) requires optimally balancing  exploration and exploitation. When it comes to a finite-horizon episodic Markov decision process with $S$ states, $A$ actions and horizon length $H$, substantial progress has been achieved towards characterizing the minimax-optimal regret, which scales on the order of $\\sqrt{H^2SAT}$ (modulo log factors) with $T$ the total number of samples. While several competing solution paradigms have been proposed to minimize regret, they are either memory-inefficient, or fall short of optimality unless the sample size exceeds an enormous threshold (e.g., $S^6A^4 \\,\\mathrm{poly}(H)$ for existing model-free methods).To overcome such a large sample size barrier to efficient RL, we design a novel model-free algorithm, with space complexity $O(SAH)$, that achieves near-optimal regret as soon as the sample size exceeds the order of $SA\\,\\mathrm{poly}(H)$. In terms of this sample size requirement (also referred to the initial burn-in cost), our method improves --- by at least a factor of $S^5A^3$ --- upon any prior memory-efficient algorithm that is asymptotically regret-optimal. Leveraging the recently introduced variance reduction strategy (also called {\\em reference-advantage decomposition}), the proposed algorithm employs an {\\em early-settled}  reference update rule, with the aid of two Q-learning sequences with upper and lower confidence bounds. The design principle of our early-settled variance reduction method might be of independent interest to other RL settings that involve intricate exploration-exploitation trade-offs.",
    "authors": [
      "Li, Gen",
      "Shi, Laixi",
      "Chen, Yuxin",
      "Gu, Yuantao",
      "Chi, Yuejie"
    ]
  },
  {
    "id": "948f847055c6bf156997ce9fb59919be",
    "title": "Robust Auction Design in the Auto-bidding World",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/948f847055c6bf156997ce9fb59919be-Paper.pdf",
    "abstract": "In classic auction theory, reserve prices are known to be effective for improving revenue for the auctioneer against quasi-linear utility maximizing bidders. The introduction of reserve prices, however, usually do not help improve total welfare of the auctioneer and the bidders. In this paper, we focus on value maximizing bidders with return on spend constraints---a paradigm that has drawn considerable attention recently as more advertisers adopt auto-bidding algorithms in advertising platforms---and show that the introduction of reserve prices has a novel impact on the market. Namely, by choosing reserve prices appropriately the auctioneer can improve not only the total revenue but also the total welfare. Our results also demonstrate that reserve prices are robust to bidder types, i.e., reserve prices work well for different bidder types, such as value maximizers and utility maximizers, without using bidder type information. We generalize these results for a variety of auction mechanisms such as VCG, GSP, and first-price auctions. Moreover, we show how to combine these results with additive boosts to improve the welfare of the outcomes of the auction further. Finally, we complement our theoretical observations with an empirical study confirming the effectiveness of these ideas using data from online advertising auctions. ",
    "authors": [
      "Balseiro, Santiago",
      "Deng, Yuan",
      "Mao, Jieming",
      "Mirrokni, Vahab",
      "Zuo, Song"
    ]
  },
  {
    "id": "949694a5059302e7283073b502f094d7",
    "title": "Weighted model estimation for offline model-based reinforcement learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/949694a5059302e7283073b502f094d7-Paper.pdf",
    "abstract": "This paper discusses model estimation in offline model-based reinforcement learning (MBRL), which is important for subsequent policy improvement using an estimated model. From the viewpoint of covariate shift, a natural idea is model estimation weighted by the ratio of the state-action distributions of offline data and real future data. However, estimating such a natural weight is one of the main challenges for off-policy evaluation, which is not easy to use. As an artificial alternative, this paper considers weighting with the state-action distribution ratio of offline data and simulated future data, which can be estimated relatively easily by standard density ratio estimation techniques for supervised learning. Based on the artificial weight, this paper defines a loss function for offline MBRL and presents an algorithm to optimize it. Weighting with the artificial weight is justified as evaluating an upper bound of the policy evaluation error. Numerical experiments demonstrate the effectiveness of weighting with the artificial weight.",
    "authors": [
      "Hishinuma, Toru",
      "Senda, Kei"
    ]
  },
  {
    "id": "94aada62f90dd50a84ca74304563d5db",
    "title": "Practical, Provably-Correct Interactive Learning in the Realizable Setting: The Power of True Believers",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/94aada62f90dd50a84ca74304563d5db-Paper.pdf",
    "abstract": "We consider interactive learning in the realizable setting and develop a general framework to handle problems ranging from best arm identification to active classification. We begin our investigation with the observation that agnostic algorithms \\emph{cannot} be minimax-optimal in the realizable setting. Hence, we design novel computationally efficient algorithms for the realizable setting that match the minimax lower bound up to logarithmic factors and are general-purpose, accommodating a wide variety of function classes including kernel methods, H{\\\"o}lder smooth functions, and convex functions. The sample complexities of our algorithms can be quantified in terms of well-known quantities like the extended teaching dimension and haystack dimension. However, unlike algorithms based directly on those combinatorial quantities, our algorithms are computationally efficient. To achieve computational efficiency, our algorithms sample from the version space using Monte Carlo ``hit-and-run'' algorithms instead of maintaining the version space explicitly. Our approach has two key strengths. First, it is simple, consisting of two unifying, greedy algorithms. Second, our algorithms have the capability to seamlessly leverage prior knowledge that is often available and useful in practice. In addition to our new theoretical results, we demonstrate empirically that our algorithms are competitive with Gaussian process UCB methods.",
    "authors": [
      "Katz-Samuels, Julian",
      "Mason, Blake",
      "Jamieson, Kevin G.",
      "Nowak, Rob"
    ]
  },
  {
    "id": "94aef38441efa3380a3bed3faf1f9d5d",
    "title": "Deconditional Downscaling with Gaussian Processes",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/94aef38441efa3380a3bed3faf1f9d5d-Paper.pdf",
    "abstract": "Refining low-resolution (LR) spatial fields with high-resolution (HR) information, often known as statistical downscaling, is challenging as the diversity of spatial datasets often prevents direct matching of observations. Yet, when LR samples are modeled as aggregate conditional means of HR samples with respect to a mediating variable that is globally observed, the recovery of the underlying fine-grained field can be framed as taking an \"inverse\" of the conditional expectation, namely a deconditioning problem. In this work, we propose a Bayesian formulation of deconditioning which naturally recovers the initial reproducing kernel Hilbert space formulation from Hsu and Ramos (2019). We extend deconditioning to a downscaling setup and devise efficient conditional mean embedding estimator for multiresolution data. By treating conditional expectations as inter-domain features of the underlying field, a posterior for the latent field can be established as a solution to the deconditioning problem. Furthermore, we show that this solution can be viewed as a two-staged vector-valued kernel ridge regressor and show that it has a minimax optimal convergence rate under mild assumptions. Lastly, we demonstrate its proficiency in a synthetic and a real-world atmospheric field downscaling problem, showing substantial improvements over existing methods.",
    "authors": [
      "Chau, Siu Lun",
      "Bouabid, Shahine",
      "Sejdinovic, Dino"
    ]
  },
  {
    "id": "94c7bb58efc3b337800875b5d382a072",
    "title": "Image Generation using Continuous Filter Atoms",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/94c7bb58efc3b337800875b5d382a072-Paper.pdf",
    "abstract": "In this paper, we model the subspace of convolutional filters with a neural ordinary differential equation (ODE) to enable gradual changes in generated images. Decomposing convolutional filters over a set of filter atoms allows efficiently modeling and sampling from a subspace of high-dimensional filters. By further modeling filters atoms with a neural ODE, we show both empirically and theoretically that such introduced continuity can be propagated to the generated images, and thus achieves gradually evolved image generation. We support the proposed framework of image generation with continuous filter atoms using various experiments, including image-to-image translation and image generation conditioned on continuous labels. Without auxiliary network components and heavy supervision, the proposed continuous filter atoms allow us to easily manipulate the gradual change of generated images by controlling integration intervals of neural ordinary differential equation. This research sheds the light on using the subspace of network parameters to navigate the diverse appearance of image generation.",
    "authors": [
      "Wang, Ze",
      "Hwang, Seunghyun",
      "Miao, Zichen",
      "Qiu, Qiang"
    ]
  },
  {
    "id": "94cdbdb84e8e1de8a725fa2ed61498a4",
    "title": "Latent Equilibrium: A unified learning theory for arbitrarily fast computation with arbitrarily slow neurons",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/94cdbdb84e8e1de8a725fa2ed61498a4-Paper.pdf",
    "abstract": "The response time of physical computational elements is finite, and neurons are no exception. In hierarchical models of cortical networks each layer thus introduces a response lag. This inherent property of physical dynamical systems results in delayed processing of stimuli and causes a timing mismatch between network output and instructive signals, thus afflicting not only inference, but also learning. We introduce Latent Equilibrium, a new framework for inference and learning in networks of slow components which avoids these issues by harnessing the ability of biological neurons to phase-advance their output with respect to their membrane potential. This principle enables quasi-instantaneous inference independent of network depth and avoids the need for phased plasticity or computationally expensive network relaxation phases. We jointly derive disentangled neuron and synapse dynamics from a prospective energy function that depends on a network's generalized position and momentum. The resulting model can be interpreted as a biologically plausible approximation of error backpropagation in deep cortical networks with continuous-time, leaky neuronal dynamics and continuously active, local plasticity. We demonstrate successful learning of standard benchmark datasets, achieving competitive performance using both fully-connected and convolutional architectures, and show how our principle can be applied to detailed models of cortical microcircuitry. Furthermore, we study the robustness of our model to spatio-temporal substrate imperfections to demonstrate its feasibility for physical realization, be it in vivo or in silico.",
    "authors": [
      "Haider, Paul",
      "Ellenberger, Benjamin",
      "Kriener, Laura",
      "Jordan, Jakob",
      "Senn, Walter",
      "Petrovici, Mihai A."
    ]
  },
  {
    "id": "94e70705efae423efda1088614128d0b",
    "title": "Learning Fast-Inference Bayesian Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/94e70705efae423efda1088614128d0b-Paper.pdf",
    "abstract": "We propose new methods for learning Bayesian networks (BNs) that reliably support fast inference. We utilize maximum state space size as a more fine-grained measure for the BN's reasoning complexity than the standard treewidth measure, thereby accommodating the possibility that variables range over domains of different sizes. Our methods combine heuristic BN structure learning algorithms with the recently introduced MaxSAT-powered local improvement method (Peruvemba Ramaswamy and Szeider, AAAI'21). Our experiments show that our new learning methods produce BNs that support significantly faster exact probabilistic inference than BNs learned with treewidth bounds.",
    "authors": [
      "Peruvemba Ramaswamy, Vaidyanathan",
      "Szeider, Stefan"
    ]
  },
  {
    "id": "950a4152c2b4aa3ad78bdd6b366cc179",
    "title": "Per-Pixel Classification is Not All You Need for Semantic Segmentation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/950a4152c2b4aa3ad78bdd6b366cc179-Paper.pdf",
    "abstract": "Modern approaches typically formulate semantic segmentation as a per-pixel classification task, while instance-level segmentation is handled with an alternative mask classification. Our key insight: mask classification is sufficiently general to solve both semantic- and instance-level segmentation tasks in a unified manner using the exact same model, loss, and training procedure. Following this observation, we propose MaskFormer, a simple mask classification model which predicts a set of binary masks, each associated with a single global class label prediction. Overall, the proposed mask classification-based method simplifies the landscape of effective approaches to semantic and panoptic segmentation tasks and shows excellent empirical results. In particular, we observe that MaskFormer outperforms per-pixel classification baselines when the number of classes is large. Our mask classification-based method outperforms both current state-of-the-art semantic (55.6 mIoU on ADE20K) and panoptic segmentation (52.7 PQ on COCO) models.",
    "authors": [
      "Cheng, Bowen",
      "Schwing, Alex",
      "Kirillov, Alexander"
    ]
  },
  {
    "id": "951124d4a093eeae83d9726a20295498",
    "title": "Deep Markov Factor Analysis: Towards Concurrent Temporal and Spatial Analysis of fMRI Data",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/951124d4a093eeae83d9726a20295498-Paper.pdf",
    "abstract": "Factor analysis methods have been widely used in neuroimaging to transfer high dimensional imaging data into low dimensional, ideally interpretable representations. However, most of these methods overlook the highly nonlinear and complex temporal dynamics of neural processes when factorizing their imaging data. In this paper, we present deep Markov factor analysis (DMFA), a generative model that employs Markov property in a chain of low dimensional temporal embeddings together with spatial inductive assumptions, all related through neural networks, to capture temporal dynamics in functional magnetic resonance imaging (fMRI) data, and tackle their high spatial dimensionality, respectively. Augmented with a discrete latent, DMFA is able to cluster fMRI data in its low dimensional temporal embedding with regard to subject and cognitive state variability, therefore, enables validation of a variety of fMRI-driven neuroscientific hypotheses. Experimental results on both synthetic and real fMRI data demonstrate the capacity of DMFA in revealing interpretable clusters and capturing nonlinear temporal dependencies in these high dimensional imaging data.",
    "authors": [
      "Farnoosh, Amirreza",
      "Ostadabbas, Sarah"
    ]
  },
  {
    "id": "952285b9b7e7a1be5aa7849f32ffff05",
    "title": "BooVAE: Boosting Approach for Continual Learning of VAE",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/952285b9b7e7a1be5aa7849f32ffff05-Paper.pdf",
    "abstract": "Variational autoencoder (VAE) is a deep generative model for unsupervised learning, allowing to encode observations into the meaningful latent space. VAE is prone to catastrophic forgetting when tasks arrive sequentially, and only the data for the current one is available. We address this problem of continual learning for VAEs. It is known that the choice of the prior distribution over the latent space is crucial for VAE in the non-continual setting. We argue that it can also be helpful to avoid catastrophic forgetting. We learn the approximation of the aggregated posterior as a prior for each task. This approximation is parametrised as an additive mixture of distributions induced by an encoder evaluated at trainable pseudo-inputs. We use a greedy boosting-like approach with entropy regularisation to learn the components. This method encourages components diversity, which is essential as we aim at memorising the current task with the fewest components possible. Based on the learnable prior, we introduce an end-to-end approach for continual learning of VAEs and provide empirical studies on commonly used benchmarks (MNIST, Fashion MNIST, NotMNIST) and CelebA datasets. For each dataset, the proposed method avoids catastrophic forgetting in a fully automatic way.",
    "authors": [
      "Egorov, Evgenii",
      "Kuzina, Anna",
      "Burnaev, Evgeny"
    ]
  },
  {
    "id": "95323660ed2124450caaac2c46b5ed90",
    "title": "Handling Long-tailed Feature Distribution in AdderNets",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/95323660ed2124450caaac2c46b5ed90-Paper.pdf",
    "abstract": "Adder neural networks (ANNs) are designed for low energy cost which replace expensive multiplications in convolutional neural networks (CNNs) with cheaper additions to yield energy-efficient neural networks and hardware accelerations. Although ANNs achieve satisfactory efficiency, there exist gaps between ANNs and CNNs where the accuracy of ANNs can hardly be compared to CNNs without the assistance of other training tricks, such as knowledge distillation. The inherent discrepancy lies in the similarity measurement between filters and features, however how to alleviate this difference remains unexplored. To locate the potential problem of ANNs, we focus on the property difference due to similarity measurement. We demonstrate that unordered heavy tails in ANNs could be the key component which prevents ANNs from achieving superior classification performance since fatter tails tend to overlap in feature space. Through pre-defining Multivariate Skew Laplace distributions and embedding feature distributions into the loss function, ANN features can be fully controlled and designed for various properties. We further present a novel method for tackling existing heavy tails in ANNs with only a modification of classifier where ANN features are clustered with their tails well-formulated through proposed angle-based constraint on the distribution parameters to encourage high diversity of tails. Experiments conducted on several benchmarks and comparison with other distributions demonstrate the effectiveness of proposed approach for boosting the performance of ANNs.",
    "authors": [
      "Dong, Minjing",
      "Wang, Yunhe",
      "Chen, Xinghao",
      "Xu, Chang"
    ]
  },
  {
    "id": "9559fc73b13fa721a816958488a5b449",
    "title": "Pessimism Meets Invariance: Provably Efficient Offline Mean-Field Multi-Agent RL",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9559fc73b13fa721a816958488a5b449-Paper.pdf",
    "abstract": "Mean-Field Multi-Agent Reinforcement Learning (MF-MARL) is attractive in the applications involving a large population of homogeneous agents, as it exploits the permutation invariance of agents and avoids the curse of many agents. Most existing results only focus on online settings, in which agents can interact with the environment during training. In some applications such as social welfare optimization, however, the interaction during training can be prohibitive or even unethical in the societal systems. To bridge such a gap, we propose a SAFARI (peSsimistic meAn-Field vAlue iteRatIon) algorithm for off-line MF-MARL, which only requires a handful of pre-collected experience data. Theoretically, under a weak coverage assumption that the experience dataset contains enough information about the optimal policy, we prove that for an episodic mean-field MDP with a horizon $H$ and $N$ training trajectories, SAFARI attains a sub-optimality gap of $\\mathcal{O}(H^2d_{\\rm eff} /\\sqrt{N})$, where $d_{\\rm eff}$ is the effective dimension of the function class for parameterizing the value function, but independent on the number of agents. Numerical experiments are provided.",
    "authors": [
      "Chen, Minshuo",
      "Li, Yan",
      "Wang, Ethan",
      "Yang, Zhuoran",
      "Wang, Zhaoran",
      "Zhao, Tuo"
    ]
  },
  {
    "id": "955fd82131e15e7b5199cbc8f983306a",
    "title": "A Law of Iterated Logarithm for Multi-Agent Reinforcement Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/955fd82131e15e7b5199cbc8f983306a-Paper.pdf",
    "abstract": "In Multi-Agent Reinforcement Learning (MARL), multiple agents interact with a common environment, as also with each other, for solving a shared problem in sequential decision-making. It has wide-ranging applications in gaming, robotics, finance, communication, etc. In this work, we derive a novel law of iterated logarithm for a family of  distributed nonlinear stochastic approximation schemes that is useful in MARL. In particular, our result describes the convergence rate on almost every sample path where the algorithm converges. This result is the first of its kind in the distributed setup and provides deeper insights than the existing ones, which only discuss convergence rates in the expected or the CLT sense. Importantly, our result holds under significantly weaker assumptions: neither the gossip matrix needs to be doubly stochastic nor the stepsizes square summable. As an application, we show  that, for the stepsize $n^{-\\gamma}$ with $\\gamma \\in (0, 1),$ the distributed TD(0) algorithm with linear function approximation has a convergence rate of $O(\\sqrt{n^{-\\gamma} \\ln n })$ a.s.; for the $1/n$ type stepsize, the same is $O(\\sqrt{n^{-1} \\ln \\ln n})$ a.s. These decay rates do not depend on the graph depicting the interactions among the different agents. ",
    "authors": [
      "Thoppe, Gugan Chandrashekhar",
      "Kumar, Bhumesh"
    ]
  },
  {
    "id": "95688ba636a4720a85b3634acfec8cdd",
    "title": "MOMA: Multi-Object Multi-Actor Activity Parsing",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/95688ba636a4720a85b3634acfec8cdd-Paper.pdf",
    "abstract": "Complex activities often involve multiple humans utilizing different objects to complete actions (e.g., in healthcare settings, physicians, nurses, and patients interact with each other and various medical devices). Recognizing activities poses a challenge that requires a detailed understanding of actors' roles, objects' affordances, and their associated relationships. Furthermore, these purposeful activities are composed of multiple achievable steps, including sub-activities and atomic actions, which jointly define a hierarchy of action parts. This paper introduces Activity Parsing as the overarching task of temporal segmentation and classification of activities, sub-activities, atomic actions, along with an instance-level understanding of actors, objects, and their relationships in videos. Involving multiple entities (actors and objects), we argue that traditional pair-wise relationships, often used in scene or action graphs, do not appropriately represent the dynamics between them. Hence, we introduce Action Hypergraph, a spatial-temporal graph containing hyperedges (i.e., edges with higher-order relationships), as a new representation. In addition, we introduce Multi-Object Multi-Actor (MOMA), the first benchmark and dataset dedicated to activity parsing. Lastly, to parse a video, we propose the HyperGraph Activity Parsing (HGAP) network, which outperforms several baselines, including those based on regular graphs and raw video data. ",
    "authors": [
      "Luo, Zelun",
      "Xie, Wanze",
      "Kapoor, Siddharth",
      "Liang, Yiyun",
      "Cooper, Michael",
      "Niebles, Juan Carlos",
      "Adeli, Ehsan",
      "Li, Fei-Fei"
    ]
  },
  {
    "id": "9570efef719d705326f0ff817ef084e6",
    "title": "The Pareto Frontier of model selection for general Contextual Bandits",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9570efef719d705326f0ff817ef084e6-Paper.pdf",
    "abstract": "Recent progress in model selection raises the question of the fundamental limits of these techniques. Under specific scrutiny has been model selection for general contextual bandits with nested policy classes, resulting in a COLT2020 open problem. It asks whether it is possible to obtain simultaneously the optimal single algorithm guarantees over all policies in a nested sequence of policy classes, or if otherwise this is possible for a trade-off  $\\alpha\\in[\\frac{1}{2},1)$ between complexity term and time: $\\ln(|\\Pi_m|)^{1-\\alpha}T^\\alpha$. We give a disappointing answer to this question. Even in the purely stochastic regime, the desired results are unobtainable. We present a Pareto frontier of up to logarithmic factors matching upper and lower bounds, thereby proving that an increase in the complexity term $\\ln(|\\Pi_m|)$ independent of $T$ is unavoidable for general policy classes.As a side result, we also resolve a COLT2016 open problem concerning second-order bounds in full-information games.",
    "authors": [
      "Marinov, Teodor Vanislavov",
      "Zimmert, Julian"
    ]
  },
  {
    "id": "958adb57686c2fdec5796398de5f317a",
    "title": "Teaching an Active Learner with Contrastive Examples",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/958adb57686c2fdec5796398de5f317a-Paper.pdf",
    "abstract": "We study the problem of active learning with the added twist that the learner is assisted by a helpful teacher. We consider the following natural interaction protocol: At each round, the learner proposes a query asking for the label of an instance $x^q$, the teacher provides the requested label $\\{x^q, y^q\\}$ along with explanatory information to guide the learning process. In this paper, we view this information in the form of an additional contrastive example ($\\{x^c, y^c\\}$) where $x^c$ is picked from a set constrained by $x^q$ (e.g., dissimilar instances with the same label). Our focus is to design a teaching algorithm that can provide an informative sequence of contrastive examples to the learner to speed up the learning process. We show that this leads to a challenging sequence optimization problem where the algorithm's choices at a given round depend on the history of interactions. We investigate an efficient teaching algorithm that adaptively picks these contrastive examples. We derive strong performance guarantees for our algorithm based on two problem-dependent parameters and further show that for specific types of active learners (e.g., a generalized binary search learner), the proposed teaching algorithm exhibits strong approximation guarantees. Finally, we illustrate our bounds and demonstrate the effectiveness of our teaching framework via two numerical case studies.",
    "authors": [
      "Wang, Chaoqi",
      "Singla, Adish",
      "Chen, Yuxin"
    ]
  },
  {
    "id": "958c530554f78bcd8e97125b70e6973d",
    "title": "Structured Denoising Diffusion Models in Discrete State-Spaces",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/958c530554f78bcd8e97125b70e6973d-Paper.pdf",
    "abstract": "Denoising diffusion probabilistic models (DDPMs) [Ho et al. 2021] have shown impressive results on image and waveform generation in continuous state spaces. Here, we introduce Discrete Denoising Diffusion Probabilistic Models (D3PMs), diffusion-like generative models for discrete data that generalize the multinomial diffusion model of Hoogeboom et al. [2021], by going beyond corruption processes with uniform transition probabilities. This includes corruption with transition matrices that mimic Gaussian kernels in continuous space, matrices based on nearest neighbors in embedding space, and matrices that introduce absorbing states. The third allows us to draw a connection between diffusion models and autoregressive and mask-based generative models. We show that the choice of transition matrix is an important design decision that leads to improved results in image and text domains. We also introduce a new loss function that combines the variational lower bound with an auxiliary cross entropy loss.  For text, this model class achieves strong results on character-level text generation while scaling to large vocabularies on LM1B. On the image dataset CIFAR-10, our models approach the sample quality and exceed the log-likelihood of the continuous-space DDPM model.",
    "authors": [
      "Austin, Jacob",
      "Johnson, Daniel D.",
      "Ho, Jonathan",
      "Tarlow, Daniel",
      "van den Berg, Rianne"
    ]
  },
  {
    "id": "9597353e41e6957b5e7aa79214fcb256",
    "title": "Emergent Communication of Generalizations",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9597353e41e6957b5e7aa79214fcb256-Paper.pdf",
    "abstract": "To build agents that can collaborate effectively with others, recent research has trained artificial agents to communicate with each other in Lewis-style referential games. However, this often leads to successful but uninterpretable communication. We argue that this is due to the game objective: communicating about a single object in a shared visual context is prone to overfitting and does not encourage language useful beyond concrete reference. In contrast, human language conveys a rich variety of abstract ideas. To promote such skills, we propose games that require communicating generalizations over sets of objects representing abstract visual concepts, optionally with separate contexts for each agent. We find that these games greatly improve systematicity and interpretability of the learned languages, according to several metrics in the literature. Finally, we propose a method for identifying logical operations embedded in the emergent languages by learning an approximate compositional reconstruction of the language.",
    "authors": [
      "Mu, Jesse",
      "Goodman, Noah"
    ]
  },
  {
    "id": "959776b99b006e5785c3a3364949ce47",
    "title": "Distributed Machine Learning with Sparse Heterogeneous Data",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/959776b99b006e5785c3a3364949ce47-Paper.pdf",
    "abstract": "Motivated by distributed machine learning settings such as Federated Learning, we consider the problem of fitting a statistical model across a distributed collection of heterogeneous data sets whose similarity structure is encoded by a graph topology. Precisely, we analyse the case where each node is associated with fitting a sparse linear model, and edges join two nodes if the difference of their solutions is also sparse. We propose a method based on Basis Pursuit Denoising with a total variation penalty, and provide finite sample guarantees for sub-Gaussian  design matrices. Taking the root of the tree as a reference node, we show that if the sparsity of the differences across nodes is smaller than the sparsity at the root, then recovery is successful with fewer samples than by solving the problems independently, or by using methods that rely on a large overlap in the signal supports, such as the group Lasso. We consider both the noiseless and noisy setting, and numerically investigate the performance of distributed methods based on Distributed Alternating Direction Methods of Multipliers (ADMM) and hyperspectral unmixing.",
    "authors": [
      "Richards, Dominic",
      "Negahban, Sahand",
      "Rebeschini, Patrick"
    ]
  },
  {
    "id": "959ab9a0695c467e7caf75431a872e5c",
    "title": "Manipulating SGD with Data Ordering Attacks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/959ab9a0695c467e7caf75431a872e5c-Paper.pdf",
    "abstract": "Machine learning is vulnerable to a wide variety of attacks. It is now well understood that by changing the underlying data distribution, an adversary can poison the model trained with it or introduce backdoors. In this paper we present a novel class of training-time attacks that require no changes to the underlying dataset or model architecture, but instead only change the order in which data are supplied to the model. In particular, we find that the attacker can either prevent the model from learning, or poison it to learn behaviours specified by the attacker. Furthermore, we find that even a single adversarially-ordered epoch can be enough to slow down model learning, or even to reset all of the learning progress. Indeed, the attacks presented here are not specific to the model or dataset, but rather target the stochastic nature of modern learning procedures. We extensively evaluate our attacks on computer vision and natural language benchmarks to find that the adversary can disrupt model training and even introduce backdoors.",
    "authors": [
      "Shumailov, I",
      "Shumaylov, Zakhar",
      "Kazhdan, Dmitry",
      "Zhao, Yiren",
      "Papernot, Nicolas",
      "Erdogdu, Murat A.",
      "Anderson, Ross J"
    ]
  },
  {
    "id": "95b431e51fc53692913da5263c214162",
    "title": "Graph Posterior Network: Bayesian Predictive Uncertainty for Node Classification",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/95b431e51fc53692913da5263c214162-Paper.pdf",
    "abstract": "The interdependence between nodes in graphs is key to improve class prediction on nodes, utilized in approaches like Label Probagation (LP) or in Graph Neural Networks (GNNs). Nonetheless, uncertainty estimation for non-independent node-level predictions is under-explored.  In this work, we explore uncertainty quantification for node classification in three ways: (1) We derive three axioms explicitly characterizing the expected predictive uncertainty behavior in homophilic attributed graphs.(2) We propose a new model Graph Posterior Network (GPN) which explicitly performs Bayesian posterior updates for predictions on interdependent nodes. GPN provably obeys the proposed axioms. (3) We extensively evaluate GPN and a strong set of baselines on semi-supervised node classification including detection of anomalous features, and detection of left-out classes. GPN outperforms existing approaches for uncertainty estimation in the experiments.",
    "authors": [
      "Stadler, Maximilian",
      "Charpentier, Bertrand",
      "Geisler, Simon",
      "Z\u00fcgner, Daniel",
      "G\u00fcnnemann, Stephan"
    ]
  },
  {
    "id": "95c3f1a8b262ec7a929a8739e21142d7",
    "title": "Locality Sensitive Teaching",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/95c3f1a8b262ec7a929a8739e21142d7-Paper.pdf",
    "abstract": "The emergence of the Internet-of-Things (IoT) sheds light on applying the machine teaching (MT) algorithms for online personalized education on home devices. This direction becomes more promising during the COVID-19 pandemic when in-person education becomes infeasible. However, as one of the most influential and practical MT paradigms, iterative machine teaching (IMT) is prohibited on IoT devices due to its inefficient and unscalable algorithms. IMT is a paradigm where a teacher feeds examples iteratively and intelligently based on the learner's status. In each iteration, current IMT algorithms greedily traverse the whole training set to find an example for the learner, which is computationally expensive in practice.  We propose a novel teaching framework, Locality Sensitive Teaching (LST), based on locality sensitive sampling, to overcome these challenges. LST has provable near-constant time complexity, which is exponentially better than the existing baseline. With at most 425.12x speedups and 99.76% energy savings over IMT, LST is the first algorithm that enables energy and time efficient machine teaching on IoT devices. Owing to LST's substantial efficiency and scalability, it is readily applicable in real-world education scenarios.",
    "authors": [
      "Xu, Zhaozhuo",
      "Chen, Beidi",
      "Li, Chaojian",
      "Liu, Weiyang",
      "Song, Le",
      "Lin, Yingyan",
      "Shrivastava, Anshumali"
    ]
  },
  {
    "id": "95f2b84de5660ddf45c8a34933a2e66f",
    "title": "No-Press Diplomacy from Scratch",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/95f2b84de5660ddf45c8a34933a2e66f-Paper.pdf",
    "abstract": "Prior AI successes in complex games have largely focused on settings with at most hundreds of actions at each decision point. In contrast, Diplomacy is a game with more than 10^20 possible actions per turn. Previous attempts to address games with large branching factors, such as Diplomacy, StarCraft, and Dota, used human data to bootstrap the policy or used handcrafted reward shaping. In this paper, we describe an algorithm for action exploration and equilibrium approximation in games with combinatorial action spaces. This algorithm simultaneously performs value iteration while learning a policy proposal network. A double oracle step is used to explore additional actions to add to the policy proposals. At each state, the target state value and policy for the model training are computed via an equilibrium search procedure. Using this algorithm, we train an agent, DORA, completely from scratch for a popular two-player variant of Diplomacy and show that it achieves superhuman performance. Additionally, we extend our methods to full-scale no-press Diplomacy and for the first time train an agent from scratch with no human data. We present evidence that this agent plays a strategy that is incompatible with human-data bootstrapped agents. This presents the first strong evidence of multiple equilibria in Diplomacy and suggests that self play alone may be insufficient for achieving superhuman performance in Diplomacy.",
    "authors": [
      "Bakhtin, Anton",
      "Wu, David",
      "Lerer, Adam",
      "Brown, Noam"
    ]
  },
  {
    "id": "9627c45df543c816a3ddf2d8ea686a99",
    "title": "Remember What You Want to Forget: Algorithms for Machine Unlearning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9627c45df543c816a3ddf2d8ea686a99-Paper.pdf",
    "abstract": "We study the problem of unlearning datapoints from a learnt model. The learner first receives a dataset $S$ drawn i.i.d. from an unknown distribution, and outputs a model $\\widehat{w}$ that performs well on  unseen samples from the same distribution. However, at some point in the future, any training datapoint $z \\in S$ can request to be unlearned, thus prompting the learner to modify its output model while still ensuring the same accuracy guarantees.  We initiate a rigorous study of generalization in machine unlearning, where the goal is to perform well on previously unseen datapoints. Our focus is on both computational and storage complexity. For the setting of convex losses, we provide an unlearning algorithm that can unlearn up to $O(n/d^{1/4})$ samples, where $d$ is the problem dimension. In comparison, in general, differentially private learning (which implies unlearning) only guarantees deletion of $O(n/d^{1/2})$ samples. This demonstrates a novel separation between differential privacy and machine unlearning. ",
    "authors": [
      "Sekhari, Ayush",
      "Acharya, Jayadev",
      "Kamath, Gautam",
      "Suresh, Ananda Theertha"
    ]
  },
  {
    "id": "966aad8981dcc75b5b8ab04427a833b2",
    "title": "Learning latent causal graphs via mixture oracles",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/966aad8981dcc75b5b8ab04427a833b2-Paper.pdf",
    "abstract": "We study the problem of reconstructing a causal graphical model from data in the presence of latent variables. The main problem of interest is recovering the causal structure over the latent variables while allowing for general, potentially nonlinear dependencies. In many practical problems, the dependence between raw observations (e.g. pixels in an image) is much less relevant than the dependence between certain high-level, latent features (e.g. concepts or objects), and this is the setting of interest. We provide conditions under which both the latent representations and the underlying latent causal model are identifiable by a reduction to a mixture oracle. These results highlight an intriguing connection between the well-studied problem of learning the order of a mixture model and the problem of learning the bipartite structure between observables and unobservables. The proof is constructive, and leads to several algorithms for explicitly reconstructing the full graphical model. We discuss efficient algorithms and provide experiments illustrating the algorithms in practice.",
    "authors": [
      "Kivva, Bohdan",
      "Rajendran, Goutham",
      "Ravikumar, Pradeep",
      "Aragam, Bryon"
    ]
  },
  {
    "id": "968c9b4f09cbb7d7925f38aea3484111",
    "title": "ErrorCompensatedX: error compensation for variance reduced algorithms",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/968c9b4f09cbb7d7925f38aea3484111-Paper.pdf",
    "abstract": "Communication cost is one major bottleneck for the scalability for distributed learning. One approach to reduce the communication cost is to compress the gradient during communication. However, directly compressing the gradient decelerates the convergence speed, and the resulting algorithm may diverge for biased compression. Recent work addressed this problem for stochastic gradient descent by adding back the compression error from the previous step. This idea was further extended to one class of variance reduced algorithms, where the variance of the stochastic gradient is reduced by taking a moving average over all history gradients. However, our analysis shows that just adding the previous step's compression error, as done in existing work, does not fully compensate the compression error. So, we propose ErrorCompensateX, which uses the compression error from the previous two steps. We show that ErrorCompensateX can achieve the same asymptotic convergence rate with the training without compression. Moreover, we  provide a unified theoretical analysis framework for this class of variance reduced algorithms, with or without error compensation. ",
    "authors": [
      "Tang, Hanlin",
      "Li, Yao",
      "Liu, Ji",
      "Yan, Ming"
    ]
  },
  {
    "id": "96b250a90d3cf0868c83f8c965142d2a",
    "title": "Deep Contextual Video Compression",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/96b250a90d3cf0868c83f8c965142d2a-Paper.pdf",
    "abstract": "Most of the existing neural video compression methods adopt the predictive coding framework, which first generates the predicted frame and then encodes its residue with the current frame. However, as for compression ratio, predictive coding is only a sub-optimal solution as it uses simple subtraction operation to remove the redundancy across frames. In this paper, we propose a deep contextual video compression framework to enable a paradigm shift from predictive coding to conditional coding. In particular, we try to answer the following questions: how to define, use, and learn condition under a deep video compression framework. To tap the potential of conditional coding, we propose using feature domain context as condition. This enables us to leverage the high dimension context to carry rich information to both the encoder and the decoder, which helps reconstruct the high-frequency contents for higher video quality. Our framework is also extensible, in which the condition can be flexibly designed. Experiments show that our method can significantly outperform the previous state-of-the-art (SOTA) deep video compression methods. When compared with x265 using veryslow preset, we can achieve 26.0% bitrate saving for 1080P standard test videos.",
    "authors": [
      "Li, Jiahao",
      "Li, Bin",
      "Lu, Yan"
    ]
  },
  {
    "id": "96bf57c6ff19504ff145e2a32991ea96",
    "title": "On the Frequency Bias of Generative Models",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/96bf57c6ff19504ff145e2a32991ea96-Paper.pdf",
    "abstract": "The key objective of Generative Adversarial Networks (GANs) is to generate new data with the same statistics as the provided training data. However, multiple recent works show that state-of-the-art architectures yet struggle to achieve this goal. In particular, they report an elevated amount of high frequencies in the spectral statistics which makes it straightforward to distinguish real and generated images. Explanations for this phenomenon are controversial: While most works attribute the artifacts to the generator, other works point to the discriminator.  We take a sober look at those explanations and provide insights on what makes proposed measures against high-frequency artifacts effective. To achieve this, we first independently assess the architectures of both the generator and discriminator and investigate if they exhibit a frequency bias that makes learning the distribution of high-frequency content particularly problematic. Based on these experiments, we make the following four observations: 1) Different upsampling operations bias the generator towards different spectral properties. 2) Checkerboard artifacts introduced by upsampling cannot explain the spectral discrepancies alone as the generator is able to compensate for these artifacts. 3) The discriminator does not struggle with detecting high frequencies per se but rather struggles with frequencies of low magnitude. 4) The downsampling operations in the discriminator can impair the quality of the training signal it provides.In light of these findings, we analyze proposed measures against high-frequency artifacts in state-of-the-art GAN training but find that none of the existing approaches can fully resolve spectral artifacts yet. Our results suggest that there is great potential in improving the discriminator and that this could be key to match the distribution of the training data more closely.",
    "authors": [
      "Schwarz, Katja",
      "Liao, Yiyi",
      "Geiger, Andreas"
    ]
  },
  {
    "id": "9704a4fc48ae88598dcbdcdf57f3fdef",
    "title": "Learning curves of generic features maps for realistic datasets with a teacher-student model",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9704a4fc48ae88598dcbdcdf57f3fdef-Paper.pdf",
    "abstract": "Teacher-student models provide a framework in which the typical-case performance of high-dimensional supervised learning can be described in closed form. The assumptions of Gaussian i.i.d. input data underlying the canonical teacher-student model may, however, be perceived as too restrictive to capture the behaviour of realistic data sets. In this paper, we introduce a Gaussian covariate generalisation of the model where the teacher and student can act on different spaces, generated with fixed, but generic feature maps. While still solvable in a closed form, this generalization is able to capture the learning curves for a broad range of realistic data sets, thus redeeming the potential of the teacher-student framework. Our contribution is then two-fold: first, we prove a rigorous formula for the asymptotic training loss and generalisation error. Second, we present a number of situations where the learning curve of the model captures the one of a realistic data set learned with kernel regression and classification, with out-of-the-box feature maps such as random projections or scattering transforms, or with pre-learned ones - such as the features learned by training multi-layer neural networks. We discuss both the power and the limitations of the framework.",
    "authors": [
      "Loureiro, Bruno",
      "Gerbelot, Cedric",
      "Cui, Hugo",
      "Goldt, Sebastian",
      "Krzakala, Florent",
      "Mezard, Marc",
      "Zdeborov\u00e1, Lenka"
    ]
  },
  {
    "id": "97108695bd93b6be52fa0334874c8722",
    "title": "It Has Potential: Gradient-Driven Denoisers for Convergent Solutions to Inverse Problems",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/97108695bd93b6be52fa0334874c8722-Paper.pdf",
    "abstract": "In recent years there has been increasing interest in leveraging denoisers for solving general inverse problems. Two leading frameworks are regularization-by-denoising (RED) and plug-and-play priors (PnP) which incorporate explicit likelihood functions with priors induced by denoising algorithms.  RED and PnP have shown state-of-the-art performance in diverse imaging tasks when powerful denoisersare used, such as convolutional neural networks (CNNs). However, the study of their convergence remains an active line of research.  Recent works derive the convergence of RED and PnP methods by treating CNN denoisers as approximations for maximum a posteriori (MAP) or minimum mean square error (MMSE) estimators.  Yet, state-of-the-art denoisers cannot be interpreted as either MAPor MMSE estimators, since they typically do not exhibit symmetric Jacobians. Furthermore, obtaining stable inverse algorithms often requires controlling the Lipschitz constant of CNN denoisers during training.  Precisely enforcing this constraint is impractical, hence, convergence cannot be completely guaranteed. In this work, we introduce image denoisers derived as the gradients of smooth scalar-valued deep neural networks, acting as potentials. This ensures two things: (1) the proposed denoisers display symmetric Jacobians, allowing for MAP and MMSE estimators interpretation; (2) the denoisers may be integrated into RED and PnP schemes with backtracking step size, removing the need for enforcing their Lipschitz constant. To show the latter, we develop a simple inversion method that utilizes the proposed denoisers. We theoretically establish its convergence to stationary points of an underlying objective function consisting of the learned potentials. We numerically validate our method through various imaging experiments, showing improved results compared to standard RED and PnP methods, and with additional provable stability.",
    "authors": [
      "Cohen, Regev",
      "Blau, Yochai",
      "Freedman, Daniel",
      "Rivlin, Ehud"
    ]
  },
  {
    "id": "9713faa264b94e2bf346a1bb52587fd8",
    "title": "Training Over-parameterized Models with Non-decomposable Objectives",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9713faa264b94e2bf346a1bb52587fd8-Paper.pdf",
    "abstract": "Many modern machine learning applications come with complex and nuanced design goals such as minimizing the worst-case error, satisfying a given precision or recall target, or enforcing group-fairness constraints. Popular techniques for optimizing such non-decomposable objectives reduce the problem into a sequence of cost-sensitive learning tasks, each of which is then solved by re-weighting the training loss with example-specific costs. We point out that the standard approach of re-weighting the loss to incorporate label costs can produce unsatisfactory results when used to train over-parameterized models. As a remedy, we propose new cost- sensitive losses that extend the classical idea of logit adjustment to handle more general cost matrices. Our losses are calibrated, and can be further improved with distilled labels from a teacher model. Through experiments on benchmark image datasets, we showcase the effectiveness of our approach in training ResNet models with common robust and constrained optimization objectives.",
    "authors": [
      "Narasimhan, Harikrishna",
      "Menon, Aditya K."
    ]
  },
  {
    "id": "9724412729185d53a2e3e7f889d9f057",
    "title": "Reinforcement learning for optimization of variational quantum circuit architectures",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9724412729185d53a2e3e7f889d9f057-Paper.pdf",
    "abstract": "The study of Variational Quantum Eigensolvers (VQEs) has been in the spotlight in recent times as they may lead to real-world applications of near-term quantum devices. However, their performance depends on the structure of the used variational ansatz, which requires balancing the depth and expressivity of the corresponding circuit. At the same time, near-term restrictions limit the depth of the circuit we can expect to run. Thus, the optimization of the VQE ansatz requires maximizing the expressivity of the circuit while maintaining low depth. In recent years, various methods for VQE structure optimization have been introduced but the capacities of machine learning to aid with this problem have not yet been extensively investigated. In this work, we propose a reinforcement learning algorithm that autonomously explores the space of possible ansatzes, identifying economic circuits which still yield accurate ground energy estimates. The algorithm uses a feedback-driven curriculum learning method that autonomously adapts the complexity of the learning problem to the current performance of the learning algorithm and it incrementally improves the accuracy of the result while minimizing the circuit depth. We showcase the performance of our algorithm on the problem of estimating the ground-state energy of lithium hydride (LiH) in various configurations. In this well-known benchmark problem, we achieve chemical accuracy and state-of-the-art results in terms of circuit depth.",
    "authors": [
      "Ostaszewski, Mateusz",
      "Trenkwalder, Lea M.",
      "Masarczyk, Wojciech",
      "Scerri, Eleanor",
      "Dunjko, Vedran"
    ]
  },
  {
    "id": "97275a23ca44226c9964043c8462be96",
    "title": "Moshpit SGD: Communication-Efficient Decentralized Training on Heterogeneous Unreliable Devices",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/97275a23ca44226c9964043c8462be96-Paper.pdf",
    "abstract": "Training deep neural networks on large datasets can often be accelerated by using multiple compute nodes. This approach, known as distributed training, can utilize hundreds of computers via specialized message-passing protocols such as Ring All-Reduce.However, running these protocols at scale requires reliable high-speed networking that is only available in dedicated clusters.In contrast, many real-world applications, such as federated learning and cloud-based distributed training, operate on unreliable devices with unstable network bandwidth.As a result, these applications are restricted to using parameter servers or gossip-based averaging protocols.In this work, we lift that restriction by proposing Moshpit All-Reduce \u2014 an iterative averaging protocol that exponentially converges to the global average.We demonstrate the efficiency of our protocol for distributed optimization with strong theoretical guarantees.The experiments show 1.3x speedup for ResNet-50 training on ImageNet compared to competitive gossip-based strategies and 1.5x speedup when training ALBERT-large on preemptible compute nodes.",
    "authors": [
      "Ryabinin, Max",
      "Gorbunov, Eduard",
      "Plokhotnyuk, Vsevolod",
      "Pekhimenko, Gennady"
    ]
  },
  {
    "id": "972cda1e62b72640cb7ac702714a115f",
    "title": "IRM\u2014when it works and when it doesn't: A test case of natural language inference",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/972cda1e62b72640cb7ac702714a115f-Paper.pdf",
    "abstract": "Invariant Risk Minimization (IRM) is a recently proposed framework for out-of-distribution (o.o.d) generalization.  Most of the studies on IRM so far have focused on theoretical results, toy problems, and simple models. In this work, we investigate the applicability of IRM to bias mitigation-a special case of o.o.d generalization-in increasingly naturalistic settings and deep models. Using natural language inference (NLI) as a test case, we start with a setting where both the dataset and the bias are synthetic, continue with a natural dataset and synthetic bias, and end with a fully realistic setting with natural datasets and bias. Our results show that in naturalistic settings, learning complex features in place of the bias proves to be difficult, leading to a rather small improvement over empirical risk minimization. Moreover, we find that in addition to being sensitive to random seeds, the performance of IRM also depends on several critical factors, notably dataset size, bias prevalence, and bias strength, thus limiting IRM's advantage in practical scenarios. Our results  highlight key challenges in applying IRM to real-world scenarios, calling for a more naturalistic characterization of  the problem setup for o.o.d generalization.",
    "authors": [
      "Dranker, Yana",
      "He, He",
      "Belinkov, Yonatan"
    ]
  },
  {
    "id": "97416ac0f58056947e2eb5d5d253d4f2",
    "title": "Self-Supervised Learning Disentangled Group Representation as Feature",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/97416ac0f58056947e2eb5d5d253d4f2-Paper.pdf",
    "abstract": "A good visual representation is an inference map from observations (images) to features (vectors) that faithfully reflects the hidden modularized generative factors (semantics). In this paper, we formulate the notion of \"good\" representation from a group-theoretic view using Higgins' definition of disentangled representation, and show that existing Self-Supervised Learning (SSL) only disentangles simple augmentation features such as rotation and colorization, thus unable to modularize the remaining semantics. To break the limitation, we propose an iterative SSL algorithm: Iterative Partition-based Invariant Risk Minimization (IP-IRM), which successfully grounds the abstract semantics and the group acting on them into concrete contrastive learning. At each iteration, IP-IRM first partitions the training samples into two subsets that correspond to an entangled group element. Then, it minimizes a subset-invariant contrastive loss, where the invariance guarantees to disentangle the group element. We prove that IP-IRM converges to a fully disentangled representation and show its effectiveness on various benchmarks. Codes are available at https://github.com/Wangt-CN/IP-IRM.",
    "authors": [
      "Wang, Tan",
      "Yue, Zhongqi",
      "Huang, Jianqiang",
      "Sun, Qianru",
      "Zhang, Hanwang"
    ]
  },
  {
    "id": "9752d873fa71c19dc602bf2a0696f9b5",
    "title": "SalKG: Learning From Knowledge Graph Explanations for Commonsense Reasoning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9752d873fa71c19dc602bf2a0696f9b5-Paper.pdf",
    "abstract": "Augmenting pre-trained language models with knowledge graphs (KGs) has achieved success on various commonsense reasoning tasks. However, for a given task instance, the KG, or certain parts of the KG, may not be useful. Although KG-augmented models often use attention to focus on specific KG components, the KG is still always used, and the attention mechanism is never explicitly taught which KG components should be used. Meanwhile, saliency methods can measure how much a KG feature (e.g., graph, node, path) influences the model to make the correct prediction, thus explaining which KG features are useful. This paper explores how saliency explanations can be used to improve KG-augmented models' performance. First, we propose to create coarse (Is the KG useful?) and fine (Which nodes/paths in the KG are useful?) saliency explanations. Second, to motivate saliency-based supervision, we analyze oracle KG-augmented models which directly use saliency explanations as extra inputs for guiding their attention. Third, we propose SalKG, a framework for KG-augmented models to learn from coarse and/or fine saliency explanations. Given saliency explanations created from a task's training set, SalKG jointly trains the model to predict the explanations, then solve the task by attending to KG features highlighted by the predicted explanations. On three popular commonsense QA benchmarks (CSQA, OBQA, CODAH) and a range of KG-augmented models, we show that SalKG can yield considerable performance gains --- up to 2.76% absolute improvement on CSQA.",
    "authors": [
      "Chan, Aaron",
      "Xu, Jiashu",
      "Long, Boyuan",
      "Sanyal, Soumya",
      "Gupta, Tanishq",
      "Ren, Xiang"
    ]
  },
  {
    "id": "9766527f2b5d3e95d4a733fcfb77bd7e",
    "title": "Supervising the Transfer of Reasoning Patterns in VQA",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9766527f2b5d3e95d4a733fcfb77bd7e-Paper.pdf",
    "abstract": "Methods for Visual Question Anwering (VQA) are notorious for leveraging dataset biases rather than performing reasoning, hindering generalization. It has been recently shown that better reasoning patterns emerge in attention layers of a state-of-the-art VQA model when they are trained on perfect (oracle) visual inputs. This provides evidence that deep neural networks can learn to reason when training conditions are favorable enough. However, transferring this learned knowledge to deployable models is a challenge, as much of it is lost during the transfer.We propose a method for knowledge transfer based on a regularization term in our loss function, supervising the sequence of required reasoning operations.We provide a theoretical analysis based on PAC-learning, showing that such program prediction can lead to decreased sample complexity under mild hypotheses. We also demonstrate the effectiveness of this approach experimentally on the GQA dataset and show its complementarity to BERT-like self-supervised pre-training. ",
    "authors": [
      "Kervadec, Corentin",
      "Wolf, Christian",
      "Antipov, Grigory",
      "Baccouche, Moez",
      "Nadri, Madiha"
    ]
  },
  {
    "id": "97785e0500ad16c18574c64189ccf4b4",
    "title": "Conformal Bayesian Computation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/97785e0500ad16c18574c64189ccf4b4-Paper.pdf",
    "abstract": "We develop scalable methods for producing conformal Bayesian predictive intervals with finite sample calibration guarantees. Bayesian posterior predictive distributions, $p(y \\mid x)$,  characterize subjective beliefs on outcomes of interest, $y$, conditional on predictors, $x$. Bayesian prediction is well-calibrated when the model is true, but the predictive intervals may exhibit poor empirical coverage when the  model is misspecified, under the so called ${\\cal{M}}$-open perspective. In contrast, conformal inference provides finite sample frequentist guarantees on predictive confidence intervals without the requirement of model fidelity. Using 'add-one-in' importance sampling, we show that conformal Bayesian predictive intervals are efficiently obtained from re-weighted posterior samples of model parameters. Our approach contrasts with existing conformal methods that require expensive refitting of models or data-splitting to achieve computational efficiency. We demonstrate the utility on a range of examples including extensions to partially exchangeable settings such as hierarchical models.",
    "authors": [
      "Fong, Edwin",
      "Holmes, Chris C"
    ]
  },
  {
    "id": "97ea3cfb64eeaa1edba65501d0bb3c86",
    "title": "A Unified Approach to Fair Online Learning via Blackwell Approachability",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/97ea3cfb64eeaa1edba65501d0bb3c86-Paper.pdf",
    "abstract": "We provide a setting and a general approach to fair online learning with stochastic sensitive and non-sensitive contexts.The setting is a repeated game between the Player and Nature, where at each stage both pick actions based on the contexts. Inspired by the notion of unawareness, we assume that the Player can only access the non-sensitive context before making a decision, while we discuss both cases of Nature accessing the sensitive contexts and Nature unaware of the sensitive contexts. Adapting Blackwell's approachability theory to handle the case of an unknown contexts' distribution, we provide a general necessary and sufficient condition for learning objectives to be compatible with some fairness constraints. This condition is instantiated on (group-wise) no-regret and (group-wise) calibration objectives, and on demographic parity as an additional constraint. When the objective is not compatible with the constraint, the provided framework permits to characterise the optimal trade-off between the two.",
    "authors": [
      "Chzhen, Evgenii",
      "Giraud, Christophe",
      "Stoltz, Gilles"
    ]
  },
  {
    "id": "9813b270ed0288e7c0388f0fd4ec68f5",
    "title": "Training Neural Networks is ER-complete",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9813b270ed0288e7c0388f0fd4ec68f5-Paper.pdf",
    "abstract": "Given a neural network, training data, and a threshold, finding weights for the neural network such that the total error is below the threshold is known to be NP-hard. We determine the algorithmic complexity of this fundamental problem precisely, by showing that it is $\\exists\\mathbb R$-complete. This means that the problem is equivalent, up to polynomial time reductions, to deciding whether a system of polynomial equations and inequalities with integer coefficients and real unknowns has a solution. If, as widely expected, $\\exists\\mathbb R$ is strictly larger than NP, our work implies that the problem of training neural networks is not even in NP.Neural networks are usually trained using some variation of backpropagation. The result of this paper gives an explanation why techniques commonly used to solve big instances of NP-complete problems (such as SAT solvers, IP solvers, local search, dynamic programming, etc.) seem to be of no use to this task.",
    "authors": [
      "Abrahamsen, Mikkel",
      "Kleist, Linda",
      "Miltzow, Tillmann"
    ]
  },
  {
    "id": "9854d7afce413aa13cd0a1d39d0bcec5",
    "title": "Understanding the Under-Coverage Bias in Uncertainty Estimation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9854d7afce413aa13cd0a1d39d0bcec5-Paper.pdf",
    "abstract": "Estimating the data uncertainty in regression tasks is often done by learning a quantile function or a prediction interval of the true label conditioned on the input. It is frequently observed that quantile regression---a vanilla algorithm for learning quantiles with asymptotic guarantees---tends to *under-cover* than the desired coverage level in reality. While various fixes have been proposed, a more fundamental understanding of why this under-coverage bias happens in the first place remains elusive.In this paper, we present a rigorous theoretical study on the coverage of uncertainty estimation algorithms in learning quantiles. We prove that quantile regression suffers from an inherent under-coverage bias, in a vanilla setting where we learn a realizable linear quantile function and there is more data than parameters. More quantitatively, for $\\alpha>0.5$ and small $d/n$, the $\\alpha$-quantile learned by quantile regression roughly achieves coverage $\\alpha - (\\alpha-1/2)\\cdot d/n$ regardless of the noise distribution, where $d$ is the input dimension and $n$ is the number of training data. Our theory reveals that this under-coverage bias stems from a certain high-dimensional parameter estimation error that is not implied by existing theories on quantile regression. Experiments on simulated and real data verify our theory and further illustrate the effect of various factors such as sample size and model capacity on the under-coverage bias in more practical setups.",
    "authors": [
      "Bai, Yu",
      "Mei, Song",
      "Wang, Huan",
      "Xiong, Caiming"
    ]
  },
  {
    "id": "985e9a46e10005356bbaf194249f6856",
    "title": "Decentralized Q-learning in Zero-sum Markov Games",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/985e9a46e10005356bbaf194249f6856-Paper.pdf",
    "abstract": "We study multi-agent  reinforcement learning (MARL) in infinite-horizon discounted zero-sum Markov games. We focus on the practical but  challenging setting of decentralized MARL, where agents make decisions without coordination by a centralized controller, but only based on their own payoffs and local actions executed. The agents need not observe the opponent's actions or payoffs, possibly being even  oblivious to the presence of the opponent, nor be aware of the zero-sum structure of the underlying game, a setting also referred to as radically uncoupled in the literature of learning in games. In this paper, we develop a radically uncoupled Q-learning dynamics that is both rational and convergent: the learning dynamics converges to the best response to the opponent's strategy when the opponent follows an asymptotically stationary strategy;  when both agents adopt the learning dynamics, they converge to the Nash equilibrium of the game. The key challenge in this decentralized setting is the non-stationarity of the environment from an agent's perspective, since both her own payoffs and the system evolution depend on the actions of other agents, and each agent adapts her policies simultaneously and independently. To address this issue, we develop a two-timescale learning dynamics where each agent updates her local Q-function and value function estimates concurrently, with the latter happening at a slower timescale.",
    "authors": [
      "Sayin, Muhammed",
      "Zhang, Kaiqing",
      "Leslie, David",
      "Basar, Tamer",
      "Ozdaglar, Asuman"
    ]
  },
  {
    "id": "988f9153ac4fd966ea302dd9ab9bae15",
    "title": "Fast Certified Robust Training with Short Warmup",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/988f9153ac4fd966ea302dd9ab9bae15-Paper.pdf",
    "abstract": "Recently, bound propagation based certified robust training methods have been proposed for training neural networks with certifiable robustness guarantees. Despite that state-of-the-art (SOTA) methods including interval bound propagation (IBP) and CROWN-IBP have per-batch training complexity similar to standard neural network training, they usually use a long warmup schedule with hundreds or thousands epochs to reach SOTA performance and are thus still costly. In this paper, we identify two important issues in existing methods, namely exploded bounds at initialization, and the imbalance in ReLU activation states and improve IBP training. These two issues make certified training difficult and unstable, and thereby long warmup schedules were needed in prior works. To mitigate these issues and conduct faster certified training with shorter warmup, we propose three improvements based on IBP training: 1) We derive a new weight initialization method for IBP training; 2) We propose to fully add Batch Normalization (BN) to each layer in the model, since we find BN can reduce the imbalance in ReLU activation states; 3) We also design regularization to explicitly tighten certified bounds and balance ReLU activation states during wamrup. We are able to obtain 65.03% verified error on CIFAR-10 ($\\epsilon=\\frac{8}{255}$) and 82.36% verified error on TinyImageNet ($\\epsilon=\\frac{1}{255}$) using very short training schedules (160 and 80 total epochs, respectively), outperforming literature SOTA trained with hundreds or thousands epochs under the same network architecture. The code is available at https://github.com/shizhouxing/Fast-Certified-Robust-Training.",
    "authors": [
      "Shi, Zhouxing",
      "Wang, Yihan",
      "Zhang, Huan",
      "Yi, Jinfeng",
      "Hsieh, Cho-Jui"
    ]
  },
  {
    "id": "98c39996bf1543e974747a2549b3107c",
    "title": "Vector-valued Distance and Gyrocalculus on the Space of Symmetric Positive Definite Matrices",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/98c39996bf1543e974747a2549b3107c-Paper.pdf",
    "abstract": "We propose the use of the vector-valued distance to compute distances and extract geometric information from the manifold of symmetric positive definite matrices (SPD), and develop gyrovector calculus, constructing analogs of vector space operations in this curved space. We implement these operations and showcase their versatility in the tasks of knowledge graph completion, item recommendation, and question answering. In experiments, the SPD models outperform their equivalents in Euclidean and hyperbolic space. The vector-valued distance allows us to visualize embeddings, showing that the models learn to disentangle representations of positive samples from negative ones.",
    "authors": [
      "L\u00f3pez, Federico",
      "Pozzetti, Beatrice ",
      "Trettel, Steve",
      "Strube, Michael",
      "Wienhard, Anna"
    ]
  },
  {
    "id": "98dce83da57b0395e163467c9dae521b",
    "title": "Improved Transformer for High-Resolution GANs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/98dce83da57b0395e163467c9dae521b-Paper.pdf",
    "abstract": "Attention-based models, exemplified by the Transformer, can effectively model long range dependency, but suffer from the quadratic complexity of self-attention operation, making them difficult to be adopted for high-resolution image generation based on Generative Adversarial Networks (GANs). In this paper, we introduce two key ingredients to Transformer to address this challenge. First, in low-resolution stages of the generative process, standard global self-attention is replaced with the proposed multi-axis blocked self-attention which allows efficient mixing of local and global attention. Second, in high-resolution stages, we drop self-attention while only keeping multi-layer perceptrons reminiscent of the implicit neural function. To further improve the performance, we introduce an additional self-modulation component based on cross-attention. The resulting model, denoted as HiT, has a nearly linear computational complexity with respect to the image size and thus directly scales to synthesizing high definition images. We show in the experiments that the proposed HiT achieves state-of-the-art FID scores of 30.83 and 2.95 on unconditional ImageNet $128 \\times 128$ and FFHQ $256 \\times 256$, respectively, with a reasonable throughput. We believe the proposed HiT is an important milestone for generators in GANs which are completely free of convolutions. Our code is made publicly available at https://github.com/google-research/hit-gan.",
    "authors": [
      "Zhao, Long",
      "Zhang, Zizhao",
      "Chen, Ting",
      "Metaxas, Dimitris",
      "Zhang, Han"
    ]
  },
  {
    "id": "98f13708210194c475687be6106a3b84",
    "title": "Learning High-Precision Bounding Box for Rotated Object Detection via Kullback-Leibler Divergence",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/98f13708210194c475687be6106a3b84-Paper.pdf",
    "abstract": "Existing rotated object detectors are mostly inherited from the horizontal detection paradigm, as the latter has evolved into a well-developed area. However, these detectors are difficult to perform prominently in high-precision detection due to the limitation of current regression loss design, especially for objects with large aspect ratios. Taking the perspective that horizontal detection is a special case for rotated object detection, in this paper, we are motivated to change the design of rotation regression loss from induction paradigm to deduction methodology, in terms of the relation between rotation and horizontal detection. We show that one essential challenge is how to modulate the coupled parameters in the rotation regression loss, as such the estimated parameters can influence to each other during the dynamic joint optimization, in an adaptive and synergetic way. Specifically, we first convert the rotated bounding box into a 2-D Gaussian distribution, and then calculate the Kullback-Leibler Divergence (KLD) between the Gaussian distributions as the regression loss. By analyzing the gradient of each parameter, we show that KLD (and its derivatives) can dynamically adjust the parameter gradients according to the characteristics of the object. For instance, it will adjust the importance (gradient weight) of the angle parameter according to the aspect ratio. This mechanism can be vital for high-precision detection as a slight angle error would cause a serious accuracy drop for large aspect ratios objects. More importantly, we have proved that KLD is scale invariant. We further show that the KLD loss can be degenerated into the popular Ln-norm loss for horizontal detection. Experimental results on seven datasets using different detectors show its consistent superiority, and codes are available at https://github.com/yangxue0827/RotationDetection.",
    "authors": [
      "Yang, Xue",
      "Yang, Xiaojiang",
      "Yang, Jirui",
      "Ming, Qi",
      "Wang, Wentao",
      "Tian, Qi",
      "Yan, Junchi"
    ]
  },
  {
    "id": "995665640dc319973d3173a74a03860c",
    "title": "On Locality of Local Explanation Models",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/995665640dc319973d3173a74a03860c-Paper.pdf",
    "abstract": "Shapley values provide model agnostic feature attributions for model outcome at a particular instance by simulating feature absence under a global population distribution. The use of a global population can lead to potentially misleading results when local model behaviour is of interest. Hence we consider the formulation of  neighbourhood reference distributions that improve the local interpretability of Shapley values. By doing so, we find that the Nadaraya-Watson estimator, a well-studied kernel regressor, can be expressed as a self-normalised importance sampling estimator. Empirically, we observe that Neighbourhood Shapley values identify meaningful sparse  feature relevance attributions that provide insight into local model behaviour, complimenting conventional Shapley analysis. They also increase on-manifold explainability and robustness to the construction of adversarial classifiers. ",
    "authors": [
      "Ghalebikesabi, Sahra",
      "Ter-Minassian, Lucile",
      "DiazOrdaz, Karla",
      "Holmes, Chris C"
    ]
  },
  {
    "id": "995693c15f439e3d189b06e89d145dd5",
    "title": "FlexMatch: Boosting Semi-Supervised Learning with Curriculum Pseudo Labeling",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/995693c15f439e3d189b06e89d145dd5-Paper.pdf",
    "abstract": "The recently proposed FixMatch achieved state-of-the-art results on most semi-supervised learning (SSL) benchmarks. However, like other modern SSL algorithms, FixMatch uses a pre-defined constant threshold for all classes to select unlabeled data that contribute to the training, thus failing to consider different learning status and learning difficulties of different classes. To address this issue, we propose Curriculum Pseudo Labeling (CPL), a curriculum learning approach to leverage unlabeled data according to the model's learning status. The core of CPL is to flexibly adjust thresholds for different classes at each time step to let pass informative unlabeled data and their pseudo labels. CPL does not introduce additional parameters or computations (forward or backward propagation). We apply CPL to FixMatch and call our improved algorithm FlexMatch. FlexMatch achieves state-of-the-art performance on a variety of SSL benchmarks, with especially strong performances when the labeled data are extremely limited or when the task is challenging. For example, FlexMatch achieves 13.96% and 18.96% error rate reduction over FixMatch on CIFAR-100 and STL-10 datasets respectively, when there are only 4 labels per class. CPL also significantly boosts the convergence speed, e.g., FlexMatch can use only 1/5 training time of FixMatch to achieve even better performance. Furthermore, we show that CPL can be easily adapted to other SSL algorithms and remarkably improve their performances. We open-source our code at https://github.com/TorchSSL/TorchSSL.",
    "authors": [
      "Zhang, Bowen",
      "Wang, Yidong",
      "Hou, Wenxin",
      "WU, HAO",
      "Wang, Jindong",
      "Okumura, Manabu",
      "Shinozaki, Takahiro"
    ]
  },
  {
    "id": "995f5e03890b029865f402e83a81c29d",
    "title": "Relative Flatness and Generalization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/995f5e03890b029865f402e83a81c29d-Paper.pdf",
    "abstract": "Flatness of the loss curve is conjectured to be connected to the generalization ability of machine learning models, in particular neural networks. While it has been empirically observed that flatness measures consistently correlate strongly with generalization, it is still an open theoretical problem why and under which circumstances flatness is connected to generalization, in particular in light of reparameterizations that change certain flatness measures but leave generalization unchanged. We investigate the connection between flatness and generalization by relating it to the interpolation from representative data, deriving notions of representativeness, and feature robustness. The notions allow us to rigorously connect flatness and generalization and to identify conditions under which the connection holds. Moreover, they give rise to a novel, but natural relative flatness measure that correlates strongly with generalization, simplifies to ridge regression for ordinary least squares, and solves the reparameterization issue.",
    "authors": [
      "Petzka, Henning",
      "Kamp, Michael",
      "Adilova, Linara",
      "Sminchisescu, Cristian",
      "Boley, Mario"
    ]
  },
  {
    "id": "9996535e07258a7bbfd8b132435c5962",
    "title": "The Image Local Autoregressive Transformer",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9996535e07258a7bbfd8b132435c5962-Paper.pdf",
    "abstract": "Recently, AutoRegressive (AR) models for the whole image generation empowered by transformers have achieved comparable or even better performance compared to Generative Adversarial Networks (GANs). Unfortunately, directly applying such AR models to edit/change local image regions, may suffer from the problems of missing global information, slow inference speed, and information leakage of local guidance. To address these limitations, we propose a novel model -- image Local Autoregressive Transformer (iLAT), to better facilitate the locally guided image synthesis. Our iLAT learns the novel local discrete representations, by the newly proposed local autoregressive (LA) transformer of the attention mask and convolution mechanism. Thus iLAT can efficiently synthesize the local image regions by key guidance information. Our iLAT is evaluated on various locally guided image syntheses, such as pose-guided person image synthesis and face editing. Both quantitative and qualitative results show the efficacy of our model.",
    "authors": [
      "Cao, Chenjie",
      "Hong, Yuxin",
      "Li, Xiang",
      "Wang, Chengrong",
      "Xu, Chengming",
      "Fu, Yanwei",
      "Xue, Xiangyang"
    ]
  },
  {
    "id": "99bcfcd754a98ce89cb86f73acc04645",
    "title": "Towards Multi-Grained Explainability for Graph Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/99bcfcd754a98ce89cb86f73acc04645-Paper.pdf",
    "abstract": "When a graph neural network (GNN) made a prediction, one raises question about explainability: \u201cWhich fraction of the input graph is most in\ufb02uential to the model\u2019s decision?\u201d Producing an answer requires understanding the model\u2019s inner workings in general and emphasizing the insights on the decision for the instance at hand. Nonetheless, most of current approaches focus only on one aspect: (1) local explainability, which explains each instance independently, thus hardly exhibits the class-wise patterns; and (2) global explainability, which systematizes the globally important patterns, but might be trivial in the local context. This dichotomy limits the \ufb02exibility and effectiveness of explainers greatly. A performant paradigm towards multi-grained explainability is until-now lacking and thus a focus of our work. In this work, we exploit the pre-training and \ufb01ne-tuning idea to develop our explainer and generate multi-grained explanations. Speci\ufb01cally, the pre-training phase accounts for the contrastivity among different classes, so as to highlight the class-wise characteristics from a global view; afterwards, the \ufb01ne-tuning phase adapts the explanations in the local context. Experiments on both synthetic and real-world datasets show the superiority of our explainer, in terms of AUC on explaining graph classi\ufb01cation over the leading baselines. Our codes and datasets are available at https://github.com/Wuyxin/ReFine.",
    "authors": [
      "Wang, Xiang",
      "Wu, Yingxin",
      "Zhang, An",
      "He, Xiangnan",
      "Chua, Tat-Seng"
    ]
  },
  {
    "id": "99bf3d153d4bf67d640051a1af322505",
    "title": "Behavior From the Void: Unsupervised Active Pre-Training",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/99bf3d153d4bf67d640051a1af322505-Paper.pdf",
    "abstract": "We introduce a new unsupervised pre-training method for reinforcement learning called APT, which stands for Active Pre-Training. APT learns behaviors and representations by actively searching for novel states in reward-free environments. The key novel idea is to explore the environment by maximizing a non-parametric entropy computed in an abstract representation space, which avoids challenging density modeling and consequently allows our approach to scale much better in environments that have high-dimensional observations (e.g., image observations). We empirically evaluate APT by exposing task-specific reward after a long unsupervised pre-training phase. In Atari games, APT achieves human-level performance on 12 games and obtains highly competitive performance compared to canonical fully supervised RL algorithms. On DMControl suite, APT beats all baselines in terms of asymptotic performance and data efficiency and dramatically improves performance on tasks that are extremely difficult to train from scratch. ",
    "authors": [
      "Liu, Hao",
      "Abbeel, Pieter"
    ]
  },
  {
    "id": "99c83c904d0d64fbef50d919a5c66a80",
    "title": "Autonomous Reinforcement Learning via Subgoal Curricula",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/99c83c904d0d64fbef50d919a5c66a80-Paper.pdf",
    "abstract": "Reinforcement learning (RL) promises to enable autonomous acquisition of complex behaviors for diverse agents. However, the success of current reinforcement learning algorithms is predicated on an often under-emphasised requirement -- each trial needs to start from a fixed initial state distribution. Unfortunately, resetting the environment to its initial state after each trial requires substantial amount of human supervision and extensive instrumentation of the environment which defeats the goal of autonomous acquisition of complex behaviors. In this work, we propose Value-accelerated Persistent Reinforcement Learning (VaPRL), which generates a curriculum of initial states such that the agent can bootstrap on the success of easier tasks to efficiently learn harder tasks. The agent also learns to reach the initial states proposed by the curriculum, minimizing the reliance on human interventions into the learning. We observe that VaPRL reduces the interventions required by three orders of magnitude compared to episodic RL while outperforming prior state-of-the art methods for reset-free RL both in terms of sample efficiency and asymptotic performance on a variety of simulated robotics problems.",
    "authors": [
      "Sharma, Archit",
      "Gupta, Abhishek",
      "Levine, Sergey",
      "Hausman, Karol",
      "Finn, Chelsea"
    ]
  },
  {
    "id": "99e7e6ce097324aceb45f98299ceb621",
    "title": "Statistically and Computationally Efficient Linear Meta-representation Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/99e7e6ce097324aceb45f98299ceb621-Paper.pdf",
    "abstract": "In typical few-shot learning, each task is not equipped with enough data to be learned in isolation. To cope with such data scarcity, meta-representation learning methods train across many related tasks to find a shared (lower-dimensional) representation of the data where all tasks can be solved accurately. It is hypothesized that any new arriving tasks can be rapidly trained on this low-dimensional representation using only a few samples. Despite the practical successes of this approach, its statistical and computational properties are less understood. Moreover, the prescribed algorithms in these studies have little resemblance to those used in practice or they are computationally intractable. To understand and explain the success of popular meta-representation learning approaches such as ANIL, MetaOptNet, R2D2, and OML, we study a alternating gradient-descent minimization (AltMinGD) method (and its variant alternating minimization (AltMin)) which underlies the aforementioned methods. For a simple but canonical setting of shared linear representations, we show that AltMinGD achieves nearly-optimal estimation error, requiring only $\\Omega(\\mathrm{polylog}\\,d)$ samples per task. This agrees with the observed efficacy of this algorithm in the practical few-shot learning scenarios.",
    "authors": [
      "Thekumparampil, Kiran K.",
      "Jain, Prateek",
      "Netrapalli, Praneeth",
      "Oh, Sewoong"
    ]
  },
  {
    "id": "99ef04eb612baf0e86671a5109e22154",
    "title": "Decentralized Learning in Online Queuing Systems",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/99ef04eb612baf0e86671a5109e22154-Paper.pdf",
    "abstract": "Motivated by packet routing in computer networks, online queuing systems are composed of queues receiving packets at different rates. Repeatedly, they send packets to servers, each of them treating only at most one packet at a time. In the centralized case, the number of accumulated packets remains bounded (i.e., the system is stable) as long as the ratio between service rates and arrival rates is larger than $1$. In the decentralized case, individual no-regret strategies ensures stability when this ratio is larger than $2$. Yet, myopically minimizing  regret disregards the long term effects due to the carryover of packets to further rounds. On the other hand, minimizing long term costs leads to stable Nash equilibria as soon as the ratio exceeds $\\frac{e}{e-1}$. Stability with decentralized learning strategies  with a ratio below $2$ was a major remaining question. We first argue that for ratios up to $2$, cooperation is required for stability of learning strategies, as  selfish minimization of policy regret, a patient notion of regret, might indeed still be unstable in this case. We therefore consider cooperative queues and propose the first learning decentralized algorithm guaranteeing stability of the system as long as the ratio of rates is larger than $1$, thus reaching performances comparable to centralized strategies.",
    "authors": [
      "Sentenac, Flore",
      "Boursier, Etienne",
      "Perchet, Vianney"
    ]
  },
  {
    "id": "9a1335ef5ffebb0de9d089c4182e4868",
    "title": "Explainable Semantic Space by Grounding Language to Vision with Cross-Modal Contrastive Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9a1335ef5ffebb0de9d089c4182e4868-Paper.pdf",
    "abstract": "In natural language processing, most models try to learn semantic representations merely from texts. The learned representations encode the \u201cdistributional semantics\u201d but fail to connect to any knowledge about the physical world. In contrast, humans learn language by grounding concepts in perception and action and the brain encodes \u201cgrounded semantics\u201d for cognition. Inspired by this notion and recent work in vision-language learning, we design a two-stream model for grounding language learning in vision. The model includes a VGG-based visual stream and a Bert-based language stream. The two streams merge into a joint representational space. Through cross-modal contrastive learning, the model first learns to align visual and language representations with the MS COCO dataset. The model further learns to retrieve visual objects with language queries through a cross-modal attention module and to infer the visual relations between the retrieved objects through a bilinear operator with the Visual Genome dataset. After training, the model\u2019s language stream is a stand-alone language model capable of embedding concepts in a visually grounded semantic space. This semantic space manifests principal dimensions explainable with human intuition and neurobiological knowledge. Word embeddings in this semantic space are predictive of human-defined norms of semantic features and are segregated into perceptually distinctive clusters. Furthermore, the visually grounded language model also enables compositional language understanding based on visual knowledge and multimodal image search with queries based on images, texts, or their combinations.",
    "authors": [
      "Zhang, Yizhen",
      "Choi, Minkyu",
      "Han, Kuan",
      "Liu, Zhongming"
    ]
  },
  {
    "id": "9a1756fd0c741126d7bbd4b692ccbd91",
    "title": "BulletTrain: Accelerating Robust Neural Network Training via Boundary Example Mining",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9a1756fd0c741126d7bbd4b692ccbd91-Paper.pdf",
    "abstract": "Neural network robustness has become a central topic in machine learning in recent years. Most training algorithms that improve the model's robustness to adversarial and common corruptions also introduce a large computational overhead, requiring as many as ten times the number of forward and backward passes in order to converge. To combat this inefficiency, we propose BulletTrain, a boundary example mining technique to drastically reduce the computational cost of robust training. Our key observation is that only a small fraction of examples are beneficial for improving robustness. BulletTrain dynamically predicts these important examples and optimizes robust training algorithms to focus on the important examples. We apply our technique to several existing robust training algorithms and achieve a 2.2x speed-up for TRADES and MART on CIFAR-10 and a 1.7x speed-up for AugMix on CIFAR-10-C and CIFAR-100-C without any reduction in clean and robust accuracy.",
    "authors": [
      "Hua, Weizhe",
      "Zhang, Yichi",
      "Guo, Chuan",
      "Zhang, Zhiru",
      "Suh, G. Edward"
    ]
  },
  {
    "id": "9a1de01f893e0d2551ecbb7ce4dc963e",
    "title": "Neural Distance Embeddings for Biological Sequences",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9a1de01f893e0d2551ecbb7ce4dc963e-Paper.pdf",
    "abstract": "The development of data-dependent heuristics and representations for biological sequences that reflect their evolutionary distance is critical for large-scale biological research. However, popular machine learning approaches, based on continuous Euclidean spaces, have struggled with the discrete combinatorial formulation of the edit distance that models evolution and the hierarchical relationship that characterises real-world datasets. We present Neural Distance Embeddings (NeuroSEED), a general framework to embed sequences in geometric vector spaces, and illustrate the effectiveness of the hyperbolic space that captures the hierarchical structure and provides an average 38% reduction in embedding RMSE against the best competing geometry. The capacity of the framework and the significance of these improvements are then demonstrated devising supervised and unsupervised NeuroSEED approaches to multiple core tasks in bioinformatics. Benchmarked with common baselines, the proposed approaches display significant accuracy and/or runtime improvements on real-world datasets. As an example for hierarchical clustering, the proposed pretrained and from-scratch methods match the quality of competing baselines with 30x and 15x runtime reduction, respectively.",
    "authors": [
      "Corso, Gabriele",
      "Ying, Zhitao",
      "P\u00e1ndy, Michal",
      "Veli\u010dkovi\u0107, Petar",
      "Leskovec, Jure",
      "Li\u00f2, Pietro"
    ]
  },
  {
    "id": "9a32ff36c65e8ba30915a21b7bd76506",
    "title": "Fitting summary statistics of neural data with a differentiable spiking network simulator",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9a32ff36c65e8ba30915a21b7bd76506-Paper.pdf",
    "abstract": "Fitting network models to neural activity is an important tool in neuroscience. A popular approach is to model a brain area with a probabilistic recurrent spiking network whose parameters maximize the likelihood of the recorded activity. Although this is widely used, we show that the resulting model does not produce realistic neural activity. To correct for this, we suggest to augment the log-likelihood with terms that measure the dissimilarity between simulated and recorded activity. This dissimilarity is defined via summary statistics commonly used in neuroscience and the optimization is efficient because it relies on back-propagation through the stochastically simulated spike trains. We analyze this method theoretically and show empirically that it generates more realistic activity statistics. We find that it improves upon other fitting algorithms for spiking network models like GLMs (Generalized Linear Models) which do not usually rely on back-propagation. This new fitting algorithm also enables the consideration of hidden neurons which is otherwise notoriously hard, and we show that it can be crucial when trying to infer the network connectivity from spike recordings.",
    "authors": [
      "Bellec, Guillaume",
      "Wang, Shuqi",
      "Modirshanechi, Alireza",
      "Brea, Johanni",
      "Gerstner, Wulfram"
    ]
  },
  {
    "id": "9a3f263a5e5f63006098a05cd7491997",
    "title": "PerSim: Data-Efficient Offline Reinforcement Learning with Heterogeneous Agents via Personalized Simulators",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9a3f263a5e5f63006098a05cd7491997-Paper.pdf",
    "abstract": "We consider offline reinforcement learning (RL) with heterogeneous agents under severe data scarcity, i.e., we only observe a single historical trajectory for every agent under an unknown, potentially sub-optimal policy. We find that the performance of state-of-the-art offline and model-based RL methods degrade significantly given such limited data availability, even for commonly perceived \"solved\" benchmark settings such as \"MountainCar\" and \"CartPole\". To address this challenge, we propose PerSim, a model-based offline RL approach which first learns a personalized simulator for each agent by collectively using the historical trajectories across all agents, prior to learning a policy. We do so by positing that the transition dynamics across agents can be represented as a latent function of latent factors associated with agents, states, and actions; subsequently, we theoretically establish that this function is well-approximated by a \"low-rank\" decomposition of separable agent, state, and action latent functions. This representation suggests a simple, regularized neural network architecture to effectively learn the transition dynamics per agent, even with scarce, offline data. We perform extensive experiments across several benchmark environments and RL methods. The consistent improvement of our approach, measured in terms of both state dynamics prediction and eventual reward, confirms the efficacy of our framework in leveraging limited historical data to simultaneously learn personalized policies across agents. ",
    "authors": [
      "Agarwal, Anish",
      "Alomar, Abdullah",
      "Alumootil, Varkey",
      "Shah, Devavrat",
      "Shen, Dennis",
      "Xu, Zhi",
      "Yang, Cindy"
    ]
  },
  {
    "id": "9a3f54913bf27e648d1759c18d007165",
    "title": "Online Sign Identification: Minimization of the Number of Errors in Thresholding Bandits",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9a3f54913bf27e648d1759c18d007165-Paper.pdf",
    "abstract": "In the fixed budget thresholding bandit problem, an algorithm sequentially allocates a budgeted number of samples to different distributions. It then predicts whether the mean of each distribution is larger or lower than a given threshold. We introduce a large family of algorithms (containing most existing relevant ones), inspired by the Frank-Wolfe algorithm, and provide a thorough yet generic analysis of their performance. This allowed us to construct new explicit algorithms, for a broad class of problems, whose losses are within a small constant factor of the non-adaptive oracle ones. Quite interestingly, we observed that adaptive methodsempirically greatly out-perform non-adaptive oracles, an uncommon behavior in standard online learning settings, such as regret minimization. We explain this surprising phenomenon on an insightful toy problem.",
    "authors": [
      "Ouhamma, Reda",
      "Maillard, Odalric-Ambrym",
      "Perchet, Vianney"
    ]
  },
  {
    "id": "9a49a25d845a483fae4be7e341368e36",
    "title": "All Tokens Matter: Token Labeling for Training Better Vision Transformers",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9a49a25d845a483fae4be7e341368e36-Paper.pdf",
    "abstract": "In this paper, we present token labeling---a new training objective for training high-performance vision transformers (ViTs). Different from the standard training objective of ViTs that computes the classification loss on an additional trainable class token, our proposed one takes advantage of all the image patch tokens to compute the training loss in a dense manner. Specifically, token labeling reformulates the image classification problem into multiple token-level recognition problems and assigns each patch token with an individual location-specific supervision generated by a machine annotator. Experiments show that token labeling can clearly and consistently improve the performance of various ViT models across a wide spectrum. For a vision transformer with 26M learnable parameters serving as an example, with token labeling, the model can achieve 84.4% Top-1 accuracy on ImageNet. The result can be further increased to 86.4% by slightly scaling the model size up to 150M, delivering the minimal-sized model among previous models (250M+) reaching 86%. We also show that token labeling can clearly improve the generalization capability of the pretrained models on downstream tasks with dense prediction, such as semantic segmentation.  Our code and model are publiclyavailable at https://github.com/zihangJiang/TokenLabeling.",
    "authors": [
      "Jiang, Zi-Hang",
      "Hou, Qibin",
      "Yuan, Li",
      "Zhou, Daquan",
      "Shi, Yujun",
      "Jin, Xiaojie",
      "Wang, Anran",
      "Feng, Jiashi"
    ]
  },
  {
    "id": "9a4d6e8685bd057e4f68930bd7c8ecc0",
    "title": "Partition and Code: learning how to compress graphs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9a4d6e8685bd057e4f68930bd7c8ecc0-Paper.pdf",
    "abstract": "Can we use machine learning to compress graph data? The absence of ordering in graphs poses a significant challenge to conventional compression algorithms, limiting their attainable gains as well as their ability to discover relevant patterns. On the other hand, most graph compression approaches rely on domain-dependent handcrafted representations and cannot adapt to different underlying graph distributions. This work aims to establish the necessary principles a lossless graph compression method should follow to approach the entropy storage lower bound. Instead of making rigid assumptions about the graph distribution, we formulate the compressor as a probabilistic model that can be learned from data and generalise to unseen instances. Our \u201cPartition and Code\u201d framework entails three steps: first, a partitioning algorithm decomposes the graph into subgraphs, then these are mapped to the elements of a small dictionary on which we learn a probability distribution, and finally,  an entropy encoder translates the representation into bits.  All the components (partitioning, dictionary and distribution) are parametric and can be trained with gradient descent. We theoretically compare the compression quality of several graph encodings and prove, under mild conditions, that PnC achieves compression gains that grow either linearly or quadratically with the number of vertices. Empirically, PnC yields significant compression improvements on diverse real-world networks.",
    "authors": [
      "Bouritsas, Giorgos",
      "Loukas, Andreas",
      "Karalias, Nikolaos",
      "Bronstein, Michael"
    ]
  },
  {
    "id": "9a555403384fc12f931656dea910e334",
    "title": "Knowledge-inspired 3D Scene Graph Prediction in Point Cloud",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9a555403384fc12f931656dea910e334-Paper.pdf",
    "abstract": "Prior knowledge integration helps identify semantic entities and their relationships in a graphical representation, however, its meaningful abstraction and intervention remain elusive. This paper advocates a knowledge-inspired 3D scene graph prediction method solely based on point clouds. At the mathematical modeling level, we formulate the task as two sub-problems: knowledge learning and scene graph prediction with learned prior knowledge. Unlike conventional methods that learn knowledge embedding and regular patterns from encoded visual information, we propose to suppress the misunderstandings caused by appearance similarities and other perceptual confusion. At the network design level, we devise a graph auto-encoder to automatically extract class-dependent representations and topological patterns from the one-hot class labels and their intrinsic graphical structures, so that the prior knowledge can avoid perceptual errors and noises. We further devise a scene graph prediction model to predict credible relationship triplets by incorporating the related prototype knowledge with perceptual information. Comprehensive experiments confirm that, our method can successfully learn representative knowledge embedding, and the obtained prior knowledge can effectively enhance the accuracy of relationship predictions. Our thorough evaluations indicate the new method can achieve the state-of-the-art performance compared with other scene graph prediction methods.",
    "authors": [
      "Zhang, Shoulong",
      "li, shuai",
      "Hao, Aimin",
      "Qin, Hong"
    ]
  },
  {
    "id": "9a6a1aaafe73c572b7374828b03a1881",
    "title": "Online Variational Filtering and Parameter Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9a6a1aaafe73c572b7374828b03a1881-Paper.pdf",
    "abstract": "We present a variational method for online state estimation and parameter learning in state-space models (SSMs), a ubiquitous class of latent variable models for sequential data. As per standard batch variational techniques, we use stochastic gradients to simultaneously optimize a lower bound on the log evidence with respect to both model parameters and a variational approximation of the states' posterior distribution. However, unlike existing approaches, our method is able to operate in an entirely online manner, such that historic observations do not require revisitation after being incorporated and the cost of updates at each time step remains constant, despite the growing dimensionality of the joint posterior distribution of the states. This is achieved by utilizing backward decompositions of this joint posterior distribution and of its variational approximation, combined with Bellman-type recursions for the evidence lower bound and its gradients. We demonstrate the performance of this methodology across several examples, including high-dimensional SSMs and sequential Variational Auto-Encoders.",
    "authors": [
      "Campbell, Andrew",
      "Shi, Yuyang",
      "Rainforth, Thomas",
      "Doucet, Arnaud"
    ]
  },
  {
    "id": "9a86d531e19ec6f5937ad1373bb118bd",
    "title": "Heavy Ball Neural Ordinary Differential Equations",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9a86d531e19ec6f5937ad1373bb118bd-Paper.pdf",
    "abstract": "We propose heavy ball neural ordinary differential equations (HBNODEs), leveraging the continuous limit of the classical momentum accelerated gradient descent, to improve neural ODEs (NODEs) training and inference. HBNODEs have two properties that imply practical advantages over NODEs: (i) The adjoint state of an HBNODE also satisfies an HBNODE, accelerating both forward and backward ODE solvers, thus significantly reducing the number of function evaluations (NFEs) and improving the utility of the trained models. (ii) The spectrum of HBNODEs is well structured, enabling effective learning of long-term dependencies from complex sequential data. We verify the advantages of HBNODEs over NODEs on benchmark tasks, including image classification, learning complex dynamics, and sequential modeling. Our method requires remarkably fewer forward and backward NFEs, is more accurate, and learns long-term dependencies more effectively than the other ODE-based neural network models. Code is available at \\url{https://github.com/hedixia/HeavyBallNODE}.",
    "authors": [
      "Xia, Hedi",
      "Suliafu, Vai",
      "Ji, Hangjie",
      "Nguyen, Tan",
      "Bertozzi, Andrea",
      "Osher, Stanley",
      "Wang, Bao"
    ]
  },
  {
    "id": "9ab8a8a9349eb1dd73ce155ce64c80fa",
    "title": "Structure learning in polynomial time: Greedy algorithms, Bregman information, and exponential families",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9ab8a8a9349eb1dd73ce155ce64c80fa-Paper.pdf",
    "abstract": "Greedy algorithms have long been a workhorse for learning graphical models, and more broadly for learning statistical models with sparse structure. In the context of learning directed acyclic graphs, greedy algorithms are popular despite their worst-case exponential runtime. In practice, however, they are very efficient. We provide new insight into this phenomenon by studying a general greedy score-based algorithm for learning DAGs. Unlike edge-greedy algorithms such as the popular GES and hill-climbing algorithms, our approach is vertex-greedy and requires at most a polynomial number of score evaluations. We then show how recent polynomial-time algorithms for learning DAG models are a special case of this algorithm, thereby illustrating how these order-based algorithms can be rigourously interpreted as score-based algorithms. This observation suggests new score functions and optimality conditions based on the duality between Bregman divergences and exponential families, which we explore in detail. Explicit sample and computational complexity bounds are derived. Finally, we provide extensive experiments suggesting that this algorithm indeed optimizes the score in a variety of settings.",
    "authors": [
      "Rajendran, Goutham",
      "Kivva, Bohdan",
      "Gao, Ming",
      "Aragam, Bryon"
    ]
  },
  {
    "id": "9ac5a6d86e8924182271bd820acbce0e",
    "title": "On the Sample Complexity of Learning under Geometric Stability",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9ac5a6d86e8924182271bd820acbce0e-Paper.pdf",
    "abstract": "Many supervised learning problems involve high-dimensional data such as images, text, or graphs. In order to make efficient use of data, it is often useful to leverage certain geometric priors in the problem at hand, such as invariance to translations, permutation subgroups, or stability to small deformations. We study the sample complexity of learning problems where the target function presents such invariance and stability properties, by considering spherical harmonic decompositions of such functions on the sphere. We provide non-parametric rates of convergence for kernel methods, and show improvements in sample complexity by a factor equal to the size of the group when using an invariant kernel over the group, compared to the corresponding non-invariant kernel. These improvements are valid when the sample size is large enough, with an asymptotic behavior that depends on spectral properties of the group. Finally, these gains are extended beyond invariance groups to also cover geometric stability to small deformations, modeled here as subsets (not necessarily subgroups) of permutations. ",
    "authors": [
      "Bietti, Alberto",
      "Venturi, Luca",
      "Bruna, Joan"
    ]
  },
  {
    "id": "9af08cda54faea9adf40a201794183cf",
    "title": "SIMILAR: Submodular Information Measures Based Active Learning In Realistic Scenarios",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9af08cda54faea9adf40a201794183cf-Paper.pdf",
    "abstract": "Active  learning  has  proven  to  be  useful  for  minimizing  labeling  costs  by selecting  the  most  informative  samples. However,  existing  active  learning methods do not work well in realistic scenarios such as imbalance or rare classes,out-of-distribution data in the unlabeled set, and redundancy.  In this work, we propose SIMILAR (Submodular Information Measures based actIve LeARning), a unified active learning framework using recently proposed submodular information measures (SIM) as acquisition functions. We argue that SIMILAR not only works in standard active learning but also easily extends to the realistic settings considered above and acts as a one-stop solution for active learning that is scalable to large real-world datasets. Empirically, we show that SIMILAR significantly outperforms existing active learning algorithms by as much as ~5%\u221218%in the case of rare classes and ~5%\u221210%in the case of out-of-distribution data on several image classification tasks like CIFAR-10, MNIST, and ImageNet.",
    "authors": [
      "Kothawade, Suraj",
      "Beck, Nathan",
      "Killamsetty, Krishnateja",
      "Iyer, Rishabh"
    ]
  },
  {
    "id": "9b0ead00a217ea2c12e06a72eec4923f",
    "title": "Monte Carlo Tree Search With Iteratively Refining State Abstractions",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9b0ead00a217ea2c12e06a72eec4923f-Paper.pdf",
    "abstract": "Decision-time planning is the process of constructing a transient, local policy with the intent of using it to make the immediate decision. Monte Carlo tree search (MCTS), which has been leveraged to great success in Go, chess, shogi, Hex, Atari, and other settings, is perhaps the most celebrated decision-time planning algorithm. Unfortunately, in its original form, MCTS can degenerate to one-step search in domains with stochasticity. Progressive widening is one way to ameliorate this issue, but we argue that it possesses undesirable properties for some settings. In this work, we present a method, called abstraction refining, for extending MCTS to stochastic environments which, unlike progressive widening, leverages the geometry of the state space. We argue that leveraging the geometry of the space can offer advantages. To support this claim, we present a series of experimental examples in which abstraction refining outperforms progressive widening, given equal simulation budgets.",
    "authors": [
      "Sokota, Samuel",
      "Ho, Caleb Y",
      "Ahmad, Zaheen",
      "Kolter, J. Zico"
    ]
  },
  {
    "id": "9b16759a62899465ab21e2e79d2ef75c",
    "title": "Flattening Sharpness for Dynamic Gradient Projection Memory Benefits Continual Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9b16759a62899465ab21e2e79d2ef75c-Paper.pdf",
    "abstract": "The backpropagation networks are notably susceptible to catastrophic forgetting, where networks tend to forget previously learned skills upon learning new ones. To address such the 'sensitivity-stability' dilemma, most previous efforts have been contributed to minimizing the empirical risk with different parameter regularization terms and episodic memory, but rarely exploring the usages of the weight loss landscape. In this paper, we investigate the relationship between the weight loss landscape and sensitivity-stability in the continual learning scenario, based on which, we propose a novel method, Flattening Sharpness for Dynamic Gradient Projection Memory (FS-DGPM). In particular, we introduce a soft weight to represent the importance of each basis representing past tasks in GPM, which can be adaptively learned during the learning process, so that less important bases can be dynamically released to improve the sensitivity of new skill learning. We further introduce Flattening Sharpness (FS) to reduce the generalization gap by explicitly regulating the flatness of the weight loss landscape of all seen tasks. As demonstrated empirically, our proposed method consistently outperforms baselines with the superior ability to learn new skills while alleviating forgetting effectively.",
    "authors": [
      "DENG, Danruo",
      "Chen, Guangyong",
      "Hao, Jianye",
      "Wang, Qiong",
      "Heng, Pheng-Ann"
    ]
  },
  {
    "id": "9b72e31dac81715466cd580a448cf823",
    "title": "Taxonomizing local versus global structure in neural network loss landscapes",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9b72e31dac81715466cd580a448cf823-Paper.pdf",
    "abstract": "Viewing neural network models in terms of their loss landscapes has a long history in the statistical mechanics approach to learning, and in recent years it has received attention within machine learning proper. Among other things, local metrics (such as the smoothness of the loss landscape) have been shown to correlate with global properties of the model (such as good generalization performance). Here, we perform a detailed empirical analysis of the loss landscape structure of thousands of neural network models, systematically varying learning tasks, model architectures, and/or quantity/quality of data. By considering a range of metrics that attempt to capture different aspects of the loss landscape, we demonstrate that the best test accuracy is obtained when: the loss landscape is globally well-connected; ensembles of trained models are more similar to each other; and models converge to locally smooth regions. We also show that globally poorly-connected landscapes can arise when models are small or when they are trained to lower quality data; and that, if the loss landscape is globally poorly-connected, then training to zero loss can actually lead to worse test accuracy. Our detailed empirical results shed light on phases of learning (and consequent double descent behavior), fundamental versus incidental determinants of good generalization, the role of load-like and temperature-like parameters in the learning process, different influences on the loss landscape from model and data, and the relationships between local and global metrics, all topics of recent interest.",
    "authors": [
      "Yang, Yaoqing",
      "Hodgkinson, Liam",
      "Theisen, Ryan",
      "Zou, Joe",
      "Gonzalez, Joseph E.",
      "Ramchandran, Kannan",
      "Mahoney, Michael W."
    ]
  },
  {
    "id": "9b82909c30456ac902e14526e63081d4",
    "title": "Learning Models for Actionable Recourse",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9b82909c30456ac902e14526e63081d4-Paper.pdf",
    "abstract": "As machine learning models are increasingly deployed in high-stakes domains such as legal and financial decision-making, there has been growing interest in post-hoc methods for generating counterfactual explanations. Such explanations provide individuals adversely impacted by predicted outcomes (e.g., an applicant denied a loan) with recourse---i.e., a description of how they can change their features to obtain a positive outcome. We propose a novel algorithm that leverages adversarial training and PAC confidence sets to learn models that theoretically guarantee recourse to affected individuals with high probability without sacrificing accuracy. We demonstrate the efficacy of our approach via extensive experiments on real data.",
    "authors": [
      "Ross, Alexis",
      "Lakkaraju, Himabindu",
      "Bastani, Osbert"
    ]
  },
  {
    "id": "9ba196c7a6e89eafd0954de80fc1b224",
    "title": "Efficient and Accurate Gradients for Neural SDEs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9ba196c7a6e89eafd0954de80fc1b224-Paper.pdf",
    "abstract": "Neural SDEs combine many of the best qualities of both RNNs and SDEs, and as such are a natural choice for modelling many types of temporal dynamics. They offer memory efficiency, high-capacity function approximation, and strong priors on model space. Neural SDEs may be trained as VAEs or as GANs; in either case it is necessary to backpropagate through the SDE solve. In particular this may be done by constructing a backwards-in-time SDE whose solution is the desired parameter gradients. However, this has previously suffered from severe speed and accuracy issues, due to high computational complexity, numerical errors in the SDE solve, and the cost of reconstructing Brownian motion. Here, we make several technical innovations to overcome these issues. First, we introduce the \\textit{reversible Heun method}: a new SDE solver that is algebraically reversible -- which reduces numerical gradient errors to almost zero, improving several test metrics by substantial margins over state-of-the-art. Moreover it requires half as many function evaluations as comparable solvers, giving up to a $1.98\\times$ speedup. Next, we introduce the \\textit{Brownian interval}. This is a new and computationally efficient way of exactly sampling \\textit{and reconstructing} Brownian motion; this is in contrast to previous reconstruction techniques that are both approximate and relatively slow. This gives up to a $10.6\\times$ speed improvement over previous techniques. After that, when specifically training Neural SDEs as GANs (Kidger et al. 2021), we demonstrate how SDE-GANs may be trained through careful weight clipping and choice of activation function. This reduces computational cost (giving up to a $1.87\\times$ speedup), and removes the truncation errors of the double adjoint required for gradient penalty, substantially improving several test metrics. Altogether these techniques offer substantial improvements over the state-of-the-art, with respect to both training speed and with respect to classification, prediction, and MMD test metrics. We have contributed implementations of all of our techniques to the \\texttt{torchsde} library to help facilitate their adoption.",
    "authors": [
      "Kidger, Patrick",
      "Foster, James",
      "Li, Xuechen (Chen)",
      "Lyons, Terry"
    ]
  },
  {
    "id": "9bd5ee6fe55aaeb673025dbcb8f939c1",
    "title": "EIGNN: Efficient Infinite-Depth Graph Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9bd5ee6fe55aaeb673025dbcb8f939c1-Paper.pdf",
    "abstract": "Graph neural networks (GNNs) are widely used for modelling graph-structured data in numerous applications. However, with their inherently finite aggregation layers, existing GNN models may not be able to effectively capture long-range dependencies in the underlying graphs. Motivated by this limitation, we propose a GNN model with infinite depth, which we call Efficient Infinite-Depth Graph Neural Networks (EIGNN), to efficiently capture very long-range dependencies. We theoretically derive a closed-form solution of EIGNN which makes training an infinite-depth GNN model tractable. We then further show that we can achieve more efficient computation for training EIGNN by using eigendecomposition. The empirical results of comprehensive experiments on synthetic and real-world datasets show that EIGNN has a better ability to capture long-range dependencies than recent baselines, and consistently achieves state-of-the-art performance. Furthermore, we show that our model is also more robust against both noise and adversarial perturbations on node features.",
    "authors": [
      "Liu, Juncheng",
      "Kawaguchi, Kenji",
      "Hooi, Bryan",
      "Wang, Yiwei",
      "Xiao, Xiaokui"
    ]
  },
  {
    "id": "9bdb8b1faffa4b3d41779bb495d79fb9",
    "title": "Fractal Structure and Generalization Properties of Stochastic Optimization Algorithms",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9bdb8b1faffa4b3d41779bb495d79fb9-Paper.pdf",
    "abstract": "Understanding generalization in deep learning has been one of the major challenges in statistical learning theory over the last decade. While recent work has illustrated that the dataset and the training algorithm must be taken into account in order to obtain meaningful generalization bounds, it is still theoretically not clear which properties of the data and the algorithm determine the generalization performance. In this study, we approach this problem from a dynamical systems theory perspective and represent stochastic optimization algorithms as \\emph{random iterated function systems} (IFS). Well studied in the dynamical systems literature, under mild assumptions, such IFSs can be shown to be ergodic with an invariant measure that is often supported on sets with a \\emph{fractal structure}. As our main contribution, we prove that the generalization error of a stochastic optimization algorithm can be bounded based on the `complexity' of the fractal structure that underlies its invariant measure. Then, by leveraging results from dynamical systems theory, we show that the generalization error can be explicitly linked to the choice of the algorithm (e.g., stochastic gradient descent -- SGD), algorithm hyperparameters (e.g., step-size, batch-size), and the geometry of the problem (e.g., Hessian of the loss). We further specialize our results to specific problems (e.g., linear/logistic regression, one hidden-layered neural networks) and algorithms (e.g., SGD and preconditioned variants), and obtain analytical estimates for our bound. For modern neural networks, we develop an efficient algorithm to compute the developed bound and support our theory with various experiments on neural networks. ",
    "authors": [
      "Camuto, Alexander",
      "Deligiannidis, George",
      "Erdogdu, Murat A.",
      "Gurbuzbalaban, Mert",
      "Simsekli, Umut",
      "Zhu, Lingjiong "
    ]
  },
  {
    "id": "9be40cee5b0eee1462c82c6964087ff9",
    "title": "An Infinite-Feature Extension for Bayesian ReLU Nets That Fixes Their Asymptotic Overconfidence",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9be40cee5b0eee1462c82c6964087ff9-Paper.pdf",
    "abstract": "A Bayesian treatment can mitigate overconfidence in ReLU nets around the training data. But far away from them, ReLU Bayesian neural networks (BNNs) can still underestimate uncertainty and thus be asymptotically overconfident. This issue arises since the output variance of a BNN with finitely many features is quadratic in the distance from the data region. Meanwhile, Bayesian linear models with ReLU features converge, in the infinite-width limit, to a particular Gaussian process (GP) with a variance that grows cubically so that no asymptotic overconfidence can occur. While this may seem of mostly theoretical interest, in this work, we show that it can be used in practice to the benefit of BNNs. We extend finite ReLU BNNs with infinite ReLU features via the GP and show that the resulting model is asymptotically maximally uncertain far away from the data while the BNNs' predictive power is unaffected near the data. Although the resulting model approximates a full GP posterior, thanks to its structure, it can be applied post-hoc to any pre-trained ReLU BNN at a low cost.",
    "authors": [
      "Kristiadi, Agustinus",
      "Hein, Matthias",
      "Hennig, Philipp"
    ]
  },
  {
    "id": "9c36b930df0e0e8b05d4e1fcb4cdef27",
    "title": "Bandit Phase Retrieval",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9c36b930df0e0e8b05d4e1fcb4cdef27-Paper.pdf",
    "abstract": "We study a bandit version of phase retrieval where the learner chooses actions $(A_t)_{t=1}^n$ in the $d$-dimensional unit ball and the expected reward is $\\langle A_t, \\theta_\\star \\rangle^2$ with $\\theta_\\star \\in \\mathbb R^d$ an unknown parameter vector. We prove an upper bound on the minimax cumulative regret in this problem of $\\smash{\\tilde \\Theta(d \\sqrt{n})}$, which matches known lower bounds up to logarithmic factors and improves on the best known upper bound by a factor of $\\smash{\\sqrt{d}}$. We also show that the minimax simple regret is $\\smash{\\tilde \\Theta(d / \\sqrt{n})}$ and that this is only achievable by an adaptive algorithm. Our analysis shows that an apparently convincing heuristic for guessing lower bounds can be misleading and that uniform bounds on the information ratio for information-directed sampling (Russo and Van Roy, 2014) are not sufficient for optimal regret.",
    "authors": [
      "Lattimore, Tor",
      "Hao, Botao"
    ]
  },
  {
    "id": "9c4e6233c6d5ff637e7984152a3531d5",
    "title": "Lower Bounds on Metropolized Sampling Methods for Well-Conditioned Distributions",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9c4e6233c6d5ff637e7984152a3531d5-Paper.pdf",
    "abstract": "We give lower bounds on the performance of two of the most popular sampling methods in practice, the Metropolis-adjusted Langevin algorithm (MALA) and multi-step Hamiltonian Monte Carlo (HMC) with a leapfrog integrator, when applied to well-conditioned distributions. Our main result is a nearly-tight lower bound of $\\widetilde{\\Omega}(\\kappa d)$ on the mixing time of MALA from an exponentially warm start, matching a line of algorithmic results \\cite{DwivediCW018, ChenDWY19, LeeST20a} up to logarithmic factors and answering an open question of \\cite{ChewiLACGR20}. We also show that a polynomial dependence on dimension is necessary for the relaxation time of HMC under any number of leapfrog steps, and bound the gains achievable by changing the step count. Our HMC analysis draws upon a novel connection between leapfrog integration and Chebyshev polynomials, which may be of independent interest.",
    "authors": [
      "Lee, Yin Tat",
      "Shen, Ruoqi",
      "Tian, Kevin"
    ]
  },
  {
    "id": "9c51a13764ca629f439f6accbb4ec413",
    "title": " Taming Communication and Sample Complexities in Decentralized Policy Evaluation for Cooperative Multi-Agent Reinforcement Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9c51a13764ca629f439f6accbb4ec413-Paper.pdf",
    "abstract": "Cooperative multi-agent reinforcement learning (MARL) has received increasing attention in recent years and has found many scientific and engineering applications. However, a key challenge arising from many cooperative MARL algorithm designs (e.g., the actor-critic framework) is the policy evaluation problem, which can only be conducted in a {\\em decentralized} fashion. In this paper, we focus on decentralized MARL policy evaluation with nonlinear function approximation, which is often seen in deep MARL. We first show that the empirical decentralized MARL policy evaluation problem can be reformulated as a decentralized nonconvex-strongly-concave minimax saddle point problem. We then develop a decentralized gradient-based descent ascent algorithm called GT-GDA that enjoys a convergence rate of $\\mathcal{O}(1/T)$. To further reduce the sample complexity, we propose two decentralized stochastic optimization algorithms called GT-SRVR and GT-SRVRI, which enhance GT-GDA by variance reduction techniques. We show that all algorithms all enjoy an $\\mathcal{O}(1/T)$ convergence rate to a stationary point of the reformulated minimax problem. Moreover, the fast convergence rates of GT-SRVR and GT-SRVRI imply $\\mathcal{O}(\\epsilon^{-2})$ communication complexity and $\\mathcal{O}(m\\sqrt{n}\\epsilon^{-2})$ sample complexity, where $m$ is the number of agents and $n$ is the length of trajectories. To our knowledge, this paper is the first work that achieves both $\\mathcal{O}(\\epsilon^{-2})$ sample complexity and $\\mathcal{O}(\\epsilon^{-2})$ communication complexity in decentralized policy evaluation for cooperative MARL. Our extensive experiments also corroborate the theoretical performance of our proposed decentralized policy evaluation algorithms.",
    "authors": [
      "Zhang, Xin",
      "Liu, Zhuqing",
      "Liu, Jia",
      "Zhu, Zhengyuan",
      "Lu, Songtao"
    ]
  },
  {
    "id": "9c6947bd95ae487c81d4e19d3ed8cd6f",
    "title": "Federated Graph Classification over Non-IID Graphs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9c6947bd95ae487c81d4e19d3ed8cd6f-Paper.pdf",
    "abstract": "Federated learning has emerged as an important paradigm for training machine learning models in different domains. For graph-level tasks such as graph classification, graphs can also be regarded as a special type of data samples, which can be collected and stored in separate local systems. Similar to other domains, multiple local systems, each holding a small set of graphs, may benefit from collaboratively training a powerful graph mining model, such as the popular graph neural networks (GNNs). To provide more motivation towards such endeavors, we analyze real-world graphs from different domains to confirm that they indeed share certain graph properties that are statistically significant compared with random graphs. However, we also find that different sets of graphs, even from the same domain or same dataset, are non-IID regarding both graph structures and node features. To handle this, we propose a graph clustered federated learning (GCFL) framework that dynamically finds clusters of local systems based on the gradients of GNNs, and theoretically justify that such clusters can reduce the structure and feature heterogeneity among graphs owned by the local systems. Moreover, we observe the gradients of GNNs to be rather fluctuating in GCFL which impedes high-quality clustering, and design a gradient sequence-based clustering mechanism based on dynamic time warping (GCFL+). Extensive experimental results and in-depth analysis demonstrate the effectiveness of our proposed frameworks.",
    "authors": [
      "Xie, Han",
      "Ma, Jing",
      "Xiong, Li",
      "Yang, Carl"
    ]
  },
  {
    "id": "9c8661befae6dbcd08304dbf4dcaf0db",
    "title": "SubTab: Subsetting Features of Tabular Data for Self-Supervised Representation Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9c8661befae6dbcd08304dbf4dcaf0db-Paper.pdf",
    "abstract": "Self-supervised learning has been shown to be very effective in learning useful representations, and yet much of the success is achieved in data types such as images, audio, and text. The success is mainly enabled by taking advantage of spatial, temporal, or semantic structure in the data through augmentation. However, such structure may not exist in tabular datasets commonly used in fields such as healthcare, making it difficult to design an effective augmentation method, and hindering a similar progress in tabular data setting. In this paper, we introduce a new framework, Subsetting features of Tabular data (SubTab), that turns the task of learning from tabular data into a multi-view representation learning problem by dividing the input features to multiple subsets. We argue that reconstructing the data from the subset of its features rather than its corrupted version in an autoencoder setting can better capture its underlying latent representation. In this framework, the joint representation can be expressed as the aggregate of latent variables of the subsets at test time, which we refer to as collaborative inference. Our experiments show that the SubTab achieves the state of the art (SOTA) performance of 98.31% on MNIST in tabular setting, on par with CNN-based SOTA models, and surpasses existing baselines on three other real-world datasets by a significant margin.",
    "authors": [
      "Ucar, Talip",
      "Hajiramezanali, Ehsan",
      "Edwards, Lindsay"
    ]
  },
  {
    "id": "9cdf26568d166bc6793ef8da5afa0846",
    "title": "Convergence Rates of Stochastic Gradient Descent under Infinite Noise Variance",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9cdf26568d166bc6793ef8da5afa0846-Paper.pdf",
    "abstract": "Recent studies have provided both empirical and theoretical evidence illustrating that heavy tails can emerge in stochastic gradient descent (SGD) in various scenarios. Such heavy tails potentially result in iterates with diverging variance, which hinders the use of conventional convergence analysis techniques that rely on the existence of the second-order moments. In this paper, we provide convergence guarantees for SGD under a state-dependent and heavy-tailed noise with a potentially infinite variance, for a class of strongly convex objectives. In the case where the $p$-th moment of the noise exists for some $p\\in [1,2)$, we first identify a condition on the Hessian, coined `$p$-positive (semi-)definiteness', that leads to an interesting interpolation between the positive semi-definite cone ($p=2$) and the cone of diagonally dominant matrices with non-negative diagonal entries ($p=1$). Under this condition, we provide a convergence rate for the distance to the global optimum in $L^p$. Furthermore, we provide a generalized central limit theorem, which shows that the properly scaled Polyak-Ruppert averaging converges weakly to a multivariate $\\alpha$-stable random vector.Our results indicate that even under heavy-tailed noise with infinite variance, SGD can converge to the global optimum without necessitating any modification neither to the loss function nor to the algorithm itself, as typically required in robust statistics.We demonstrate the implications of our resultsover misspecified models, in the presence of heavy-tailed data.",
    "authors": [
      "Wang, Hongjian",
      "Gurbuzbalaban, Mert",
      "Zhu, Lingjiong ",
      "Simsekli, Umut",
      "Erdogdu, Murat A."
    ]
  },
  {
    "id": "9d27fdf2477ffbff837d73ef7ae23db9",
    "title": "Conflict-Averse Gradient Descent for Multi-task learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9d27fdf2477ffbff837d73ef7ae23db9-Paper.pdf",
    "abstract": "The goal of multi-task learning is to enable more efficient learning than single task learning by sharing model structures for a diverse set of tasks. A standard multi-task learning objective is to minimize the average loss across all tasks. While straightforward, using this objective often results in much worse final performance for each task than learning them independently. A major challenge in optimizing a multi-task model is the conflicting gradients, where gradients of different task objectives are not well aligned so that following the average gradient direction can be detrimental to specific tasks' performance. Previous work has proposed several heuristics to manipulate the task gradients for mitigating this problem. But most of them lack convergence guarantee and/or could converge to any Pareto-stationary point.In this paper, we introduce Conflict-Averse Gradient descent (CAGrad) which minimizes the average loss function, while leveraging the worst local improvement of individual tasks to regularize the algorithm trajectory. CAGrad balances the objectives automatically and still provably converges to a minimum over the average loss. It includes the regular gradient descent (GD) and the multiple gradient descent algorithm (MGDA) in the multi-objective optimization (MOO) literature as special cases. On a series of challenging multi-task supervised learning and reinforcement learning tasks, CAGrad achieves improved performance over prior state-of-the-art multi-objective gradient manipulation methods.",
    "authors": [
      "Liu, Bo",
      "Liu, Xingchao",
      "Jin, Xiaojie",
      "Stone, Peter",
      "Liu, Qiang"
    ]
  },
  {
    "id": "9d38e6eab92b2aeb0a83b570188d5a1a",
    "title": "Amortized Synthesis of Constrained Configurations Using a Differentiable Surrogate",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9d38e6eab92b2aeb0a83b570188d5a1a-Paper.pdf",
    "abstract": "In design, fabrication, and control problems, we are often faced with the task of synthesis, in which we must generate an object or configuration that satisfies a set of constraints while maximizing one or more objective functions. The synthesis problem is typically characterized by a physical process in which many different realizations may achieve the goal. This many-to-one map presents challenges to the supervised learning of feed-forward synthesis, as the set of viable designs may have a complex structure. In addition, the non-differentiable nature of many physical simulations prevents efficient direct optimization. We address both of these problems with a two-stage neural network architecture that we may consider to be an autoencoder. We first learn the decoder: a differentiable surrogate that approximates the many-to-one physical realization process. We then learn the encoder, which maps from goal to design, while using the fixed decoder to evaluate the quality of the realization. We evaluate the approach on two case studies: extruder path planning in additive manufacturing and constrained soft robot inverse kinematics. We compare our approach to direct optimization of the design using the learned surrogate, and to supervised learning of the synthesis problem. We find that our approach produces higher quality solutions than supervised learning, while being competitive in quality with direct optimization, at a greatly reduced computational cost.",
    "authors": [
      "Sun, Xingyuan",
      "Xue, Tianju",
      "Rusinkiewicz, Szymon",
      "Adams, Ryan P."
    ]
  },
  {
    "id": "9d684c589d67031a627ad33d59db65e5",
    "title": "Efficient First-Order Contextual Bandits: Prediction, Allocation, and Triangular Discrimination",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9d684c589d67031a627ad33d59db65e5-Paper.pdf",
    "abstract": "A recurring theme in statistical learning, online learning, and beyond is that faster convergence rates are possible for problems with low noise, often quantified by the performance of the best hypothesis; such results are known as first-order or small-loss guarantees. While first-order guarantees are relatively well understood in statistical and online learning, adapting to low noise in contextual bandits (and more broadly, decision making) presents major algorithmic challenges. In a COLT 2017 open problem, Agarwal, Krishnamurthy, Langford, Luo, and Schapire asked whether first-order guarantees are even possible for contextual bandits and---if so---whether they can be attained by efficient algorithms. We give a resolution to this question by providing an optimal and efficient reduction from contextual bandits to online regression with the logarithmic (or, cross-entropy) loss. Our algorithm is simple and practical, readily accommodates rich function classes, and requires no distributional assumptions beyond realizability. In a large-scale empirical evaluation, we find that our approach typically outperforms  comparable non-first-order methods.On the technical side, we show that the logarithmic loss and an information-theoretic quantity called the triangular discrimination play a fundamental role in obtaining first-order guarantees, and we combine this observation with new refinements to the regression oracle reduction framework of Foster and Rakhlin (2020). The use of triangular discrimination yields novel results even for the classical statistical learning model, and we anticipate that it will find broader use.",
    "authors": [
      "Foster, Dylan J.",
      "Krishnamurthy, Akshay"
    ]
  },
  {
    "id": "9d740bd0f36aaa312c8d504e28c42163",
    "title": "Distributed Estimation with Multiple Samples per User: Sharp Rates and Phase Transition",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9d740bd0f36aaa312c8d504e28c42163-Paper.pdf",
    "abstract": "We obtain tight minimax rates for the problem of distributed estimation of discrete distributions under communication constraints, where $n$ users observing $m $ samples each can broadcast only $\\ell$  bits. Our main result is a tight characterization (up to logarithmic factors) of the error rate as a function of $m$, $\\ell$, the domain size, and the number of users under most regimes of interest. While previous work focused on the setting where each user only holds one sample, we show that as $m$ grows the $\\ell_1$ error rate gets reduced by a factor of $\\sqrt{m}$ for small $m$. However, for large $m$ we observe an interesting phase transition: the dependence of the error rate on the communication constraint $\\ell$ changes from $1/\\sqrt{2^{\\ell}}$ to $1/\\sqrt{\\ell}$.",
    "authors": [
      "Acharya, Jayadev",
      "Canonne, Clement",
      "Liu, Yuhan",
      "Sun, Ziteng",
      "Tyagi, Himanshu"
    ]
  },
  {
    "id": "9d86d83f925f2149e9edb0ac3b49229c",
    "title": "Revisiting Deep Learning Models for Tabular Data",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9d86d83f925f2149e9edb0ac3b49229c-Paper.pdf",
    "abstract": "The existing literature on deep learning for tabular data proposes a wide range of novel architectures and reports competitive results on various datasets. However, the proposed models are usually not properly compared to each other and existing works often use different benchmarks and experiment protocols. As a result, it is unclear for both researchers and practitioners what models perform best. Additionally, the field still lacks effective baselines, that is, the easy-to-use models that provide competitive performance across different problems.In this work, we perform an overview of the main families of DL architectures for tabular data and raise the bar of baselines in tabular DL by identifying two simple and powerful deep architectures. The first one is a ResNet-like architecture which turns out to be a strong baseline that is often missing in prior works. The second model is our simple adaptation of the Transformer architecture for tabular data, which outperforms other solutions on most tasks. Both models are compared to many existing architectures on a diverse set of tasks under the same training and tuning protocols. We also compare the best DL models with Gradient Boosted Decision Trees and conclude that there is still no universally superior solution. The source code is available at https://github.com/yandex-research/rtdl.",
    "authors": [
      "Gorishniy, Yury",
      "Rubachev, Ivan",
      "Khrulkov, Valentin",
      "Babenko, Artem"
    ]
  },
  {
    "id": "9d99197e2ebf03fc388d09f1e94af89b",
    "title": "Backdoor Attack with Imperceptible Input and Latent Modification",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9d99197e2ebf03fc388d09f1e94af89b-Paper.pdf",
    "abstract": "Recent studies have shown that deep neural networks (DNN) are vulnerable to various adversarial attacks. In particular, an adversary can inject a stealthy backdoor into a model such that the compromised model will behave normally without the presence of the trigger. Techniques for generating backdoor images that are visually imperceptible from clean images have also been developed recently, which further enhance the stealthiness of the backdoor attacks from the input space. Along with the development of attacks, defense against backdoor attacks is also evolving. Many existing countermeasures found that backdoor tends to leave tangible footprints in the latent or feature space, which can be utilized to mitigate backdoor attacks.In this paper, we extend the concept of imperceptible backdoor from the input space to the latent representation, which significantly improves the effectiveness against the existing defense mechanisms, especially those relying on the distinguishability between clean inputs and backdoor inputs in latent space. In the proposed framework, the trigger function will learn to manipulate the input by injecting imperceptible input noise while matching the latent representations of the clean and manipulated inputs via a Wasserstein-based regularization of the corresponding empirical distributions. We formulate such an objective as a non-convex and constrained optimization problem and solve the problem with an efficient stochastic alternating optimization procedure. We name the proposed backdoor attack as Wasserstein Backdoor (WB), which achieves a high attack success rate while being stealthy from both the input and latent spaces, as tested in several benchmark datasets, including MNIST, CIFAR10, GTSRB, and TinyImagenet.",
    "authors": [
      "Doan, Khoa",
      "Lao, Yingjie",
      "Li, Ping"
    ]
  },
  {
    "id": "9dd16e049becf4d5087c90a83fea403b",
    "title": "SOPE: Spectrum of Off-Policy Estimators",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9dd16e049becf4d5087c90a83fea403b-Paper.pdf",
    "abstract": "Many sequential decision making problems are high-stakes and require off-policy evaluation (OPE) of a new policy using historical data collected using some other policy. One of the most common OPE techniques that provides unbiased estimates is trajectory based importance sampling (IS). However, due to the high variance of trajectory IS estimates, importance sampling methods based on state-action visitation distributions (SIS) have recently been adopted. Unfortunately, while SIS often provides lower variance estimates for long horizons, estimating the state-action distribution ratios can be challenging and lead to biased estimates. In this paper, we present a new perspective on this bias-variance trade-off and show the existence of a spectrum of estimators whose endpoints are SIS and IS. Additionally, we also establish a spectrum for doubly-robust and weighted version of these estimators. We provide empirical evidence that estimators in this spectrum can be used to trade-off between the bias and variance of IS and SIS and can achieve lower mean-squared error than both IS and SIS.",
    "authors": [
      "Yuan, Christina",
      "Chandak, Yash",
      "Giguere, Stephen",
      "Thomas, Philip S.",
      "Niekum, Scott"
    ]
  },
  {
    "id": "9dfcf16f0adbc5e2a55ef02db36bac7f",
    "title": "Label-Imbalanced and Group-Sensitive Classification under Overparameterization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9dfcf16f0adbc5e2a55ef02db36bac7f-Paper.pdf",
    "abstract": "The goal in label-imbalanced and group-sensitive classification is to optimize relevant metrics such as balanced error and equal opportunity. Classical methods, such as weighted cross-entropy, fail when training deep nets to the terminal phase of training (TPT), that is training beyond zero training error. This observation has motivated recent flurry of activity in developing heuristic alternatives following the intuitive mechanism of promoting larger margin for minorities. In contrast to previous heuristics, we follow a principled analysis explaining how different loss adjustments affect margins. First, we prove that for all linear classifiers trained in TPT, it is necessary to introduce multiplicative, rather than additive, logit adjustments so that the interclass margins change appropriately. To show this, we discover a connection of the multiplicative CE modification to the cost-sensitive support-vector machines. Perhaps counterintuitively, we also find that, at the start of training, the same multiplicative weights can actually harm the minority classes. Thus, while additive adjustments are ineffective in the TPT, we show that they can speed up convergence by countering the initial negative effect of the multiplicative weights. Motivated by these findings, we formulate the vector-scaling (VS) loss, that captures existing techniques as special cases. Moreover, we introduce a natural extension of the VS-loss to group-sensitive classification, thus treating the two common types of imbalances (label/group) in a unifying way. Importantly, our experiments on state-of-the-art datasets are fully consistent with our theoretical insights and confirm the superior performance of our algorithms. Finally, for imbalanced Gaussian-mixtures data, we perform a generalization analysis, revealing tradeoffs between balanced / standard error and equal opportunity.",
    "authors": [
      "Kini, Ganesh Ramachandra",
      "Paraskevas, Orestis",
      "Oymak, Samet",
      "Thrampoulidis, Christos"
    ]
  },
  {
    "id": "9e1a36515d6704d7eb7a30d783400e5d",
    "title": "Neural Program Generation Modulo Static Analysis",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9e1a36515d6704d7eb7a30d783400e5d-Paper.pdf",
    "abstract": "State-of-the-art neural models of source code tend to be evaluated on the generation of individual expressions and lines of code, and commonly fail on long-horizon tasks such as the generation of entire method bodies. We propose to address this deficiency using weak supervision from a static program analyzer. Our neurosymbolic method allows a deep generative model to symbolically compute, using calls to a static analysis tool, long-distance semantic relationships in the code that it has already generated. During training, the model observes these relationships and learns to generate programs conditioned on them. We apply our approach to the problem of generating entire Java methods given the remainder of the class that contains the method. Our experiments show that the approach substantially outperforms a state-of-the-art transformer and a model that explicitly tries to learn program semantics on this task, both in terms of producing programs free of basic semantic errors and in terms of syntactically matching the ground truth. ",
    "authors": [
      "Mukherjee, Rohan",
      "Wen, Yeming",
      "Chaudhari, Dipak",
      "Reps, Thomas",
      "Chaudhuri, Swarat",
      "Jermaine, Christopher"
    ]
  },
  {
    "id": "9e3cfc48eccf81a0d57663e129aef3cb",
    "title": "Unfolding Taylor's Approximations for Image Restoration",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9e3cfc48eccf81a0d57663e129aef3cb-Paper.pdf",
    "abstract": "Deep learning provides a new avenue for image restoration, which demands a delicate balance between fine-grained details and high-level contextualized information during recovering the latent clear image. In practice, however, existing methods empirically construct encapsulated end-to-end mapping networks without deepening into the rationality, and neglect the intrinsic prior knowledge of restoration task. To solve the above problems, inspired by Taylor\u2019s Approximations, we unfold Taylor\u2019s Formula to construct a novel framework for image restoration. We find the main part and the derivative part of Taylor\u2019s Approximations take the same effect as the two competing goals of high-level contextualized information and spatial details of image restoration respectively. Specifically, our framework consists of two steps, which are correspondingly responsible for the mapping and derivative functions. The former first learns the high-level contextualized information and the later combines it with the degraded input to progressively recover local high-order spatial details. Our proposed framework is orthogonal to existing methods and thus can be easily integrated with them for further improvement, and extensive experiments demonstrate the effectiveness and scalability of our proposed framework.",
    "authors": [
      "zhou, man",
      "Fu, Xueyang",
      "Xiao, Zeyu",
      "Yang, Gang",
      "Liu, Aiping",
      "Xiong, Zhiwei"
    ]
  },
  {
    "id": "9e7ba617ad9e69b39bd0c29335b79629",
    "title": "Metropolis-Hastings Data Augmentation for Graph Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9e7ba617ad9e69b39bd0c29335b79629-Paper.pdf",
    "abstract": "Graph Neural Networks (GNNs) often suffer from weak-generalization due to sparsely labeled data despite their promising results on various graph-based tasks. Data augmentation is a prevalent remedy to improve the generalization ability of models in many domains. However, due to the non-Euclidean nature of data space and the dependencies between samples, designing effective augmentation on graphs is challenging. In this paper, we propose a novel framework Metropolis-Hastings Data Augmentation (MH-Aug) that draws augmented graphs from an explicit target distribution for semi-supervised learning. MH-Aug produces a sequence of augmented graphs from the target distribution enables flexible control of the strength and diversity of augmentation. Since the direct sampling from the complex target distribution is challenging, we adopt the Metropolis-Hastings algorithm to obtain the augmented samples. We also propose a simple and effective semi-supervised learning strategy with generated samples from MH-Aug. Our extensive experiments demonstrate that MH-Aug can generate a sequence of samples according to the target distribution to significantly improve the performance of GNNs.",
    "authors": [
      "Park, Hyeonjin",
      "Lee, Seunghun",
      "Kim, Sihyeon",
      "Park, Jinyoung",
      "Jeong, Jisu",
      "Kim, Kyung-Min",
      "Ha, Jung-Woo",
      "Kim, Hyunwoo J."
    ]
  },
  {
    "id": "9edcc1391c208ba0b503fe9a22574251",
    "title": "Strategic Behavior is Bliss: Iterative Voting Improves Social Welfare",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9edcc1391c208ba0b503fe9a22574251-Paper.pdf",
    "abstract": "Recent work in iterative voting has defined the additive dynamic price of anarchy (ADPoA) as the difference in social welfare between the truthful and worst-case equilibrium profiles resulting from repeated strategic manipulations. While iterative plurality has been shown to only return alternatives with at most one less initial votes than the truthful winner, it is less understood how agents' welfare changes in equilibrium. To this end, we differentiate agents' utility from their manipulation mechanism and determine iterative plurality's ADPoA in the worst- and average-cases. We first prove that the worst-case ADPoA is linear in the number of agents. To overcome this negative result, we study the average-case ADPoA and prove that equilibrium winners have a constant order welfare advantage over the truthful winner in expectation. Our positive results illustrate the prospect for social welfare to increase due to strategic manipulation. ",
    "authors": [
      "Kavner, Joshua",
      "Xia, Lirong"
    ]
  },
  {
    "id": "9eed867b73ab1eab60583c9d4a789b1b",
    "title": "Agnostic Reinforcement Learning with Low-Rank MDPs and Rich Observations",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9eed867b73ab1eab60583c9d4a789b1b-Paper.pdf",
    "abstract": "There have been many recent advances on provably efficient Reinforcement Learning (RL) in problems with rich observation spaces. However, all these works share a strong realizability assumption about the optimal value function of the true MDP. Such realizability assumptions are often too strong to hold in practice. In this work, we consider the more realistic setting of agnostic RL with rich observation spaces and a fixed class of policies $\\Pi$ that may not contain any near-optimal policy. We provide an algorithm for this setting whose error is bounded in terms of the rank $d$ of the underlying MDP.  Specifically, our algorithm enjoys a sample complexity bound of $\\widetilde{O}\\left((H^{4d} K^{3d} \\log |\\Pi|)/\\epsilon^2\\right)$ where $H$ is the length of episodes, $K$ is the number of actions and $\\epsilon>0$ is the desired sub-optimality.  We also provide a nearly matching lower bound for this agnostic setting that shows that the exponential dependence on rank is unavoidable, without further assumptions. ",
    "authors": [
      "Sekhari, Ayush",
      "Dann, Christoph",
      "Mohri, Mehryar",
      "Mansour, Yishay",
      "Sridharan, Karthik"
    ]
  },
  {
    "id": "9f0609b9d45dd55bed75f892cf095fcf",
    "title": "Functional Regularization for Reinforcement Learning via Learned Fourier Features",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9f0609b9d45dd55bed75f892cf095fcf-Paper.pdf",
    "abstract": "We propose a simple architecture for deep reinforcement learning by embedding inputs into a learned Fourier basis and show that it improves the sample efficiency of both state-based and image-based RL. We perform infinite-width analysis of our architecture using the Neural Tangent Kernel and theoretically show that tuning the initial variance of the Fourier basis is equivalent to functional regularization of the learned deep network. That is, these learned Fourier features allow for adjusting the degree to which networks underfit or overfit different frequencies in the training data, and hence provide a controlled mechanism to improve the stability and performance of RL optimization. Empirically, this allows us to prioritize learning low-frequency functions and speed up learning by reducing networks' susceptibility to noise in the optimization process, such as during Bellman updates. Experiments on standard state-based and image-based RL benchmarks show clear benefits of our architecture over the baselines.",
    "authors": [
      "Li, Alexander",
      "Pathak, Deepak"
    ]
  },
  {
    "id": "9f16b57bdd4400066a83cd8eaa151c41",
    "title": "Adaptive First-Order Methods Revisited: Convex Minimization without Lipschitz Requirements",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9f16b57bdd4400066a83cd8eaa151c41-Paper.pdf",
    "abstract": "We propose a new family of adaptive first-order methods for a class of convex minimization problems that may fail to be Lipschitz continuous or smooth in the standard sense. Specifically, motivated by a recent flurry of activity on non-Lipschitz (NoLips) optimization, we consider problems that are continuous or smooth relative to a reference Bregman function \u2013 as opposed to a global, ambient norm (Euclidean or otherwise). These conditions encompass a wide range ofproblems with singular objective, such as Fisher markets, Poisson tomography, D-design, and the like. In this setting, the application of existing order-optimal adaptive methods \u2013 like UnixGrad or AcceleGrad \u2013 is not possible, especially in the presence of randomness and uncertainty. The proposed method, adaptive mirror descent (AdaMir), aims to close this gap by concurrently achieving min-max optimal rates in problems that are relatively continuous or smooth, including stochastic ones.",
    "authors": [
      "Antonakopoulos, Kimon",
      "Mertikopoulos, Panayotis"
    ]
  },
  {
    "id": "9f820adf84bf8a1c259f464ba89ea11f",
    "title": "Adapting to function difficulty and growth conditions in private optimization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9f820adf84bf8a1c259f464ba89ea11f-Paper.pdf",
    "abstract": "We develop algorithms for private stochastic convex optimization that adapt to the hardness of the specific function we wish to optimize. While previous work provide worst-case bounds for arbitrary convex functions, it is often the case that the function at hand belongs to a smaller class that enjoys faster rates. Concretely, we show that for functions exhibiting $\\kappa$-growth around the optimum, i.e., $f(x) \\ge f(x^\\star) + \\lambda \\kappa^{-1} \\|x-x^\\star\\|_2^\\kappa$ for $\\kappa > 1$, our algorithms improve upon the standard ${\\sqrt{d}}/{n\\varepsilon}$ privacy rate to the faster $({\\sqrt{d}}/{n\\varepsilon})^{\\tfrac{\\kappa}{\\kappa - 1}}$. Crucially, they achieve these rates without knowledge of the growth constant $\\kappa$ of the function. Our algorithms build upon the inverse sensitivity mechanism, which adapts to instance difficulty [2], and recent localization techniques in private optimization [25]. We complement our algorithms with matching lower bounds for these function classes and demonstrate that our adaptive algorithm is simultaneously (minimax) optimal over all $\\kappa \\ge 1+c$ whenever $c = \\Theta(1)$.",
    "authors": [
      "Asi, Hilal",
      "Levy, Daniel",
      "Duchi, John C."
    ]
  },
  {
    "id": "9f8785c7f9b578bec2c09e616568d270",
    "title": "Support Recovery of Sparse Signals from a Mixture of Linear Measurements",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9f8785c7f9b578bec2c09e616568d270-Paper.pdf",
    "abstract": "Recovery of support of a sparse vector from simple measurements is a widely studied problem, considered under the frameworks of compressed sensing, 1-bit compressed sensing, and more general single index models. We consider generalizations of this problem: mixtures of linear regressions, and mixtures of linear classifiers, where the goal is to recover supports of multiple sparse vectors using only a small number of possibly noisy linear, and 1-bit measurements respectively. The key challenge is that the measurements from different vectors are randomly mixed. Both of these problems have also received attention recently. In mixtures of linear classifiers, an observation corresponds to the side of the queried hyperplane a random unknown vector lies in; whereas in mixtures of linear regressions we observe the projection of a random unknown vector on the queried hyperplane. The primary step in recovering the unknown vectors from the mixture is to first identify the support of all the individual component vectors. In this work, we study the number of measurements sufficient for recovering the supports of all the component vectors in a mixture in both these models. We provide algorithms that use a number of measurements polynomial in $k, \\log n$ and quasi-polynomial in $\\ell$, to recover the support of all the $\\ell$ unknown vectors in the mixture with high probability when each individual component is a $k$-sparse $n$-dimensional vector.",
    "authors": [
      "Pal, Soumyabrata",
      "Mazumdar, Arya",
      "Gandikota, Venkata"
    ]
  },
  {
    "id": "9f96f36b7aae3b1ff847c26ac94c604e",
    "title": "Stochastic Gradient Descent-Ascent and Consensus Optimization for Smooth Games: Convergence Analysis under Expected Co-coercivity",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9f96f36b7aae3b1ff847c26ac94c604e-Paper.pdf",
    "abstract": "Two of the most prominent algorithms for solving unconstrained smooth games are the classical stochastic gradient descent-ascent (SGDA) and the recently introduced stochastic consensus optimization (SCO) [Mescheder et al., 2017]. SGDA is known to converge to a stationary point for specific classes of games, but current convergence analyses require a bounded variance assumption. SCO is used successfully for solving large-scale adversarial problems, but its convergence guarantees are limited to its deterministic variant. In this work, we introduce the expected co-coercivity condition, explain its benefits, and provide the first last-iterate convergence guarantees of SGDA and SCO under this condition for solving a class of stochastic variational inequality problems that are potentially non-monotone. We prove linear convergence of both methods to a neighborhood of the solution when they use constant step-size, and we propose insightful stepsize-switching rules to guarantee convergence to the exact solution. In addition, our convergence guarantees hold under the arbitrary sampling paradigm, and as such, we give insights into the complexity of minibatching. ",
    "authors": [
      "Loizou, Nicolas",
      "Berard, Hugo",
      "Gidel, Gauthier",
      "Mitliagkas, Ioannis",
      "Lacoste-Julien, Simon"
    ]
  },
  {
    "id": "9f975093da0252e2c0ae181d74c90dc6",
    "title": "Tighter Expected Generalization Error Bounds via Wasserstein Distance",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9f975093da0252e2c0ae181d74c90dc6-Paper.pdf",
    "abstract": "This work presents several expected generalization error bounds based on the Wasserstein distance. More specifically, it introduces full-dataset, single-letter, and random-subset bounds, and their analogous in the randomized subsample setting from Steinke and Zakynthinou [1]. Moreover, when the loss function is bounded and the geometry of the space is ignored by the choice of the metric in the Wasserstein distance, these bounds recover from below (and thus, are tighter than) current bounds based on the relative entropy. In particular, they generate new, non-vacuous bounds based on the relative entropy. Therefore, these results can be seen as a bridge between works that account for the geometry of the hypothesis space and those based on the relative entropy, which is agnostic to such geometry. Furthermore, it is shown how to produce various new bounds based on different information measures (e.g., the lautum information or several $f$-divergences) based on these bounds and how to derive similar bounds with respect to the backward channel using the presented proof techniques.",
    "authors": [
      "Rodr\u00edguez G\u00e1lvez, Borja",
      "Bassi, German",
      "Thobaben, Ragnar",
      "Skoglund, Mikael"
    ]
  },
  {
    "id": "9f9e8cba3700df6a947a8cf91035ab84",
    "title": "Unifying Width-Reduced Methods for Quasi-Self-Concordant Optimization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9f9e8cba3700df6a947a8cf91035ab84-Paper.pdf",
    "abstract": "We provide several algorithms for constrained optimization of a large class of convex problems, including softmax, $\\ell_p$ regression, and logistic regression. Central to our approach is the notion of width reduction, a technique which has proven immensely useful in the context of maximum flow [Christiano et al., STOC'11] and, more recently, $\\ell_p$ regression [Adil et al., SODA'19], in terms of improving the iteration complexity from $O(m^{1/2})$ to $\\tilde{O}(m^{1/3})$, where $m$ is the number of rows of the design matrix, and where each iteration amounts to a linear system solve. However, a considerable drawback is that these methods require both problem-specific potentials and individually tailored analyses.As our main contribution, we initiate a new direction of study by presenting the first \\emph{unified} approach to achieving $m^{1/3}$-type rates. Notably, our method goes beyond these previously considered problems to more broadly capture \\emph{quasi-self-concordant} losses, a class which has recently generated much interest and includes the well-studied problem of logistic regression, among others. In order to do so, we develop a unified width reduction method for carefully handling these losses based on a more general set of potentials. Additionally, we directly achieve $m^{1/3}$-type rates in the constrained setting without the need for any explicit acceleration schemes, thus naturally complementing recent work based on a ball-oracle approach [Carmon et al., NeurIPS'20].",
    "authors": [
      "Adil, Deeksha",
      "Bullins, Brian",
      "Sachdeva, Sushant"
    ]
  },
  {
    "id": "9fc664916bce863561527f06a96f5ff3",
    "title": "Bridging the Imitation Gap by Adaptive Insubordination",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9fc664916bce863561527f06a96f5ff3-Paper.pdf",
    "abstract": "In practice, imitation learning is preferred over pure reinforcement learning whenever it is possible to design a teaching agent to provide expert supervision. However, we show that when the teaching agent makes decisions with access to privileged information that is unavailable to the student, this information is marginalized during imitation learning, resulting in an \"imitation gap\" and, potentially, poor results. Prior work bridges this gap via a progression from imitation learning to reinforcement learning. While often successful, gradual progression fails for tasks that require frequent switches between exploration and memorization. To better address these tasks and alleviate the imitation gap we propose 'Adaptive Insubordination' (ADVISOR). ADVISOR dynamically weights imitation and reward-based reinforcement learning losses during training, enabling on-the-fly switching between imitation and exploration. On a suite of challenging tasks set within gridworlds, multi-agent particle environments, and high-fidelity 3D simulators, we show that on-the-fly switching with ADVISOR outperforms pure imitation, pure reinforcement learning, as well as their sequential and parallel combinations.",
    "authors": [
      "Weihs, Luca",
      "Jain, Unnat",
      "Liu, Iou-Jen",
      "Salvador, Jordi",
      "Lazebnik, Svetlana",
      "Kembhavi, Aniruddha",
      "Schwing, Alex"
    ]
  },
  {
    "id": "9fd98f856d3ca2086168f264a117ed7c",
    "title": "Adversarial Robustness with Non-uniform Perturbations",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9fd98f856d3ca2086168f264a117ed7c-Paper.pdf",
    "abstract": "Robustness of machine learning models is critical for security related applications, where real-world adversaries are uniquely focused on evading neural network based detectors. Prior work mainly focus on crafting adversarial examples (AEs) with small uniform norm-bounded perturbations across features to maintain the requirement of imperceptibility. However, uniform perturbations do not result in realistic AEs in domains such as malware, finance, and social networks. For these types of applications, features typically have some semantically meaningful dependencies. The key idea of our proposed approach is to enable non-uniform perturbations that can adequately represent these feature dependencies during adversarial training. We propose using characteristics of the empirical data distribution, both on correlations between the features and the importance of the features themselves. Using experimental datasets for malware classification, credit risk prediction, and spam detection, we show that our approach is more robust to real-world attacks. Finally, we present robustness certification utilizing non-uniform perturbation bounds, and show that non-uniform bounds achieve better certification.",
    "authors": [
      "Erdemir, Ecenaz",
      "Bickford, Jeffrey",
      "Melis, Luca",
      "Aydore, Sergul"
    ]
  },
  {
    "id": "9fe77ac7060e716f2d42631d156825c0",
    "title": "Container: Context Aggregation Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/9fe77ac7060e716f2d42631d156825c0-Paper.pdf",
    "abstract": "Convolutional neural networks (CNNs) are ubiquitous in computer vision, with a myriad of effective and efficient variations. Recently, Transformers -- originally introduced in natural language processing -- have been increasingly adopted in computer vision. While early adopters continued to employ CNN backbones, the latest networks are end-to-end CNN-free Transformer solutions. A recent surprising finding now shows that a simple MLP based solution without any traditional convolutional or Transformer components can produce effective visual representations. While CNNs, Transformers and MLP-Mixers may be considered as completely disparate architectures, we provide a unified view showing that they are in fact special cases of a more general method to aggregate spatial context in a neural network stack. We present the \\model (CONText AggregatIon NEtwoRk), a general-purpose building block for multi-head context aggregation that can exploit long-range interactions \\emph{a la} Transformers while still exploiting the inductive bias of the local convolution operation leading to faster convergence speeds, often seen in CNNs. Our \\model architecture achieves 82.7 \\% Top-1 accuracy on ImageNet using 22M parameters, +2.8 improvement compared with DeiT-Small, and can converge to 79.9 \\% Top-1 accuracy in just 200 epochs. In contrast to Transformer-based methods that do not scale well to downstream tasks that rely on larger input image resolutions, our efficient network, named \\modellight, can be employed in object detection and instance segmentation networks such as DETR, RetinaNet and Mask-RCNN to obtain an impressive detection mAP of 38.9, 43.8, 45.1 and mask mAP of 41.3, providing large improvements of 6.6, 7.3, 6.9 and 6.6 pts respectively, compared to a ResNet-50 backbone with a comparable compute and parameter size. Our method also achieves promising results on self-supervised learning compared to DeiT on the DINO framework. Code is released at https://github.com/allenai/container. ",
    "authors": [
      "gao, peng",
      "Lu, Jiasen",
      "Li, hongsheng",
      "Mottaghi, Roozbeh",
      "Kembhavi, Aniruddha"
    ]
  },
  {
    "id": "a0160709701140704575d499c997b6ca",
    "title": "ConE: Cone Embeddings for Multi-Hop Reasoning over Knowledge Graphs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a0160709701140704575d499c997b6ca-Paper.pdf",
    "abstract": "Query embedding (QE)---which aims to embed entities and first-order logical (FOL) queries in low-dimensional spaces---has shown great power in multi-hop reasoning over knowledge graphs. Recently, embedding entities and queries with geometric shapes becomes a promising direction, as geometric shapes can naturally represent answer sets of queries and logical relationships among them. However, existing geometry-based models have difficulty in modeling queries with negation, which significantly limits their applicability. To address this challenge, we propose a novel query embedding model, namely \\textbf{Con}e \\textbf{E}mbeddings (ConE), which is the first geometry-based QE model that can handle all the FOL operations, including conjunction, disjunction, and negation. Specifically, ConE represents entities and queries as Cartesian products of two-dimensional cones, where the intersection and union of cones naturally model the conjunction and disjunction operations. By further noticing that the closure of complement of cones remains cones, we design geometric complement operators in the embedding space for the negation operations. Experiments demonstrate that ConE significantly outperforms existing state-of-the-art methods on benchmark datasets.",
    "authors": [
      "Zhang, Zhanqiu",
      "Wang, Jie",
      "Chen, Jiajun",
      "Ji, Shuiwang",
      "Wu, Feng"
    ]
  },
  {
    "id": "a0205b87490c847182672e8d371e9948",
    "title": "Federated Hyperparameter Tuning: Challenges, Baselines, and Connections to Weight-Sharing",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a0205b87490c847182672e8d371e9948-Paper.pdf",
    "abstract": "Tuning hyperparameters is a crucial but arduous part of the machine learning pipeline. Hyperparameter optimization is even more challenging in federated learning, where models are learned over a distributed network of heterogeneous devices; here, the need to keep data on device and perform local training makes it difficult to efficiently train and evaluate configurations. In this work, we investigate the problem of federated hyperparameter tuning. We first identify key challenges and show how standard approaches may be adapted to form baselines for the federated setting. Then, by making a novel connection to the neural architecture search technique of weight-sharing, we introduce a new method, FedEx, to accelerate federated hyperparameter tuning that is applicable to widely-used federated optimization methods such as FedAvg and recent variants. Theoretically, we show that a FedEx variant correctly tunes the on-device learning rate in the setting of online convex optimization across devices. Empirically, we show that FedEx can outperform natural baselines for federated hyperparameter tuning by several percentage points on the Shakespeare, FEMNIST, and CIFAR-10 benchmarks\u2014obtaining higher accuracy using the same training budget.",
    "authors": [
      "Khodak, Mikhail",
      "Tu, Renbo",
      "Li, Tian",
      "Li, Liam",
      "Balcan, Maria-Florina F.",
      "Smith, Virginia",
      "Talwalkar, Ameet"
    ]
  },
  {
    "id": "a02ef8389f6d40f84b50504613117f88",
    "title": "Training for the Future: A Simple Gradient Interpolation Loss to Generalize Along Time",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a02ef8389f6d40f84b50504613117f88-Paper.pdf",
    "abstract": "In several real world applications, machine learning models are deployed to make predictions on data whose distribution changes gradually along time, leading to a drift between the train and test distributions. Such models are often re-trained on new data periodically, and they hence need to generalize to data not too far into the future. In this context, there is much prior work on enhancing temporal generalization, e.g. continuous transportation of past data, kernel smoothed time-sensitive parameters and more recently, adversarial learning of time-invariant features. However, these methods share several limitations, e.g, poor scalability, training instability, and dependence on unlabeled data from the future. Responding to the above limitations, we propose a simple method that starts with a model with time-sensitive parameters but regularizes its temporal complexity using a Gradient Interpolation  (GI) loss. GI allows the decision boundary to change along time and can still prevent overfitting to the limited training time snapshots  by allowing task-specific control over changes along time. We compare our method to existing baselines on multiple real-world datasets, which show that GI outperforms more complicated generative and adversarial approaches on the one hand, and simpler gradient regularization methods on the other.",
    "authors": [
      "Nasery, Anshul",
      "Thakur, Soumyadeep",
      "Piratla, Vihari",
      "De, Abir",
      "Sarawagi, Sunita"
    ]
  },
  {
    "id": "a03caec56cd82478bf197475b48c05f9",
    "title": "Agent Modelling under Partial Observability for Deep Reinforcement Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a03caec56cd82478bf197475b48c05f9-Paper.pdf",
    "abstract": "Modelling the behaviours of other agents is essential for understanding how agents interact and making effective decisions. Existing methods for agent modelling commonly assume knowledge of the local observations and chosen actions of the modelled agents during execution. To eliminate this assumption, we extract representations from the local information of the controlled agent using encoder-decoder architectures. Using the observations and actions of the modelled agents during training, our models learn to extract representations about the modelled agents conditioned only on the local observations of the controlled agent. The representations are used to augment the controlled agent's decision policy which is trained via deep reinforcement learning; thus, during execution, the policy does not require access to other agents' information. We provide a comprehensive evaluation and ablations studies in cooperative, competitive and mixed multi-agent environments, showing that our method achieves significantly higher returns than baseline methods which do not use the learned representations.",
    "authors": [
      "Papoudakis, Georgios",
      "Christianos, Filippos",
      "Albrecht, Stefano"
    ]
  },
  {
    "id": "a0443c8c8c3372d662e9173c18faaa2c",
    "title": "Leveraging Distribution Alignment via Stein Path for Cross-Domain Cold-Start Recommendation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a0443c8c8c3372d662e9173c18faaa2c-Paper.pdf",
    "abstract": "Cross-Domain Recommendation (CDR) has been popularly studied to utilize different domain knowledge to solve the cold-start problem in recommender systems. In this paper, we focus on the Cross-Domain Cold-Start Recommendation (CDCSR) problem. That is, how to leverage the information from a source domain, where items are 'warm', to improve the recommendation performance of a target domain, where items are 'cold'. Unfortunately, previous approaches on cold-start and CDR cannot reduce the latent embedding discrepancy across domains efficiently and lead to model degradation. To address this issue, we propose DisAlign, a cross-domain recommendation framework for the CDCSR problem, which utilizes both rating and auxiliary representations from the source domain to improve the recommendation performance of the target domain. Specifically, we first propose Stein path alignment for aligning the latent embedding distributions across domains, and then further propose its improved version, i.e., proxy Stein path, which can reduce the operation consumption and improve efficiency. Our empirical study on Douban and Amazon datasets demonstrate that DisAlign significantly outperforms the state-of-the-art models under the CDCSR setting.",
    "authors": [
      "Liu, Weiming",
      "Su, Jiajie",
      "Chen, Chaochao",
      "Zheng, Xiaolin"
    ]
  },
  {
    "id": "a05d886123a54de3ca4b0985b718fb9b",
    "title": "Conservative Offline Distributional Reinforcement Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a05d886123a54de3ca4b0985b718fb9b-Paper.pdf",
    "abstract": "Many reinforcement learning (RL) problems in practice are offline, learning purely from observational data. A key challenge is how to ensure the learned policy is safe, which requires quantifying the risk associated with different actions. In the online setting, distributional RL algorithms do so by learning the distribution over returns (i.e., cumulative rewards) instead of the expected return; beyond quantifying risk, they have also been shown to learn better representations for planning. We proposeConservative Offline Distributional Actor Critic (CODAC), an offline RL algorithm suitable for both risk-neutral and risk-averse domains. CODAC adapts distributional RL to the offline setting by penalizing the predicted quantiles of the return for out-of-distribution actions. We prove that CODAC learns a conservative return distribution---in particular, for finite MDPs, CODAC converges to an uniform lower bound on the quantiles of the return distribution; our proof relies on a novel analysis of the distributional Bellman operator. In our experiments, on two challenging robot navigation tasks, CODAC successfully learns risk-averse policies using offline data collected purely from risk-neutral agents. Furthermore, CODAC is state-of-the-art on the D4RL MuJoCo benchmark in terms of both expected and risk-sensitive performance. ",
    "authors": [
      "Ma, Yecheng",
      "Jayaraman, Dinesh",
      "Bastani, Osbert"
    ]
  },
  {
    "id": "a081c174f5913958ba8c6443bacffcb9",
    "title": "Separation Results between Fixed-Kernel and Feature-Learning Probability Metrics",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a081c174f5913958ba8c6443bacffcb9-Paper.pdf",
    "abstract": "Several works in implicit and explicit generative modeling empirically observed that feature-learning discriminators  outperform  fixed-kernel discriminators in terms of the sample quality of the models. We provide separation results between probability metrics with fixed-kernel and feature-learning discriminators using the function classes $\\mathcal{F}_2$  and $\\mathcal{F}_1$ respectively, which were developed to study overparametrized two-layer neural networks. In particular, we construct pairs of distributions over hyper-spheres that can not be discriminated by  fixed kernel $(\\mathcal{F}_2)$ integral probability metric (IPM) and Stein discrepancy (SD) in high dimensions, but that can be discriminated by their feature learning ($\\mathcal{F}_1$) counterparts. To further study the separation we provide links between the $\\mathcal{F}_1$ and $\\mathcal{F}_2$ IPMs with sliced Wasserstein distances. Our work suggests that fixed-kernel discriminators perform worse than their feature learning counterparts because their corresponding metrics are weaker.",
    "authors": [
      "Domingo i Enrich, Carles",
      "Mroueh, Youssef"
    ]
  },
  {
    "id": "a0ae15571eb4a97ac1c34a114f1bb179",
    "title": "Risk Minimization from Adaptively Collected Data: Guarantees for Supervised and Policy Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a0ae15571eb4a97ac1c34a114f1bb179-Paper.pdf",
    "abstract": "Empirical risk minimization (ERM) is the workhorse of machine learning, whether for classification and regression or for off-policy policy learning, but its model-agnostic guarantees can fail when we use adaptively collected data, such as the result of running a contextual bandit algorithm. We study a generic importance sampling weighted ERM algorithm for using adaptively collected data to minimize the average of a loss function over a hypothesis class and provide first-of-their-kind generalization guarantees and fast convergence rates. Our results are based on a new maximal inequality that carefully leverages the importance sampling structure to obtain rates with the good dependence on the exploration rate in the data. For regression, we provide fast rates that leverage the strong convexity of squared-error loss. For policy learning, we provide regret guarantees that close an open gap in the existing literature whenever exploration decays to zero, as is the case for bandit-collected data. An empirical investigation validates our theory.",
    "authors": [
      "Bibaut, Aurelien",
      "Kallus, Nathan",
      "Dimakopoulou, Maria",
      "Chambaz, Antoine",
      "van der Laan, Mark"
    ]
  },
  {
    "id": "a0d3973ad100ad83a64c304bb58677dd",
    "title": "Bayesian Optimization with High-Dimensional Outputs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a0d3973ad100ad83a64c304bb58677dd-Paper.pdf",
    "abstract": "Bayesian optimization is a sample-efficient black-box optimization procedure that is typically applied to a small number of independent objectives. However, in practice we often wish to optimize objectives defined over many correlated outcomes (or \u201ctasks\u201d). For example, scientists may want to optimize the coverage of a cell tower network across a dense grid of locations. Similarly, engineers may seek to balance the performance of a robot across dozens of different environments via constrained or robust optimization. However, the Gaussian Process (GP) models typically used as probabilistic surrogates for multi-task Bayesian optimization scale poorly with the number of outcomes, greatly limiting applicability. We devise an efficient technique for exact multi-task GP sampling that combines exploiting Kronecker structure in the covariance matrices with Matheron\u2019s identity, allowing us to perform Bayesian optimization using exact multi-task GP models with tens of thousands of correlated outputs. In doing so, we achieve substantial improvements in sample efficiency compared to existing approaches that model solely the outcome metrics. We demonstrate how this unlocks a new class of applications for Bayesian optimization across a range of tasks in science and engineering, including optimizing interference patterns of an optical interferometer with 65,000 outputs. ",
    "authors": [
      "Maddox, Wesley J.",
      "Balandat, Maximilian",
      "Wilson, Andrew G.",
      "Bakshy, Eytan"
    ]
  },
  {
    "id": "a113c1ecd3cace2237256f4c712f61b5",
    "title": "Finding Optimal Tangent Points for Reducing Distortions of Hard-label Attacks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a113c1ecd3cace2237256f4c712f61b5-Paper.pdf",
    "abstract": "One major problem in black-box adversarial attacks is the high query complexity in the hard-label attack setting, where only the top-1 predicted label is available. In this paper, we propose a novel geometric-based approach called Tangent Attack (TA), which identifies an optimal tangent point of a virtual hemisphere located on the decision boundary to reduce the distortion of the attack. Assuming the decision boundary is locally flat, we theoretically prove that the minimum $\\ell_2$ distortion can be obtained by reaching the decision boundary along the tangent line passing through such tangent point in each iteration. To improve the robustness of our method, we further propose a generalized method which replaces the hemisphere with a semi-ellipsoid to adapt to curved decision boundaries. Our approach is free of pre-training. Extensive experiments conducted on the ImageNet and CIFAR-10 datasets demonstrate that our approach can consume only a small number of queries to achieve the low-magnitude distortion. The implementation source code is released online.",
    "authors": [
      "Ma, Chen",
      "Guo, Xiangyu",
      "Chen, Li",
      "Yong, Jun-Hai",
      "Wang, Yisen"
    ]
  },
  {
    "id": "a1140a3d0df1c81e24ae954d935e8926",
    "title": "Scalable Diverse Model Selection for Accessible Transfer Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a1140a3d0df1c81e24ae954d935e8926-Paper.pdf",
    "abstract": "With the preponderance of pretrained deep learning models available off-the-shelf from model banks today, finding the best weights to fine-tune to your use-case can be a daunting task. Several methods have recently been proposed to find good models for transfer learning, but they either don't scale well to large model banks or don't perform well on the diversity of off-the-shelf models. Ideally the question we want to answer is, \"given some data and a source model, can you quickly predict the model's accuracy after fine-tuning?\" In this paper, we formalize this setting as \"Scalable Diverse Model Selection\" and propose several benchmarks for evaluating on this task. We find that existing model selection and transferability estimation methods perform poorly here and analyze why this is the case. We then introduce simple techniques to improve the performance and speed of these algorithms. Finally, we iterate on existing methods to create PARC, which outperforms all other methods on diverse model selection. We have released the benchmarks and method code in hope to inspire future work in model selection for accessible transfer learning.",
    "authors": [
      "Bolya, Daniel",
      "Mittapalli, Rohit",
      "Hoffman, Judy"
    ]
  },
  {
    "id": "a11ce019e96a4c60832eadd755a17a58",
    "title": "Light Field Networks: Neural Scene Representations with Single-Evaluation Rendering",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a11ce019e96a4c60832eadd755a17a58-Paper.pdf",
    "abstract": "Inferring representations of 3D scenes from 2D observations is a fundamental problem of computer graphics, computer vision, and artificial intelligence. Emerging 3D-structured neural scene representations are a promising approach to 3D scene understanding. In this work, we propose a novel neural scene representation, Light Field Networks or LFNs, which represent both geometry and appearance of the underlying 3D scene in a 360-degree, four-dimensional light field parameterized via a neural implicit representation.  Rendering a ray from an LFN requires only a single network evaluation, as opposed to hundreds of evaluations per ray for ray-marching or volumetric based renderers in 3D-structured neural scene representations.  In the setting of simple scenes, we leverage meta-learning to learn a prior over LFNs that enables multi-view consistent light field reconstruction from as little as a single image observation. This results in dramatic reductions in time and memory complexity, and enables real-time rendering. The cost of storing a 360-degree light field via an LFN is two orders of magnitude lower than conventional methods such as the Lumigraph.  Utilizing the analytical differentiability of neural implicit representations and a novel parameterization of light space, we further demonstrate the extraction of sparse depth maps from LFNs. ",
    "authors": [
      "Sitzmann, Vincent",
      "Rezchikov, Semon",
      "Freeman, Bill",
      "Tenenbaum, Josh",
      "Durand, Fredo"
    ]
  },
  {
    "id": "a11f9e533f28593768ebf87075ab34f2",
    "title": "ViSER: Video-Specific Surface Embeddings for Articulated 3D Shape Reconstruction",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a11f9e533f28593768ebf87075ab34f2-Paper.pdf",
    "abstract": "We introduce ViSER, a method for recovering articulated 3D shapes and dense3D trajectories from monocular videos.  Previous work on high-quality reconstruction of dynamic 3D shapes typically relies on multiple camera views, strong category-specific priors, or 2D keypoint supervision. We show that none of these are required if one can reliably estimate long-range correspondences in a video, making use of only 2D object masks and two-frame optical flow as inputs. ViSER infers correspondences by matching 2D pixels to a canonical,  deformable 3D mesh via video-specific surface embeddings that capture the pixel appearance of each surface point.  These embeddings behave as a continuous set of keypoint descriptors defined over the mesh surface, which can be used to establish dense long-range correspondences across pixels.  The surface embeddings are implemented as coordinate-based MLPs that are fit to each video via self-supervised losses.Experimental results show that ViSER compares favorably against prior work on challenging videos of humans with loose clothing and unusual poses as well as animals videos from DAVIS and YTVOS. Project page: viser-shape.github.io.",
    "authors": [
      "Yang, Gengshan",
      "Sun, Deqing",
      "Jampani, Varun",
      "Vlasic, Daniel",
      "Cole, Forrester",
      "Liu, Ce",
      "Ramanan, Deva"
    ]
  },
  {
    "id": "a12f69495f41bb3b637ba1b6238884d6",
    "title": "Understanding the Effect of Stochasticity in Policy Optimization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a12f69495f41bb3b637ba1b6238884d6-Paper.pdf",
    "abstract": "We study the effect of stochasticity in on-policy policy optimization, and make the following four contributions. \\emph{First}, we show that the preferability of optimization methods depends critically on whether stochastic versus exact gradients are used. In particular, unlike the true gradient setting, geometric information cannot be easily exploited in the stochastic case for accelerating policy optimization without detrimental consequences or impractical assumptions. \\emph{Second}, to explain these findings we introduce the concept of committal rate for stochastic policy optimization, and show that this can serve as a criterion for determining almost sure convergence to global optimality. \\emph{Third}, we show that in the absence of external oracle information, which allows an algorithm to determine the difference between optimal and sub-optimal actions given only on-policy samples, there is an inherent trade-off between exploiting geometry to accelerate convergence versus achieving optimality almost surely. That is, an uninformed algorithm either converges to a globally optimal policy with probability $1$ but at a rate no better than $O(1/t)$, or it achieves faster than $O(1/t)$ convergence but then must fail to converge to the globally optimal policy with some positive probability. \\emph{Finally}, we use the committal rate theory to explain why practical policy optimization methods are sensitive to random initialization, then develop an ensemble method that can be guaranteed to achieve near-optimal solutions with high probability.",
    "authors": [
      "Mei, Jincheng",
      "Dai, Bo",
      "Xiao, Chenjun",
      "Szepesvari, Csaba",
      "Schuurmans, Dale"
    ]
  },
  {
    "id": "a18630ab1c3b9f14454cf70dc7114834",
    "title": "Fine-Grained Zero-Shot Learning with DNA as Side Information",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a18630ab1c3b9f14454cf70dc7114834-Paper.pdf",
    "abstract": "Fine-grained zero-shot learning task requires some form of side-information to transfer discriminative information from seen to unseen classes. As manually annotated visual attributes are extremely costly and often impractical to obtain for a large number of classes, in this study we use DNA as a side information for the first time for fine-grained zero-shot classification of species. Mitochondrial DNA plays an important role as a genetic marker in evolutionary biology and has been used to achieve near perfect accuracy in species classification of living organisms. We implement a simple hierarchical Bayesian model that uses DNA information to establish the hierarchy in the image space and employs local priors to define surrogate classes for unseen ones. On the benchmark CUB dataset we show that DNA can be equally promising, yet in general a more accessible alternative than word vectors as a side information. This is especially important as obtaining robust word representations for fine-grained species names is not a practicable goal when information about these species in free-form text is limited. On a newly compiled fine-grained insect dataset that uses DNA information from over a thousand species we show that the Bayesian approach outperforms state-of-the-art by a wide margin. ",
    "authors": [
      "Badirli, Sarkhan",
      "Akata, Zeynep",
      "Mohler, George",
      "Picard, Christine",
      "Dundar, Mehmet M"
    ]
  },
  {
    "id": "a18aa23ee676d7f5ffb34cf16df3e08c",
    "title": "Optimal Underdamped Langevin MCMC Method",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a18aa23ee676d7f5ffb34cf16df3e08c-Paper.pdf",
    "abstract": "In the paper, we study the underdamped Langevin diffusion (ULD) with strongly-convex potential consisting of finite summation of $N$ smooth components, and propose an efficient discretization method, which requires $O(N+d^\\frac{1}{3}N^\\frac{2}{3}/\\varepsilon^\\frac{2}{3})$ gradient evaluations to achieve $\\varepsilon$-error (in $\\sqrt{\\mathbb{E}{\\lVert{\\cdot}\\rVert_2^2}}$ distance) for approximating $d$-dimensional ULD. Moreover, we prove a lower bound of gradient complexity as $\\Omega(N+d^\\frac{1}{3}N^\\frac{2}{3}/\\varepsilon^\\frac{2}{3})$, which indicates that our method is optimal in dependence of $N$, $\\varepsilon$, and $d$. In particular, we apply our method to sample the strongly-log-concave distribution and obtain gradient complexity better than all existing gradient based sampling algorithms. Experimental results on both synthetic and real-world data show that our new method consistently outperforms the existing ULD approaches.",
    "authors": [
      "Hu, Zhengmian",
      "Huang, Feihu",
      "Huang, Heng"
    ]
  },
  {
    "id": "a19744e268754fb0148b017647355b7b",
    "title": "Scheduling jobs with stochastic holding costs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a19744e268754fb0148b017647355b7b-Paper.pdf",
    "abstract": "This paper proposes a learning and scheduling algorithm to minimize the expected cumulative holding cost incurred by jobs, where statistical parameters defining their individual holding costs are unknown a priori. In each time slot, the server can process a job while receiving the realized random holding costs of the jobs remaining in the system. Our algorithm is a learning-based variant of the $c\\mu$ rule for scheduling: it starts with a preemption period of fixed length which serves as a learning phase, and after accumulating enough data about individual jobs, it switches to nonpreemptive scheduling mode. The algorithm is designed to handle instances with large or small gaps in jobs' parameters and achieves near-optimal performance guarantees. The performance of our algorithm is captured by its regret, where the benchmark is the minimum possible cost attained when the statistical parameters of jobs are fully known.  We prove upper bounds on the regret of our algorithm, and we derive a regret lower bound that is almost matching the proposed upper bounds. Our numerical results demonstrate the effectiveness of our algorithm and show that our theoretical regret analysis is nearly tight.",
    "authors": [
      "Lee, Dabeen",
      "Vojnovic, Milan"
    ]
  },
  {
    "id": "a1a2c3fed88e9b3ba5bc3625c074a04e",
    "title": "REMIPS: Physically Consistent 3D Reconstruction of Multiple Interacting People under Weak Supervision",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a1a2c3fed88e9b3ba5bc3625c074a04e-Paper.pdf",
    "abstract": "The three-dimensional reconstruction of multiple interacting humans given a monocular image is crucial for the general task of scene understanding, as capturing the subtleties of interaction is often the very reason for taking a picture. Current 3D human reconstruction methods either treat each person independently, ignoring most of the context, or reconstruct people jointly, but cannot recover interactions correctly when people are in close proximity. In this work, we introduce \\textbf{REMIPS}, a model for 3D \\underline{Re}construction of \\underline{M}ultiple \\underline{I}nteracting \\underline{P}eople under Weak \\underline{S}upervision. \\textbf{REMIPS} can reconstruct a variable number of people directly from monocular images. At the core of our methodology stands a novel transformer network that combines unordered person tokens (one for each detected human) with positional-encoded tokens from image features patches. We introduce a novel unified model for self- and interpenetration-collisions based on a mesh approximation computed by applying decimation operators. We rely on self-supervised losses for flexibility and generalisation in-the-wild and incorporate self-contact and interaction-contact losses directly into the learning process. With \\textbf{REMIPS}, we report state-of-the-art quantitative results on common benchmarks even in cases where no 3D supervision is used. Additionally, qualitative visual results show that our reconstructions are plausible in terms of pose and shape and coherent for challenging images, collected in-the-wild, where people are often interacting.",
    "authors": [
      "Fieraru, Mihai",
      "Zanfir, Mihai",
      "Szente, Teodor",
      "Bazavan, Eduard",
      "Olaru, Vlad",
      "Sminchisescu, Cristian"
    ]
  },
  {
    "id": "a1a609f1ac109d0be28d8ae112db1bbb",
    "title": "Differentiable Annealed Importance Sampling and the Perils of Gradient Noise",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a1a609f1ac109d0be28d8ae112db1bbb-Paper.pdf",
    "abstract": "Annealed importance sampling (AIS) and related algorithms are highly effective tools for marginal likelihood estimation, but are not fully differentiable due to the use of Metropolis-Hastings correction steps. Differentiability is a desirable property as it would admit the possibility of optimizing marginal likelihood as an objective using gradient-based methods. To this end, we propose Differentiable AIS (DAIS), a variant of AIS which ensures differentiability by abandoning the Metropolis-Hastings corrections. As a further advantage, DAIS allows for mini-batch gradients. We provide a detailed convergence analysis for Bayesian linear regression which goes beyond previous analyses by explicitly accounting for the sampler not having reached equilibrium. Using this analysis, we prove that DAIS is consistent in the full-batch setting and provide a sublinear convergence rate. Furthermore, motivated by the problem of learning from large-scale datasets, we study a stochastic variant of DAIS that uses mini-batch gradients. Surprisingly, stochastic DAIS can be arbitrarily bad due to a fundamental incompatibility between the goals of last-iterate convergence to the posterior and elimination of the accumulated stochastic error. This is in stark contrast with other settings such as gradient-based optimization and Langevin dynamics, where the effect of gradient noise can be washed out by taking smaller steps. This indicates that annealing-based marginal likelihood estimation with stochastic gradients may require new ideas.",
    "authors": [
      "Zhang, Guodong",
      "Hsu, Kyle",
      "Li, Jianing",
      "Finn, Chelsea",
      "Grosse, Roger B."
    ]
  },
  {
    "id": "a1b63b36ba67b15d2f47da55cdb8018d",
    "title": "PSD Representations for Effective Probability Models",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a1b63b36ba67b15d2f47da55cdb8018d-Paper.pdf",
    "abstract": "Finding a good way to model probability densities is key to probabilistic inference. An ideal model should be able to concisely approximate any probability while being also compatible with two main operations: multiplications of two models (product rule) and marginalization with respect to a subset of the random variables (sum rule). In this work, we show that a recently proposed class of positive semi-definite (PSD) models for non-negative functions is particularly suited to this end. In particular, we characterize both approximation and generalization capabilities of PSD models, showing that they enjoy strong theoretical guarantees. Moreover, we show that we can perform efficiently both sum and product rule in closed form via matrix operations, enjoying the same versatility of mixture models. Our results open the way to applications of PSD models to density estimation, decision theory, and inference.",
    "authors": [
      "Rudi, Alessandro",
      "Ciliberto, Carlo"
    ]
  },
  {
    "id": "a1c3ae6c49a89d92aef2d423dadb477f",
    "title": "Exploiting a Zoo of Checkpoints for Unseen Tasks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a1c3ae6c49a89d92aef2d423dadb477f-Paper.pdf",
    "abstract": "There are so many models in the literature that it is difficult for practitioners to decide which combinations are likely to be effective for a new task. This paper attempts to address this question by capturing relationships among checkpoints published on the web. We model the space of tasks as a Gaussian process. The covariance can be estimated from checkpoints and unlabeled probing data. With the Gaussian process, we can identify representative checkpoints by a maximum mutual information criterion. This objective is submodular. A greedy method identifies representatives that are likely to \"cover'' the task space. These representatives generalize to new tasks with superior performance. Empirical evidence is provided for applications from both computational linguistics as well as computer vision.",
    "authors": [
      "Huang, Jiaji",
      "Qiu, Qiang",
      "Church, Kenneth"
    ]
  },
  {
    "id": "a1c5aff9679455a233086e26b72b9a06",
    "title": "Towards Open-World Feature Extrapolation: An Inductive Graph Learning Approach",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a1c5aff9679455a233086e26b72b9a06-Paper.pdf",
    "abstract": "We target open-world feature extrapolation problem where the feature space of input data goes through expansion and a model trained on partially observed features needs to handle new features in test data without further retraining. The problem is of much significance for dealing with features incrementally collected from different fields. To this end, we propose a new learning paradigm with graph representation and learning. Our framework contains two modules: 1) a backbone network (e.g., feedforward neural nets) as a lower model takes features as input and outputs predicted labels; 2) a graph neural network as an upper model learns to extrapolate embeddings for new features via message passing over a feature-data graph built from observed data. Based on our framework, we design two training strategies, a self-supervised approach and an inductive learning approach, to endow the model with extrapolation ability and alleviate feature-level over-fitting. We also provide theoretical analysis on the generalization error on test data with new features, which dissects the impact of training features and algorithms on generalization performance. Our experiments over several classification datasets and large-scale advertisement click prediction datasets demonstrate that our model can produce effective embeddings for unseen features and significantly outperforms baseline methods that adopt KNN and local aggregation.",
    "authors": [
      "Wu, Qitian",
      "Yang, Chenxiao",
      "Yan, Junchi"
    ]
  },
  {
    "id": "a2137a2ae8e39b5002a3f8909ecb88fe",
    "title": "Adversarial Teacher-Student Representation Learning for Domain Generalization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a2137a2ae8e39b5002a3f8909ecb88fe-Paper.pdf",
    "abstract": "Domain generalization (DG) aims to transfer the learning task from a single or multiple source domains to unseen target domains. To extract and leverage the information which exhibits sufficient generalization ability, we propose a simple yet effective approach of Adversarial Teacher-Student Representation Learning, with the goal of deriving the domain generalizable representations via generating and exploring out-of-source data distributions. Our proposed framework advances Teacher-Student learning in an adversarial learning manner, which alternates between knowledge-distillation based representation learning and novel-domain data augmentation. The former progressively updates the teacher network for deriving domain-generalizable representations, while the latter synthesizes data out-of-source yet plausible distributions. Extensive image classification experiments on benchmark datasets in multiple and single source DG settings confirm that, our model exhibits sufficient generalization ability and performs favorably against state-of-the-art DG methods.",
    "authors": [
      "Yang, Fu-En",
      "Cheng, Yuan-Chia",
      "Shiau, Zu-Yun",
      "Wang, Yu-Chiang Frank"
    ]
  },
  {
    "id": "a22c0238589078fb10b606ab62015744",
    "title": "Stochastic bandits with groups of similar arms.",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a22c0238589078fb10b606ab62015744-Paper.pdf",
    "abstract": "We consider a variant of the stochastic multi-armed bandit problem where arms are known to be organized into different groups having the same mean. The groups are unknown but a lower bound $q$ on their size is known. This situation typically appears when each arm can be described with a list of categorical attributes, and the (unknown) mean reward function only depends on a subset of them, the others being redundant. In this case, $q$ is linked naturally to the number of attributes considered redundant, and the number of categories of each attribute. For this structured problem of practical relevance, we first derive the asymptotic regret lower bound and corresponding constrained optimization problem. They reveal  the achievable regret can be substantially reduced when compared to the unstructured setup, possibly by a factor $q$. However, solving exactly the exact constrained optimization problem involves a combinatorial problem. We introduce a lower-bound inspired strategy involving a computationally efficient relaxation that is based on a sorting mechanism. We further prove it achieves a lower bound close to the optimal one up to a controlled factor, and achieves an asymptotic regret $q$ times smaller than the unstructured one. We believe this shows it is a valuable strategy for the practitioner. Last, we illustrate the performance of the considered strategy on numerical experiments involving a large number of arms.",
    "authors": [
      "Pesquerel, Fabien",
      "SABER, Hassan",
      "Maillard, Odalric-Ambrym"
    ]
  },
  {
    "id": "a2557a7b2e94197ff767970b67041697",
    "title": "Tracking Without Re-recognition in Humans and Machines",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a2557a7b2e94197ff767970b67041697-Paper.pdf",
    "abstract": "Imagine trying to track one particular fruitfly in a swarm of hundreds. Higher biological visual systems have evolved to track moving objects by relying on both their appearance and their motion trajectories. We investigate if state-of-the-art spatiotemporal deep neural networks are capable of the same. For this, we introduce PathTracker, a synthetic visual challenge that asks human observers and machines to track a target object in the midst of identical-looking \"distractor\" objects. While humans effortlessly learn PathTracker and generalize to systematic variations in task design, deep networks struggle. To address this limitation, we identify and model circuit mechanisms in biological brains that are implicated in tracking objects based on motion cues. When instantiated as a recurrent network, our circuit model learns to solve PathTracker with a robust visual strategy that rivals human performance and explains a significant proportion of their decision-making on the challenge. We also show that the success of this circuit model extends to object tracking in natural videos. Adding it to a transformer-based architecture for object tracking builds tolerance to visual nuisances that affect object appearance, establishing the new state of the art on the large-scale TrackingNet challenge. Our work highlights the importance of understanding human vision to improve computer vision.",
    "authors": [
      "Linsley, Drew",
      "Malik, Girik",
      "Kim, Junkyung",
      "Govindarajan, Lakshmi Narasimhan",
      "Mingolla, Ennio",
      "Serre, Thomas"
    ]
  },
  {
    "id": "a267f936e54d7c10a2bb70dbe6ad7a89",
    "title": "Rethinking conditional GAN training: An approach using geometrically structured latent manifolds",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a267f936e54d7c10a2bb70dbe6ad7a89-Paper.pdf",
    "abstract": "Conditional GANs (cGAN), in their rudimentary form, suffer from critical drawbacks such as the lack of diversity in generated outputs and distortion between the latent and output manifolds.  Although efforts have been made to improve results, they can suffer from unpleasant side-effects such as the topology mismatch between latent and output spaces. In contrast, we tackle this problem from a geometrical perspective and propose a novel training mechanism that increases both the diversity and the visual quality of a vanilla cGAN, by systematically encouraging a bi-lipschitz mapping between the latent and the output manifolds. We validate the efficacy of our solution on a baseline cGAN (i.e., Pix2Pix) which lacks diversity, and show that by only modifying its training mechanism (i.e., with our proposed Pix2Pix-Geo), one can achieve more diverse and realistic outputs on a broad set of image-to-image translation tasks.",
    "authors": [
      "Ramasinghe, Sameera",
      "Farazi, Moshiur",
      "Khan, Salman H",
      "Barnes, Nick",
      "Gould, Stephen"
    ]
  },
  {
    "id": "a2802cade04644083dcde1c8c483ed9a",
    "title": "How to transfer algorithmic reasoning knowledge to learn new algorithms?",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a2802cade04644083dcde1c8c483ed9a-Paper.pdf",
    "abstract": "Learning to execute algorithms is a fundamental problem that has been widely studied. Prior work (Veli\u010dkovi\u0107 et al., 2019) has shown that to enable systematic generalisation on graph algorithms it is critical to have access to the intermediate steps of the program/algorithm. In many reasoning tasks, where algorithmic-style reasoning is important, we only have access to the input and output examples. Thus, inspired by the success of pre-training on similar tasks or data in Natural Language Processing (NLP) and Computer vision, we set out to study how we can transfer algorithmic reasoning knowledge. Specifically, we investigate how we can use algorithms for which we have access to the execution trace to learn to solve similar tasks for which we do not. We investigate two major classes of graph algorithms, parallel algorithms such as breadth-first search and Bellman-Ford and sequential greedy algorithms such as Prims and Dijkstra. Due to the fundamental differences between algorithmic reasoning knowledge and feature extractors such as used in Computer vision or NLP, we hypothesis that standard transfer techniques will not be sufficient to achieve systematic generalisation. To investigate this empirically we create a dataset including 9 algorithms and 3 different graph types. We validate this empirically and show how instead multi-task learning can be used to achieve the transfer of algorithmic reasoning knowledge.",
    "authors": [
      "Xhonneux, Louis-Pascal",
      "Deac, Andreea-Ioana",
      "Veli\u010dkovi\u0107, Petar",
      "Tang, Jian"
    ]
  },
  {
    "id": "a284df1155ec3e67286080500df36a9a",
    "title": "Fast Axiomatic Attribution for Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a284df1155ec3e67286080500df36a9a-Paper.pdf",
    "abstract": "Mitigating the dependence on spurious correlations present in the training dataset is a quickly emerging and important topic of deep learning. Recent approaches include priors on the feature attribution of a deep neural network (DNN) into the training process to reduce the dependence on unwanted features. However, until now one needed to trade off high-quality attributions, satisfying desirable axioms, against the time required to compute them. This in turn either led to long training times or ineffective attribution priors. In this work, we break this trade-off by considering a special class of efficiently axiomatically attributable DNNs for which an axiomatic feature attribution can be computed with only a single forward/backward pass. We formally prove that nonnegatively homogeneous DNNs, here termed $\\mathcal{X}$-DNNs, are efficiently axiomatically attributable and show that they can be effortlessly constructed from a wide range of regular DNNs by simply removing the bias term of each layer. Various experiments demonstrate the advantages of $\\mathcal{X}$-DNNs, beating state-of-the-art generic attribution methods on regular DNNs for training with attribution priors.",
    "authors": [
      "Hesse, Robin",
      "Schaub-Meyer, Simone",
      "Roth, Stefan"
    ]
  },
  {
    "id": "a2915ad0d57ca8c644f99f9c3f20a918",
    "title": "OSOA: One-Shot Online Adaptation of Deep Generative Models for Lossless Compression",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a2915ad0d57ca8c644f99f9c3f20a918-Paper.pdf",
    "abstract": "Explicit deep generative models (DGMs), e.g., VAEs and Normalizing Flows, have shown to offer an effective data modelling alternative for lossless compression. However, DGMs themselves normally require large storage space and thus contaminate the advantage brought by accurate data density estimation.To eliminate the requirement of saving separate models for different target datasets, we propose a novel setting that starts from a pretrained deep generative model and compresses the data batches while adapting the model with a dynamical system for only one epoch.We formalise this setting as that of One-Shot Online Adaptation (OSOA) of DGMs for lossless compression and propose a vanilla algorithm under this setting. Experimental results show that vanilla OSOA can save significant time versus training bespoke models and space versus using one model for all targets.With the same adaptation step number or adaptation time, it is shown vanilla OSOA can exhibit better space efficiency, e.g., $47\\%$ less space, than fine-tuning the pretrained model and saving the fine-tuned model.Moreover, we showcase the potential of OSOA and motivate more sophisticated OSOA algorithms by showing further space or time efficiency with multiple updates per batch and early stopping.",
    "authors": [
      "Zhang, Chen",
      "Zhang, Shifeng",
      "Carlucci, Fabio Maria",
      "Li, Zhenguo"
    ]
  },
  {
    "id": "a29a5ba2cb7bdeabba22de8c83321b46",
    "title": "Compressive Visual Representations",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a29a5ba2cb7bdeabba22de8c83321b46-Paper.pdf",
    "abstract": "Learning effective visual representations that generalize well without human supervision is a fundamental problem in order to apply Machine Learning to a wide variety of tasks. Recently, two families of self-supervised methods, contrastive learning and latent bootstrapping, exemplified by SimCLR and BYOL respectively, have made significant progress. In this work, we hypothesize that adding explicit information compression to these algorithms yields better and more robust representations. We verify this by developing SimCLR and BYOL formulations compatible with the Conditional Entropy Bottleneck (CEB) objective, allowing us to both measure and control the amount of compression in the learned representation, and observe their impact on downstream tasks. Furthermore, we explore the relationship between Lipschitz continuity and compression, showing a tractable lower bound on the Lipschitz constant of the encoders we learn. As Lipschitz continuity is closely related to robustness, this provides a new explanation for why compressed models are more robust. Our experiments confirm that adding compression to SimCLR and BYOL significantly improves linear evaluation accuracies and model robustness across a wide range of domain shifts. In particular, the compressed version of BYOL achieves 76.0% Top-1 linear evaluation accuracy on ImageNet with ResNet-50, and 78.8% with ResNet-50 2x.",
    "authors": [
      "Lee, Kuang-Huei",
      "Arnab, Anurag",
      "Guadarrama, Sergio",
      "Canny, John",
      "Fischer, Ian"
    ]
  },
  {
    "id": "a2f04745390fd6897d09772b2cd1f581",
    "title": "Multi-Armed Bandits with Bounded Arm-Memory: Near-Optimal Guarantees for Best-Arm Identification and Regret Minimization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a2f04745390fd6897d09772b2cd1f581-Paper.pdf",
    "abstract": "We study the Stochastic Multi-armed Bandit problem under bounded arm-memory. In this setting, the arms arrive in a stream, and the number of arms that can be stored in the memory at any time, is bounded. The decision-maker can only pull arms that are present in the memory.  We address the problem from the perspective of two standard objectives: 1) regret minimization, and 2) best-arm identification. For regret minimization, we settle an important open question by showing an almost tight guarantee. We show $\\Omega(T^{2/3})$ cumulative regret in expectation for single-pass algorithms for arm-memory size of $(n-1)$, where $n$ is the number of arms. For best-arm identification, we provide an $(\\varepsilon, \\delta)$-PAC algorithm with arm memory size of $O(\\log^*n)$ and $O(\\frac{n}{\\varepsilon^2}\\cdot \\log(\\frac{1}{\\delta}))$ optimal sample complexity. ",
    "authors": [
      "Maiti, Arnab",
      "Patil, Vishakha",
      "Khan, Arindam"
    ]
  },
  {
    "id": "a2fe8c05877ec786290dd1450c3385cd",
    "title": "Grounding inductive biases in natural images: invariance stems from variations in data",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a2fe8c05877ec786290dd1450c3385cd-Paper.pdf",
    "abstract": "To perform well on unseen and potentially out-of-distribution samples, it is desirable for machine learning models to have a predictable response with respect to transformations affecting the factors of variation of the input. Here, we study the relative importance of several types of inductive biases towards such predictable behavior: the choice of data, their augmentations, and model architectures. Invariance is commonly achieved through hand-engineered data augmentation, but do standard data augmentations address transformations that explain variations in real data? While prior work has focused on synthetic data, we attempt here to characterize the factors of variation in a real dataset, ImageNet, and study the invariance of both standard residual networks and the recently proposed vision transformer with respect to changes in these factors. We show standard augmentation relies on a precise combination of translation and scale, with translation recapturing most of the performance improvement---despite the (approximate) translation invariance built in to convolutional architectures, such as residual networks. In fact, we found that scale and translation invariance was similar across residual networks and vision transformer models despite their markedly different architectural inductive biases. We show the training data itself is the main source of invariance, and that data augmentation only further increases the learned invariances. Notably, the invariances learned during training align with the ImageNet factors of variation we found. Finally, we find that the main factors of variation in ImageNet mostly relate to appearance and are specific to each class.",
    "authors": [
      "Bouchacourt, Diane",
      "Ibrahim, Mark",
      "Morcos, Ari"
    ]
  },
  {
    "id": "a3048e47310d6efaa4b1eaf55227bc92",
    "title": "Directed Graph Contrastive Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a3048e47310d6efaa4b1eaf55227bc92-Paper.pdf",
    "abstract": "Graph Contrastive Learning (GCL) has emerged to learn generalizable representations from contrastive views. However, it is still in its infancy with two concerns: 1) changing the graph structure through data augmentation to generate contrastive views may mislead the message passing scheme, as such graph changing action deprives the intrinsic graph structural information, especially the directional structure in directed graphs; 2) since GCL usually uses predefined contrastive views with hand-picking parameters, it does not take full advantage of the contrastive information provided by data augmentation, resulting in incomplete structure information for models learning. In this paper, we design a directed graph data augmentation method called Laplacian perturbation and theoretically analyze how it provides contrastive information without changing the directed graph structure. Moreover, we present a directed graph contrastive learning framework, which dynamically learns from all possible contrastive views generated by Laplacian perturbation. Then we train it using multi-task curriculum learning to progressively learn from multiple easy-to-difficult contrastive views. We empirically show that our model can retain more structural features of directed graphs than other GCL models because of its ability to provide complete contrastive information. Experiments on various benchmarks reveal our dominance over the state-of-the-art approaches.",
    "authors": [
      "Tong, Zekun",
      "Liang, Yuxuan",
      "Ding, Henghui",
      "Dai, Yongxing",
      "Li, Xinke",
      "Wang, Changhu"
    ]
  },
  {
    "id": "a34bacf839b923770b2c360eefa26748",
    "title": "Space-time Mixing Attention for Video Transformer",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a34bacf839b923770b2c360eefa26748-Paper.pdf",
    "abstract": "This paper is on video recognition using Transformers. Very recent attempts in this area have demonstrated promising results in terms of recognition accuracy, yet they have been also shown to induce, in many cases, significant computational overheads due to the additional modelling of the temporal information. In this work, we propose a Video Transformer model the complexity of which scales linearly with the number of frames in the video sequence and hence induces no overhead compared to an image-based Transformer model. To achieve this, our model makes two approximations to the full space-time attention used in Video Transformers: (a) It restricts time attention to a local temporal window and capitalizes on the Transformer's depth to obtain full temporal coverage of the video sequence. (b) It uses efficient space-time mixing to attend jointly spatial and temporal locations without inducing any additional cost on top of a spatial-only attention model. We also show how to integrate 2 very lightweight mechanisms for global temporal-only attention which provide additional accuracy improvements at minimal computational cost. We demonstrate that our model produces very high recognition accuracy on the most popular video recognition datasets while at the same time being significantly more efficient than other Video Transformer models.",
    "authors": [
      "Bulat, Adrian",
      "Perez Rua, Juan Manuel",
      "Sudhakaran, Swathikiran",
      "Martinez, Brais",
      "Tzimiropoulos, Georgios"
    ]
  },
  {
    "id": "a34e1ddbb4d329167f50992ba59fe45a",
    "title": "Particle Dual Averaging: Optimization of Mean Field Neural Network with Global Convergence Rate Analysis",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a34e1ddbb4d329167f50992ba59fe45a-Paper.pdf",
    "abstract": "We propose the particle dual averaging (PDA) method, which generalizes the dual averaging method in convex optimization to the optimization over probability distributions with quantitative runtime guarantee. The algorithm consists of an inner loop and outer loop: the inner loop utilizes the Langevin algorithm to approximately solve for a stationary distribution, which is then optimized in the outer loop. The method can be interpreted as an extension of the Langevin algorithm to naturally handle nonlinear functional on the probability space. An important application of the proposed method is the optimization of neural network in the mean field regime, which is theoretically attractive due to the presence of nonlinear feature learning, but quantitative convergence rate can be challenging to obtain. By adapting finite-dimensional convex optimization theory into the space of measures, we not only establish global convergence of PDA for two-layer mean field neural networks under more general settings and simpler analysis, but also provide quantitative polynomial runtime guarantee. Our theoretical results are supported by numerical simulations on neural networks with reasonable size. ",
    "authors": [
      "Nitanda, Atsushi",
      "Wu, Denny",
      "Suzuki, Taiji"
    ]
  },
  {
    "id": "a35fe7f7fe8217b4369a0af4244d1fca",
    "title": "Learning Tree Interpretation from Object Representation for Deep Reinforcement Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a35fe7f7fe8217b4369a0af4244d1fca-Paper.pdf",
    "abstract": "Interpreting Deep Reinforcement Learning (DRL) models is important to enhance trust and comply with transparency regulations. Existing methods typically explain a DRL model by visualizing the importance of low-level input features with super-pixels, attentions, or saliency maps. Our approach provides an interpretation based on high-level latent object features derived from a disentangled representation. We propose a Represent And Mimic (RAMi) framework for training 1) an identifiable latent representation to capture the independent factors of variation for the objects and 2) a mimic tree that extracts the causal impact of the latent features on DRL action values. To jointly optimize both the fidelity and the simplicity of a mimic tree, we derive a novel Minimum Description Length (MDL) objective based on the Information Bottleneck (IB) principle. Based on this objective, we describe a Monte Carlo Regression Tree Search (MCRTS) algorithm that explores different splits to find the IB-optimal mimic tree. Experiments show that our mimic tree achieves strong approximation performance with significantly fewer nodes than baseline models. We demonstrate the interpretability of our mimic tree by showing latent traversals, decision rules, causal impacts, and human evaluation results.",
    "authors": [
      "Liu, Guiliang",
      "Sun, Xiangyu",
      "Schulte, Oliver",
      "Poupart, Pascal"
    ]
  },
  {
    "id": "a376033f78e144f494bfc743c0be3330",
    "title": "Only Train Once: A One-Shot Neural Network Training And Pruning Framework",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a376033f78e144f494bfc743c0be3330-Paper.pdf",
    "abstract": "Structured pruning is a commonly used technique in deploying deep neural networks (DNNs) onto resource-constrained devices. However, the existing pruning methods are usually heuristic, task-specified, and require an extra fine-tuning procedure. To overcome these limitations, we propose a framework that compresses DNNs into slimmer architectures with competitive performances and significant FLOPs reductions by Only-Train-Once (OTO). OTO contains two key steps: (i) we partition the parameters of DNNs into zero-invariant groups, enabling us to prune zero groups without affecting the output; and (ii) to promote zero groups, we then formulate a structured-sparsity optimization problem, and propose a novel optimization algorithm, Half-Space Stochastic Projected Gradient (HSPG), to solve it, which outperforms the standard proximal methods on group sparsity exploration, and maintains comparable convergence. To demonstrate the effectiveness of OTO, we train and compress full models simultaneously from scratch without fine-tuning for inference speedup and parameter reduction, and achieve state-of-the-art results on VGG16 for CIFAR10, ResNet50 for CIFAR10 and Bert for SQuAD and competitive result on ResNet50 for ImageNet. The source code is available at https://github.com/tianyic/onlytrainonce.",
    "authors": [
      "Chen, Tianyi",
      "Ji, Bo",
      "Ding, Tianyu",
      "Fang, Biyi",
      "Wang, Guanyi",
      "Zhu, Zhihui",
      "Liang, Luming",
      "Shi, Yixin",
      "Yi, Sheng",
      "Tu, Xiao"
    ]
  },
  {
    "id": "a376802c0811f1b9088828288eb0d3f0",
    "title": "Referring Transformer: A One-step Approach to Multi-task Visual Grounding",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a376802c0811f1b9088828288eb0d3f0-Paper.pdf",
    "abstract": "As an important step towards visual reasoning, visual grounding (e.g., phrase localization, referring expression comprehension / segmentation) has been widely explored. Previous approaches to referring expression comprehension (REC) or segmentation (RES) either suffer from limited performance, due to a two-stage setup, or require the designing of complex task-specific one-stage architectures. In this paper, we propose a simple one-stage multi-task framework for visual grounding tasks. Specifically, we leverage a transformer architecture, where two modalities are fused in a visual-lingual encoder. In the decoder, the model learns to generate contextualized lingual queries which are then decoded and used to directly regress the bounding box and produce a segmentation mask for the corresponding referred regions. With this simple but highly contextualized model, we outperform state-of-the-art methods by a large margin on both REC and RES tasks. We also show that a simple pre-training schedule (on an external dataset) further improves the performance. Extensive experiments and ablations illustrate that our model benefits greatly from contextualized information and multi-task training.",
    "authors": [
      "Li, Muchen",
      "Sigal, Leonid"
    ]
  },
  {
    "id": "a378383b89e6719e15cd1aa45478627c",
    "title": "Decoupling the Depth and Scope of Graph Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a378383b89e6719e15cd1aa45478627c-Paper.pdf",
    "abstract": "State-of-the-art Graph Neural Networks (GNNs) have limited scalability with respect to the graph and model sizes. On large graphs, increasing the model depth often means exponential expansion of the scope (i.e., receptive field). Beyond just a few layers, two fundamental challenges emerge:  1. degraded expressivity due to oversmoothing, and 2. expensive computation due to neighborhood explosion. We propose a design principle to decouple the depth and scope of GNNs \u2013 to generate representation of a target entity (i.e., a node or an edge), we first extract a localized subgraph as the bounded-size scope, and then apply a GNN of arbitrary depth on top of the subgraph. A properly extracted subgraph consists of a small number of critical neighbors, while excluding irrelevant ones. The GNN, no matter how deep it is, smooths the local neighborhood into informative representation rather than oversmoothing the global graph into \u201cwhite noise\u201d. Theoretically, decoupling improves the GNN expressive power from the perspectives of graph signal processing (GCN), function approximation (GraphSAGE) and topological learning (GIN). Empirically, on seven graphs (with up to 110M nodes) and six backbone GNN architectures, our design achieves significant accuracy improvement with orders of magnitude reduction in computation and hardware cost.",
    "authors": [
      "Zeng, Hanqing",
      "Zhang, Muhan",
      "Xia, Yinglong",
      "Srivastava, Ajitesh",
      "Malevich, Andrey",
      "Kannan, Rajgopal",
      "Prasanna, Viktor",
      "Jin, Long",
      "Chen, Ren"
    ]
  },
  {
    "id": "a3842ed7b3d0fe3ac263bcabd2999790",
    "title": "Fast and Memory Efficient Differentially Private-SGD via JL Projections",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a3842ed7b3d0fe3ac263bcabd2999790-Paper.pdf",
    "abstract": "Differentially Private-SGD (DP-SGD) of Abadi et al. and its variations are the only known algorithms for private training of large scale neural networks. This algorithm requires computation of per-sample gradients norms which is extremely slow and memory intensive in practice. In this paper, we present a new framework to design differentially private optimizers called DP-SGD-JL and DP-Adam-JL. Our approach uses Johnson\u2013Lindenstrauss (JL) projections to quickly approximate the per-sample gradient norms without exactly computing them, thus making the training time and memory requirements of our optimizers closer to that of their non-DP versions. Unlike previous attempts to make DP-SGD faster which work only on a subset of network architectures or use compiler techniques, we propose an algorithmic solution which works for any network in a black-box manner which is the main contribution of this paper. To illustrate this, on IMDb dataset, we train a Recurrent Neural Network (RNN) to achieve good privacy-vs-accuracy tradeoff, while being significantly faster than DP-SGD and with a similar memory footprint as non-private SGD. ",
    "authors": [
      "Bu, Zhiqi",
      "Gopi, Sivakanth",
      "Kulkarni, Janardhan",
      "Lee, Yin Tat",
      "Shen, Hanwen",
      "Tantipongpipat, Uthaipon"
    ]
  },
  {
    "id": "a3ab4ff8fa4deed2e3bae3a5077675f0",
    "title": "Formalizing Generalization and Adversarial Robustness of Neural Networks to Weight Perturbations",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a3ab4ff8fa4deed2e3bae3a5077675f0-Paper.pdf",
    "abstract": "Studying the sensitivity of weight perturbation in neural networks and its impacts on model performance, including generalization and robustness, is an active research topic due to its implications on a wide range of machine learning tasks such as model compression, generalization gap assessment, and adversarial attacks. In this paper, we provide the first integral study and analysis for feed-forward neural networks in terms of the robustness in pairwise class margin and its generalization behavior under weight perturbation. We further design a new theory-driven loss function for training generalizable and robust neural networks against weight perturbations. Empirical experiments are conducted to validate our theoretical analysis. Our results offer fundamental insights for characterizing the generalization and robustness of neural networks against weight perturbations.",
    "authors": [
      "Tsai, Yu-Lin",
      "Hsu, Chia-Yi",
      "Yu, Chia-Mu",
      "Chen, Pin-Yu"
    ]
  },
  {
    "id": "a3b36cb25e2e0b93b5f334ffb4e4064e",
    "title": "Pipeline Combinators for Gradual AutoML",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a3b36cb25e2e0b93b5f334ffb4e4064e-Paper.pdf",
    "abstract": "Automated machine learning (AutoML) can make data scientists more productive.  But if machine learning is totally automated, that leaves no room for data scientists to apply their intuition.  Hence, data scientists often prefer not total but gradual automation, where they control certain choices and AutoML explores the rest.  Unfortunately, gradual AutoML is cumbersome with state-of-the-art tools, requiring large non-compositional code changes.  More concise compositional code can be achieved with combinators, a powerful concept from functional programming.  This paper introduces a small set of orthogonal combinators for composing machine-learning operators into pipelines.  It describes a translation scheme from pipelines and associated hyperparameter schemas to search spaces for AutoML optimizers.  On that foundation, this paper presents Lale, an open-source sklearn-compatible AutoML library, and evaluates it with a user study.",
    "authors": [
      "Baudart, Guillaume",
      "Hirzel, Martin",
      "Kate, Kiran",
      "Ram, Parikshit",
      "Shinnar, Avi",
      "Tsay, Jason"
    ]
  },
  {
    "id": "a40511cad8383e5ae8ddd8b855d135da",
    "title": "Boost Neural Networks by Checkpoints",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a40511cad8383e5ae8ddd8b855d135da-Paper.pdf",
    "abstract": "Training multiple deep neural networks (DNNs) and averaging their outputs is a simple way to improve the predictive performance. Nevertheless, the multiplied training cost prevents this ensemble method to be practical and efficient. Several recent works attempt to save and ensemble the checkpoints of DNNs, which only requires the same computational cost as training a single network. However, these methods suffer from either marginal accuracy improvements due to the low diversity of checkpoints or high risk of divergence due to the cyclical learning rates they adopted. In this paper, we propose a novel method to ensemble the checkpoints, where a boosting scheme is utilized to accelerate model convergence and maximize the checkpoint diversity. We theoretically prove that it converges by reducing exponential loss. The empirical evaluation also indicates our proposed ensemble outperforms single model and existing ensembles in terms of accuracy and efficiency. With the same training budget, our method achieves 4.16% lower error on Cifar-100 and 6.96% on Tiny-ImageNet with ResNet-110 architecture. Moreover, the adaptive sample weights in our method make it an effective solution to address the imbalanced class distribution. In the experiments, it yields up to 5.02% higher accuracy over single EfficientNet-B0 on the imbalanced datasets.",
    "authors": [
      "Wang, Feng",
      "Wei, Guoyizhe",
      "Liu, Qiao",
      "Ou, Jinxiang",
      "wei, xian",
      "Lv, Hairong"
    ]
  },
  {
    "id": "a41db61e2728ef963614a8c8755b9b9a",
    "title": "Model Selection for Bayesian Autoencoders",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a41db61e2728ef963614a8c8755b9b9a-Paper.pdf",
    "abstract": "We develop a novel method for carrying out model selection for Bayesian autoencoders (BAEs) by means of prior hyper-parameter optimization. Inspired by the common practice of type-II maximum likelihood optimization and its equivalence to Kullback-Leibler divergence minimization, we propose to optimize the distributional sliced-Wasserstein distance (DSWD) between the output of the autoencoder and the empirical data distribution. The advantages of this formulation are that we can estimate the DSWD based on samples and handle high-dimensional problems. We carry out posterior estimation of the BAE parameters via stochastic gradient Hamiltonian Monte Carlo and turn our BAE into a generative model by fitting a flexible Dirichlet mixture model in the latent space. Thanks to this approach, we obtain a powerful alternative to variational autoencoders, which are the preferred choice in modern application of autoencoders for representation learning with uncertainty. We evaluate our approach qualitatively and quantitatively using a vast experimental campaign on a number of unsupervised learning tasks and show that, in small-data regimes where priors matter,  our approach provides state-of-the-art results, outperforming multiple competitive baselines.",
    "authors": [
      "Tran, Ba-Hien",
      "Rossi, Simone",
      "Milios, Dimitrios",
      "Michiardi, Pietro",
      "Bonilla, Edwin V.",
      "Filippone, Maurizio"
    ]
  },
  {
    "id": "a4267159aa970aa5a6542bcbb7ef575e",
    "title": "Three Operator Splitting with Subgradients, Stochastic Gradients, and Adaptive Learning Rates",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a4267159aa970aa5a6542bcbb7ef575e-Paper.pdf",
    "abstract": "Three Operator Splitting (TOS) (Davis & Yin, 2017) can minimize the sum of multiple convex functions effectively when an efficient gradient oracle or proximal operator is available for each term. This requirement often fails in machine learning applications: (i) instead of full gradients only stochastic gradients may be available; and (ii) instead of proximal operators, using subgradients to handle complex penalty functions may be more efficient and realistic. Motivated by these concerns, we analyze three potentially valuable extensions of TOS. The first two permit using subgradients and stochastic gradients, and are shown to ensure a $\\mathcal{O}(1/\\sqrt{t})$ convergence rate. The third extension AdapTOS endows TOS with adaptive step-sizes. For the important setting of optimizing a convex loss over the intersection of convex sets AdapTOS attains universal convergence rates, i.e., the rate adapts to the unknown smoothness degree of the objective. We compare our proposed methods with competing methods on various applications. ",
    "authors": [
      "Yurtsever, Alp",
      "Gu, Alex",
      "Sra, Suvrit"
    ]
  },
  {
    "id": "a4380923dd651c195b1631af7c829187",
    "title": "Knowledge-Adaptation Priors",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a4380923dd651c195b1631af7c829187-Paper.pdf",
    "abstract": "Humans and animals have a natural ability to quickly adapt to their surroundings, but machine-learning models, when subjected to changes, often require a complete retraining from scratch. We present Knowledge-adaptation priors (K-priors) to reduce the cost of retraining by enabling quick and accurate adaptation for a wide-variety of tasks and models. This is made possible by a combination of weight and function-space priors to reconstruct the gradients of the past, which recovers and generalizes many existing, but seemingly-unrelated, adaptation strategies. Training with simple first-order gradient methods can often recover the exact retrained model to an arbitrary accuracy by choosing a sufficiently large memory of the past data. Empirical results show that adaptation with K-priors achieves performance similar to full retraining, but only requires training on a handful of past examples.",
    "authors": [
      "Khan, Mohammad Emtiyaz E.",
      "Swaroop, Siddharth"
    ]
  },
  {
    "id": "a440a3d316c5614c7a9310e902f4a43e",
    "title": "Provably efficient multi-task reinforcement learning with model transfer",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a440a3d316c5614c7a9310e902f4a43e-Paper.pdf",
    "abstract": "We study multi-task reinforcement learning (RL) in tabular episodic Markov decision processes (MDPs). We formulate a heterogeneous multi-player RL problem, in which a group of players concurrently face similar but not necessarily identical MDPs, with a goal of improving their collective performance through inter-player information sharing. We design and analyze a model-based algorithm, and provide gap-dependent and gap-independent regret upper and lower bounds that characterize the intrinsic complexity of the problem.",
    "authors": [
      "Zhang, Chicheng",
      "Wang, Zhi"
    ]
  },
  {
    "id": "a45a1d12ee0fb7f1f872ab91da18f899",
    "title": "Predicting Molecular Conformation via Dynamic Graph Score Matching",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a45a1d12ee0fb7f1f872ab91da18f899-Paper.pdf",
    "abstract": "Predicting stable 3D conformations from 2D molecular graphs has been a long-standing challenge in computational chemistry. Recently, machine learning approaches have demonstrated very promising results compared to traditional experimental and physics-based simulation methods. These approaches mainly focus on modeling the local interactions between neighboring atoms on the molecular graphs and overlook the long-range interactions between non-bonded atoms. However, these non-bonded atoms may be proximal to each other in 3D space, and modeling their interactions is of crucial importance to accurately determine molecular conformations, especially for large molecules and multi-molecular complexes. In this paper, we propose a new approach called Dynamic Graph Score Matching (DGSM) for molecular conformation prediction, which models both the local and long-range interactions by dynamically constructing graph structures between atoms according to their spatial proximity during both training and inference. Specifically, the DGSM directly estimates the gradient fields of the logarithm density of atomic coordinates according to the dynamically constructed graphs using score matching methods. The whole framework can be efficiently trained in an end-to-end fashion. Experiments across multiple tasks show that the DGSM outperforms state-of-the-art baselines by a large margin, and it is capable of generating conformations for a broader range of systems such as proteins and multi-molecular complexes.",
    "authors": [
      "Luo, Shitong",
      "Shi, Chence",
      "Xu, Minkai",
      "Tang, Jian"
    ]
  },
  {
    "id": "a4a1108bbcc329a70efa93d7bf060914",
    "title": "When in Doubt: Neural Non-Parametric Uncertainty Quantification for Epidemic Forecasting",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a4a1108bbcc329a70efa93d7bf060914-Paper.pdf",
    "abstract": "Accurate and trustworthy epidemic forecasting is an important problem for public health planning and disease mitigation. Most existing epidemic forecasting models disregard uncertainty quantification, resulting in mis-calibrated predictions. Recent works in deep neural models for uncertainty-aware time-series forecasting also have several limitations; e.g., it is difficult to specify proper priors in Bayesian NNs, while methods like deep ensembling can be computationally expensive. In this paper, we propose to use neural functional processes to fill this gap. We model epidemic time-series with a probabilistic generative process and propose a functional neural process model called EpiFNP, which directly models the probability distribution of the forecast value in a non-parametric way. In EpiFNP, we use a dynamic stochastic correlation graph to model the correlations between sequences, and design different stochastic latent variables to capture functional uncertainty from different perspectives. Our experiments in a real-time flu forecasting setting show that EpiFNP significantly outperforms state-of-the-art models in both accuracy and calibration metrics, up to 2.5x in accuracy and 2.4x in calibration. Additionally, as EpiFNP learns the relations between the current season and similar patterns of historical seasons, it enables interpretable forecasts. Beyond epidemic forecasting, EpiFNP can be of independent interest for advancing uncertainty quantification in deep sequential models for predictive analytics.",
    "authors": [
      "Kamarthi, Harshavardhan",
      "Kong, Lingkai",
      "Rodriguez, Alexander",
      "Zhang, Chao",
      "Prakash, B. Aditya"
    ]
  },
  {
    "id": "a4d8e2a7e0d0c102339f97716d2fdfb6",
    "title": "Bounds all around: training energy-based models with bidirectional bounds",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a4d8e2a7e0d0c102339f97716d2fdfb6-Paper.pdf",
    "abstract": "Energy-based models (EBMs) provide an elegant framework for density estimation, but they are notoriously difficult to train. Recent work has established links to generative adversarial networks, where the EBM is trained through a minimax game with a variational value function. We propose a bidirectional bound on the EBM log-likelihood, such that we maximize a lower bound and minimize an upper bound when solving the minimax game. We link one bound to a gradient penalty that stabilizes training, thereby provide grounding for best engineering practice. To evaluate the bounds we develop a new and efficient estimator of the Jacobi-determinant of the EBM generator. We demonstrate that these developments stabilize training and yield high-quality density estimation and sample generation.",
    "authors": [
      "Geng, Cong",
      "Wang, Jia",
      "Gao, Zhiyong",
      "Frellsen, Jes",
      "Hauberg, S\u00f8ren"
    ]
  },
  {
    "id": "a4d92e2cd541fca87e4620aba658316d",
    "title": "CogView: Mastering Text-to-Image Generation via Transformers",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a4d92e2cd541fca87e4620aba658316d-Paper.pdf",
    "abstract": "Text-to-Image generation in the general domain has long been an open problem, which requires both a powerful generative model and cross-modal understanding. We propose CogView, a 4-billion-parameter Transformer with VQ-VAE tokenizer to advance this problem. We also demonstrate the finetuning strategies for various downstream tasks, e.g. style learning, super-resolution, text-image ranking and fashion design, and methods to stabilize pretraining, e.g. eliminating NaN losses. CogView achieves the state-of-the-art FID on the blurred MS COCO dataset, outperforming previous GAN-based models and a recent similar work DALL-E.",
    "authors": [
      "Ding, Ming",
      "Yang, Zhuoyi",
      "Hong, Wenyi",
      "Zheng, Wendi",
      "Zhou, Chang",
      "Yin, Da",
      "Lin, Junyang",
      "Zou, Xu",
      "Shao, Zhou",
      "Yang, Hongxia",
      "Tang, Jie"
    ]
  },
  {
    "id": "a4ee59dd868ba016ed2de90d330acb6a",
    "title": "Time-independent Generalization Bounds for SGLD in Non-convex Settings",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a4ee59dd868ba016ed2de90d330acb6a-Paper.pdf",
    "abstract": "We establish generalization error bounds for stochastic gradient Langevin dynamics (SGLD) with constant learning rate under the assumptions of dissipativity and smoothness, a setting that has received increased attention in the sampling/optimization literature. Unlike existing bounds for SGLD in non-convex settings, ours are time-independent and decay to zero as the sample size increases. Using the framework of uniform stability, we establish time-independent bounds by exploiting the Wasserstein contraction property of the Langevin diffusion, which also allows us to circumvent the need to bound gradients using Lipschitz-like assumptions. Our analysis also supports variants of SGLD that use different discretization methods, incorporate Euclidean projections, or use non-isotropic noise.",
    "authors": [
      "Farghly, Tyler",
      "Rebeschini, Patrick"
    ]
  },
  {
    "id": "a51c896c9cb81ecb5a199d51ac9fc3c5",
    "title": "Nonuniform Negative Sampling and Log Odds Correction with Rare Events Data",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a51c896c9cb81ecb5a199d51ac9fc3c5-Paper.pdf",
    "abstract": "We investigate the issue of parameter estimation with nonuniform negative sampling for imbalanced data. We first prove that, with imbalanced data, the available information about unknown parameters is only tied to the relatively small number of positive instances, which justifies the usage of negative sampling. However, if the negative instances are subsampled to the same level of the positive cases, there is information loss. To maintain more information, we derive the asymptotic distribution of a general inverse probability weighted (IPW) estimator and obtain the optimal sampling probability that minimizes its variance. To further improve the estimation efficiency over the IPW method, we propose a likelihood-based estimator by correcting log odds for the sampled data and prove that the improved estimator has the smallest asymptotic variance among a large class of estimators. It is also more robust to pilot misspecification. We validate our approach on simulated data as well as a real click-through rate dataset with more than 0.3 trillion instances, collected over a period of a month. Both theoretical and empirical results demonstrate the effectiveness of our method.",
    "authors": [
      "Wang, HaiYing",
      "Zhang, Aonan",
      "Wang, Chong"
    ]
  },
  {
    "id": "a546203962b88771bb06faf8d6ec065e",
    "title": "Algorithmic stability and generalization of an unsupervised feature selection algorithm",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a546203962b88771bb06faf8d6ec065e-Paper.pdf",
    "abstract": "Feature selection, as a vital dimension reduction technique, reduces data dimension by identifying an essential subset of input features, which can facilitate interpretable insights into learning and inference processes. Algorithmic stability is a key characteristic of an algorithm regarding its sensitivity to perturbations of input samples. In this paper, we propose an innovative unsupervised feature selection algorithm attaining this stability with provable guarantees. The architecture of our algorithm consists of a feature scorer and a feature selector. The scorer trains a neural network (NN) to globally score all the features, and the selector adopts a dependent sub-NN to locally evaluate the representation abilities for selecting features. Further, we present algorithmic stability analysis and show that our algorithm has a performance guarantee via a generalization error bound. Extensive experimental results on real-world datasets demonstrate superior generalization performance of our proposed algorithm to strong baseline methods. Also, the properties revealed by our theoretical analysis and the stability of our algorithm-selected features are empirically confirmed.",
    "authors": [
      "wu, xinxing",
      "Cheng, Qiang"
    ]
  },
  {
    "id": "a5481cd6d7517aa3fc6476dc7d9019ab",
    "title": "On learning sparse vectors from mixture of responses",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a5481cd6d7517aa3fc6476dc7d9019ab-Paper.pdf",
    "abstract": " In this paper, we address two learning problems. Suppose a family of $\\ell$ unknown sparse vectors is fixed, where each vector has at most $k$ non-zero elements. In the first problem, we concentrate on robust learning the supports of all vectors from the family using a sequence of noisy responses. Each response to a query vector shows the sign of the inner product between a randomly chosen vector from the family and the query vector. In the second problem, we aim at designing queries such that all sparse vectors from the family can be approximately reconstructed based on the error-free responses.  This learning model was introduced in the work of Gandikota et al., 2020, and these problems can be seen as generalizations of support recovery and approximate recovery problems, well-studied under the framework of  1-bit compressed sensing.  As the main contribution of the paper, we prove the existence of learning algorithms for the first problem which work without any assumptions. Under a mild structural assumption on the unknown vectors, we also show the existence of learning algorithms for the second problem and rigorously analyze their query complexity.",
    "authors": [
      "Polyanskii, Nikita"
    ]
  },
  {
    "id": "a576eafbce762079f7d1f77fca1c5cc2",
    "title": "Convergence and Alignment of Gradient Descent with Random Backpropagation Weights",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a576eafbce762079f7d1f77fca1c5cc2-Paper.pdf",
    "abstract": "Stochastic gradient descent with backpropagation is the workhorse of artificial neural networks. It has long been recognized that backpropagation fails to be a biologically plausible algorithm. Fundamentally, it is a non-local procedure---updating one neuron's synaptic weights requires knowledge of synaptic weights or receptive fields of downstream neurons. This limits the use of artificial neural networks as a tool for understanding the biological principles of information processing in the brain. Lillicrap et al. (2016) propose a more biologically plausible \"feedback alignment\" algorithm that uses random and fixed backpropagation weights, and show promising simulations. In this paper we study the mathematical properties of the feedback alignment procedure by analyzing convergence and alignment for two-layer networks under squared error loss. In the overparameterized setting, we prove that the error converges to zero exponentially fast, and also that regularization is necessary in order for the \u00a0parameters to become aligned with the random backpropagation weights. Simulations are given that are consistent with this analysis and suggest further generalizations. These results contribute to our understanding of how biologically plausible algorithms might carry out weight learning in a manner different from Hebbian learning, with performance that is comparable with the full non-local backpropagation algorithm.",
    "authors": [
      "Song, Ganlin",
      "Xu, Ruitu",
      "Lafferty, John"
    ]
  },
  {
    "id": "a57e8915461b83adefb011530b711704",
    "title": "Adder Attention for Vision Transformer",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a57e8915461b83adefb011530b711704-Paper.pdf",
    "abstract": "Transformer is a new kind of calculation paradigm for deep learning which has shown strong performance on a large variety of computer vision tasks. However, compared with conventional deep models (e.g., convolutional neural networks), vision transformers require more computational resources which cannot be easily deployed on mobile devices. To this end, we present to reduce the energy consumptions using adder neural network (AdderNet). We first theoretically analyze the mechanism of self-attention and the difficulty for applying adder operation into this module. Specifically, the feature diversity, i.e., the rank of attention map using only additions cannot be well preserved. Thus, we develop an adder attention layer that includes an additional identity mapping. With the new operation, vision transformers constructed using additions can also provide powerful feature representations. Experimental results on several benchmarks demonstrate that the proposed approach can achieve highly competitive performance to that of the baselines while achieving an about 2~3\u00d7 reduction on the energy consumption. ",
    "authors": [
      "Shu, Han",
      "Wang, Jiahao",
      "Chen, Hanting",
      "Li, Lin",
      "Yang, Yujiu",
      "Wang, Yunhe"
    ]
  },
  {
    "id": "a57ecd54d4df7d999bd9c5e3b973ec75",
    "title": "Reverse engineering learned optimizers reveals known and novel mechanisms",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a57ecd54d4df7d999bd9c5e3b973ec75-Paper.pdf",
    "abstract": "Learned optimizers are parametric algorithms that can themselves be trained to solve optimization problems. In contrast to baseline optimizers (such as momentum or Adam) that use simple update rules derived from theoretical principles, learned optimizers use flexible, high-dimensional, nonlinear parameterizations. Although this can lead to better performance, their inner workings remain a mystery. How is a given learned optimizer able to outperform a well tuned baseline? Has it learned a sophisticated combination of existing optimization techniques, or is it implementing completely new behavior? In this work, we address these questions by careful analysis and visualization of learned optimizers. We study learned optimizers trained from scratch on four disparate tasks, and discover that they have learned interpretable behavior, including: momentum, gradient clipping, learning rate schedules, and new forms of learning rate adaptation. Moreover, we show how dynamics and mechanisms inside of learned optimizers orchestrate these computations. Our results help elucidate the previously murky understanding of how learned optimizers work, and establish tools for interpreting future learned optimizers.",
    "authors": [
      "Maheswaranathan, Niru",
      "Sussillo, David",
      "Metz, Luke",
      "Sun, Ruoxi",
      "Sohl-Dickstein, Jascha"
    ]
  },
  {
    "id": "a5a61717dddc3501cfdf7a4e22d7dbaa",
    "title": "Matching a Desired Causal State via Shift Interventions",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a5a61717dddc3501cfdf7a4e22d7dbaa-Paper.pdf",
    "abstract": "Transforming a causal system from a given initial state to a desired target state is an important task permeating multiple fields including control theory, biology, and materials science. In causal models, such transformations can be achieved by performing a set of interventions. In this paper, we consider the problem of identifying a shift intervention that matches the desired mean of a system through active learning. We define the Markov equivalence class that is identifiable from shift interventions and propose two active learning strategies that are guaranteed to exactly match a desired mean. We then derive a worst-case lower bound for the number of interventions required and show that these strategies are optimal for certain classes of graphs. In particular, we show that our strategies may require exponentially fewer interventions than the previously considered approaches, which optimize for structure learning in the underlying causal graph. In line with our theoretical results, we also demonstrate experimentally that our proposed active learning strategies require fewer interventions compared to several baselines.",
    "authors": [
      "Zhang, Jiaqi",
      "Squires, Chandler",
      "Uhler, Caroline"
    ]
  },
  {
    "id": "a5c7b30fb632c92feb59154517223dc9",
    "title": "Unsupervised Noise Adaptive Speech Enhancement by Discriminator-Constrained Optimal Transport",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a5c7b30fb632c92feb59154517223dc9-Paper.pdf",
    "abstract": "This paper presents a novel discriminator-constrained optimal transport network (DOTN) that performs unsupervised domain adaptation for speech enhancement (SE), which is an essential regression task in speech processing. The DOTN aims to estimate clean references of noisy speech in a target domain, by exploiting the knowledge available from the source domain. The domain shift between training and testing data has been reported to be an obstacle to learning problems in diverse fields. Although rich literature exists on unsupervised domain adaptation for classification, the methods proposed, especially in regressions, remain scarce and often depend on additional information regarding the input data. The proposed DOTN approach tactically fuses the optimal transport (OT) theory from mathematical analysis with generative adversarial frameworks, to help evaluate continuous labels in the target domain. The experimental results on two SE tasks demonstrate that by extending the classical OT formulation, our proposed DOTN outperforms previous adversarial domain adaptation frameworks in a purely unsupervised manner.",
    "authors": [
      "Lin, Hsin-Yi",
      "Tseng, Huan-Hsin",
      "Lu, Xugang",
      "Tsao, Yu"
    ]
  },
  {
    "id": "a5e308070bd6dd3cc56283f2313522de",
    "title": "Optimality of variational inference for stochasticblock model with missing links",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a5e308070bd6dd3cc56283f2313522de-Paper.pdf",
    "abstract": "Variational methods are extremely popular in the analysis of network data. Statistical guarantees obtained for these methods typically provide asymptotic normality for the problem of estimation of global model parameters under the stochastic block model. In the present work, we consider the case of networks with missing links that is important in application and show that the variational approximation to the maximum likelihood estimator converges at the minimax rate. This provides the first minimax optimal and tractable estimator for the problem of parameter estimation for the stochastic block model with missing links. We complement our results with numerical studies of simulated and real networks, which confirm the advantages of this estimator over current methods.",
    "authors": [
      "Gaucher, Solenne",
      "Klopp, Olga"
    ]
  },
  {
    "id": "a613863f6a3ada47ae5bca2a558872d1",
    "title": "Policy Learning Using Weak Supervision",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a613863f6a3ada47ae5bca2a558872d1-Paper.pdf",
    "abstract": "Most existing policy learning solutions require the learning agents to receive high-quality supervision signals, e.g., rewards in reinforcement learning (RL) or high-quality expert demonstrations in behavioral cloning (BC). These quality supervisions are either infeasible or prohibitively expensive to obtain in practice. We aim for a unified framework that leverages the available cheap weak supervisions to perform policy learning efficiently. To handle this problem, we treat the weak supervision'' as imperfect information coming from a peer agent, and evaluate the learning agent's policy based on a  correlated agreement'' with the peer agent's policy (instead of simple agreements). Our approach explicitly punishes a policy for overfitting to the weak supervision. In addition to theoretical guarantees, extensive evaluations on tasks including RL with noisy reward, BC with weak demonstrations, and standard policy co-training (RL + BC) show that our method leads to substantial performance improvements, especially when the complexity or the noise of the learning environments is high. ",
    "authors": [
      "Wang, Jingkang",
      "Guo, Hongyi ",
      "Zhu, Zhaowei",
      "Liu, Yang"
    ]
  },
  {
    "id": "a61f27ab2165df0e18cc9433bd7f27c5",
    "title": "Chasing Sparsity in Vision Transformers: An End-to-End Exploration",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a61f27ab2165df0e18cc9433bd7f27c5-Paper.pdf",
    "abstract": "Vision transformers (ViTs) have recently received explosive popularity, but their enormous model sizes and training costs remain daunting. Conventional post-training pruning often incurs higher training budgets. In contrast, this paper aims to trim down both the training memory overhead and the inference complexity, without sacrificing the achievable accuracy. We carry out the first-of-its-kind comprehensive exploration, on taking a unified approach of integrating sparsity in ViTs \"from end to end''. Specifically, instead of training full ViTs, we dynamically extract and train sparse subnetworks, while sticking to a fixed small parameter budget. Our approach jointly optimizes model parameters and explores connectivity throughout training, ending up with one sparse network as the final output. The approach is seamlessly extended from unstructured to structured sparsity, the latter by considering to guide the prune-and-grow of self-attention heads inside ViTs. We further co-explore data and architecture sparsity for additional efficiency gains by plugging in a novel learnable token selector to adaptively determine the currently most vital patches. Extensive results on ImageNet with diverse ViT backbones validate the effectiveness of our proposals which obtain significantly reduced computational cost and almost unimpaired generalization. Perhaps most surprisingly, we find that the proposed sparse (co-)training can sometimes \\textit{improve the ViT accuracy} rather than compromising it, making sparsity a tantalizing \"free lunch''. For example, our sparsified DeiT-Small at ($5\\%$, $50\\%$) sparsity for (data, architecture), improves $\\mathbf{0.28\\%}$ top-1 accuracy, and meanwhile enjoys $\\mathbf{49.32\\%}$ FLOPs and $\\mathbf{4.40\\%}$ running time savings. Our codes are available at https://github.com/VITA-Group/SViTE.",
    "authors": [
      "Chen, Tianlong",
      "Cheng, Yu",
      "Gan, Zhe",
      "Yuan, Lu",
      "Zhang, Lei",
      "Wang, Zhangyang"
    ]
  },
  {
    "id": "a64a034c3cb8eac64eb46ea474902797",
    "title": "Graphical Models in Heavy-Tailed Markets",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a64a034c3cb8eac64eb46ea474902797-Paper.pdf",
    "abstract": "Heavy-tailed statistical distributions have long been considered a more realistic statistical model for the data generating process in financial markets in comparison to their Gaussian counterpart. Nonetheless, mathematical nuisances, including nonconvexities, involved in estimating graphs in heavy-tailed settings pose a significant challenge to the practical design of algorithms for graph learning. In this work, we present graph learning estimators based on the Markov random field framework that assume a Student-$t$ data generating process. We design scalable numerical algorithms, via the alternating direction method of multipliers, to learn both connected and $k$-component graphs along with their theoretical convergence guarantees. The proposed methods outperform state-of-the-art benchmarks in an extensive series of practical experiments with publicly available data from the S\\&P500 index, foreign exchanges, and cryptocurrencies.",
    "authors": [
      "de Miranda Cardoso, Jose Vinicius",
      "Ying, Jiaxi",
      "Palomar, Daniel"
    ]
  },
  {
    "id": "a64c94baaf368e1840a1324e839230de",
    "title": "A Shading-Guided Generative Implicit Model for Shape-Accurate 3D-Aware Image Synthesis",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a64c94baaf368e1840a1324e839230de-Paper.pdf",
    "abstract": "The advancement of generative radiance fields has pushed the boundary of 3D-aware image synthesis. Motivated by the observation that a 3D object should look realistic from multiple viewpoints, these methods introduce a multi-view constraint as regularization to learn valid 3D radiance fields from 2D images. Despite the progress, they often fall short of capturing accurate 3D shapes due to the shape-color ambiguity, limiting their applicability in downstream tasks. In this work, we address this ambiguity by proposing a novel shading-guided generative implicit model that is able to learn a starkly improved shape representation. Our key insight is that an accurate 3D shape should also yield a realistic rendering under different lighting conditions. This multi-lighting constraint is realized by modeling illumination explicitly and performing shading with various lighting conditions. Gradients are derived by feeding the synthesized images to a discriminator. To compensate for the additional computational burden of calculating surface normals, we further devise an efficient volume rendering strategy via surface tracking, reducing the training and inference time by 24% and 48%, respectively. Our experiments on multiple datasets show that the proposed approach achieves photorealistic 3D-aware image synthesis while capturing accurate underlying 3D shapes. We demonstrate improved performance of our approach on 3D shape reconstruction against existing methods, and show its applicability on image relighting. Our code is available at https://github.com/XingangPan/ShadeGAN.",
    "authors": [
      "Pan, Xingang",
      "XU, Xudong",
      "Loy, Chen Change",
      "Theobalt, Christian",
      "Dai, Bo"
    ]
  },
  {
    "id": "a655fbe4b8d7439994aa37ddad80de56",
    "title": "XCiT: Cross-Covariance Image Transformers",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a655fbe4b8d7439994aa37ddad80de56-Paper.pdf",
    "abstract": "Following their success in natural language processing, transformers have recently shown much promise for computer vision. The self-attention operation underlying transformers yields global interactions between all tokens ,i.e. words or image patches, and enables flexible modelling of image data beyond the local interactions of convolutions. This flexibility, however, comes with a quadratic complexity in time and memory, hindering application to long sequences and high-resolution images. We propose a \u201ctransposed\u201d version of self-attention that operates across feature channels rather than tokens, where the interactions are based on the cross-covariance matrix between keys and queries. The resulting cross-covariance attention (XCA) has linear complexity in the number of tokens, and allows efficient processing of high-resolution images.Our cross-covariance image transformer (XCiT) is built upon XCA. It combines the accuracy of conventional transformers with the scalability of convolutional architectures. We validate the effectiveness and generality of XCiT by reporting excellent results on multiple vision benchmarks, including image classification and self-supervised feature learning on ImageNet-1k, object detection and instance segmentation on COCO, and semantic segmentation on ADE20k.We will opensource our code and trained models to reproduce the reported results.",
    "authors": [
      "Ali, Alaaeldin",
      "Touvron, Hugo",
      "Caron, Mathilde",
      "Bojanowski, Piotr",
      "Douze, Matthijs",
      "Joulin, Armand",
      "Laptev, Ivan",
      "Neverova, Natalia",
      "Synnaeve, Gabriel",
      "Verbeek, Jakob",
      "Jegou, Herve"
    ]
  },
  {
    "id": "a6a38989dc7e433f1f42388e7afca318",
    "title": "Row-clustering of a Point Process-valued Matrix",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a6a38989dc7e433f1f42388e7afca318-Paper.pdf",
    "abstract": "Structured point process data harvested from various platforms poses new challenges to the machine learning community. To cluster repeatedly observed marked point processes, we propose a novel mixture model of multi-level marked point processes for identifying potential heterogeneity in the observed data. Specifically, we study a matrix whose entries are marked log-Gaussian Cox processes and cluster rows of such a matrix.  An efficient semi-parametric Expectation-Solution (ES) algorithm combined with functional principal component analysis (FPCA) of point processes is proposed for model estimation. The effectiveness of the proposed framework is demonstrated through simulation studies and real data analyses.",
    "authors": [
      "Yin, Lihao",
      "Xu, Ganggang",
      "Sang, Huiyan",
      "Guan, Yongtao"
    ]
  },
  {
    "id": "a6d259bfbfa2062843ef543e21d7ec8e",
    "title": "Fine-Grained Neural Network Explanation by Identifying Input Features with Predictive Information",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a6d259bfbfa2062843ef543e21d7ec8e-Paper.pdf",
    "abstract": "One principal approach for illuminating a black-box neural network is feature attribution, i.e. identifying the importance of input features for the network\u2019s prediction. The predictive information of features is recently proposed as a proxy for the measure of their importance. So far, the predictive information is only identified for latent features by placing an information bottleneck within the network. We propose a method to identify features with predictive information in the input domain. The method results in fine-grained identification of input features' information and is agnostic to network architecture. The core idea of our method is leveraging a bottleneck on the input that only lets input features associated with predictive latent features pass through. We compare our method with several feature attribution methods using mainstream feature attribution evaluation experiments. The code is publicly available.",
    "authors": [
      "Zhang, Yang",
      "Khakzar, Ashkan",
      "Li, Yawei",
      "Farshad, Azade",
      "Kim, Seong Tae",
      "Navab, Nassir"
    ]
  },
  {
    "id": "a709909b1ea5c2bee24248203b1728a5",
    "title": "Fast Minimum-norm Adversarial Attacks through Adaptive Norm Constraints",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a709909b1ea5c2bee24248203b1728a5-Paper.pdf",
    "abstract": "Evaluating adversarial robustness amounts to finding the minimum perturbation needed to have an input sample misclassified. The inherent complexity of the underlying optimization requires current gradient-based attacks to be carefully tuned, initialized, and possibly executed for many computationally-demanding iterations, even if specialized to a given perturbation model.In this work, we overcome these limitations by proposing a fast minimum-norm (FMN) attack that works with different $\\ell_p$-norm perturbation models ($p=0, 1, 2, \\infty$), is robust to hyperparameter choices, does not require adversarial starting points, and converges within few lightweight steps. It works by iteratively finding the sample misclassified with maximum confidence within an $\\ell_p$-norm constraint of size $\\epsilon$, while adapting $\\epsilon$ to minimize the distance of the current sample to the decision boundary.Extensive experiments show that FMN significantly outperforms existing $\\ell_0$, $\\ell_1$, and $\\ell_\\infty$-norm attacks in terms of perturbation size, convergence speed and computation time, while reporting comparable performances with state-of-the-art $\\ell_2$-norm attacks. Our open-source code is available at: https://github.com/pralab/Fast-Minimum-Norm-FMN-Attack.",
    "authors": [
      "Pintor, Maura",
      "Roli, Fabio",
      "Brendel, Wieland",
      "Biggio, Battista"
    ]
  },
  {
    "id": "a70dc40477bc2adceef4d2c90f47eb82",
    "title": "Uncertainty Quantification and Deep Ensembles",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a70dc40477bc2adceef4d2c90f47eb82-Paper.pdf",
    "abstract": "Deep Learning methods are known to suffer from calibration issues: they typically produce over-confident estimates. These problems are exacerbated in the low data regime. Although the calibration of probabilistic models is well studied, calibrating extremely over-parametrized models in the low-data regime presents unique challenges. We show that deep-ensembles do not necessarily lead to improved calibration properties. In fact, we show that standard ensembling methods, when used in conjunction with modern techniques such as mixup regularization, can lead to less calibrated models. This text examines the interplay between three of the most simple and commonly used approaches to leverage deep learning when data is scarce: data-augmentation, ensembling, and post-processing calibration methods. We demonstrate that, although standard ensembling techniques certainly help to boost accuracy, the calibration of deep ensembles relies on subtle trade-offs. We also find that calibration methods such as temperature scaling need to be slightly tweaked when used with deep-ensembles and, crucially, need to be executed after the averaging process. Our simulations indicate that, in the low data regime, this simple strategy can halve the Expected Calibration Error (ECE) on a range of benchmark classification problems when compared to standard deep-ensembles.",
    "authors": [
      "Rahaman, Rahul",
      "thiery, alexandre"
    ]
  },
  {
    "id": "a73d9b34d6f7c322fa3e34c633b1297d",
    "title": "Directed Probabilistic Watershed",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a73d9b34d6f7c322fa3e34c633b1297d-Paper.pdf",
    "abstract": "The Probabilistic Watershed is a semi-supervised learning algorithm applied on undirected graphs. Given a set of labeled nodes (seeds), it defines a Gibbs probability distribution over all possible spanning forests disconnecting the seeds. It calculates, for every node, the probability of sampling a forest connecting a certain seed with the considered node. We propose the \"Directed Probabilistic Watershed\", an extension of the Probabilistic Watershed algorithm to directed graphs. Building on the Probabilistic Watershed, we apply the Matrix Tree Theorem for directed graphs and define a Gibbs probability distribution over all incoming directed forests rooted at the seeds. Similar to the undirected case, this turns out to be equivalent to the Directed Random Walker. Furthermore, we show that in the limit case in which the Gibbs distribution has infinitely low temperature, the labeling of the Directed Probabilistic Watershed is equal to the one induced by the incoming directed forest of minimum cost. Finally, for illustration, we compare the empirical performance of the proposed method with other semi-supervised segmentation methods for directed graphs.",
    "authors": [
      "Fita Sanmartin, Enrique",
      "Damrich, Sebastian",
      "Hamprecht, Fred A."
    ]
  },
  {
    "id": "a7c9585703d275249f30a088cebba0ad",
    "title": "Laplace Redux - Effortless Bayesian Deep Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a7c9585703d275249f30a088cebba0ad-Paper.pdf",
    "abstract": "Bayesian formulations of deep learning have been shown to have compelling theoretical properties and offer practical functional benefits, such as improved predictive uncertainty quantification and model selection. The Laplace approximation (LA) is a classic, and arguably the simplest family of approximations for the intractable posteriors of deep neural networks. Yet, despite its simplicity, the LA is not as popular as alternatives like variational Bayes or deep ensembles. This may be due to assumptions that the LA is expensive due to the involved Hessian computation, that it is difficult to implement, or that it yields inferior results. In this work we show that these are misconceptions: we (i) review the range of variants of the LA including versions with minimal cost overhead; (ii) introduce \"laplace\", an easy-to-use software library for PyTorch offering user-friendly access to all major flavors of the LA; and (iii) demonstrate through extensive experiments that the LA is competitive with more popular alternatives in terms of performance, while excelling in terms of computational cost. We hope that this work will serve as a catalyst to a wider adoption of the LA in practical deep learning, including in domains where Bayesian approaches are not typically considered at the moment.",
    "authors": [
      "Daxberger, Erik",
      "Kristiadi, Agustinus",
      "Immer, Alexander",
      "Eschenhagen, Runa",
      "Bauer, Matthias",
      "Hennig, Philipp"
    ]
  },
  {
    "id": "a7d8ae4569120b5bec12e7b6e9648b86",
    "title": "Hessian Eigenspectra of More Realistic Nonlinear Models",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a7d8ae4569120b5bec12e7b6e9648b86-Paper.pdf",
    "abstract": "Given an optimization problem, the Hessian matrix and its eigenspectrum can be used in many ways, ranging from designing more efficient second-order algorithms to performing model analysis and regression diagnostics. When nonlinear models and non-convex problems are considered, strong simplifying assumptions are often made to make Hessian spectral analysis more tractable.This leads to the question of how relevant the conclusions of such analyses are for realistic nonlinear models. In this paper, we exploit tools from random matrix theory to make a precise characterization of the Hessian eigenspectra for a broad family of nonlinear models that extends the classical generalized linear models, without relying on strong simplifying assumptions used previously. We show that, depending on the data properties, the nonlinear response model, and the loss function, the Hessian can have qualitatively different spectral behaviors: of bounded or unbounded support, with single- or multi-bulk, and with isolated eigenvalues on the left- or right-hand side of the main eigenvalue bulk. By focusing on such a simple but nontrivial model, our analysis takes a step forward to unveil the theoretical origin of many visually striking features observed in more realistic machine learning models.",
    "authors": [
      "Liao, Zhenyu",
      "Mahoney, Michael W."
    ]
  },
  {
    "id": "a7f0d2b95c60161b3f3c82f764b1d1c9",
    "title": "Explicable Reward Design for Reinforcement Learning Agents",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a7f0d2b95c60161b3f3c82f764b1d1c9-Paper.pdf",
    "abstract": "We study the design of explicable reward functions for a reinforcement learning agent while guaranteeing that an optimal policy induced by the function belongs to a set of target policies. By being explicable, we seek to capture two properties: (a) informativeness so that the rewards speed up the agent's convergence, and (b) sparseness as a proxy for ease of interpretability of the rewards. The key challenge is that higher informativeness typically requires dense rewards for many learning tasks, and existing techniques do not allow one to balance these two properties appropriately. In this paper, we investigate the problem from the perspective of discrete optimization and introduce a novel framework, ExpRD, to design explicable reward functions. ExpRD builds upon an informativeness criterion that captures the (sub-)optimality of target policies at different time horizons in terms of actions taken from any given starting state. We provide a  mathematical analysis of ExpRD, and show its connections to existing reward design techniques, including potential-based reward shaping. Experimental results on two navigation tasks demonstrate the effectiveness of ExpRD in designing explicable reward functions.",
    "authors": [
      "Devidze, Rati",
      "Radanovic, Goran",
      "Kamalaruban, Parameswaran",
      "Singla, Adish"
    ]
  },
  {
    "id": "a8166da05c5a094f7dc03724b41886e5",
    "title": "A Minimalist Approach to Offline Reinforcement Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a8166da05c5a094f7dc03724b41886e5-Paper.pdf",
    "abstract": "Offline reinforcement learning (RL) defines the task of learning from a fixed batch of data. Due to errors in value estimation from out-of-distribution actions, most offline RL algorithms take the approach of constraining or regularizing the policy with the actions contained in the dataset. Built on pre-existing RL algorithms, modifications to make an RL algorithm work offline comes at the cost of additional complexity. Offline RL algorithms introduce new hyperparameters and often leverage secondary components such as generative models, while adjusting the underlying RL algorithm. In this paper we aim to make a deep RL algorithm work while making minimal changes. We find that we can match the performance of state-of-the-art offline RL algorithms by simply adding a behavior cloning term to the policy update of an online RL algorithm and normalizing the data. The resulting algorithm is a simple to implement and tune baseline, while more than halving the overall run time by removing the additional computational overheads of previous methods. ",
    "authors": [
      "Fujimoto, Scott",
      "Gu, Shixiang (Shane)"
    ]
  },
  {
    "id": "a860a7886d7c7e2a8d3eaac96f76dc0d",
    "title": "SIMONe: View-Invariant, Temporally-Abstracted Object Representations via Unsupervised Video Decomposition",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a860a7886d7c7e2a8d3eaac96f76dc0d-Paper.pdf",
    "abstract": "To help agents reason about scenes in terms of their building blocks, we wish to extract the compositional structure of any given scene (in particular, the configuration and characteristics of objects comprising the scene). This problem is especially difficult when scene structure needs to be inferred while also estimating the agent\u2019s location/viewpoint, as the two variables jointly give rise to the agent\u2019s observations. We present an unsupervised variational approach to this problem. Leveraging the shared structure that exists across different scenes, our model learns to infer two sets of latent representations from RGB video input alone: a set of \"object\" latents, corresponding to the time-invariant, object-level contents of the scene, as well as a set of \"frame\" latents, corresponding to global time-varying elements such as viewpoint. This factorization of latents allows our model, SIMONe, to represent object attributes in an allocentric manner which does not depend on viewpoint. Moreover, it allows us to disentangle object dynamics and summarize their trajectories as time-abstracted, view-invariant, per-object properties. We demonstrate these capabilities, as well as the model's performance in terms of view synthesis and instance segmentation, across three procedurally generated video datasets.     ",
    "authors": [
      "Kabra, Rishabh",
      "Zoran, Daniel",
      "Erdogan, Goker",
      "Matthey, Loic",
      "Creswell, Antonia",
      "Botvinick, Matt",
      "Lerchner, Alexander",
      "Burgess, Chris"
    ]
  },
  {
    "id": "a87d27f712df362cd22c7a8ef823e987",
    "title": "Simple Stochastic and Online Gradient Descent Algorithms for Pairwise Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a87d27f712df362cd22c7a8ef823e987-Paper.pdf",
    "abstract": "Pairwise learning refers to learning tasks where  the loss function depends on a pair of  instances. It instantiates many important machine learning tasks such as bipartite ranking and metric learning. A popular approach to handle streaming data in pairwise learning is an online gradient descent (OGD) algorithm, where one needs to pair the current instance with a buffering set of previous instances with a sufficiently large size and therefore suffers from a scalability issue. In this paper, we propose simple stochastic and online gradient descent methods for pairwise learning. A notable difference from the existing studies  is that we only pair the current instance with the previous one in building a gradient direction, which is efficient in both the storage and computational complexity. We develop novel stability results, optimization, and generalization error bounds for both convex and nonconvex as well as both smooth and nonsmooth problems. We introduce novel techniques to decouple the dependency of models and the previous instance in both the optimization and generalization analysis. Our study resolves an open question on developing meaningful generalization bounds for OGD using a buffering set with a very small fixed size. We also extend our algorithms and stability analysis to develop differentially private SGD algorithms for pairwise learning which significantly improves the existing results.",
    "authors": [
      "YANG, ZHENHUAN",
      "Lei, Yunwen",
      "Wang, Puyu",
      "Yang, Tianbao",
      "Ying, Yiming"
    ]
  },
  {
    "id": "a89cf525e1d9f04d16ce31165e139a4b",
    "title": "User-Level Differentially Private Learning via Correlated Sampling",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a89cf525e1d9f04d16ce31165e139a4b-Paper.pdf",
    "abstract": "Most works in learning with differential privacy (DP) have focused on the setting where each user has a single sample. In this work, we consider the setting where each user holds $m$ samples and the privacy protection is enforced at the level of each user's data.  We show that, in this setting, we may learn with a much fewer number of users. Specifically, we show that, as long as each user receives sufficiently many samples, we can learn any privately learnable class via an $(\\epsilon, \\delta)$-DP algorithm using only $O(\\log(1/\\delta)/\\epsilon)$ users. For $\\epsilon$-DP algorithms, we show that we can learn using only $O_{\\epsilon}(d)$ users even in the local model, where $d$ is the probabilistic representation dimension. In both cases, we show a nearly-matching lower bound on the number of users required.A crucial component of our results is a generalization of global stability [Bun, Livni, Moran, FOCS 2020]  that allows the use of public randomness. Under this relaxed notion, we employ a correlated sampling strategy to show that the global stability can be boosted to be arbitrarily close to one, at a polynomial expense in the number of samples.",
    "authors": [
      "Ghazi, Badih",
      "Kumar, Ravi",
      "Manurangsi, Pasin"
    ]
  },
  {
    "id": "a8e864d04c95572d1aece099af852d0a",
    "title": "Asynchronous Decentralized Online Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a8e864d04c95572d1aece099af852d0a-Paper.pdf",
    "abstract": "Most existing algorithms in decentralized online learning are conducted in the synchronous setting. However, synchronization makes these algorithms suffer from the straggler problem, i.e., fast learners have to wait for slow learners, which significantly reduces such algorithms' overall efficiency. To overcome this problem, we study decentralized online learning in the asynchronous setting, which allows different learners to work at their own pace. We first formulate the framework of Asynchronous Decentralized Online Convex Optimization, which specifies the whole process of asynchronous decentralized online learning using a sophisticated event indexing system. Then we propose the Asynchronous Decentralized Online Gradient-Push (AD-OGP) algorithm, which performs asymmetric gossiping communication and instantaneous model averaging. We further derive a regret bound of AD-OGP, which is a function of the network topology, the levels of processing delays, and the levels of communication delays. Extensive experiments show that AD-OGP runs significantly faster than its synchronous counterpart and also verify the theoretical results. ",
    "authors": [
      "Jiang, Jiyan",
      "Zhang, Wenpeng",
      "GU, Jinjie",
      "Zhu, Wenwu"
    ]
  },
  {
    "id": "a8ecbabae151abacba7dbde04f761c37",
    "title": "Multi-Step Budgeted Bayesian Optimization with Unknown Evaluation Costs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a8ecbabae151abacba7dbde04f761c37-Paper.pdf",
    "abstract": "Bayesian optimization (BO) is a sample-efficient approach to optimizing costly-to-evaluate black-box functions. Most BO methods ignore how evaluation costs may vary over the optimization domain. However, these costs can be highly heterogeneous and are often unknown in advance in many practical settings, such as hyperparameter tuning of machine learning algorithms or physics-based simulation optimization. Moreover, those few existing methods that acknowledge cost heterogeneity do not naturally accommodate a budget constraint on the total evaluation cost. This combination of unknown costs and a budget constraint introduces a new dimension to the exploration-exploitation trade-off, where learning about the cost incurs a cost itself. Existing methods do not reason about the various trade-offs of this problem in a principled way, leading often to poor performance. We formalize this claim by proving that the expected improvement and the expected improvement per unit of cost, arguably the two most widely used acquisition functions in practice, can be arbitrarily inferior with respect to the optimal non-myopic policy. To overcome the shortcomings of existing approaches,  we propose the budgeted multi-step expected improvement, a non-myopic acquisition function that generalizes classical expected improvement to the setting of heterogeneous and unknown evaluation costs. We show that our acquisition function outperforms existing methods in a variety of synthetic and real problems.",
    "authors": [
      "Astudillo, Raul",
      "Jiang, Daniel",
      "Balandat, Maximilian",
      "Bakshy, Eytan",
      "Frazier, Peter"
    ]
  },
  {
    "id": "a8f12d9486cbcc2fe0cfc5352011ad35",
    "title": "Model-Based Domain Generalization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a8f12d9486cbcc2fe0cfc5352011ad35-Paper.pdf",
    "abstract": "Despite remarkable success in a variety of applications, it is well-known that deep learning can fail catastrophically when presented with out-of-distribution data.  Toward addressing this challenge, we consider the \\emph{domain generalization} problem, wherein predictors are trained using data drawn from a family of related training domains and then evaluated on a distinct and unseen test domain.  We show that under a natural model of data generation and a concomitant invariance condition, the domain generalization problem is equivalent to an infinite-dimensional constrained statistical learning problem; this problem forms the basis of our approach, which we call Model-Based Domain Generalization.  Due to the inherent challenges in solving constrained optimization problems in deep learning, we exploit nonconvex duality theory to develop unconstrained relaxations of this statistical problem with tight bounds on the duality gap.  Based on this theoretical motivation, we propose a novel domain generalization algorithm with convergence guarantees.   In our experiments, we report improvements of up to 30% over state-of-the-art domain generalization baselines on several benchmarks including ColoredMNIST, Camelyon17-WILDS, FMoW-WILDS, and PACS.",
    "authors": [
      "Robey, Alexander",
      "Pappas, George J.",
      "Hassani, Hamed"
    ]
  },
  {
    "id": "a8f15eda80c50adb0e71943adc8015cf",
    "title": "$\\alpha$-IoU: A Family of Power Intersection over Union Losses for Bounding Box Regression",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a8f15eda80c50adb0e71943adc8015cf-Paper.pdf",
    "abstract": "Bounding box (bbox) regression is a fundamental task in computer vision. So far, the most commonly used loss functions for bbox regression are the Intersection over Union (IoU) loss and its variants. In this paper, we generalize existing IoU-based losses to a new family of power IoU losses that have a power IoU term and an additional power regularization term with a single power parameter $\\alpha$. We call this new family of losses the $\\alpha$-IoU losses and analyze properties such as order preservingness and loss/gradient reweighting. Experiments on multiple object detection benchmarks and models demonstrate that $\\alpha$-IoU losses, 1) can surpass existing IoU-based losses by a noticeable performance margin; 2) offer detectors more flexibility in achieving different levels of bbox regression accuracy by modulating $\\alpha$; and 3) are more robust to small datasets and noisy bboxes.",
    "authors": [
      "HE, JIABO",
      "Erfani, Sarah",
      "Ma, Xingjun",
      "Bailey, James",
      "Chi, Ying",
      "Hua, Xian-Sheng"
    ]
  },
  {
    "id": "a8fbbd3b11424ce032ba813493d95ad7",
    "title": "Practical Large-Scale Linear Programming using Primal-Dual Hybrid Gradient",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a8fbbd3b11424ce032ba813493d95ad7-Paper.pdf",
    "abstract": "We present PDLP, a practical first-order method for linear programming (LP) that can solve to the high levels of accuracy that are expected in traditional LP applications. In addition, it can scale to very large problems because its core operation is matrix-vector multiplications. PDLP is derived by applying the primal-dual hybrid gradient (PDHG) method, popularized by Chambolle and Pock (2011), to a saddle-point formulation of LP. PDLP enhances PDHG for LP by combining several new techniques with older tricks from the literature; the enhancements include diagonal preconditioning, presolving, adaptive step sizes, and adaptive restarting. PDLP improves the state of the art for first-order methods applied to LP. We compare PDLP with SCS, an ADMM-based solver, on a set of 383 LP instances derived from MIPLIB 2017. With a target of $10^{-8}$ relative accuracy and 1 hour time limit, PDLP achieves a 6.3x reduction in the geometric mean of solve times and a 4.6x reduction in the number of instances unsolved (from 227 to 49). Furthermore, we highlight standard benchmark instances and a large-scale application (PageRank) where our open-source prototype of PDLP, written in Julia, outperforms a commercial LP solver.",
    "authors": [
      "Applegate, David",
      "Diaz, Mateo",
      "Hinder, Oliver",
      "Lu, Haihao",
      "Lubin, Miles",
      "O'Donoghue, Brendan",
      "Schudy, Warren"
    ]
  },
  {
    "id": "a928731e103dfc64c0027fa84709689e",
    "title": "On the Provable Generalization of Recurrent Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a928731e103dfc64c0027fa84709689e-Paper.pdf",
    "abstract": "Recurrent Neural Network (RNN) is a fundamental structure in deep learning. Recently, some works study the training process of over-parameterized neural networks, and show that over-parameterized networks can learn functions in some notable concept classes with a provable generalization error bound. In this paper, we analyze the training and generalization for RNNs with random initialization, and provide the following improvements over recent works:(1) For a RNN with input sequence $x=(X_1,X_2,...,X_L)$, previous works study to learn functions that are summation of $f(\\beta^T_lX_l)$ and require normalized conditions that $||X_l||\\leq\\epsilon$ with some very small $\\epsilon$ depending on the complexity of $f$. In this paper, using detailed analysis about the neural tangent kernel matrix, we prove a generalization error bound to learn such functions without normalized conditions and show that some notable concept classes are learnable with  the numbers of iterations and samples scaling almost-polynomially in the input length $L$.(2) Moreover, we prove a novel result to learn N-variables functions of input sequence  with the form $f(\\beta^T[X_{l_1},...,X_{l_N}])$, which do not belong to the ``additive'' concept class, i,e., the summation of function $f(X_l)$. And we show that when either $N$ or $l_0=\\max(l_1,..,l_N)-\\min(l_1,..,l_N)$ is small, $f(\\beta^T[X_{l_1},...,X_{l_N}])$ will be learnable with the number iterations and samples scaling  almost-polynomially in the input length $L$.",
    "authors": [
      "Wang, Lifu",
      "Shen, Bo",
      "Hu, Bo",
      "Cao, Xing"
    ]
  },
  {
    "id": "a952ddeda0b7e2c20744e52e728e5594",
    "title": "Differentiable Spline Approximations",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a952ddeda0b7e2c20744e52e728e5594-Paper.pdf",
    "abstract": "The paradigm of differentiable programming has significantly enhanced the scope of machine learning via the judicious use of gradient-based optimization. However, standard differentiable programming methods (such as autodiff) typically require that the machine learning models be differentiable, limiting their applicability. Our goal in this paper is to use a new, principled approach to extend gradient-based optimization to functions well modeled by splines, which encompass a large family of piecewise polynomial models. We derive the form of the (weak) Jacobian of such functions and show that it exhibits a block-sparse structure that can be computed implicitly and efficiently. Overall, we show that leveraging this redesigned Jacobian in the form of a differentiable \"layer'' in predictive models leads to improved performance in diverse applications such as image segmentation, 3D point cloud reconstruction, and finite element analysis. We also open-source the code at \\url{https://github.com/idealab-isu/DSA}.",
    "authors": [
      "Cho, Minsu",
      "Balu, Aditya",
      "Joshi, Ameya",
      "Deva Prasad, Anjana",
      "Khara, Biswajit",
      "Sarkar, Soumik",
      "Ganapathysubramanian, Baskar",
      "Krishnamurthy, Adarsh",
      "Hegde, Chinmay"
    ]
  },
  {
    "id": "a97f6e2fedcabc887911dc9b5fd3ccc3",
    "title": "Rate-Optimal Subspace Estimation on Random Graphs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a97f6e2fedcabc887911dc9b5fd3ccc3-Paper.pdf",
    "abstract": "We study the theory of random bipartite graph whose adjacency matrix is generated according to a connectivity matrix $M$. We consider the bipartite graph to be sparse, i.e., the entries of $M$ are upper bounded by certain sparsity parameter. We show that the performance of estimating the connectivity matrix $M$ depends on the sparsity of the graph. We focus on two measurement of performance of estimation: the error of estimating $M$ and the error of estimating the column space of $M$. In the first case, we consider the operator norm and Frobenius norm of the difference between the estimation and the true connectivity matrix. In the second case, the performance will be measured by the difference between the estimated projection matrix and the true projection matrix in operator norm and Frobenius norm. We will show that the estimators we propose achieve the minimax optimal rate.",
    "authors": [
      "Zhou, Zhixin",
      "Zhou, Fan",
      "Li, Ping",
      "Zhang, Cun-Hui"
    ]
  },
  {
    "id": "a9a1d5317a33ae8cef33961c34144f84",
    "title": "Estimating the Unique Information of Continuous Variables",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a9a1d5317a33ae8cef33961c34144f84-Paper.pdf",
    "abstract": "The integration and transfer of information from multiple sources to multiple targets is a core motive of neural systems. The emerging field of partial information decomposition (PID) provides a novel information-theoretic lens into these mechanisms by identifying synergistic, redundant, and unique contributions to the mutual information between one and several variables. While many works have studied aspects of PID for Gaussian and discrete distributions, the case of general continuous distributions is still uncharted territory. In this work we present a method for estimating the unique information in continuous distributions, for the case of one versus two variables. Our method solves the associated optimization problem over the space of distributions with fixed bivariate  marginals by combining copula decompositions and techniques developed to optimize variational autoencoders. We obtain excellent agreement with known analytic results for Gaussians, and  illustrate the power of our new approach in several brain-inspired neural models. Our method is capable of recovering the effective connectivity of a chaotic network of rate neurons, and uncovers a complex trade-off between redundancy, synergy and unique information in recurrent networks trained to solve a generalized XOR~task.",
    "authors": [
      "Pakman, Ari",
      "Nejatbakhsh, Amin",
      "Gilboa, Dar",
      "Makkeh, Abdullah",
      "Mazzucato, Luca",
      "Wibral, Michael",
      "Schneidman, Elad"
    ]
  },
  {
    "id": "a9b4ec2eb4ab7b1b9c3392bb5388119d",
    "title": "Reliable Causal Discovery with Improved Exact Search and Weaker Assumptions",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a9b4ec2eb4ab7b1b9c3392bb5388119d-Paper.pdf",
    "abstract": "Many of the causal discovery methods rely on the faithfulness assumption to guarantee asymptotic correctness. However, the assumption can be approximately violated in many ways, leading to sub-optimal solutions. Although there is a line of research in Bayesian network structure learning that focuses on weakening the assumption, such as exact search methods with well-defined score functions, they do not scale well to large graphs. In this work, we introduce several strategies to improve the scalability of exact score-based methods in the linear Gaussian setting. In particular, we develop a super-structure estimation method based on the support of inverse covariance matrix which requires assumptions that are strictly weaker than faithfulness, and apply it to restrict the search space of exact search. We also propose a local search strategy that performs exact search on the local clusters formed by each variable and its neighbors within two hops in the super-structure. Numerical experiments validate the efficacy of the proposed procedure, and demonstrate that it scales up to hundreds of nodes with a high accuracy.",
    "authors": [
      "Ng, Ignavier",
      "Zheng, Yujia",
      "Zhang, Jiji",
      "Zhang, Kun"
    ]
  },
  {
    "id": "a9eb812238f753132652ae09963a05e9",
    "title": "Node Dependent Local Smoothing for Scalable Graph Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/a9eb812238f753132652ae09963a05e9-Paper.pdf",
    "abstract": "Recent works reveal that feature or label smoothing lies at the core of Graph Neural Networks (GNNs). Concretely, they show feature smoothing combined with simple linear regression achieves comparable performance with the carefully designed GNNs, and a simple MLP model with label smoothing of its prediction can outperform the vanilla GCN. Though an interesting finding, smoothing has not been well understood, especially regarding how to control the extent of smoothness. Intuitively, too small or too large smoothing iterations may cause under-smoothing or over-smoothing and can lead to sub-optimal performance. Moreover, the extent of smoothness is node-specific, depending on its degree and local structure. To this end, we propose a novel algorithm called node-dependent local smoothing (NDLS), which aims to control the smoothness of every node by setting a node-specific smoothing iteration. Specifically, NDLS computes influence scores based on the adjacency matrix and selects the iteration number by setting a threshold on the scores. Once selected, the iteration number can be applied to both feature smoothing and label smoothing. Experimental results demonstrate that NDLS enjoys high accuracy -- state-of-the-art performance on node classifications tasks, flexibility -- can be incorporated with any models, scalability and efficiency -- can support large scale graphs with fast training.",
    "authors": [
      "Zhang, Wentao",
      "Yang, Mingyu",
      "Sheng, Zeang",
      "Li, Yang",
      "Ouyang, Wen",
      "Tao, Yangyu",
      "Yang, Zhi",
      "CUI, Bin"
    ]
  },
  {
    "id": "aa495e18c7e3a21a4e48923b92048a61",
    "title": "Parallel and Efficient Hierarchical k-Median Clustering",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/aa495e18c7e3a21a4e48923b92048a61-Paper.pdf",
    "abstract": "As a fundamental unsupervised learning task, hierarchical clustering has been extensively studied in the past decade. In particular, standard metric formulations as hierarchical $k$-center, $k$-means,  and $k$-median received a lot of attention and the problems have been studied extensively in different models of computation. Despite all this interest, not many efficient parallel algorithms are known for these problems. In this paper we introduce a new parallel algorithm for the Euclidean hierarchical $k$-median problem that, when using machines with memory $s$ (for $s\\in \\Omega(\\log^2 (n+\\Delta+d))$), outputs a hierarchical clustering such that for every fixed value of $k$ the cost of the solution is at most an $O(\\min\\{d, \\log n\\} \\log \\Delta)$ factor larger in expectation than that of an optimal solution. Furthermore, we also get that for all $k$ simultanuously the cost of the solution is at most an $O(\\min\\{d, \\log n\\} \\log \\Delta \\log (\\Delta d n))$ factor bigger that the corresponding optimal solution.  The algorithm requires in $O\\left(\\log_{s} (nd\\log(n+\\Delta))\\right)$ rounds. Here $d$ is the dimension of the data set and $\\Delta$ is  the ratio between the maximum and minimum distance of two points in the input dataset. To the best of our knowledge, this is the first \\emph{parallel} algorithm  for the hierarchical $k$-median problem with theoretical guarantees. We further complement our theoretical results with an empirical study of our algorithm that shows its effectiveness in practice.",
    "authors": [
      "Cohen-Addad, Vincent",
      "Lattanzi, Silvio",
      "Norouzi-Fard, Ashkan",
      "Sohler, Christian",
      "Svensson, Ola"
    ]
  },
  {
    "id": "aa97d584861474f4097cf13ccb5325da",
    "title": "Human-Adversarial Visual Question Answering",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/aa97d584861474f4097cf13ccb5325da-Paper.pdf",
    "abstract": "Performance on the most commonly used Visual Question Answering dataset (VQA v2) is starting to approach human accuracy. However, in interacting with state-of-the-art VQA models, it is clear that the problem is far from being solved. In order to stress test VQA models, we benchmark them against human-adversarial examples. Human subjects interact with a state-of-the-art VQA model, and for each image in the dataset, attempt to find a question where the model\u2019s predicted answer is incorrect. We find that a wide range of state-of-the-art models perform poorly when evaluated on these examples. We conduct an extensive analysis of the collected adversarial examples and provide guidance on future research directions. We hope that this Adversarial VQA (AdVQA) benchmark can help drive progress in the field and advance the state of the art.",
    "authors": [
      "Sheng, Sasha",
      "Singh, Amanpreet",
      "Goswami, Vedanuj",
      "Magana, Jose",
      "Thrush, Tristan",
      "Galuba, Wojciech",
      "Parikh, Devi",
      "Kiela, Douwe"
    ]
  },
  {
    "id": "aad64398a969ec3186800d412fa7ab31",
    "title": "Across-animal odor decoding by probabilistic manifold alignment",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/aad64398a969ec3186800d412fa7ab31-Paper.pdf",
    "abstract": "Identifying the common structure of neural dynamics across subjects is key for extracting unifying principles of brain computation and for many brain machine interface applications. Here, we propose a novel probabilistic approach for aligning stimulus-evoked responses from multiple animals in a common low dimensional manifold and use hierarchical inference to identify which stimulus drives neural activity in any given trial. Our probabilistic decoder is robust to a range of features of the neural responses and significantly outperforms existing neural alignment procedures. When applied to recordings from the mouse olfactory bulb, our approach reveals low-dimensional population dynamics that are odor specific and have consistent structure across animals. Thus, our decoder can be used for increasing the robustness and scalability of neural-based chemical detection.",
    "authors": [
      "Herrero-Vidal, Pedro",
      "Rinberg, Dmitry",
      "Savin, Cristina"
    ]
  },
  {
    "id": "aaebdb8bb6b0e73f6c3c54a0ab0c6415",
    "title": "Excess Capacity and Backdoor Poisoning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/aaebdb8bb6b0e73f6c3c54a0ab0c6415-Paper.pdf",
    "abstract": "A backdoor data poisoning attack is an adversarial attack wherein the attacker injects several watermarked, mislabeled training examples into a training set. The watermark does not impact the test-time performance of the model on typical data; however, the model reliably errs on watermarked examples.To gain a better foundational understanding of backdoor data poisoning attacks, we present a formal theoretical framework within which one can discuss backdoor data poisoning attacks for classification problems. We then use this to analyze important statistical and computational issues surrounding these attacks.On the statistical front, we identify a parameter we call the memorization capacity that captures the intrinsic vulnerability of a learning problem to a backdoor attack. This allows us to argue about the robustness of several natural learning problems to backdoor attacks. Our results favoring the attacker involve presenting explicit constructions of backdoor attacks, and our robustness results show that some natural problem settings cannot yield successful backdoor attacks.From a computational standpoint, we show that under certain assumptions, adversarial training can detect the presence of backdoors in a training set. We then show that under similar assumptions, two closely related problems we call backdoor filtering and robust generalization are nearly equivalent. This implies that it is both asymptotically necessary and sufficient to design algorithms that can identify watermarked examples in the training set in order to obtain a learning algorithm that both generalizes well to unseen data and is robust to backdoors.",
    "authors": [
      "Manoj, Naren",
      "Blum, Avrim"
    ]
  },
  {
    "id": "aaf2979785deb27864047e0ea40ef1b7",
    "title": "A Convergence Analysis of Gradient Descent on Graph Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/aaf2979785deb27864047e0ea40ef1b7-Paper.pdf",
    "abstract": "Graph Neural Networks~(GNNs) are a powerful class of architectures for solving learning problems on graphs. While many variants of GNNs have been proposed in the literature and have achieved strong empirical performance, their theoretical properties are less well understood. In this work we study the convergence properties of the gradient descent algorithm when used to train GNNs. In particular, we consider the realizable setting where the data is generated from a network with unknown weights and our goal is to study conditions under which gradient descent on a GNN architecture can recover near optimal solutions. While such analysis has been performed in recent years for other architectures such as fully connected feed-forward networks, the message passing nature of the updates in a GNN poses a new challenge in understanding the nature of the gradient descent updates. We take a step towards overcoming this by proving that for the case of deep linear GNNs gradient descent provably recovers solutions up to error $\\epsilon$ in $O(\\text{log}(1/\\epsilon))$ iterations, under natural assumptions on the data distribution. Furthermore, for the case of one-round GNNs with ReLU activations, we show that gradient descent provably recovers solutions up to error $\\epsilon$ in $O(\\frac{1}{\\epsilon^2} \\log(\\frac{1}{\\epsilon}))$ iterations. ",
    "authors": [
      "Awasthi, Pranjal",
      "Das, Abhimanyu",
      "Gollapudi, Sreenivas"
    ]
  },
  {
    "id": "ab233b682ec355648e7891e66c54191b",
    "title": "Differentiable rendering with perturbed optimizers",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ab233b682ec355648e7891e66c54191b-Paper.pdf",
    "abstract": "Reasoning about 3D scenes from their 2D image projections is one of the core problems in computer vision. Solutions to this inverse and ill-posed problem typically involve a search for models that best explain observed image data. Notably, images depend both on the properties of observed scenes and on the process of image formation. Hence, if optimization techniques should be used to explain images, it is crucial to design differentable functions for the projection of 3D scenes into images, also known as differentiable rendering. Previous approaches to differentiable rendering typically replace non-differentiable operations by smooth approximations, impacting the subsequent 3D estimation. In this paper, we take a more general approach and study differentiable renderers through the prism of randomized optimization and the related notion of perturbed optimizers. In particular, our work highlights the link between some well-known differentiable renderer formulations and randomly smoothed optimizers, and introduces differentiable perturbed renderers. We also propose a variance reduction mechanism to alleviate the computational burden inherent to perturbed optimizers and introduce an adaptive scheme to automatically adjust the smoothing parameters of the rendering process. We apply our method to 3D scene reconstruction and demonstrate its advantages on the tasks of 6D pose estimation and 3D mesh reconstruction.  By providing informative gradients that can be used as a strong supervisory signal, we demonstrate the benefits of perturbed renderers to obtain more accurate solutions when compared to the state-of-the-art alternatives using smooth gradient approximations.",
    "authors": [
      "Le Lidec, Quentin",
      "Laptev, Ivan",
      "Schmid, Cordelia",
      "Carpentier, Justin"
    ]
  },
  {
    "id": "ab452534c5ce28c4fbb0e102d4a4fb2e",
    "title": "BCORLE($\\lambda$): An Offline Reinforcement Learning and Evaluation Framework for Coupons Allocation in E-commerce Market",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ab452534c5ce28c4fbb0e102d4a4fb2e-Paper.pdf",
    "abstract": "Coupons allocation is an important tool for enterprises to increase the activity and loyalty of users on the e-commerce market. One fundamental problem related is how to allocate coupons within a fixed budget while maximizing users' retention on the e-commerce platform. The online e-commerce environment is complicated and ever changing, so it requires the coupons allocation policy learning can quickly adapt to the changes of the company's business strategy. Unfortunately, existing studies with a huge computation overhead can hardly satisfy the requirements of real-time and fast-response in the real world. Specifically, the problem of coupons allocation within a fixed budget is usually formulated as a Lagrangian problem. Existing solutions need to re-learn the policy once the value of Lagrangian multiplier variable $\\lambda$ is updated, causing a great computation overhead. Besides, a mature e-commerce market often faces tens of millions of users and dozens of types of coupons which construct the huge policy space, further increasing the difficulty of solving the problem. To tackle with above problems, we propose a budget constrained offline reinforcement learning and evaluation with $\\lambda$-generalization (BCORLE($\\lambda$)) framework. The proposed method can help enterprises develop a coupons allocation policy which greatly improves users' retention rate on the platform while ensuring the cost does not exceed the budget. Specifically, $\\lambda$-generalization method is proposed to lead the policy learning process can be executed according to different $\\lambda$ values adaptively, avoiding re-learning new polices from scratch. Thus the computation overhead is greatly reduced. Further, a novel offline reinforcement learning method and an off-policy evaluation algorithm are proposed for policy learning and policy evaluation, respectively. Finally, experiments on the simulation platform and real-world e-commerce market validate the effectiveness of our approach.",
    "authors": [
      "Zhang, Yang",
      "Tang, Bo",
      "Yang, Qingyu",
      "An, Dou",
      "Tang, Hongyin",
      "Xi, Chenyang",
      "LI, Xueying",
      "Xiong, Feiyu"
    ]
  },
  {
    "id": "ab49b208848abe14418090d95df0d590",
    "title": "Nested Variational Inference",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ab49b208848abe14418090d95df0d590-Paper.pdf",
    "abstract": "We develop nested variational inference (NVI), a family of methods that learn proposals for nested importance samplers by minimizing an forward or reverse KL divergence at each level of nesting. NVI is applicable to many commonly-used importance sampling strategies and provides a mechanism for learning intermediate densities, which can serve as heuristics to guide the sampler. Our experiments apply NVI to (a) sample from a multimodal distribution using a learned annealing path (b) learn heuristics that approximate the likelihood of future observations in a hidden Markov model and (c) to perform amortized inference in hierarchical deep generative models. We observe that optimizing nested objectives leads to improved sample quality in terms of log average weight and effective sample size.",
    "authors": [
      "Zimmermann, Heiko",
      "Wu, Hao",
      "Esmaeili, Babak",
      "van de Meent, Jan-Willem"
    ]
  },
  {
    "id": "ab6439fa2daf0246f92eea433bca5ac4",
    "title": "Exponential Bellman Equation and Improved Regret Bounds for Risk-Sensitive Reinforcement Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ab6439fa2daf0246f92eea433bca5ac4-Paper.pdf",
    "abstract": "We study risk-sensitive reinforcement learning (RL) based on the entropic risk measure. Although existing works have established non-asymptotic regret guarantees for this problem, they leave open an exponential gap between the upper and lower bounds. We identify the deficiencies in existing algorithms and their analysis that result in such a gap. To remedy these deficiencies, we investigate a simple transformation of the risk-sensitive Bellman equations, which we call the exponential Bellman equation. The exponential Bellman equation inspires us to develop a novel analysis of Bellman backup procedures in risk-sensitive RL algorithms, and further motivates the design of a novel exploration mechanism. We show that these analytic and algorithmic innovations together lead to improved regret upper bounds over existing ones.",
    "authors": [
      "Fei, Yingjie",
      "Yang, Zhuoran",
      "Chen, Yudong",
      "Wang, Zhaoran"
    ]
  },
  {
    "id": "ab73f542b6d60c4de151800b8abc0a6c",
    "title": "On sensitivity of meta-learning to support data",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ab73f542b6d60c4de151800b8abc0a6c-Paper.pdf",
    "abstract": "Meta-learning algorithms are widely used for few-shot learning. For example, image recognition systems that readily adapt to unseen classes after seeing only a few labeled examples. Despite their success, we show that modern meta-learning algorithms are extremely sensitive to the data used for adaptation, i.e. support data. In particular, we demonstrate the existence of (unaltered, in-distribution, natural) images that, when used for adaptation, yield accuracy as low as 4\\% or as high as 95\\% on standard few-shot image classification benchmarks. We explain our empirical findings in terms of class margins, which in turn suggests that robust and safe meta-learning requires larger margins than supervised learning.",
    "authors": [
      "Agarwal, Mayank",
      "Yurochkin, Mikhail",
      "Sun, Yuekai"
    ]
  },
  {
    "id": "ab9ebd57177b5106ad7879f0896685d4",
    "title": "On Large-Cohort Training for Federated Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ab9ebd57177b5106ad7879f0896685d4-Paper.pdf",
    "abstract": "Federated learning methods typically learn a model by iteratively sampling updates from a population of clients. In this work, we explore how the number of clients sampled at each round (the cohort size) impacts the quality of the learned model and the training dynamics of federated learning algorithms. Our work poses three fundamental questions. First, what challenges arise when trying to scale federated learning to larger cohorts? Second, what parallels exist between cohort sizes in federated learning, and batch sizes in centralized learning? Last, how can we design federated learning methods that effectively utilize larger cohort sizes? We give partial answers to these questions based on extensive empirical evaluation. Our work highlights a number of challenges stemming from the use of larger cohorts. While some of these (such as generalization issues and diminishing returns) are analogs of large-batch training challenges, others (including catastrophic training failures and fairness concerns) are unique to federated learning.",
    "authors": [
      "Charles, Zachary",
      "Garrett, Zachary",
      "Huo, Zhouyuan",
      "Shmulyian, Sergei",
      "Smith, Virginia"
    ]
  },
  {
    "id": "aba53da2f6340a8b89dc96d09d0d0430",
    "title": "Generic Neural Architecture Search via Regression",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/aba53da2f6340a8b89dc96d09d0d0430-Paper.pdf",
    "abstract": "Most existing neural architecture search (NAS) algorithms are dedicated to and evaluated by the downstream tasks, e.g., image classification in computer vision. However, extensive experiments have shown that, prominent neural architectures, such as ResNet in computer vision and LSTM in natural language processing, are generally good at extracting patterns from the input data and perform well on different downstream tasks. In this paper, we attempt to answer two fundamental questions related to NAS. (1) Is it necessary to use the performance of specific downstream tasks to evaluate and search for good neural architectures? (2) Can we perform NAS effectively and efficiently while being agnostic to the downstream tasks? To answer these questions, we propose a novel and generic NAS framework, termed Generic NAS (GenNAS). GenNAS does not use task-specific labels but instead adopts regression on a set of manually designed synthetic signal bases for architecture evaluation. Such a self-supervised regression task can effectively evaluate the intrinsic power of an architecture to capture and transform the input signal patterns, and allow more sufficient usage of training samples. Extensive experiments across 13 CNN search spaces and one NLP space demonstrate the remarkable efficiency of GenNAS using regression, in terms of both evaluating the neural architectures (quantified by the ranking correlation Spearman's rho between the approximated performances and the downstream task performances) and the convergence speed for training (within a few seconds). For example, on NAS-Bench-101, GenNAS achieves 0.85 rho while the existing efficient methods only achieve 0.38. We then propose an automatic task search to optimize the combination of synthetic signals using limited downstream-task-specific labels, further improving the performance of GenNAS. We also thoroughly evaluate GenNAS's generality and end-to-end NAS performance on all search spaces, which outperforms almost all existing works with significant speedup. For example, on NASBench-201, GenNAS can find near-optimal architectures within 0.3 GPU hour.",
    "authors": [
      "Li, Yuhong",
      "Hao, Cong",
      "Li, Pan",
      "Xiong, Jinjun",
      "Chen, Deming"
    ]
  },
  {
    "id": "abb9d15b3293a96a3ea116867b2b16d5",
    "title": "The best of both worlds: stochastic and adversarial episodic MDPs with unknown transition",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/abb9d15b3293a96a3ea116867b2b16d5-Paper.pdf",
    "abstract": "We consider the best-of-both-worlds problem for learning an episodic Markov Decision Process through $T$ episodes, with the goal of achieving $\\widetilde{\\mathcal{O}}(\\sqrt{T})$ regret when the losses are adversarial and simultaneously $\\mathcal{O}(\\log T)$ regret when the losses are (almost) stochastic. Recent work by [Jin and Luo, 2020]  achieves this goal when the fixed transition is known, and leaves the case of unknown transition as a major open question. In this work, we resolve this open problem by using the same Follow-the-Regularized-Leader (FTRL) framework together with a set of new techniques. Specifically, we first propose a loss-shifting trick in the FTRL analysis, which greatly simplifies the approach of [Jin and Luo, 2020] and already improves their results for the known transition case. Then, we extend this idea to the unknown transition case and develop a novel analysis which upper bounds the transition estimation error by the regret itself in the stochastic setting, a key property to ensure $\\mathcal{O}(\\log T)$ regret.",
    "authors": [
      "Jin, Tiancheng",
      "Huang, Longbo",
      "Luo, Haipeng"
    ]
  },
  {
    "id": "abdbeb4d8dbe30df8430a8394b7218ef",
    "title": "Private learning implies quantum stability",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/abdbeb4d8dbe30df8430a8394b7218ef-Paper.pdf",
    "abstract": "Learning an unknown n-qubit quantum state rho is a fundamental challenge in quantum computing. Information-theoretically, it is known that tomography requires exponential in n many copies of rho to estimate its entries. Motivated by learning theory, Aaronson et al. introduced many (weaker) learning models: the PAC model of learning states (Proceedings of Royal Society A'07), shadow tomography (STOC'18) for learning shadows\" of a state, a model that also requires learners to be differentially private (STOC'19) and the online model of learning states (NeurIPS'18). In these models it was shown that an unknown state can be learnedapproximately\" using linear in n many copies of rho. But is there any relationship between these models? In this paper we prove a sequence of (information-theoretic) implications from differentially-private PAC learning to online learning and then to quantum stability.Our main result generalizes the recent work of Bun, Livni and Moran (Journal of the ACM'21) who showed that finite Littlestone dimension (of Boolean-valued concept classes) implies PAC learnability in the (approximate) differentially private (DP) setting. We first consider their work in the real-valued setting and further extend to their techniques to the setting of learning quantum states. Key to our results is our generic quantum online learner, Robust Standard Optimal Algorithm (RSOA), which is robust to adversarial imprecision. We then show information-theoretic implications between DP learning quantum states in the PAC model, learnability of quantum states in the one-way communication model, online learning of quantum states, quantum stability (which is our conceptual contribution), various combinatorial parameters and give further applications to gentle shadow tomography and noisy quantum state learning.",
    "authors": [
      "Quek, Yihui",
      "Arunachalam, Srinivasan",
      "Smolin, John A"
    ]
  },
  {
    "id": "abe8e03e3ac71c2ec3bfb0de042638d8",
    "title": "Interesting Object, Curious Agent: Learning Task-Agnostic Exploration",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/abe8e03e3ac71c2ec3bfb0de042638d8-Paper.pdf",
    "abstract": "Common approaches for task-agnostic exploration learn tabula-rasa --the agent assumes isolated environments and no prior knowledge or experience. However, in the real world, agents learn in many environments and always come with prior experiences as they explore new ones. Exploration is a lifelong process. In this paper, we propose a paradigm change in the formulation and evaluation of task-agnostic exploration. In this setup, the agent first learns to explore across many environments without any extrinsic goal in a task-agnostic manner.Later on, the agent effectively transfers the learned exploration policy to better explore new environments when solving tasks. In this context, we evaluate several baseline exploration strategies and present a simple yet effective approach to learning task-agnostic exploration policies. Our key idea is that there are two components of exploration: (1) an agent-centric component encouraging exploration of unseen parts of the environment based on an agent\u2019s belief; (2) an environment-centric component encouraging exploration of inherently interesting objects. We show that our formulation is effective and provides the most consistent exploration across several training-testing environment pairs. We also introduce benchmarks and metrics for evaluating task-agnostic exploration strategies. The source code is available at https://github.com/sparisi/cbet/.",
    "authors": [
      "Parisi, Simone",
      "Dean, Victoria",
      "Pathak, Deepak",
      "Gupta, Abhinav"
    ]
  },
  {
    "id": "abea47ba24142ed16b7d8fbf2c740e0d",
    "title": "SimiGrad: Fine-Grained Adaptive Batching for Large Scale Training using Gradient Similarity Measurement",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/abea47ba24142ed16b7d8fbf2c740e0d-Paper.pdf",
    "abstract": "Large scale training requires massive parallelism to finish the training within a reasonable amount of time. To support massive parallelism, large batch training is the key enabler but often at the cost of generalization performance. Existing works explore adaptive batching or hand-tuned static large batching, in order to strike a balance between the computational efficiency and the performance. However, these methods can provide only coarse-grained adaption (e.g., at a epoch level) due to the intrinsic expensive calculation or hand tuning requirements. In this paper, we propose a fully automated and lightweight adaptive batching methodology to enable fine-grained batch size adaption (e.g., at a mini-batch level) that can achieve state-of-the-art performance with record breaking batch sizes. The core component of our method is a lightweight yet efficient representation of the critical gradient noise information. We open-source the proposed methodology by providing a plugin tool that supports mainstream machine learning frameworks. Extensive evaluations on popular benchmarks (e.g., CIFAR10, ImageNet, and BERT-Large) demonstrate that the proposed methodology outperforms state-of-the-art methodologies using adaptive batching approaches or hand-tuned static strategies in both performance and batch size. Particularly, we achieve a new state-of-the-art batch size of 78k in BERT-Large pretraining with SQuAD score 90.69 compared to 90.58 reported in previous state-of-the-art with 59k batch size.",
    "authors": [
      "Qin, Heyang",
      "Rajbhandari, Samyam",
      "Ruwase, Olatunji",
      "Yan, Feng",
      "Yang, Lei",
      "He, Yuxiong"
    ]
  },
  {
    "id": "abec16f483abb4f1810ca029aadf8446",
    "title": "Variational Inference for Continuous-Time Switching Dynamical Systems",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/abec16f483abb4f1810ca029aadf8446-Paper.pdf",
    "abstract": "Switching dynamical systems provide a powerful, interpretable modeling framework for inference in time-series data in, e.g., the natural sciences or engineering applications. Since many areas, such as biology or discrete-event systems, are naturally described in continuous time, we present a model based on a Markov jump process modulating a subordinated diffusion process. We provide the exact evolution equations for the prior and posterior marginal densities, the direct solutions of which are however computationally intractable. Therefore, we develop a new continuous-time variational inference algorithm, combining a Gaussian process approximation on the diffusion level with posterior inference for Markov jump processes. By minimizing the path-wise Kullback-Leibler divergence we obtain (i) Bayesian latent state estimates for arbitrary points on the real axis and (ii) point estimates of unknown system parameters, utilizing variational expectation maximization. We extensively evaluate our algorithm under the model assumption and for real-world examples.",
    "authors": [
      "K\u00f6hs, Lukas",
      "Alt, Bastian",
      "Koeppl, Heinz"
    ]
  },
  {
    "id": "abf0931987f2f8eb7a8d26f2c21fe172",
    "title": "Implicit Regularization in Matrix Sensing via Mirror Descent",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/abf0931987f2f8eb7a8d26f2c21fe172-Paper.pdf",
    "abstract": "We study discrete-time mirror descent applied to the unregularized empirical risk in matrix sensing. In both the general case of rectangular matrices and the particular case of positive semidefinite matrices, a simple potential-based analysis in terms of the Bregman divergence allows us to establish convergence of mirror descent---with different choices of the mirror maps---to a matrix that, among all global minimizers of the empirical risk, minimizes a quantity explicitly related to the nuclear norm, the Frobenius norm, and the von Neumann entropy. In both cases, this characterization implies that mirror descent, a first-order algorithm minimizing the unregularized empirical risk, recovers low-rank matrices under the same set of assumptions that are sufficient to guarantee recovery for nuclear-norm minimization. When the sensing matrices are symmetric and commute, we show that gradient descent with full-rank factorized parametrization is a first-order approximation to mirror descent, in which case we obtain an explicit characterization of the implicit bias of gradient flow as a by-product.",
    "authors": [
      "Wu, Fan",
      "Rebeschini, Patrick"
    ]
  },
  {
    "id": "ac10ff1941c540cd87c107330996f4f6",
    "title": "STORM+: Fully Adaptive SGD with Recursive Momentum for Nonconvex Optimization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ac10ff1941c540cd87c107330996f4f6-Paper.pdf",
    "abstract": "In this work we investigate stochastic non-convex optimization problems where the objective is an expectation over smooth loss functions, and the goal is to find an approximate stationary point. The most popular approach to handling such problems is variance reduction techniques, which are also known to obtain tight convergence rates, matching the lower bounds in this case. Nevertheless, these techniques require a careful maintenance of anchor points in conjunction with appropriately selected ``mega-batchsizes\". This leads to a challenging hyperparameter tuning problem, that weakens their practicality. Recently, [Cutkosky and Orabona, 2019] have shown that one can employ recursive momentum in order to avoid the use of anchor points and large batchsizes, and still obtain the optimal rate for this setting. Yet, their method called $\\rm{STORM}$ crucially relies on the knowledge of the smoothness, as well a bound on the gradient norms. In this work we propose $\\rm{STORM}^{+}$, a new method that is completely parameter-free, does not require large batch-sizes, and obtains the optimal $O(1/T^{1/3})$ rate for finding an approximate stationary point. Our work builds on the $\\rm{STORM}$ algorithm, in conjunction with a novel approach to adaptively set the learning rate and momentum parameters.",
    "authors": [
      "Levy, Kfir",
      "Kavis, Ali",
      "Cevher, Volkan"
    ]
  },
  {
    "id": "ac53fab47b547a0d47b77e424cf119ba",
    "title": "Skipping the Frame-Level: Event-Based Piano Transcription With Neural Semi-CRFs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ac53fab47b547a0d47b77e424cf119ba-Paper.pdf",
    "abstract": "Piano transcription systems are typically optimized to estimate pitch activity at each frame of audio. They are often followed by carefully designed heuristics and post-processing algorithms to estimate note events from the frame-level predictions. Recent methods have also framed piano transcription as a multi-task learning problem, where the activation of different stages of a note event are estimated independently. These practices are not well aligned with the desired outcome of the task, which is the specification of note intervals as holistic events, rather than the aggregation of disjoint observations. In this work, we propose a novel formulation of piano transcription, which is optimized to directly predict note events. Our method is based on Semi-Markov Conditional Random Fields (semi-CRF), which produce scores for intervals rather than individual frames. When formulating piano transcription in this way, we eliminate the need to rely on disjoint frame-level estimates for different stages of a note event. We conduct experiments on the MAESTRO dataset and demonstrate that the proposed model surpasses the current state-of-the-art for piano transcription. Our results suggest that the semi-CRF output layer, while still quadratic in complexity, is a simple, fast and well-performing solution for event-based prediction, and may lead to similar success in other areas which currently rely on frame-level estimates.",
    "authors": [
      "Yan, Yujia",
      "Cwitkowitz, Frank",
      "Duan, Zhiyao"
    ]
  },
  {
    "id": "ac56f8fe9eea3e4a365f29f0f1957c55",
    "title": "Deep Learning on a Data Diet: Finding Important Examples Early in Training",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ac56f8fe9eea3e4a365f29f0f1957c55-Paper.pdf",
    "abstract": "Recent success in deep learning has partially been driven by training increasingly overparametrized networks on ever larger datasets. It is therefore natural to ask: how much of the data is superfluous, which examples are important for generalization, and how do we find them? In this work, we make the striking observation that, in standard vision datasets, simple scores averaged over several weight initializations can be used to identify important examples very early in training. We propose two such scores\u2014the Gradient Normed (GraNd) and the Error L2-Norm (EL2N) scores\u2014and demonstrate their efficacy on a range of architectures and datasets by pruning significant fractions of training data without sacrificing test accuracy. In fact, using EL2N scores calculated a few epochs into training, we can prune half of the CIFAR10 training set while slightly improving test accuracy. Furthermore, for a given dataset, EL2N scores from one architecture or hyperparameter configuration generalize to other configurations. Compared to recent work that prunes data by discarding examples that are rarely forgotten over the course of training, our scores use only local information early in training. We also use our scores to detect noisy examples and study training dynamics through the lens of important examples\u2014we investigate how the data distribution shapes the loss surface and identify subspaces of the model\u2019s data representation that are relatively stable over training.",
    "authors": [
      "Paul, Mansheej",
      "Ganguli, Surya",
      "Dziugaite, Gintare Karolina"
    ]
  },
  {
    "id": "ac64504cc249b070772848642cffe6ff",
    "title": "BNS: Building Network Structures Dynamically for Continual Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ac64504cc249b070772848642cffe6ff-Paper.pdf",
    "abstract": "Continual learning (CL) of a sequence of tasks is often accompanied with the catastrophic forgetting(CF) problem. Existing research has achieved remarkable results in overcoming CF, especially for task continual learning. However, limited work has been done to achieve another important goal of CL,knowledge transfer.In this paper, we propose a technique (called BNS) to do both.  The novelty of BNS is that it dynamically builds a network to learn each new task to overcome CF and to transfer knowledge across tasks at the same time. Experimental results show that when the tasks are different (with little shared knowledge), BNS can already outperform the state-of-the-art baselines. When the tasks are similar and have shared knowledge, BNS outperforms the baselines substantially by a large margin due to its knowledge transfer capability.",
    "authors": [
      "Qin, Qi",
      "Hu, Wenpeng",
      "Peng, Han",
      "Zhao, Dongyan",
      "Liu, Bing"
    ]
  },
  {
    "id": "ac6b3cce8c74b2e23688c3e45532e2a7",
    "title": "Auditing Black-Box Prediction Models for Data Minimization Compliance",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ac6b3cce8c74b2e23688c3e45532e2a7-Paper.pdf",
    "abstract": "In this paper, we focus on auditing black-box prediction models for compliance with the GDPR\u2019s data minimization principle. This principle restricts prediction models to use the minimal information that is necessary for performing the task at hand. Given the challenge of the black-box setting, our key idea is to check if each of the prediction model\u2019s input features is individually necessary by assigning it some constant value (i.e., applying a simple imputation) across all prediction instances, and measuring the extent to which the model outcomes would change. We introduce a metric for data minimization that is based on model instability under simple imputations. We extend the applicability of this metric from a finite sample model to a distributional setting by introducing a probabilistic data minimization guarantee, which we derive using a Bayesian approach. Furthermore, we address the auditing problem under a constraint on the number of queries to the prediction system. We formulate the problem of allocating a budget of system queries to feasible simple imputations (for investigating model instability) as a multi-armed bandit framework with probabilistic success metrics. We define two bandit problems for providing a probabilistic data minimization guarantee at a given confidence level: a decision problem given a data minimization level, and a measurement problem given a fixed query budget. We design efficient algorithms for these auditing problems using novel exploration strategies that expand classical bandit strategies. Our experiments with real-world prediction systems show that our auditing algorithms significantly outperform simpler benchmarks in both measurement and decision problems.",
    "authors": [
      "Rastegarpanah, Bashir",
      "Gummadi, Krishna",
      "Crovella, Mark"
    ]
  },
  {
    "id": "ac73001b1d44f4925449ce09d9f5d5ca",
    "title": "Dueling Bandits with Team Comparisons",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ac73001b1d44f4925449ce09d9f5d5ca-Paper.pdf",
    "abstract": "We introduce the dueling teams problem, a new online-learning setting in which the learner observes noisy comparisons of disjoint pairs of $k$-sized teams from a universe of $n$ players. The goal of the learner is to minimize the number of duels required to identify, with high probability, a Condorcet winning team, i.e., a team which wins against any other disjoint team (with probability at least $1/2$).Noisy comparisons are linked to a total order on the teams. We formalize our model by building upon the dueling bandits setting (Yue et al. 2012) and provide several algorithms, both for stochastic and deterministic settings. For the stochastic setting, we provide a reduction to the classical dueling bandits setting, yielding an algorithm that identifies a Condorcet winning team within $\\mathcal{O}((n + k \\log (k)) \\frac{\\max(\\log\\log n, \\log k)}{\\Delta^2})$ duels, where $\\Delta$ is a gap parameter. For deterministic feedback, we additionally present a gap-independent algorithm that identifies a Condorcet winning team within $\\mathcal{O}(nk\\log(k)+k^5)$ duels. ",
    "authors": [
      "Cohen, Lee",
      "Schmidt-Kraepelin, Ulrike",
      "Mansour, Yishay"
    ]
  },
  {
    "id": "ac796a52db3f16bbdb6557d3d89d1c5a",
    "title": "Meta Internal Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ac796a52db3f16bbdb6557d3d89d1c5a-Paper.pdf",
    "abstract": "Internal learning for single-image generation is a framework, where a generator is trained to produce novel images based on a single image. Since these models are trained on a single image, they are limited in their scale and application. To overcome these issues, we propose a meta-learning approach that enables training over a collection of images, in order to model the internal statistics of the sample image more effectively.In the presented meta-learning approach, a single-image GAN model is generated given an input image, via a convolutional feedforward hypernetwork $f$. This network is trained over a dataset of images, allowing for feature sharing among different models, and for interpolation in the space of generative models. The generated single-image model contains a hierarchy of multiple generators and discriminators. It is therefore required to train the meta-learner in an adversarial manner, which requires careful design choices that we justify by a theoretical analysis. Our results show that the models obtained are as suitable as single-image GANs for many common image applications, {significantly reduce the training time per image without loss in performance}, and introduce novel capabilities, such as interpolation and feedforward modeling of novel images. ",
    "authors": [
      "Bensadoun, Raphael",
      "Gur, Shir",
      "Galanti, Tomer",
      "Wolf, Lior"
    ]
  },
  {
    "id": "ac9815bef801f58de83804bce86984ad",
    "title": "Uniform Convergence of Interpolators: Gaussian Width, Norm Bounds and Benign Overfitting",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ac9815bef801f58de83804bce86984ad-Paper.pdf",
    "abstract": "We consider interpolation learning in high-dimensional linear regression with Gaussian data, and prove a generic uniform convergence guarantee on the generalization error of interpolators in an arbitrary hypothesis class in terms of the class\u2019s Gaussian width.  Applying the generic bound to Euclidean norm balls recovers the consistency result of Bartlett et al. (2020) for minimum-norm interpolators, and confirms a prediction of Zhou et al. (2020) for near-minimal-norm interpolators in the special case of Gaussian data.  We demonstrate the generality of the bound by applying it to the simplex, obtaining a novel consistency result for minimum $\\ell_1$-norm interpolators (basis pursuit). Our results show how norm-based generalization bounds can explain and be used to analyze benign overfitting, at least in some settings.",
    "authors": [
      "Koehler, Frederic",
      "Zhou, Lijia",
      "Sutherland, Danica J.",
      "Srebro, Nathan"
    ]
  },
  {
    "id": "acaa23f71f963e96c8847585e71352d6",
    "title": "Adaptive wavelet distillation from neural networks through interpretations",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/acaa23f71f963e96c8847585e71352d6-Paper.pdf",
    "abstract": "Recent deep-learning models have achieved impressive prediction performance, but often sacrifice interpretability and computational efficiency. Interpretability is crucial in many disciplines, such as science and medicine, where models must be carefully vetted or where interpretation is the goal itself. Moreover, interpretable models are concise and often yield computational efficiency. Here, we propose adaptive wavelet distillation (AWD), a method which aims to distill information from a trained neural network into a wavelet transform. Specifically, AWD penalizes feature attributions of a neural network in the wavelet domain to learn an effective multi-resolution wavelet transform. The resulting model is highly predictive, concise, computationally efficient, and has properties (such as a multi-scale structure) which make it easy to interpret. In close collaboration with domain experts, we showcase how AWD addresses challenges in two real-world settings: cosmological parameter inference and molecular-partner prediction. In both cases, AWD yields a scientifically interpretable and concise model which gives predictive performance better than state-of-the-art neural networks. Moreover, AWD identifies predictive features that are scientifically meaningful in the context of respective domains. All code and models are released in a full-fledged package available on Github.",
    "authors": [
      "Ha, Wooseok",
      "Singh, Chandan",
      "Lanusse, Francois",
      "Upadhyayula, Srigokul",
      "Yu, Bin"
    ]
  },
  {
    "id": "acab0116c354964a558e65bdd07ff047",
    "title": "Generative Occupancy Fields for 3D Surface-Aware Image Synthesis",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/acab0116c354964a558e65bdd07ff047-Paper.pdf",
    "abstract": "The advent of generative radiance fields has significantly promoted the development of 3D-aware image synthesis. The cumulative rendering process in radiance fields makes training these generative models much easier since gradients are distributed over the entire volume, but leads to diffused object surfaces. In the meantime, compared to radiance fields occupancy representations could inherently ensure deterministic surfaces. However, if we directly apply occupancy representations to generative models, during training they will only receive sparse gradients located on object surfaces and eventually suffer from the convergence problem. In this paper, we propose Generative Occupancy Fields (GOF), a novel model based on generative radiance fields that can learn compact object surfaces without impeding its training convergence. The key insight of GOF is a dedicated transition from the cumulative rendering in radiance fields to rendering with only the surface points as the learned surface gets more and more accurate. In this way, GOF combines the merits of two representations in a unified framework. In practice, the training-time transition of start from radiance fields and march to occupancy representations is achieved in GOF by gradually shrinking the sampling region in its rendering process from the entire volume to a minimal neighboring region around the surface. Through comprehensive experiments on multiple datasets, we demonstrate that GOF can synthesize high-quality images with 3D consistency and simultaneously learn compact and smooth object surfaces. Our code is available at https://github.com/SheldonTsui/GOF_NeurIPS2021.",
    "authors": [
      "XU, Xudong",
      "Pan, Xingang",
      "Lin, Dahua",
      "Dai, Bo"
    ]
  },
  {
    "id": "acb55f9af76808c5fd5522dcdb519fde",
    "title": "Relaxed Marginal Consistency for Differentially Private Query Answering",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/acb55f9af76808c5fd5522dcdb519fde-Paper.pdf",
    "abstract": "Many differentially private algorithms for answering database queries involve astep that reconstructs a discrete data distribution from noisy measurements. Thisprovides consistent query answers and reduces error, but often requires space thatgrows exponentially with dimension. PRIVATE-PGM is a recent approach that usesgraphical models to represent the data distribution, with complexity proportional tothat of exact marginal inference in a graphical model with structure determined bythe co-occurrence of variables in the noisy measurements. PRIVATE-PGM is highlyscalable for sparse measurements, but may fail to run in high dimensions with densemeasurements. We overcome the main scalability limitation of PRIVATE-PGMthrough a principled approach that relaxes consistency constraints in the estimationobjective. Our new approach works with many existing private query answeringalgorithms and improves scalability or accuracy with no privacy cost.",
    "authors": [
      "McKenna, Ryan",
      "Pradhan, Siddhant",
      "Sheldon, Daniel R.",
      "Miklau, Gerome"
    ]
  },
  {
    "id": "ad0f7a25211abc3889cb0f420c85e671",
    "title": "Local policy search with Bayesian optimization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ad0f7a25211abc3889cb0f420c85e671-Paper.pdf",
    "abstract": "Reinforcement learning (RL) aims to find an optimal policy by interaction with an environment. Consequently, learning complex behavior requires a vast number of samples, which can be prohibitive in practice. Nevertheless, instead of systematically reasoning and actively choosing informative samples, policy gradients for local search are often obtained from random perturbations. These random samples yield high variance estimates and hence are sub-optimal in terms of sample complexity. Actively selecting informative samples is at the core of Bayesian optimization, which constructs a probabilistic surrogate of the objective from past samples to reason about informative subsequent ones. In this paper, we propose to join both worlds. We develop an algorithm utilizing a probabilistic model of the objective function and its gradient. Based on the model, the algorithm decides where to query a noisy zeroth-order oracle to improve the gradient estimates. The resulting algorithm is a novel type of policy search method, which we compare to existing black-box algorithms. The comparison reveals improved sample complexity and reduced variance in extensive empirical evaluations on synthetic objectives. Further, we highlight the benefits of active sampling on popular RL benchmarks.",
    "authors": [
      "M\u00fcller, Sarah",
      "von Rohr, Alexander",
      "Trimpe, Sebastian"
    ]
  },
  {
    "id": "ad68473a64305626a27c32a5408552d7",
    "title": "DominoSearch: Find layer-wise fine-grained N:M sparse schemes from dense neural networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ad68473a64305626a27c32a5408552d7-Paper.pdf",
    "abstract": "Neural pruning is a widely-used compression technique for Deep Neural Networks (DNNs). Recent innovations in Hardware Architectures (e.g. Nvidia Ampere Sparse Tensor Core) and N:M fine-grained Sparse Neural Network algorithms (i.e. every M-weights contains N non-zero values) reveal a promising research line of neural pruning. However, the existing N:M algorithms only address the challenge of how to train N:M sparse neural networks in a uniform fashion (i.e. every layer has the same N:M sparsity) and suffer from a significant accuracy drop for high sparsity (i.e. when sparsity > 80\\%). To tackle this problem, we present a novel technique -- \\textbf{\\textit{DominoSearch}} to find mixed N:M sparsity schemes from pre-trained dense deep neural networks to achieve higher accuracy than the uniform-sparsity scheme with equivalent complexity constraints (e.g. model size or FLOPs). For instance, for the same model size with 2.1M parameters (87.5\\% sparsity), our layer-wise N:M sparse ResNet18 outperforms its uniform counterpart by 2.1\\% top-1 accuracy, on the large-scale ImageNet dataset. For the same computational complexity of 227M FLOPs, our layer-wise sparse ResNet18 outperforms the uniform one by 1.3\\% top-1 accuracy. Furthermore, our layer-wise fine-grained N:M sparse ResNet50 achieves 76.7\\% top-1 accuracy with 5.0M parameters. {This is competitive to the results achieved by layer-wise unstructured sparsity} that is believed to be the upper-bound of Neural Network pruning with respect to the accuracy-sparsity trade-off. We believe that our work can build a strong baseline for further sparse DNN research and encourage future hardware-algorithm co-design work. Our code and models are publicly available at \\url{https://github.com/NM-sparsity/DominoSearch}.",
    "authors": [
      "Sun, Wei",
      "Zhou, Aojun",
      "Stuijk, Sander",
      "Wijnhoven, Rob",
      "Nelson, Andrew O.",
      "Li, hongsheng",
      "Corporaal, Henk"
    ]
  },
  {
    "id": "ad7ed5d47b9baceb12045a929e7e2f66",
    "title": "Techniques for Symbol Grounding with SATNet",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ad7ed5d47b9baceb12045a929e7e2f66-Paper.pdf",
    "abstract": "Many experts argue that the future of artificial intelligence is limited by the field\u2019s ability to integrate symbolic logical reasoning into deep learning architectures. The recently proposed differentiable MAXSAT solver, SATNet, was a breakthrough in its capacity to integrate with a traditional neural network and solve visual reasoning problems. For instance, it can learn the rules of Sudoku purely from image examples. Despite its success, SATNet was shown to succumb to a key challenge in neurosymbolic systems known as the Symbol Grounding Problem: the inability to map visual inputs to symbolic variables without explicit supervision (\"label leakage\"). In this work, we present a self-supervised pre-training pipeline that enables SATNet to overcome this limitation, thus broadening the class of problems that SATNet architectures can solve to include datasets where no intermediary labels are available at all. We demonstrate that our method allows SATNet to attain full accuracy even with a harder problem setup that prevents any label leakage. We additionally introduce a proofreading method that further improves the performance of SATNet architectures, beating the state-of-the-art on Visual Sudoku. ",
    "authors": [
      "Topan, Sever",
      "Rolnick, David",
      "Si, Xujie"
    ]
  },
  {
    "id": "ade1d98c5ab2997e867b1151a5c5028d",
    "title": "Object DGCNN: 3D Object Detection using Dynamic Graphs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ade1d98c5ab2997e867b1151a5c5028d-Paper.pdf",
    "abstract": "3D object detection often involves complicated training and testing pipelines, which require substantial domain knowledge about individual datasets. Inspired by recent non-maximum suppression-free 2D object detection models, we propose a 3D object detection architecture on point clouds. Our method models 3D object detection as message passing on a dynamic graph, generalizing the DGCNN framework to predict a set of objects. In our construction, we remove the necessity of post-processing via object confidence aggregation or non-maximum suppression. To facilitate object detection from sparse point clouds, we also propose a set-to-set distillation approach customized to 3D detection. This approach aligns the outputs of the teacher model and the student model in a permutation-invariant fashion, significantly simplifying knowledge distillation for the 3D detection task. Our method achieves state-of-the-art performance on autonomous driving benchmarks. We also provide abundant analysis of the detection model and distillation framework. ",
    "authors": [
      "Wang, Yue",
      "Solomon, Justin M."
    ]
  },
  {
    "id": "adf7e293599134777339fdc40ddfa818",
    "title": "Safe Policy Optimization with Local Generalized Linear Function Approximations",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/adf7e293599134777339fdc40ddfa818-Paper.pdf",
    "abstract": "Safe exploration is a key to applying reinforcement learning (RL) in safety-critical systems. Existing safe exploration methods guaranteed safety under the assumption of regularity, and it has been difficult to apply them to large-scale real problems. We propose a novel algorithm, SPO-LF, that optimizes an agent's policy while learning the relation between a locally available feature obtained by sensors and environmental reward/safety using generalized linear function approximations. We provide theoretical guarantees on its safety and optimality. We experimentally show that our algorithm is 1) more efficient in terms of sample complexity and computational cost and 2) more applicable to large-scale problems than previous safe RL methods with theoretical guarantees, and 3) comparably sample-efficient and safer compared with existing advanced deep RL methods with safety constraints.",
    "authors": [
      "Wachi, Akifumi",
      "Wei, Yunyue",
      "Sui, Yanan"
    ]
  },
  {
    "id": "adf8d7f8c53c8688e63a02bfb3055497",
    "title": "Symplectic Adjoint Method for Exact Gradient of Neural ODE with Minimal Memory",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/adf8d7f8c53c8688e63a02bfb3055497-Paper.pdf",
    "abstract": "A neural network model of a differential equation, namely neural ODE, has enabled the learning of continuous-time dynamical systems and probabilistic distributions with high accuracy. The neural ODE uses the same network repeatedly during a numerical integration. The memory consumption of the backpropagation algorithm is proportional to the number of uses times the network size. This is true even if a checkpointing scheme divides the computation graph into sub-graphs. Otherwise, the adjoint method obtains a gradient by a numerical integration backward in time. Although this method consumes memory only for a single network use, it requires high computational cost to suppress numerical errors. This study proposes the symplectic adjoint method, which is an adjoint method solved by a symplectic integrator. The symplectic adjoint method obtains the exact gradient (up to rounding error) with memory proportional to the number of uses plus the network size. The experimental results demonstrate that the symplectic adjoint method consumes much less memory than the naive backpropagation algorithm and checkpointing schemes, performs faster than the adjoint method, and is more robust to rounding errors.",
    "authors": [
      "Matsubara, Takashi",
      "Miyatake, Yuto",
      "Yaguchi, Takaharu"
    ]
  },
  {
    "id": "ae06fbdc519bddaa88aa1b24bace4500",
    "title": "Exponential Separation between Two Learning Models and Adversarial Robustness",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ae06fbdc519bddaa88aa1b24bace4500-Paper.pdf",
    "abstract": "We prove an exponential separation for the sample/query complexity between the standard PAC-learning model and a version of the Equivalence-Query-learning model. In the PAC model all samples are provided at the beginning of the learning process. In the Equivalence-Query model the samples are acquired through an interaction between a teacher and a learner, where the teacher provides counterexamples to hypotheses given by the learner. It is intuitive that in an interactive setting fewer samples are needed. We make this formal and prove that in order to achieve an error $\\epsilon$ {\\em exponentially} (in $\\epsilon$) fewer samples suffice than what the PAC bound requires. It was shown experimentally by Stutz, Hein, and Schiele that adversarial training with on-manifold adversarial examples aids generalization (compared to standard training). If we think of the adversarial examples as counterexamples to the current hypothesis then our result can be thought of as a theoretical confirmation of those findings.  We also discuss how our result relates to adversarial robustness. In the standard adversarial model one restricts the adversary by introducing a norm constraint. An alternative was pioneered by Goldwasser et. al. Rather than restricting the adversary the learner is enhanced. We pursue a third path. We require the adversary to return samples according to the Equivalance-Query model and show that this leads to robustness. Even though our model has its limitations it provides a fresh point of view on adversarial robustness.",
    "authors": [
      "Gluch, Grzegorz",
      "Urbanke, Ruediger"
    ]
  },
  {
    "id": "ae0909a324fb2530e205e52d40266418",
    "title": "The balancing principle for parameter choice in distance-regularized domain adaptation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ae0909a324fb2530e205e52d40266418-Paper.pdf",
    "abstract": "We address the unsolved algorithm design problem of choosing a justified regularization parameter in unsupervised domain adaptation. This problem is intriguing as no labels are available in the target domain. Our approach starts with the observation that the widely-used method of minimizing the source error, penalized by a distance measure between source and target feature representations, shares characteristics with regularized ill-posed inverse problems. Regularization parameters in inverse problems are optimally chosen by the fundamental principle of balancing approximation and sampling errors. We use this principle to balance learning errors and domain distance in a target error bound. As a result, we obtain a theoretically justified rule for the choice of the regularization parameter. In contrast to the state of the art, our approach allows source and target distributions with disjoint supports. An empirical comparative study on benchmark datasets underpins the performance of our approach.",
    "authors": [
      "Zellinger, Werner",
      "Shepeleva, Natalia",
      "Dinu, Marius-Constantin",
      "Eghbal-zadeh, Hamid",
      "Nguyen, Hoan Duc",
      "Nessler, Bernhard",
      "Pereverzyev, Sergei",
      "Moser, Bernhard A."
    ]
  },
  {
    "id": "ae1eaa32d10b6c886981755d579fb4d8",
    "title": "Gaussian Kernel Mixture Network for Single Image Defocus Deblurring",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ae1eaa32d10b6c886981755d579fb4d8-Paper.pdf",
    "abstract": "Defocus blur is one kind of blur effects often seen in images, which is challenging to remove due to its spatially variant amount. This paper presents  an end-to-end deep learning approach for removing defocus blur from a single image, so as to have an all-in-focus image for consequent vision tasks. First, a  pixel-wise Gaussian kernel mixture (GKM) model is  proposed for representing spatially variant defocus blur kernels in an efficient linear parametric form, with higher accuracy than existing models. Then, a deep neural network called GKMNet is developed by unrolling a fixed-point iteration of the GKM-based deblurring.  The GKMNet is built on a lightweight scale-recurrent architecture, with a scale-recurrent attention module for estimating the mixing coefficients in GKM for defocus deblurring. Extensive experiments show that the GKMNet not only noticeably outperforms existing defocus deblurring methods, but also has its advantages in terms of model complexity and computational efficiency.",
    "authors": [
      "Quan, Yuhui",
      "Wu, Zicong",
      "Ji, Hui"
    ]
  },
  {
    "id": "ae3539867aaeec609a4260c6feb725f4",
    "title": "Cockpit: A Practical Debugging Tool for the Training of Deep Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ae3539867aaeec609a4260c6feb725f4-Paper.pdf",
    "abstract": "When engineers train deep learning models, they are very much \"flying blind\". Commonly used methods for real-time training diagnostics, such as monitoring the train/test loss, are limited. Assessing a network's training process solely through these performance indicators is akin to debugging software without access to internal states through a debugger. To address this, we present Cockpit, a collection of instruments that enable a closer look into the inner workings of a learning machine, and a more informative and meaningful status report for practitioners. It facilitates the identification of learning phases and failure modes, like ill-chosen hyperparameters. These instruments leverage novel higher-order information about the gradient distribution and curvature, which has only recently become efficiently accessible. We believe that such a debugging tool, which we open-source for PyTorch, is a valuable help in troubleshooting the training process. By revealing new insights, it also more generally contributes to explainability and interpretability of deep nets.",
    "authors": [
      "Schneider, Frank",
      "Dangel, Felix",
      "Hennig, Philipp"
    ]
  },
  {
    "id": "ae3f4c649fb55c2ee3ef4d1abdb79ce5",
    "title": "MEST: Accurate and Fast Memory-Economic Sparse Training Framework on the Edge",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ae3f4c649fb55c2ee3ef4d1abdb79ce5-Paper.pdf",
    "abstract": "Recently, a new trend of exploring sparsity for accelerating neural network training has emerged, embracing the paradigm of training on the edge. This paper proposes a novel Memory-Economic Sparse Training (MEST) framework targeting for accurate and fast execution on edge devices. The proposed MEST framework consists of enhancements by Elastic Mutation (EM) and Soft Memory Bound (&S) that ensure superior accuracy at high sparsity ratios. Different from the existing works for sparse training, this current work reveals the importance of sparsity schemes on the performance of sparse training in terms of accuracy as well as training speed on real edge devices. On top of that, the paper proposes to employ data efficiency for further acceleration of sparse training. Our results suggest that unforgettable examples can be identified in-situ even during the dynamic exploration of sparsity masks in the sparse training process, and therefore can be removed for further training speedup on edge devices. Comparing with state-of-the-art (SOTA) works on accuracy, our MEST increases Top-1 accuracy significantly on ImageNet when using the same unstructured sparsity scheme. Systematical evaluation on accuracy, training speed, and memory footprint are conducted, where the proposed MEST framework consistently outperforms representative SOTA works. A reviewer strongly against our work based on his false assumptions and misunderstandings. On top of the previous submission, we employ data efficiency for further acceleration of sparse training. And we explore the impact of model sparsity, sparsity schemes, and sparse training algorithms on the number of removable training examples. Our codes are publicly available at: https://github.com/boone891214/MEST.",
    "authors": [
      "Yuan, Geng",
      "Ma, Xiaolong",
      "Niu, Wei",
      "Li, Zhengang",
      "Kong, Zhenglun",
      "Liu, Ning",
      "Gong, Yifan",
      "Zhan, Zheng",
      "He, Chaoyang",
      "Jin, Qing",
      "Wang, Siyue",
      "Qin, Minghai",
      "Ren, Bin",
      "Wang, Yanzhi",
      "Liu, Sijia",
      "Lin, Xue"
    ]
  },
  {
    "id": "ae4503ec3da32f5e9033604744ec45ae",
    "title": "Precise characterization of the prior predictive distribution of deep ReLU networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ae4503ec3da32f5e9033604744ec45ae-Paper.pdf",
    "abstract": "Recent works on Bayesian neural networks (BNNs) have highlighted the need to better understand the implications of using Gaussian priors in combination with the compositional structure of the network architecture. Similar in spirit to the kind of analysis that has been developed to devise better initialization schemes for neural networks (cf. He- or Xavier initialization), we derive a precise characterization of the prior predictive distribution of finite-width ReLU networks with Gaussian weights.While theoretical results have been obtained for their heavy-tailedness,the full characterization of the prior predictive distribution (i.e. its density, CDF and moments), remained unknown prior to this work. Our analysis, based on the Meijer-G function, allows us to quantify the influence of architectural choices such as the width or depth of the network on the resulting shape of the prior predictive distribution. We also formally connect our results to previous work in the infinite width setting, demonstrating that the moments of the distribution converge to those of a normal log-normal mixture in the infinite depth limit. Finally, our results provide valuable guidance on prior design: for instance, controlling the predictive variance with depth- and width-informed priors on the weights of the network.",
    "authors": [
      "Noci, Lorenzo",
      "Bachmann, Gregor",
      "Roth, Kevin",
      "Nowozin, Sebastian",
      "Hofmann, Thomas"
    ]
  },
  {
    "id": "ae5e3ce40e0404a45ecacaaf05e5f735",
    "title": "RED : Looking for Redundancies for Data-FreeStructured Compression of Deep Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ae5e3ce40e0404a45ecacaaf05e5f735-Paper.pdf",
    "abstract": "Deep Neural Networks (DNNs) are ubiquitous in today's computer vision landscape, despite involving considerable computational costs. The mainstream approaches for runtime acceleration consist in pruning connections (unstructured pruning) or, better, filters (structured pruning), both often requiring data to retrain the model.  In this paper, we present RED, a data-free, unified approach to tackle structured pruning. First, we propose a novel adaptive hashing of the scalar DNN weight distribution densities to increase the number of identical neurons represented by their weight vectors. Second, we prune the network by merging redundant neurons based on their relative similarities, as defined by their distance. Third, we propose a novel uneven depthwise separation technique to further prune convolutional layers. We demonstrate through a large variety of benchmarks that RED largely outperforms other data-free pruning methods, often reaching performance similar to unconstrained, data-driven methods.",
    "authors": [
      "YVINEC, Edouard",
      "Dapogny, Arnaud",
      "Cord, Matthieu",
      "Bailly, Kevin"
    ]
  },
  {
    "id": "ae78510109d46b0a6eef9820a4ca95d6",
    "title": "TestRank: Bringing Order into Unlabeled Test Instances for Deep Learning Tasks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ae78510109d46b0a6eef9820a4ca95d6-Paper.pdf",
    "abstract": "Deep learning (DL) systems are notoriously difficult to test and debug due to the lack of correctness proof and the huge test input space to cover. Given the ubiquitous unlabeled test data and high labeling cost, in this paper, we propose a novel test prioritization technique, namely TestRank, which aims at revealing more model failures with less labeling effort. TestRank brings order into the unlabeled test data according to their likelihood of being a failure, i.e., their failure-revealing capabilities. Different from existing solutions, TestRank leverages both intrinsic and contextual attributes of the unlabeled test data when prioritizing them. To be specific, we first build a similarity graph on both unlabeled test samples and labeled samples (e.g., training or previously labeled test samples). Then, we conduct graph-based semi-supervised learning to extract contextual features from the correctness of similar labeled samples. For a particular test instance, the contextual features extracted with the graph neural network and the intrinsic features obtained with the DL model itself are combined to predict its failure-revealing capability. Finally, TestRank prioritizes unlabeled test inputs in descending order of the above probability value. We evaluate TestRank on three popular image classification datasets, and results show that TestRank significantly outperforms existing test prioritization techniques.   ",
    "authors": [
      "LI, YU",
      "LI, Min",
      "LAI, Qiuxia",
      "Liu, Yannan",
      "Xu, Qiang"
    ]
  },
  {
    "id": "ae816a80e4c1c56caa2eb4e1819cbb2f",
    "title": "Large Scale Learning on Non-Homophilous Graphs: New Benchmarks and Strong Simple Methods",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ae816a80e4c1c56caa2eb4e1819cbb2f-Paper.pdf",
    "abstract": "Many widely used datasets for graph machine learning tasks have generally been homophilous, where nodes with similar labels connect to each other. Recently, new Graph Neural Networks (GNNs) have been developed that move beyond the homophily regime; however, their evaluation has often been conducted on small graphs with limited application domains. We collect and introduce diverse non-homophilous datasets from a variety of application areas that have up to 384x more nodes and 1398x more edges than prior datasets. We further show that existing scalable graph learning and graph minibatching techniques lead to performance degradation on these non-homophilous datasets, thus highlighting the need for further work on scalable non-homophilous methods. To address these concerns, we introduce LINKX --- a strong simple method that admits straightforward minibatch training and inference. Extensive experimental results with representative simple methods and GNNs across our proposed datasets show that LINKX achieves state-of-the-art performance for learning on non-homophilous graphs. Our codes and data are available at https://github.com/CUAI/Non-Homophily-Large-Scale.",
    "authors": [
      "Lim, Derek",
      "Hohne, Felix",
      "Li, Xiuyu",
      "Huang, Sijia Linda",
      "Gupta, Vaishnavi",
      "Bhalerao, Omkar",
      "Lim, Ser Nam"
    ]
  },
  {
    "id": "af1c25e88a9e818f809f6b5d18ca02e2",
    "title": "Reinforcement Learning based Disease Progression Model for Alzheimer\u2019s Disease",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/af1c25e88a9e818f809f6b5d18ca02e2-Paper.pdf",
    "abstract": "We model Alzheimer\u2019s disease (AD) progression by combining differential equations (DEs) and reinforcement learning (RL) with domain knowledge. DEs  provide relationships between some, but not all, factors relevant to AD. We assume that the missing relationships must satisfy general criteria about the working of the brain, for e.g., maximizing cognition while minimizing the cost of supporting cognition. This allows us to extract the missing relationships by using RL to optimize an objective (reward) function that captures the above criteria. We use our model consisting of DEs (as a simulator) and the trained RL agent to predict individualized 10-year AD progression using baseline (year 0) features on synthetic and real data. The model was comparable or better at predicting 10-year cognition trajectories than state-of-the-art learning-based models. Our interpretable model demonstrated, and provided insights into, \"recovery/compensatory\" processes that mitigate the effect of AD, even though those processes were not explicitly encoded in the model. Our framework combines DEs with RL for modelling AD progression and has broad applicability for understanding other neurological disorders.",
    "authors": [
      "Saboo, Krishnakant",
      "Choudhary, Anirudh",
      "Cao, Yurui",
      "Worrell, Gregory",
      "Jones, David",
      "Iyer, Ravishankar"
    ]
  },
  {
    "id": "af21d0c97db2e27e13572cbf59eb343d",
    "title": "Catch-A-Waveform: Learning to Generate Audio from a Single Short Example",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/af21d0c97db2e27e13572cbf59eb343d-Paper.pdf",
    "abstract": "Models for audio generation are typically trained on hours of recordings. Here, we illustrate that capturing the essence of an audio source is typically possible from as little as a few tens of seconds from a single training signal. Specifically, we present a GAN-based generative model that can be trained on one short audio signal from any domain (e.g. speech, music, etc.) and does not require pre-training or any other form of external supervision. Once trained, our model can generate random  samples of arbitrary duration that maintain semantic similarity to the training waveform, yet exhibit new compositions of its audio primitives. This enables a long line of interesting applications, including generating new jazz improvisations or new a-cappella rap variants based on a single short example, producing coherent modifications to famous songs (e.g. adding a new verse to a Beatles song based solely on the original recording), filling-in of missing parts (inpainting), extending the bandwidth of a speech signal (super-resolution), and enhancing old recordings without access to any clean training example. We show that in all cases, no more than 20 seconds of training audio commonly suffice for our model to achieve state-of-the-art results. This is despite its complete lack of prior knowledge about the nature of audio signals in general.",
    "authors": [
      "Greshler, Gal",
      "Shaham, Tamar",
      "Michaeli, Tomer"
    ]
  },
  {
    "id": "af3b6a54e9e9338abc54258e3406e485",
    "title": "Explanation-based Data Augmentation for Image Classification",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/af3b6a54e9e9338abc54258e3406e485-Paper.pdf",
    "abstract": "Existing works have generated explanations for deep neural network decisions to provide insights into model behavior. We observe that these explanations can also be used to identify concepts that caused misclassifications. This allows us to understand the possible limitations of the dataset used to train the model, particularly the under-represented regions in the dataset. This work proposes a framework that utilizes concept-based explanations to automatically augment the dataset with new images that can cover these under-represented regions to improve the model performance. The framework is able to use the explanations generated by both interpretable classifiers and post-hoc explanations from black-box classifiers. Experiment results demonstrate that the proposed approach improves the accuracy of classifiers compared to state-of-the-art augmentation strategies.",
    "authors": [
      "Wickramanayake, Sandareka",
      "Hsu, Wynne",
      "Lee, Mong Li"
    ]
  },
  {
    "id": "af4f00ca48321fb026865c5a1772dafd",
    "title": "Data-Efficient GAN Training Beyond (Just) Augmentations: A Lottery Ticket Perspective",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/af4f00ca48321fb026865c5a1772dafd-Paper.pdf",
    "abstract": "Training generative adversarial networks (GANs) with limited real image data generally results in deteriorated performance and collapsed models. To conquer this challenge, we are inspired by the latest observation, that one can discover independently trainable and highly sparse subnetworks (a.k.a., lottery tickets) from GANs. Treating this as an inductive prior, we suggest a brand-new angle towards data-efficient GAN training: by first identifying the lottery ticket from the original GAN using the small training set of real images; and then focusing on training that sparse subnetwork by re-using the same set. We find our coordinated framework to offer orthogonal gains to existing real image data augmentation methods, and we additionally present a new feature-level augmentation that can be applied together with them. Comprehensive experiments endorse the effectiveness of our proposed framework, across various GAN architectures (SNGAN, BigGAN, and StyleGAN-V2) and diverse datasets (CIFAR-10, CIFAR-100, Tiny-ImageNet, ImageNet, and multiple few-shot generation datasets). Codes are available at: https://github.com/VITA-Group/Ultra-Data-Efficient-GAN-Training.",
    "authors": [
      "Chen, Tianlong",
      "Cheng, Yu",
      "Gan, Zhe",
      "Liu, Jingjing",
      "Wang, Zhangyang"
    ]
  },
  {
    "id": "af5baf594e9197b43c9f26f17b205e5b",
    "title": "When Are Solutions Connected in Deep Networks?",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/af5baf594e9197b43c9f26f17b205e5b-Paper.pdf",
    "abstract": "The question of how and why the phenomenon of mode connectivity occurs in training deep neural networks has gained remarkable attention in the research community. From a theoretical perspective, two possible explanations have been proposed: (i) the loss function has connected sublevel sets, and (ii) the solutions found by stochastic gradient descent are dropout stable. While these explanations provide insights into the phenomenon, their assumptions are not always satisfied in practice. In particular, the first approach requires the network to have one layer with order of $N$ neurons ($N$ being the number of training samples), while the second one requires the loss to be almost invariant after removing half of the neurons at each layer (up to some rescaling of the remaining ones). In this work, we improve both conditions by exploiting the quality of the features at every intermediate layer together with a milder over-parameterization requirement. More specifically, we show that: (i) under generic assumptions on the features of intermediate layers, it suffices that the last two hidden layers have order of $\\sqrt{N}$ neurons, and (ii) if subsets of features at each layer are linearly separable, then almost no over-parameterization is needed to show the connectivity. Our experiments confirm that the proposed condition ensures the connectivity of solutions found by stochastic gradient descent, even in settings where the previous requirements do not hold.",
    "authors": [
      "Nguyen, Quynh N.",
      "Br\u00e9chet, Pierre",
      "Mondelli, Marco"
    ]
  },
  {
    "id": "af5d5ef24881f3c3049a7b9bfe74d58b",
    "title": "TOHAN: A One-step Approach towards Few-shot Hypothesis Adaptation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/af5d5ef24881f3c3049a7b9bfe74d58b-Paper.pdf",
    "abstract": "In few-shot domain adaptation (FDA), classifiers for the target domain are trained with \\emph{accessible} labeled data in the source domain (SD) and few labeled data in the target domain (TD). However, data usually contain private information in the current era, e.g., data distributed on personal phones. Thus, the private data will be leaked if we directly access data in SD to train a target-domain classifier (required by FDA methods). In this paper, to prevent privacy leakage in SD, we consider a very challenging problem setting, where the classifier for the TD has to be trained using few labeled target data and a well-trained SD classifier, named few-shot hypothesis adaptation (FHA). In FHA, we cannot access data in SD, as a result, the private information in SD will be protected well. To this end, we propose a target-oriented hypothesis adaptation network (TOHAN) to solve the FHA problem, where we generate highly-compatible unlabeled data (i.e., an intermediate domain) to help train a target-domain classifier. TOHAN maintains two deep networks simultaneously, in which one focuses on learning an intermediate domain and the other takes care of the intermediate-to-target distributional adaptation and the target-risk minimization. Experimental results show that TOHAN outperforms competitive baselines significantly.",
    "authors": [
      "Chi, Haoang",
      "Liu, Feng",
      "Yang, Wenjing",
      "Lan, Long",
      "Liu, Tongliang",
      "Han, Bo",
      "Cheung, William",
      "Kwok, James"
    ]
  },
  {
    "id": "af87f7cdcda223c41c3f3ef05a3aaeea",
    "title": "Learning Graph Cellular Automata",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/af87f7cdcda223c41c3f3ef05a3aaeea-Paper.pdf",
    "abstract": "Cellular automata (CA) are a class of computational models that exhibit rich dynamics emerging from the local interaction of cells arranged in a regular lattice. In this work we focus on a generalised version of typical CA, called graph cellular automata (GCA), in which the lattice structure is replaced by an arbitrary graph. In particular, we extend previous work that used convolutional neural networks to learn the transition rule of conventional CA and we use graph neural networks to learn a variety of transition rules for GCA. First, we present a general-purpose architecture for learning GCA, and we show that it can represent any arbitrary GCA with finite and discrete state space. Then, we test our approach on three different tasks: 1) learning the transition rule of a GCA on a Voronoi tessellation; 2) imitating the behaviour of a group of flocking agents; 3) learning a rule that converges to a desired target state.",
    "authors": [
      "Grattarola, Daniele",
      "Livi, Lorenzo",
      "Alippi, Cesare"
    ]
  },
  {
    "id": "af8d1eb220186400c494db7091e402b0",
    "title": "Efficient Online Estimation of Causal Effects by Deciding What to Observe",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/af8d1eb220186400c494db7091e402b0-Paper.pdf",
    "abstract": "Researchers often face data fusion problems, where multiple data sources are available, each capturing a distinct subset of variables. While problem formulations typically take the data as given, in practice, data acquisition can be an ongoing process. In this paper, we introduce the problem of deciding, at each time, which data source to sample from. Our goal is to estimate a given functional of the parameters of a probabilistic model as efficiently as possible. We propose online moment selection (OMS), a framework in which structural assumptions are encoded as moment conditions. The optimal action at each step depends, in part, on the very moments that identify the functional of interest. Our algorithms balance exploration with choosing the best action as suggested by estimated moments. We propose two selection strategies: (1) explore-then-commit (ETC) and (2) explore-then-greedy (ETG), proving that both achieve zero asymptotic regret as assessed by MSE. We instantiate our setup for average treatment effect estimation, where structural assumptions are given by a causal graph and data sources include subsets of mediators, confounders, and instrumental variables.",
    "authors": [
      "Gupta, Shantanu",
      "Lipton, Zachary",
      "Childers, David"
    ]
  },
  {
    "id": "af8d9c4e238c63fb074b44eb6aed80ae",
    "title": "Perturbation Theory for the Information Bottleneck",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/af8d9c4e238c63fb074b44eb6aed80ae-Paper.pdf",
    "abstract": "Extracting relevant information from data is crucial for all forms of learning. The information bottleneck (IB) method formalizes this, offering a mathematically precise and conceptually appealing framework for understanding learning phenomena. However the nonlinearity of the IB problem makes it computationally expensive and analytically intractable in general. Here we derive a perturbation theory for the IB method and report the first complete characterization of the learning onset, the limit of maximum relevant information per bit extracted from data. We test our results on synthetic probability distributions, finding good agreement with the exact numerical solution near the onset of learning. We explore the difference and subtleties in our derivation and previous attempts at deriving a perturbation theory for the learning onset and attribute the discrepancy to a flawed assumption. Our work also provides a fresh perspective on the intimate relationship between the IB method and the strong data processing inequality.",
    "authors": [
      "Ngampruetikorn, Vudtiwat",
      "Schwab, David J."
    ]
  },
  {
    "id": "afa299a4d1d8c52e75dd8a24c3ce534f",
    "title": "Deconvolutional Networks on Graph Data",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/afa299a4d1d8c52e75dd8a24c3ce534f-Paper.pdf",
    "abstract": "In this paper, we consider an inverse problem in graph learning domain -- \"given the graph representations smoothed by Graph Convolutional Network (GCN), how can we reconstruct the input graph signal?\" We propose Graph Deconvolutional Network (GDN) and motivate the design of GDN via a combination of inverse filters in spectral domain and de-noising layers in wavelet domain, as the inverse operation results in a high frequency amplifier and may amplify the noise. We demonstrate the effectiveness of the proposed method on several tasks including graph feature imputation and graph structure generation.  ",
    "authors": [
      "Li, Jia",
      "Li, Jiajin",
      "Liu, Yang",
      "Yu, Jianwei",
      "Li, Yueting",
      "Cheng, Hong"
    ]
  },
  {
    "id": "afd4836712c5e77550897e25711e1d96",
    "title": "Variational Multi-Task Learning with Gumbel-Softmax Priors",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/afd4836712c5e77550897e25711e1d96-Paper.pdf",
    "abstract": "Multi-task learning aims to explore task relatedness to improve individual tasks, which is of particular significance in the challenging scenario that only limited data is available for each task. To tackle this challenge, we propose variational multi-task learning (VMTL), a general probabilistic inference framework for learning multiple related tasks. We cast multi-task learning as a variational Bayesian inference problem, in which task relatedness is explored in a unified manner by specifying priors. To incorporate shared knowledge into each task, we design the prior of a task to be a learnable mixture of the variational posteriors of other related tasks, which is learned by the Gumbel-Softmax technique. In contrast to previous methods, our VMTL can exploit task relatedness for both representations and classifiers in a principled way by jointly inferring their posteriors. This enables individual tasks to fully leverage inductive biases provided by related tasks, therefore improving the overall performance of all tasks. Experimental results demonstrate that the proposed VMTL is able to effectively tackle a variety of challenging multi-task learning settings with limited training data for both classification and regression. Our method consistently surpasses previous methods, including strong Bayesian approaches, and achieves state-of-the-art performance on five benchmark datasets.",
    "authors": [
      "Shen, Jiayi",
      "Zhen, Xiantong",
      "Worring, Marcel",
      "Shao, Ling"
    ]
  },
  {
    "id": "afdec7005cc9f14302cd0474fd0f3c96",
    "title": "Accelerating Quadratic Optimization with Reinforcement Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/afdec7005cc9f14302cd0474fd0f3c96-Paper.pdf",
    "abstract": "First-order methods for quadratic optimization such as OSQP are widely used for large-scale machine learning and embedded optimal control, where many related problems must be rapidly solved. These methods face two persistent challenges: manual hyperparameter tuning and convergence time to high-accuracy solutions. To address these, we explore how Reinforcement Learning (RL) can learn a policy to tune parameters to accelerate convergence. In experiments with well-known QP benchmarks we find that our RL policy, RLQP, significantly outperforms state-of-the-art QP solvers by up to 3x. RLQP generalizes surprisingly well to previously unseen problems with varying dimension and structure from different applications, including the QPLIB, Netlib LP and Maros-M{\\'e}sz{\\'a}ros problems. Code, models, and videos are available at https://berkeleyautomation.github.io/rlqp/.",
    "authors": [
      "Ichnowski, Jeffrey",
      "Jain, Paras",
      "Stellato, Bartolomeo",
      "Banjac, Goran",
      "Luo, Michael",
      "Borrelli, Francesco",
      "Gonzalez, Joseph E.",
      "Stoica, Ion",
      "Goldberg, Ken"
    ]
  },
  {
    "id": "afe434653a898da20044041262b3ac74",
    "title": "Deep Residual Learning in Spiking Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/afe434653a898da20044041262b3ac74-Paper.pdf",
    "abstract": "Deep Spiking Neural Networks (SNNs) present optimization difficulties for gradient-based approaches due to discrete binary activation and complex spatial-temporal dynamics.  Considering the huge success of ResNet in deep learning, it would be natural to train deep SNNs with residual learning. Previous Spiking ResNet mimics the standard residual block in ANNs and simply replaces ReLU activation layers with spiking neurons, which suffers the degradation problem and can hardly implement residual learning. In this paper, we propose the spike-element-wise (SEW) ResNet to realize residual learning in deep SNNs. We prove that the SEW ResNet can easily implement identity mapping and overcome the vanishing/exploding gradient problems of Spiking ResNet. We evaluate our SEW ResNet on ImageNet, DVS Gesture, and CIFAR10-DVS datasets, and show that SEW ResNet outperforms the state-of-the-art directly trained SNNs in both accuracy and time-steps.  Moreover, SEW ResNet can achieve higher performance by simply adding more layers, providing a simple method to train deep SNNs. To our best knowledge, this is the first time that directly training deep SNNs with more than 100 layers becomes possible. Our codes are available at https://github.com/fangwei123456/Spike-Element-Wise-ResNet.",
    "authors": [
      "Fang, Wei",
      "Yu, Zhaofei",
      "Chen, Yanqi",
      "Huang, Tiejun",
      "Masquelier, Timoth\u00e9e",
      "Tian, Yonghong"
    ]
  },
  {
    "id": "afecc60f82be41c1b52f6705ec69e0f1",
    "title": "Duplex Sequence-to-Sequence Learning for Reversible Machine Translation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/afecc60f82be41c1b52f6705ec69e0f1-Paper.pdf",
    "abstract": "Sequence-to-sequence learning naturally has two directions. How to effectively utilize supervision signals from both directions? Existing approaches either require two separate models, or a multitask-learned model but with inferior performance. In this paper, we propose REDER (Reversible Duplex Transformer), a parameter-efficient model and apply it to machine translation. Either end of REDER can simultaneously input and output a distinct language. Thus REDER enables {\\em reversible machine translation} by simply flipping the input and output ends. Experiments verify that REDER achieves the first success of reversible machine translation, which helps outperform its multitask-trained baselines by up to 1.3 BLEU.",
    "authors": [
      "Zheng, Zaixiang",
      "Zhou, Hao",
      "Huang, Shujian",
      "Chen, Jiajun",
      "Xu, Jingjing",
      "Li, Lei"
    ]
  },
  {
    "id": "b035d6563a2adac9f822940c145263ce",
    "title": "Improved Coresets and Sublinear Algorithms for Power Means in Euclidean Spaces",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b035d6563a2adac9f822940c145263ce-Paper.pdf",
    "abstract": "In this paper, we consider the problem of finding high dimensional power means: given a set $A$ of $n$ points in $\\R^d$, find the point $m$ that minimizes the sum of Euclidean distance, raised to the power $z$, over all input points. Special cases of problem include the well-known Fermat-Weber problem -- or geometric median problem -- where $z = 1$, the mean or centroid where $z=2$, and the Minimum Enclosing Ball problem, where $z = \\infty$.We consider these problem in the big data regime.Here, we are interested in sampling as few points as possible such that we can accurately estimate $m$.More specifically, we consider sublinear algorithms as well as coresets for these problems.Sublinear algorithms have a random query access to the $A$ and the goal is to minimize the number of queries.Here, we show that $\\tilde{O}(\\varepsilon^{-z-3})$ samples are sufficient to achieve a $(1+\\varepsilon)$ approximation, generalizing the results from Cohen, Lee, Miller, Pachocki, and Sidford [STOC '16] and Inaba, Katoh, and Imai [SoCG '94] to arbitrary $z$. Moreover, we show that this bound is nearly optimal, as any algorithm requires at least $\\Omega(\\varepsilon^{-z+1})$ queries to achieve said approximation.The second contribution are coresets for these problems, where we aim to find find a small, weighted subset of the points which approximate cost of every candidate point $c\\in \\mathbb{R}^d$ up to a $(1\\pm\\varepsilon)$ factor. Here, we show that $\\tilde{O}(\\varepsilon^{-2})$ points are sufficient, improving on the $\\tilde{O}(d\\varepsilon^{-2})$ bound by Feldman and Langberg [STOC '11] and the $\\tilde{O}(\\varepsilon^{-4})$ bound by Braverman, Jiang, Krauthgamer, and Wu [SODA 21].",
    "authors": [
      "Cohen-Addad, Vincent",
      "Saulpic, David",
      "Schwiegelshohn, Chris"
    ]
  },
  {
    "id": "b0490b85e92b64dbb5db76bf8fca6a82",
    "title": "Accelerated Sparse Neural Training: A Provable and Efficient Method to Find N:M Transposable Masks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b0490b85e92b64dbb5db76bf8fca6a82-Paper.pdf",
    "abstract": "Unstructured pruning reduces the memory footprint in deep neural networks (DNNs). Recently, researchers proposed different types of structural pruning intending to reduce also the computation complexity. In this work, we first suggest a new measure called mask-diversity which correlates with the expected accuracy of the different types of structural pruning. We focus on the recently suggested N:M fine-grained block sparsity mask, in which for each block of M weights, we have at least N zeros. While N:M fine-grained block sparsity allows acceleration in actual modern hardware, it can be used only to accelerate the inference phase. In order to allow for similar accelerations in the training phase, we suggest a novel transposable fine-grained sparsity mask, where the same mask can be used for both forward and backward passes. Our transposable mask guarantees that both the weight matrix and its transpose follow the same sparsity pattern; thus, the matrix multiplication required for passing the error backward can also be accelerated. We formulate the problem of finding the optimal transposable-mask as a minimum-cost flow problem. Additionally, to speed up the minimum-cost flow computation, we also introduce a  fast linear-time approximation that can be used when the masks dynamically change during training. Our experiments suggest a 2x speed-up in the matrix multiplications with no accuracy degradation over vision and language models. Finally, to solve the problem of switching between different structure constraints, we suggest a method to convert a pre-trained model with unstructured sparsity to an N:M fine-grained block sparsity model with little to no training.  A reference implementation can be found at https://github.com/papers-submission/structuredtransposablemasks.",
    "authors": [
      "Hubara, Itay",
      "Chmiel, Brian",
      "Island, Moshe",
      "Banner, Ron",
      "Naor, Joseph",
      "Soudry, Daniel"
    ]
  },
  {
    "id": "b04c387c8384ca083a71b8da516f65f6",
    "title": "Learning and Generalization in RNNs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b04c387c8384ca083a71b8da516f65f6-Paper.pdf",
    "abstract": "Simple recurrent neural networks (RNNs) and their more advanced cousins LSTMs etc. have been very successful in sequence modeling. Their theoretical understanding, however, is lacking and has not kept pace with the progress for feedforward networks, where a reasonably complete understanding in the special case of highly overparametrized one-hidden-layer networks has emerged. In this paper, we make progress towards remedying this situation by proving that RNNs can learn functions of sequences. In contrast to the previous work that could only deal with functions of sequences that are sums of functions of individual tokens in the sequence, we allow general functions. Conceptually and technically, we introduce new ideas which enable us to extract information from the hidden state of the RNN in our proofs---addressing a crucial weakness in previous work. We illustrate our results on some regular language recognition problems.",
    "authors": [
      "Panigrahi, Abhishek",
      "Goyal, Navin"
    ]
  },
  {
    "id": "b056eb1587586b71e2da9acfe4fbd19e",
    "title": " Improving Visual Quality of Image Synthesis by A Token-based Generator with Transformers",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b056eb1587586b71e2da9acfe4fbd19e-Paper.pdf",
    "abstract": "We present a new perspective of achieving image synthesis by viewing this task as a visual token generation problem. Different from existing paradigms that directly synthesize a full image from a single input (e.g., a latent code), the new formulation enables a flexible local manipulation for different image regions, which makes it possible to learn content-aware and fine-grained style control for image synthesis. Specifically, it takes as input a sequence of latent tokens to predict the visual tokens for synthesizing an image. Under this perspective, we propose a token-based generator (i.e., TokenGAN). Particularly, the TokenGAN inputs two semantically different visual tokens, i.e., the learned constant content tokens and the style tokens from the latent space. Given a sequence of style tokens, the TokenGAN is able to control the image synthesis by assigning the styles to the content tokens by attention mechanism with a Transformer. We conduct extensive experiments and show that the proposed TokenGAN has achieved state-of-the-art results on several widely-used image synthesis benchmarks, including FFHQ and LSUN CHURCH with different resolutions. In particular, the generator is able to synthesize high-fidelity images with (1024x1024) size, dispensing with convolutions entirely.",
    "authors": [
      "Zeng, Yanhong",
      "Yang, Huan",
      "Chao, Hongyang",
      "Wang, Jianbo",
      "Fu, Jianlong"
    ]
  },
  {
    "id": "b0928f2d4ba7ea33b05024f21d937f48",
    "title": "The Effect of the Intrinsic Dimension on the Generalization of Quadratic Classifiers",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b0928f2d4ba7ea33b05024f21d937f48-Paper.pdf",
    "abstract": "It has been recently observed that neural networks, unlike kernel methods, enjoy a reduced sample complexity when the distribution is isotropic (i.e., when the covariance matrix is the identity). We find that this sensitivity to the data distribution is not exclusive to neural networks, and the same phenomenon can be observed on the class of quadratic classifiers (i.e., the sign of a quadratic polynomial) with a nuclear-norm constraint. We demonstrate this by deriving an upper bound on the Rademacher Complexity that depends on two key quantities: (i) the intrinsic dimension, which is a measure of isotropy, and (ii) the largest eigenvalue of the second moment (covariance) matrix of the distribution. Our result improves the dependence on the dimension over the best previously known bound and precisely quantifies the relation between the sample complexity and the level of isotropy of the distribution.",
    "authors": [
      "Latorre, Fabian",
      "Dadi, Leello Tadesse",
      "Rolland, Paul",
      "Cevher, Volkan"
    ]
  },
  {
    "id": "b0ab42fcb7133122b38521d13da7120b",
    "title": "DeepReduce: A Sparse-tensor Communication Framework for Federated Deep Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b0ab42fcb7133122b38521d13da7120b-Paper.pdf",
    "abstract": "Sparse tensors appear frequently in federated deep learning, either as a direct artifact of the deep neural network\u2019s gradients, or as a result of an explicit sparsification process.  Existing communication primitives are agnostic to the peculiarities of deep learning; consequently, they impose unnecessary communication overhead. This paper introduces DeepReduce, a versatile framework for the compressed communication of sparse tensors, tailored to federated deep learning. DeepReduce decomposes sparse tensors into two sets,  values and indices,  and allows both independent and combined compression of these sets.  We support a variety of common compressors, such as Deflate for values, or run-length encoding for indices. We also propose two novel compression schemes that achieve superior results: curve fitting-based for values, and bloom filter-based for indices.  DeepReduce is orthogonal to existing gradient sparsifiers and can be applied in conjunction with them, transparently to the end-user, to significantly lower the communication overhead. As proof of concept, we implement our approach on TensorFlow and PyTorch. Our experiments with large real models demonstrate that DeepReduce transmits 320% less data than existing sparsifiers, without affecting accuracy. Code is available at https://github.com/hangxu0304/DeepReduce.",
    "authors": [
      "Xu, Hang",
      "Kostopoulou, Kelly",
      "Dutta, Aritra",
      "Li, Xin",
      "Ntoulas, Alexandros",
      "Kalnis, Panos"
    ]
  },
  {
    "id": "b0b79da57b95837f14be95aaa4d54cf8",
    "title": "Provably Efficient Causal Reinforcement Learning with Confounded Observational Data",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b0b79da57b95837f14be95aaa4d54cf8-Paper.pdf",
    "abstract": "Empowered by neural networks, deep reinforcement learning (DRL) achieves tremendous empirical success. However, DRL requires a large dataset by interacting with the environment, which is unrealistic in critical scenarios such as autonomous driving and personalized medicine. In this paper, we study how to incorporate the dataset collected in the offline setting to improve the sample efficiency in the online setting. To incorporate the observational data, we face two challenges. (a) The behavior policy that generates the observational data may depend on unobserved random variables (confounders), which affect the received rewards and transition dynamics. (b) Exploration in the online setting requires quantifying the uncertainty given both the observational and interventional data. To tackle such challenges, we propose the deconfounded optimistic value iteration (DOVI) algorithm, which incorporates the confounded observational data in a provably efficient manner. DOVI explicitly adjusts for the confounding bias in the observational data, where the confounders are partially observed or unobserved. In both cases, such adjustments allow us to construct the bonus based on a notion of information gain, which takes into account the amount of information acquired from the offline setting. In particular, we prove that the regret of DOVI is smaller than the optimal regret achievable in the pure online setting when the confounded observational data are informative upon the adjustments.",
    "authors": [
      "Wang, Lingxiao",
      "Yang, Zhuoran",
      "Wang, Zhaoran"
    ]
  },
  {
    "id": "b0dd033cbe58aa5ea27747271bfd84e3",
    "title": "Predicting Deep Neural Network Generalization with Perturbation Response Curves",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b0dd033cbe58aa5ea27747271bfd84e3-Paper.pdf",
    "abstract": "The field of Deep Learning is rich with empirical evidence of human-like performance on a variety of prediction tasks. However, despite these successes, the recent Predicting Generalization in Deep Learning (PGDL) NeurIPS 2020 competition suggests that there is a need for more robust and efficient measures of network generalization. In this work, we propose a new framework for evaluating the generalization capabilities of trained networks. We use perturbation response (PR) curves that capture the accuracy change of a given network as a function of varying levels of training sample perturbation. From these PR curves, we derive novel statistics that capture generalization capability. Specifically, we introduce two new measures for accurately predicting generalization gaps: the Gi-score and Pal-score, which are inspired by the Gini coefficient and Palma ratio (measures of income inequality), that accurately predict generalization gaps. Using our framework applied to intra and inter-class sample mixup, we attain better predictive scores than the current state-of-the-art measures on a majority of tasks in the PGDL competition. In addition, we show that our framework and the proposed statistics can be used to capture to what extent a trained network is invariant to a given parametric input transformation, such as rotation or translation. Therefore, these generalization gap prediction statistics also provide a useful means for selecting optimal network architectures and hyperparameters that are invariant to a certain perturbation.",
    "authors": [
      "Schiff, Yair",
      "Quanz, Brian",
      "Das, Payel",
      "Chen, Pin-Yu"
    ]
  },
  {
    "id": "b0f2ad44d26e1a6f244201fe0fd864d1",
    "title": "Exploiting Domain-Specific Features to Enhance Domain Generalization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b0f2ad44d26e1a6f244201fe0fd864d1-Paper.pdf",
    "abstract": "Domain Generalization (DG) aims to train a model, from multiple observed source domains, in order to perform well on unseen target domains. To obtain the generalization capability, prior DG approaches have focused on extracting domain-invariant information across sources to generalize on target domains, while useful domain-specific information which strongly correlates with labels in individual domains and the generalization to target domains is usually ignored. In this paper, we propose meta-Domain Specific-Domain Invariant (mDSDI) - a novel theoretically sound framework that extends beyond the invariance view to further capture the usefulness of domain-specific information. Our key insight is to disentangle features in the latent space while jointly learning both domain-invariant and domain-specific features in a unified framework. The domain-specific representation is optimized through the meta-learning framework to adapt from source domains, targeting a robust generalization on unseen domains. We empirically show that mDSDI provides competitive results with state-of-the-art techniques in DG. A further ablation study with our generated dataset, Background-Colored-MNIST, confirms the hypothesis that domain-specific is essential, leading to better results when compared with only using domain-invariant.",
    "authors": [
      "Bui, Manh-Ha",
      "Tran, Toan",
      "Tran, Anh",
      "Phung, Dinh"
    ]
  },
  {
    "id": "b1300291698eadedb559786c809cc592",
    "title": "Optimal Order Simple Regret for Gaussian Process Bandits",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b1300291698eadedb559786c809cc592-Paper.pdf",
    "abstract": "Consider the sequential optimization of a continuous, possibly non-convex, and expensive to evaluate objective function $f$. The problem can be cast as a Gaussian Process (GP) bandit where $f$ lives in a reproducing kernel Hilbert space (RKHS). The state of the art analysis of several learning algorithms shows a significant gap between the lower and upper bounds on the simple regret performance. When $N$ is the number of exploration trials and $\\gamma_N$ is the maximal information gain, we prove an $\\tilde{\\mathcal{O}}(\\sqrt{\\gamma_N/N})$ bound on the simple regret performance of a pure exploration algorithm that is significantly tighter than the existing bounds. We show that this bound is order optimal up to logarithmic factors for the cases where a lower bound on regret is known. To establish these results, we prove novel and sharp confidence intervals for GP models applicable to RKHS elements which may be of broader interest.",
    "authors": [
      "Vakili, Sattar",
      "Bouziani, Nacime",
      "Jalali, Sepehr",
      "Bernacchia, Alberto",
      "Shiu, Da-shan"
    ]
  },
  {
    "id": "b1301141feffabac455e1f90a7de2054",
    "title": "Generalization Guarantee of SGD for Pairwise Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b1301141feffabac455e1f90a7de2054-Paper.pdf",
    "abstract": "Recently, there is a growing interest in studying pairwise learning since it includes many important machine learning tasks as specific examples, e.g., metric learning, AUC maximization and ranking. While stochastic gradient descent (SGD) is an efficient method, there is a lacking study on its generalization behavior for pairwise learning. In this paper, we present a systematic study on the generalization analysis of SGD for pairwise learning to understand the balance between generalization and optimization. We develop a novel high-probability generalization bound for uniformly-stable algorithms to incorporate the variance information for better generalization, based on which we establish the first nonsmooth learning algorithm to achieve almost optimal high-probability and dimension-independent generalization bounds in linear time. We consider both convex and nonconvex pairwise learning problems. Our stability analysis for convex problems shows how the interpolation can help generalization. We establish a uniform convergence of gradients, and apply it to derive the first generalization bounds on population gradients for nonconvex problems. Finally, we develop better generalization bounds for gradient-dominated problems.",
    "authors": [
      "Lei, Yunwen",
      "Liu, Mingrui",
      "Ying, Yiming"
    ]
  },
  {
    "id": "b151ce4935a3c2807e1dd9963eda16d8",
    "title": "Supercharging Imbalanced Data Learning With Energy-based Contrastive Representation Transfer",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b151ce4935a3c2807e1dd9963eda16d8-Paper.pdf",
    "abstract": "Dealing with severe class imbalance poses a major challenge for many real-world applications, especially when the accurate classification and generalization of minority classes are of primary interest.In computer vision and NLP, learning from datasets with long-tail behavior is a recurring theme, especially for naturally occurring labels. Existing solutions mostly appeal to sampling or weighting adjustments to alleviate the extreme imbalance, or impose inductive bias to prioritize generalizable associations. Here we take a novel perspective to promote sample efficiency and model generalization based on the invariance principles of causality. Our contribution posits a meta-distributional scenario, where the causal generating mechanism for label-conditional features is invariant across different labels. Such causal assumption enables efficient knowledge transfer from the dominant classes to their under-represented counterparts, even if their feature distributions show apparent disparities. This allows us to leverage a causal data augmentation procedure to enlarge the representation of minority classes. Our development is orthogonal to the existing imbalanced data learning techniques thus can be seamlessly integrated. The proposed approach is validated on an extensive set of synthetic and real-world tasks against state-of-the-art solutions. ",
    "authors": [
      "Chen, Junya",
      "Xiu, Zidi",
      "Goldstein, Benjamin",
      "Henao, Ricardo",
      "Carin, Lawrence",
      "Tao, Chenyang"
    ]
  },
  {
    "id": "b166b57d195370cd41f80dd29ed523d9",
    "title": "Heavy Ball Momentum for Conditional Gradient",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b166b57d195370cd41f80dd29ed523d9-Paper.pdf",
    "abstract": "Conditional gradient, aka Frank Wolfe (FW) algorithms, have well-documented merits in machine learning and signal processing applications. Unlike projection-based methods, momentum cannot improve the convergence rate of FW, in general. This limitation motivates the present work, which deals with heavy ball momentum, and its impact to FW. Specifically, it is established that heavy ball offers a unifying perspective on the primal-dual (PD) convergence, and enjoys a tighter \\textit{per iteration} PD error rate, for multiple choices of step sizes, where PD error can serve as the stopping criterion in practice. In addition, it is asserted that restart, a scheme typically employed jointly with Nesterov's momentum, can further tighten this PD error bound. Numerical results demonstrate the usefulness of heavy ball momentum in FW iterations.",
    "authors": [
      "Li, Bingcong",
      "Sadeghi, Alireza",
      "Giannakis, Georgios"
    ]
  },
  {
    "id": "b17c0907e67d868b4e0feb43dbbe6f11",
    "title": "PARP: Prune, Adjust and Re-Prune for Self-Supervised Speech Recognition",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b17c0907e67d868b4e0feb43dbbe6f11-Paper.pdf",
    "abstract": "Self-supervised speech representation learning (speech SSL) has demonstrated the benefit of scale in learning rich representations for Automatic Speech Recognition (ASR) with limited paired data, such as wav2vec 2.0. We investigate the existence of sparse subnetworks in pre-trained speech SSL models that achieve even better low-resource ASR results. However, directly applying widely adopted pruning methods such as the Lottery Ticket Hypothesis (LTH) is suboptimal in the computational cost needed. Moreover, we show that the discovered subnetworks yield minimal performance gain compared to the original dense network.We present Prune-Adjust-Re-Prune (PARP), which discovers and finetunes subnetworks for much better performance, while only requiring a single downstream ASR finetuning run. PARP is inspired by our surprising observation that subnetworks pruned for pre-training tasks need merely a slight adjustment to achieve a sizeable performance boost in downstream ASR tasks. Extensive experiments on low-resource ASR verify (1) sparse subnetworks exist in mono-lingual/multi-lingual pre-trained speech SSL, and (2) the computational advantage and performance gain of PARP over baseline pruning methods.In particular, on the 10min Librispeech split without LM decoding, PARP discovers subnetworks from wav2vec 2.0 with an absolute 10.9%/12.6% WER decrease compared to the full model. We further demonstrate the effectiveness of PARP via: cross-lingual pruning without any phone recognition degradation, the discovery of a multi-lingual subnetwork for 10 spoken languages in 1 finetuning run, and its applicability to pre-trained BERT/XLNet for natural language tasks1.",
    "authors": [
      "Lai, Cheng-I Jeff",
      "Zhang, Yang",
      "Liu, Alexander H.",
      "Chang, Shiyu",
      "Liao, Yi-Lun",
      "Chuang, Yung-Sung",
      "Qian, Kaizhi",
      "Khurana, Sameer",
      "Cox, David",
      "Glass, Jim"
    ]
  },
  {
    "id": "b19aa25ff58940d974234b48391b9549",
    "title": "Robust Learning of Optimal Auctions",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b19aa25ff58940d974234b48391b9549-Paper.pdf",
    "abstract": "We study the problem of learning revenue-optimal multi-bidder auctions from samples when the samples of bidders' valuations can be adversarially corrupted or drawn from distributions that are adversarially perturbed. First, we prove tight upper bounds on the revenue we can obtain with a corrupted distribution under a population model, for both regular valuation distributions and distributions with monotone hazard rate (MHR). We then propose new algorithms that, given only an ``approximate distribution'' for the bidder's valuation, can learn a mechanism whose revenue is nearly optimal simultaneously for all ``true distributions'' that are $\\alpha$-close to the original distribution in Kolmogorov-Smirnov distance. The proposed algorithms operate beyond the setting of bounded distributions that have been studied in prior works, and are guaranteed to obtain a fraction  $1-O(\\alpha)$ of the optimal revenue under the true distribution when the distributions are MHR.  Moreover, they are guaranteed to yield at least a fraction $1-O(\\sqrt{\\alpha})$ of the optimal revenue when the distributions are regular. We prove that these upper bounds cannot be further improved, by providing matching lower bounds. Lastly, we derive sample complexity upper bounds for learning a near-optimal auction for both MHR and regular distributions.",
    "authors": [
      "Guo, Wenshuo",
      "Jordan, Michael",
      "Zampetakis, Emmanouil"
    ]
  },
  {
    "id": "b1b20d09041289e6c3fbb81850c5da54",
    "title": "Disrupting Deep Uncertainty Estimation Without Harming Accuracy",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b1b20d09041289e6c3fbb81850c5da54-Paper.pdf",
    "abstract": "Deep neural networks (DNNs) have proven to be powerful predictors and are widely used for various tasks. Credible uncertainty estimation of their predictions, however, is crucial for their deployment in many risk-sensitive applications. In this paper we present a novel and simple attack, which unlike adversarial attacks, does not cause incorrect predictions but instead cripples the network's capacity for uncertainty estimation. The result is that after the attack, the DNN is more confident of its incorrect predictions than about its correct ones without having its accuracy reduced. We present two versions of the attack. The first scenario focuses on a black-box regime (where the attacker has no knowledge of the target network) and the second scenario attacks a white-box setting. The proposed attack is only required to be of minuscule magnitude for its perturbations to cause severe uncertainty estimation damage, with larger magnitudes resulting in completely unusable uncertainty estimations.We demonstrate successful attacks on three of the most popular uncertainty estimation methods: the vanilla softmax score, Deep Ensembles and MC-Dropout. Additionally, we show an attack on SelectiveNet, the selective classification architecture. We test the proposed attack on several contemporary architectures such as MobileNetV2 and EfficientNetB0, all trained to classify ImageNet.",
    "authors": [
      "Galil, Ido",
      "El-Yaniv, Ran"
    ]
  },
  {
    "id": "b1d10e7bafa4421218a51b1e1f1b0ba2",
    "title": "SOFT: Softmax-free Transformer with Linear Complexity",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b1d10e7bafa4421218a51b1e1f1b0ba2-Paper.pdf",
    "abstract": "Vision transformers (ViTs) have pushed the state-of-the-art for various visual recognition tasks by patch-wise image tokenization followed by self-attention. However, the employment of self-attention modules results in a quadratic complexity in both computation and memory usage. Various attempts on approximating the self-attention computation with linear complexity have been made in Natural Language Processing. However, an in-depth analysis in this work shows that they are either theoretically flawed or empirically ineffective for visual recognition. We further identify that their limitations are rooted in keeping the softmax self-attention during approximations.  Specifically, conventional self-attention is computed by normalizing the scaled dot-product between token feature vectors. Keeping this softmax operation challenges any subsequent linearization efforts. Based on this insight, for the first time, a softmax-free transformer or  SOFT is proposed. To remove softmax in self-attention,  Gaussian kernel function is used to replace the dot-product similarity without further normalization. This enables a full self-attention matrix to be approximated via a low-rank  matrix decomposition. The robustness of the approximation is achieved by calculating its Moore-Penrose inverse using  a  Newton-Raphson method. Extensive experiments on ImageNet show that our SOFT significantly improves the computational efficiency of existing ViT variants. Crucially, with a linear complexity, much longer token sequences are permitted in SOFT, resulting in superior trade-off between accuracy and complexity.",
    "authors": [
      "Lu, Jiachen",
      "Yao, Jinghan",
      "Zhang, Junge",
      "Zhu, Xiatian",
      "Xu, Hang",
      "Gao, Weiguo",
      "XU, Chunjing",
      "Xiang, Tao",
      "Zhang, Li"
    ]
  },
  {
    "id": "b20bb95ab626d93fd976af958fbc61ba",
    "title": "Task-Adaptive Neural Network Search with Meta-Contrastive Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b20bb95ab626d93fd976af958fbc61ba-Paper.pdf",
    "abstract": "Most conventional Neural Architecture Search (NAS) approaches are limited in that they only generate architectures without searching for the optimal parameters. While some NAS methods handle this issue by utilizing a supernet trained on a large-scale dataset such as ImageNet, they may be suboptimal if the target tasks are highly dissimilar from the dataset the supernet is trained on. To address such limitations, we introduce a novel problem of Neural Network Search (NNS), whose goal is to search for the optimal pretrained network for a novel dataset and constraints (e.g. number of parameters), from a model zoo. Then, we propose a novel framework to tackle the problem, namely Task-Adaptive Neural Network Search (TANS). Given a model-zoo that consists of network pretrained on diverse datasets, we use a novel amortized meta-learning framework to learn a cross-modal latent space with contrastive loss, to maximize the similarity between a dataset and a high-performing network on it, and minimize the similarity between irrelevant dataset-network pairs. We validate the effectiveness and efficiency of our method on ten real-world datasets, against existing NAS/AutoML baselines. The results show that our method instantly retrieves networks that outperform models obtained with the baselines with significantly fewer training steps to reach the target performance, thus minimizing the total cost of obtaining a task-optimal network. Our code and the model-zoo are available at https://anonymous.4open.science/r/TANS-33D6",
    "authors": [
      "Jeong, Wonyong",
      "Lee, Hayeon",
      "Park, Geon",
      "Hyung, Eunyoung",
      "Baek, Jinheon",
      "Hwang, Sung Ju"
    ]
  },
  {
    "id": "b21f9f98829dea9a48fd8aaddc1f159d",
    "title": "Neural Flows: Efficient Alternative to Neural ODEs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b21f9f98829dea9a48fd8aaddc1f159d-Paper.pdf",
    "abstract": "Neural ordinary differential equations describe how values change in time. This is the reason why they gained importance in modeling sequential data, especially when the observations are made at irregular intervals. In this paper we propose an alternative by directly modeling the solution curves - the flow of an ODE - with a neural network. This immediately eliminates the need for expensive numerical solvers while still maintaining the modeling capability of neural ODEs. We propose several flow architectures suitable for different applications by establishing precise conditions on when a function defines a valid flow. Apart from computational efficiency, we also provide empirical evidence of favorable generalization performance via applications in time series modeling, forecasting, and density estimation.",
    "authors": [
      "Bilo\u0161, Marin",
      "Sommer, Johanna",
      "Rangapuram, Syama Sundar",
      "Januschowski, Tim",
      "G\u00fcnnemann, Stephan"
    ]
  },
  {
    "id": "b23975176653284f1f7356ba5539cfcb",
    "title": "Multi-Objective Meta Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b23975176653284f1f7356ba5539cfcb-Paper.pdf",
    "abstract": "Meta learning with multiple objectives has been attracted much attention recently since many applications need to consider multiple factors when designing learning models. Existing gradient-based works on meta learning with multiple objectives mainly combine multiple objectives into a single objective in a weighted sum manner. This simple strategy usually works but it requires to tune the weights associated with all the objectives, which could be time consuming. Different from those works, in this paper, we propose a gradient-based Multi-Objective Meta Learning (MOML) framework without manually tuning weights. Specifically, MOML formulates the objective function of meta learning with multiple objectives as a Multi-Objective Bi-Level optimization Problem (MOBLP) where the upper-level subproblem is to solve several possibly conflicting objectives for the meta learner. To solve the MOBLP, we devise the first gradient-based optimization algorithm by alternatively solving the lower-level and upper-level subproblems via the gradient descent method and the gradient-based multi-objective optimization method, respectively. Theoretically, we prove the convergence properties of the proposed gradient-based optimization algorithm. Empirically, we show the effectiveness of the proposed MOML framework in several meta learning problems, including few-shot learning, domain adaptation, multi-task learning, and neural architecture search. The source code of MOML is available at https://github.com/Baijiong-Lin/MOML.",
    "authors": [
      "YE, Feiyang",
      "Lin, Baijiong",
      "Yue, Zhixiong",
      "Guo, Pengxin",
      "Xiao, Qiao",
      "Zhang, Yu"
    ]
  },
  {
    "id": "b24d21019de5e59da180f1661904f49a",
    "title": "A self consistent theory of Gaussian Processes captures feature learning effects in finite CNNs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b24d21019de5e59da180f1661904f49a-Paper.pdf",
    "abstract": "Deep neural networks (DNNs) in the infinite width/channel limit have received much attention recently, as they provide a clear analytical window to deep learning via mappings to Gaussian Processes (GPs). Despite its theoretical appeal, this viewpoint lacks a crucial ingredient of deep learning in finite DNNs, laying at the heart of their success --- \\textit{feature learning}. Here we consider DNNs trained with noisy gradient descent on a large training set and derive a self-consistent Gaussian Process theory accounting for \\textit{strong} finite-DNN and feature learning effects. Applying this to a toy model of a two-layer linear convolutional neural network (CNN) shows good agreement with experiments. We further identify, both analytically and numerically, a sharp transition between a feature learning regime and a lazy learning regime in this model. Strong finite-DNN effects are also derived for a non-linear two-layer fully connected network. We have numerical evidence demonstrating that the assumptions required for our theory hold true in more realistic settings (Myrtle5 CNN trained on CIFAR-10).Our self-consistent theory provides a rich and versatile analytical framework for studying strong finite-DNN effects, most notably - feature learning.",
    "authors": [
      "Naveh, Gadi",
      "Ringel, Zohar"
    ]
  },
  {
    "id": "b24d516bb65a5a58079f0f3526c87c57",
    "title": "Mini-Batch Consistent Slot Set Encoder for Scalable Set Encoding",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b24d516bb65a5a58079f0f3526c87c57-Paper.pdf",
    "abstract": "Most existing set encoding algorithms operate under the implicit assumption that all the set elements are accessible, and that there are ample computational and memory resources to load the set into memory during training and inference.  However, both assumptions fail when the set is excessively large such that it is impossible to load all set elements into memory, or when data arrives in a stream. To tackle such practical challenges in large-scale set encoding, the general set-function constraints of permutation invariance and equivariance are not sufficient. We introduce a new property termed Mini-Batch Consistency (MBC) that is required for large scale mini-batch set encoding. Additionally, we present a scalable and efficient attention-based set encoding mechanism that is amenable to mini-batch processing of sets, and capable of updating set representations as data arrives. The proposed method adheres to the required symmetries of invariance and equivariance as well as maintaining MBC for any partition of the input set. We perform extensive experiments and show that our method is computationally efficient and results in rich set encoding representations for set-structured data.",
    "authors": [
      "Bruno, Andreis",
      "Willette, Jeffrey",
      "Lee, Juho",
      "Hwang, Sung Ju"
    ]
  },
  {
    "id": "b282d1735283e8eea45bce393cefe265",
    "title": "Efficient and Local Parallel Random Walks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b282d1735283e8eea45bce393cefe265-Paper.pdf",
    "abstract": "Random walks are a fundamental primitive used in many machine learning algorithms with several applications in clustering and semi-supervised learning. Despite their relevance, the first efficient parallel algorithm to compute random walks has been introduced very recently (\u0141\u0105cki et al.). Unfortunately their method has a fundamental shortcoming: their algorithm is non-local in that it heavily relies on computing random walks out of all nodes in the input graph, even though in many practical applications one is interested in computing random walks only from a small subset of nodes in the graph. In this paper, we present a new algorithm that overcomes  this limitation by building random walks efficiently and locally at the same time. We show that our technique is both memory and round efficient, and in particular yields an efficient parallel local clustering algorithm. Finally, we complement our theoretical analysis with experimental results showing that our algorithm is significantly more scalable than previous approaches.",
    "authors": [
      "Kapralov, Michael",
      "Lattanzi, Silvio",
      "Nouri, Navid",
      "Tardos, Jakab"
    ]
  },
  {
    "id": "b28d7c6b6aec04f5525b453411ff4336",
    "title": "Amortized Variational Inference for Simple Hierarchical Models",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b28d7c6b6aec04f5525b453411ff4336-Paper.pdf",
    "abstract": "It is difficult to use subsampling with variational inference in hierarchical models since the number of local latent variables scales with the dataset. Thus, inference in hierarchical models remains a challenge at a large scale. It is helpful to use a variational family with a structure matching the posterior, but optimization is still slow due to the huge number of local distributions. Instead, this paper suggests an amortized approach where shared parameters simultaneously represent all local distributions. This approach is similarly accurate as using a given joint distribution (e.g., a full-rank Gaussian) but is feasible on datasets that are several orders of magnitude larger. It is also dramatically faster than using a structured variational distribution.",
    "authors": [
      "Agrawal, Abhinav",
      "Domke, Justin"
    ]
  },
  {
    "id": "b294504229c668e750dfcc4ea9617f0a",
    "title": "Online Matching in Sparse Random Graphs: Non-Asymptotic Performances of Greedy Algorithm",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b294504229c668e750dfcc4ea9617f0a-Paper.pdf",
    "abstract": "Motivated by sequential budgeted allocation problems, we investigate  online matching problems where connections between vertices are not i.i.d., but they have fixed degree distributions -- the so-called configuration model. We estimate the competitive ratio of the simplest algorithm, GREEDY, by approximating some relevant stochastic discrete processes by their continuous counterparts, that are solutions of an explicit system of partial differential equations. This technique gives precise bounds on the estimation  errors,  with arbitrarily high probability as the problem size increases. In particular, it allows the formal comparison between different configuration models. We also prove that, quite surprisingly,  GREEDY can have  better performance guarantees than RANKING, another celebrated algorithm for online matching that usually outperforms the former.",
    "authors": [
      "Noiry, Nathan",
      "Perchet, Vianney",
      "Sentenac, Flore"
    ]
  },
  {
    "id": "b2df0a0d4116c55f81fd5aa1ef876510",
    "title": "End-to-end reconstruction meets data-driven regularization for inverse problems",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b2df0a0d4116c55f81fd5aa1ef876510-Paper.pdf",
    "abstract": "We propose a new approach for learning end-to-end reconstruction operators based on unpaired training data for ill-posed inverse problems. The proposed method combines the classical variational framework with iterative unrolling and essentially seeks to minimize a weighted combination of the expected distortion in the measurement space and the Wasserstein-1 distance between the distributions of the reconstruction and the ground-truth. More specifically, the regularizer in the variational setting is parametrized by a deep neural network and learned simultaneously with the unrolled reconstruction operator. The variational problem is then initialized with the output of the reconstruction network and solved iteratively till convergence. Notably, it takes significantly fewer iterations to converge as compared to variational methods, thanks to the excellent initialization obtained via the unrolled operator. The resulting approach combines the computational efficiency of end-to-end unrolled reconstruction with the well-posedness and noise-stability guarantees of the variational setting. Moreover, we demonstrate with the example of image reconstruction in X-ray computed tomography (CT) that our approach outperforms state-of-the-art unsupervised methods and that it outperforms or is at least on par with state-of-the-art supervised data-driven reconstruction approaches.",
    "authors": [
      "Mukherjee, Subhadip",
      "Carioni, Marcello",
      "\u00d6ktem, Ozan",
      "Sch\u00f6nlieb, Carola-Bibiane"
    ]
  },
  {
    "id": "b2ea5e977c5fc1ccfa74171a9723dd61",
    "title": "An online passive-aggressive algorithm for difference-of-squares classification",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b2ea5e977c5fc1ccfa74171a9723dd61-Paper.pdf",
    "abstract": "We investigate a low-rank model of quadratic classification inspired by previous work on factorization machines, polynomial networks, and capsule-based architectures for visual object recognition. The model is parameterized by a pair of affine transformations, and it classifies examples by comparing the magnitudes of vectors that these transformations produce. The model is also over-parameterized in the sense that different pairs of affine transformations can describe classifiers with the same decision boundary and confidence scores. We show that such pairs arise from discrete and continuous symmetries of the model\u2019s parameter space: in particular, the latter define symmetry groups of rotations and Lorentz transformations, and we use these group structures to devise appropriately invariant procedures for model alignment and averaging. We also leverage the form of the model\u2019s decision boundary to derive simple margin-based updates for online learning. Here we explore a strategy of passive-aggressive learning: for each example, we compute the minimum change in parameters that is required to predict its correct label with high confidence. We derive these updates by solving a quadratically constrained quadratic program (QCQP); interestingly, this QCQP is nonconvex but tractable, and it can be solved efficiently by elementary methods. We highlight the conceptual and practical contributions of this approach. Conceptually, we show that it extends the paradigm of passive-aggressive learning to a larger family of nonlinear models for classification. Practically, we show that these models perform well on large-scale problems in online learning.",
    "authors": [
      "Saul, Lawrence"
    ]
  },
  {
    "id": "b2eeb7362ef83deff5c7813a67e14f0a",
    "title": "Finite-Sample Analysis of Off-Policy TD-Learning via Generalized Bellman Operators",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b2eeb7362ef83deff5c7813a67e14f0a-Paper.pdf",
    "abstract": "In TD-learning, off-policy sampling is known to be more practical than on-policy sampling, and by decoupling learning from data collection, it enables data reuse. It is known that policy evaluation has the interpretation of solving a generalized Bellman equation. In this paper, we derive finite-sample bounds for any general off-policy TD-like stochastic approximation algorithm that solves for the fixed-point of this generalized Bellman operator. Our key step is to show that the generalized Bellman operator is simultaneously a contraction mapping with respect to a weighted $\\ell_p$-norm for each $p$ in $[1,\\infty)$, with a common contraction factor. Off-policy TD-learning is known to suffer from  high variance due to the product of importance sampling ratios. A number of algorithms (e.g. $Q^\\pi(\\lambda)$, Tree-Backup$(\\lambda)$, Retrace$(\\lambda)$, and $Q$-trace) have been proposed in the literature to address this issue. Our results immediately imply finite-sample bounds of these algorithms. In particular, we provide first-known finite-sample guarantees for $Q^\\pi(\\lambda)$, Tree-Backup$(\\lambda)$, and Retrace$(\\lambda)$, and improve the best known bounds of $Q$-trace in \\citep{chen2021finite}. Moreover, we show the bias-variance trade-offs in each of these algorithms.",
    "authors": [
      "Chen, Zaiwei",
      "Maguluri, Siva Theja",
      "Shakkottai, Sanjay",
      "Shanmugam, Karthikeyan"
    ]
  },
  {
    "id": "b2f627fff19fda463cb386442eac2b3d",
    "title": "A Bi-Level Framework for Learning to Solve Combinatorial Optimization on Graphs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b2f627fff19fda463cb386442eac2b3d-Paper.pdf",
    "abstract": "Combinatorial Optimization (CO) has been a long-standing challenging research topic featured by its NP-hard nature. Traditionally such problems are approximately solved with heuristic algorithms which are usually fast but may sacrifice the solution quality. Currently, machine learning for combinatorial optimization (MLCO) has become a trending research topic, but most existing MLCO methods treat CO as a single-level optimization by directly learning the end-to-end solutions, which are hard to scale up and mostly limited by the capacity of ML models given the high complexity of CO. In this paper, we propose a hybrid approach to combine the best of the two worlds, in which a bi-level framework is developed with an upper-level learning method to optimize the graph (e.g. add, delete or modify edges in a graph), fused with a lower-level heuristic algorithm solving on the optimized graph. Such a bi-level approach simplifies the learning on the original hard CO and can effectively mitigate the demand for model capacity. The experiments and results on several popular CO problems like Directed Acyclic Graph scheduling, Graph Edit Distance and Hamiltonian Cycle Problem show its effectiveness over manually designed heuristics and single-level learning methods.",
    "authors": [
      "Wang, Runzhong",
      "Hua, Zhigang",
      "Liu, Gan",
      "Zhang, Jiayi",
      "Yan, Junchi",
      "Qi, Feng",
      "Yang, Shuang",
      "Zhou, Jun",
      "Yang, Xiaokang"
    ]
  },
  {
    "id": "b31df16a88ce00fed951f24b46e08649",
    "title": "Improved Learning Rates of a Functional Lasso-type SVM with Sparse Multi-Kernel Representation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b31df16a88ce00fed951f24b46e08649-Paper.pdf",
    "abstract": "In this paper, we  provide  theoretical results of estimation bounds and excess risk upper bounds for  support vector machine (SVM) with sparse multi-kernel representation. These convergence rates for multi-kernel SVM are established by analyzing a Lasso-type regularized learning scheme within composite multi-kernel spaces. It is shown that the oracle rates of convergence of classifiers depend on the complexity of  multi-kernels, the sparsity, a Bernstein condition and the sample size, which significantly improves on previous results even for the additive or linear cases. In summary, this paper not only provides unified theoretical results for multi-kernel SVMs, but also enriches the literature on high-dimensional nonparametric classification.",
    "authors": [
      "lv, shaogao",
      "Wang, Junhui",
      "Liu, Jiankun",
      "Liu, Yong"
    ]
  },
  {
    "id": "b36ed8a07e3cd80ee37138524690eca1",
    "title": "When does Contrastive Learning Preserve Adversarial Robustness from Pretraining to Finetuning?",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b36ed8a07e3cd80ee37138524690eca1-Paper.pdf",
    "abstract": "Contrastive learning (CL) can learn generalizable feature representations and achieve state-of-the-art performance of downstream tasks by finetuning a linear classifier on top of it.  However, as adversarial robustness becomes vital in image classification,  it remains unclear whether or not CL is able to preserve robustness to downstream tasks. The main challenge is that in the self-supervised pretraining + supervised finetuning paradigm, adversarial robustness is easily forgotten due to a learning task mismatch from pretraining to finetuning. We call such challenge 'cross-task robustness transferability'. To address the above problem, in this paper we revisit and advance CL principles through the lens of robustness enhancement.  We show that (1) the design of contrastive views matters: High-frequency components of images are beneficial to improving model robustness; (2) Augmenting CL with pseudo-supervision stimulus (e.g., resorting to feature clustering) helps preserve robustness without forgetting. Equipped with our new designs, we propose AdvCL, a novel  adversarial contrastive pretraining framework. We show that AdvCL is able to enhance cross-task robustness transferability without loss of model accuracy and finetuning efficiency. With a thorough experimental study,  we demonstrate that AdvCL outperforms the state-of-the-art self-supervised robust learning methods across multiple datasets (CIFAR-10, CIFAR-100, and STL-10) and finetuning schemes  (linear evaluation and full model finetuning).",
    "authors": [
      "Fan, Lijie",
      "Liu, Sijia",
      "Chen, Pin-Yu",
      "Zhang, Gaoyuan",
      "Gan, Chuang"
    ]
  },
  {
    "id": "b3b25a26a0828ea5d48d8f8aa0d6f9af",
    "title": "Learning Transferable Features for Point Cloud Detection via 3D Contrastive Co-training",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b3b25a26a0828ea5d48d8f8aa0d6f9af-Paper.pdf",
    "abstract": "Most existing point cloud detection models require large-scale, densely annotated datasets. They typically underperform in domain adaptation settings, due to geometry shifts caused by different physical environments or LiDAR sensor configurations. Therefore, it is challenging but valuable to learn transferable features between a labeled source domain and a novel target domain, without any access to target labels. To tackle this problem, we introduce the framework of 3D Contrastive Co-training (3D-CoCo) with two technical contributions. First, 3D-CoCo is inspired by our observation that the bird-eye-view (BEV) features are more transferable than low-level geometry features. We thus propose a new co-training architecture that includes separate 3D encoders with domain-specific parameters, as well as a BEV transformation module for learning domain-invariant features. Second, 3D-CoCo extends the approach of contrastive instance alignment to point cloud detection, whose performance was largely hindered by the mismatch between the fictitious distribution of BEV features, induced by pseudo-labels, and the true distribution. The mismatch is greatly reduced by 3D-CoCo with transformed point clouds, which are carefully designed by considering specific geometry priors. We construct new domain adaptation benchmarks using three large-scale 3D datasets. Experimental results show that our proposed 3D-CoCo effectively closes the domain gap and outperforms the state-of-the-art methods by large margins. ",
    "authors": [
      "Yihan, Zeng",
      "Wang, Chunwei",
      "Wang, Yunbo",
      "Xu, Hang",
      "Ye, Chaoqiang",
      "Yang, Zhen",
      "Ma, Chao"
    ]
  },
  {
    "id": "b3e3e393c77e35a4a3f3cbd1e429b5dc",
    "title": "SILG: The Multi-domain Symbolic Interactive Language Grounding Benchmark",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b3e3e393c77e35a4a3f3cbd1e429b5dc-Paper.pdf",
    "abstract": "Existing work in language grounding typically study single environments. How do we build unified models that apply across multiple environments? We propose the multi-environment Symbolic Interactive Language Grounding benchmark (SILG), which unifies a collection of diverse grounded language learning environments under a common interface. SILG consists of grid-world environments that require generalization to new dynamics, entities, and partially observed worlds (RTFM, Messenger, NetHack), as well as symbolic counterparts of visual worlds that re- quire interpreting rich natural language with respect to complex scenes (ALFWorld, Touchdown). Together, these environments provide diverse grounding challenges in richness of observation space, action space, language specification, and plan com- plexity. In addition, we propose the first shared model architecture for RL on these environments, and evaluate recent advances such as egocentric local convolution, recurrent state-tracking, entity-centric attention, and pretrained LM using SILG. Our shared architecture achieves comparable performance to environment-specific architectures. Moreover, we find that many recent modelling advances do not result in significant gains on environments other than the one they were designed for. This highlights the need for a multi-environment benchmark. Finally, the best models significantly underperform humans on SILG, which suggests ample room for future work. We hope SILG enables the community to quickly identify new methodolo- gies for language grounding that generalize to a diverse set of environments and their associated challenges.",
    "authors": [
      "Zhong, Victor",
      "Hanjie, Austin W.",
      "Wang, Sida",
      "Narasimhan, Karthik",
      "Zettlemoyer, Luke"
    ]
  },
  {
    "id": "b427426b8acd2c2e53827970f2c2f526",
    "title": "A Surrogate Objective Framework for Prediction+Programming with Soft Constraints",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b427426b8acd2c2e53827970f2c2f526-Paper.pdf",
    "abstract": "Prediction+optimization is a common real-world paradigm where we have to predict problem parameters before solving the optimization problem. However, the criteria by which the prediction model is trained are often inconsistent with the goal of the downstream optimization problem.  Recently, decision-focused prediction approaches, such as SPO+ and direct optimization, have been proposed to fill this gap.  However, they cannot directly handle the soft constraints with the max operator required in many real-world objectives.  This paper proposes a novel analytically differentiable surrogate objective framework for real-world linear and semi-definite negative quadratic programming problems with soft linear and non-negative hard constraints. This framework gives the theoretical bounds on constraints\u2019 multipliers, and derives the closed-form solution with respect to predictive parameters and thus gradients for any variable in the problem.  We evaluate our method in three applications extended with soft constraints: synthetic linear programming, portfolio optimization, and resource provisioning, demonstrating that our method outperforms traditional two-staged methods and other decision-focused approaches",
    "authors": [
      "Yan, Kai",
      "Yan, Jie",
      "Luo, Chuan",
      "Chen, Liting",
      "Lin, Qingwei",
      "Zhang, Dongmei"
    ]
  },
  {
    "id": "b432f34c5a997c8e7c806a895ecc5e25",
    "title": "Learning to Predict Trustworthiness with Steep Slope Loss",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b432f34c5a997c8e7c806a895ecc5e25-Paper.pdf",
    "abstract": "Understanding the trustworthiness of a prediction yielded by a classifier is critical for the safe and effective use of AI models. Prior efforts have been proven to be reliable on small-scale datasets. In this work, we study the problem of predicting trustworthiness on real-world large-scale datasets, where the task is more challenging due to high-dimensional features, diverse visual concepts, and a large number of samples. In such a setting, we observe that the trustworthiness predictors trained with prior-art loss functions, i.e., the cross entropy loss, focal loss, and true class probability confidence loss, are prone to view both correct predictions and incorrect predictions to be trustworthy. The reasons are two-fold. Firstly, correct predictions are generally dominant over incorrect predictions. Secondly, due to the data complexity, it is challenging to differentiate the incorrect predictions from the correct ones on real-world large-scale datasets. To improve the generalizability of trustworthiness predictors, we propose a novel steep slope loss to separate the features w.r.t. correct predictions from the ones w.r.t. incorrect predictions by two slide-like curves that oppose each other. The proposed loss is evaluated with two representative deep learning models, i.e., Vision Transformer and ResNet, as trustworthiness predictors. We conduct comprehensive experiments and analyses on ImageNet, which show that the proposed loss effectively improves the generalizability of trustworthiness predictors. The code and pre-trained trustworthiness predictors for reproducibility are available at \\url{https://github.com/luoyan407/predict_trustworthiness}.",
    "authors": [
      "Luo, Yan",
      "Wong, Yongkang",
      "Kankanhalli, Mohan S.",
      "Zhao, Qi"
    ]
  },
  {
    "id": "b433da1b32b5ca96c0ba7fcb9edba97d",
    "title": "On the Periodic Behavior of Neural Network Training with Batch Normalization and Weight Decay",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b433da1b32b5ca96c0ba7fcb9edba97d-Paper.pdf",
    "abstract": "Training neural networks with batch normalization and weight decay has become a common practice in recent years. In this work, we show that their combined use may result in a surprising periodic behavior of optimization dynamics: the training process regularly exhibits destabilizations that, however, do not lead to complete divergence but cause a new period of training. We rigorously investigate the mechanism underlying the discovered periodic behavior from both empirical and theoretical points of view and analyze the conditions in which it occurs in practice. We also demonstrate that periodic behavior can be regarded as a generalization of two previously opposing perspectives on training with batch normalization and weight decay, namely the equilibrium presumption and the instability presumption.",
    "authors": [
      "Lobacheva, Ekaterina",
      "Kodryan, Maxim",
      "Chirkova, Nadezhda",
      "Malinin, Andrey",
      "Vetrov, Dmitry P."
    ]
  },
  {
    "id": "b44182379bf9fae976e6ae5996e13cd8",
    "title": "NeRV: Neural Representations for Videos",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b44182379bf9fae976e6ae5996e13cd8-Paper.pdf",
    "abstract": "We propose a novel neural representation for videos (NeRV) which encodes videos in neural networks. Unlike conventional representations that treat videos as frame sequences, we represent videos as neural networks taking frame index as input. Given a frame index, NeRV  outputs the corresponding RGB image. Video encoding in NeRV is simply fitting a neural network to video frames and decoding process is a simple feedforward operation.  As an image-wise implicit representation, NeRV output the whole image and shows great efficiency compared to pixel-wise implicit representation, improving the encoding speed by $\\textbf{25}\\times$ to $\\textbf{70}\\times$, the decoding speed by $\\textbf{38}\\times$ to $\\textbf{132}\\times$, while achieving better video quality.  With such a representation, we can treat videos as neural networks, simplifying several video-related tasks. For example, conventional video compression methods are restricted by a long and complex pipeline, specifically designed for the task. In contrast, with NeRV, we can use any neural network compression method as a proxy for video compression, and achieve comparable performance to traditional frame-based video compression approaches (H.264, HEVC \\etc). Besides compression, we demonstrate the generalization of NeRV for video denoising. The source code and pre-trained model can be found at https://github.com/haochen-rye/NeRV.git.",
    "authors": [
      "Chen, Hao",
      "He, Bo",
      "Wang, Hanyu",
      "Ren, Yixuan",
      "Lim, Ser Nam",
      "Shrivastava, Abhinav"
    ]
  },
  {
    "id": "b4572f47b7c69e27b8e46646d9579e67",
    "title": "Surrogate Regret Bounds for Polyhedral Losses",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b4572f47b7c69e27b8e46646d9579e67-Paper.pdf",
    "abstract": "Surrogate risk minimization is an ubiquitous paradigm in supervised machine learning, wherein a target problem is solved by minimizing a surrogate loss on a dataset.  Surrogate regret bounds, also called excess risk bounds, are a common tool to prove generalization rates for surrogate risk minimization.  While surrogate regret bounds have been developed for certain classes of loss functions, such as proper losses, general results are relatively sparse.  We provide two general results.  The first gives a linear surrogate regret bound for any polyhedral (piecewise-linear and convex) surrogate, meaning that surrogate generalization rates translate directly to target rates.  The second shows that for sufficiently non-polyhedral surrogates, the regret bound is a square root, meaning fast surrogate generalization rates translate to slow rates for the target.  Together, these results suggest polyhedral surrogates are optimal in many cases.",
    "authors": [
      "Frongillo, Rafael",
      "Waggoner, Bo"
    ]
  },
  {
    "id": "b4a0e0fbaa9f16d8947c49f4e610b549",
    "title": "Last iterate convergence of SGD for Least-Squares in the Interpolation regime.",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b4a0e0fbaa9f16d8947c49f4e610b549-Paper.pdf",
    "abstract": "Motivated by the recent successes of neural networks that have the ability to fit the data perfectly \\emph{and} generalize well, we study the noiseless model in the fundamental least-squares setup. We assume that an optimum predictor perfectly fits the inputs and outputs $\\langle \\theta_* , \\phi(X) \\rangle = Y$, where $\\phi(X)$ stands for a possibly infinite dimensional non-linear feature map. To solve this problem, we consider the estimator given by the last iterate of stochastic gradient descent (SGD) with constant step-size. In this context, our contribution is two fold: (i) \\emph{from a (stochastic) optimization perspective}, we exhibit an archetypal problem where we can show explicitly the convergence of SGD final iterate for a non-strongly convex problem with constant step-size whereas usual results use some form of average and (ii) \\emph{from a statistical perspective}, we give explicit non-asymptotic convergence rates in the over-parameterized setting and leverage a \\emph{fine-grained} parameterization of the problem to exhibit polynomial rates that can be faster than $O(1/T)$. The link with reproducing kernel Hilbert spaces is established.",
    "authors": [
      "Varre, Aditya  Vardhan",
      "Pillaud-Vivien, Loucas",
      "Flammarion, Nicolas"
    ]
  },
  {
    "id": "b4e267d84075f66ebd967d95331fcc03",
    "title": "Generative vs. Discriminative: Rethinking The Meta-Continual Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b4e267d84075f66ebd967d95331fcc03-Paper.pdf",
    "abstract": "Deep neural networks have achieved human-level capabilities in various learning tasks. However, they generally lose performance in more realistic scenarios like learning in a continual manner. In contrast, humans can incorporate their prior knowledge to learn new concepts efficiently without forgetting older ones. In this work, we leverage meta-learning to encourage the model to learn how to learn continually. Inspired by human concept learning, we develop a generative classifier that efficiently uses data-driven experience to learn new concepts even from few samples while being immune to forgetting. Along with cognitive and theoretical insights, extensive experiments on standard benchmarks demonstrate the effectiveness of the proposed method. The ability to remember all previous concepts, with negligible computational and structural overheads, suggests that generative models provide a natural way for alleviating catastrophic forgetting, which is a major drawback of discriminative models.",
    "authors": [
      "Banayeeanzade, Mohammadamin",
      "Mirzaiezadeh, Rasoul",
      "Hasani, Hosein",
      "Soleymani, Mahdieh"
    ]
  },
  {
    "id": "b4f8e5c5fb53f5ba81072451531d5460",
    "title": "Model, sample, and epoch-wise descents: exact solution of gradient flow in the random feature model",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b4f8e5c5fb53f5ba81072451531d5460-Paper.pdf",
    "abstract": "Recent evidence has shown the existence of a so-called double-descent and even triple-descent behavior for the generalization error of deep-learning models. This important phenomenon commonly appears in implemented neural network architectures, and also seems to emerge in epoch-wise curves during the training process. A recent line of research has highlighted that random matrix tools can be used to obtain precise analytical asymptotics of the generalization (and training) errors of the random feature model. In this contribution, we analyze the whole temporal behavior of the generalization and training errors under gradient flow for the random feature model. We show that in the asymptotic limit of large system size the full time-evolution path of both errors can be calculated analytically. This allows us to observe how the double and triple descents develop over time, if and when early stopping is an option, and also observe time-wise descent structures. Our techniques are based on Cauchy complex integral representations of the errors together with recent random matrix methods based on linear pencils. ",
    "authors": [
      "Bodin, Antoine",
      "Macris, Nicolas"
    ]
  },
  {
    "id": "b4fd1d2cb085390fbbadae65e07876a7",
    "title": "Rethinking Graph Transformers with Spectral Attention",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b4fd1d2cb085390fbbadae65e07876a7-Paper.pdf",
    "abstract": "In recent years, the Transformer architecture has proven to be very successful in sequence processing, but its application to other data structures, such as graphs, has remained limited due to the difficulty of properly defining positions. Here, we present the \\textit{Spectral Attention Network} (SAN), which uses a learned positional encoding (LPE) that can take advantage of the full Laplacian spectrum to learn the position of each node in a given graph.This LPE is then added to the node features of the graph and passed to a fully-connected Transformer.By leveraging the full spectrum of the Laplacian, our model is theoretically powerful in distinguishing graphs, and can better detect similar sub-structures from their resonance.Further, by fully connecting the graph, the Transformer does not suffer from over-squashing, an information bottleneck of most GNNs, and enables better modeling of physical phenomenons such as heat transfer and electric interaction.When tested empirically on a set of 4 standard datasets, our model performs on par or better than state-of-the-art GNNs, and outperforms any attention-based model by a wide margin, becoming the first fully-connected architecture to perform well on graph benchmarks.",
    "authors": [
      "Kreuzer, Devin",
      "Beaini, Dominique",
      "Hamilton, Will",
      "L\u00e9tourneau, Vincent",
      "Tossou, Prudencio"
    ]
  },
  {
    "id": "b51a15f382ac914391a58850ab343b00",
    "title": "Perceptual Score: What Data Modalities Does Your Model Perceive?",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b51a15f382ac914391a58850ab343b00-Paper.pdf",
    "abstract": "Machine learning advances in the last decade have relied significantly on large-scale datasets that continue to grow in size. Increasingly, those datasets also contain different data modalities. However, large multi-modal datasets are hard to annotate, and annotations may contain biases that we are often unaware of. Deep-net-based classifiers, in turn, are prone to exploit those biases and to find shortcuts. To study and quantify this concern, we introduce the perceptual score, a metric that assesses the degree to which a model relies on the different subsets of the input features, i.e., modalities. Using the perceptual score, we find a surprisingly consistent trend across four popular datasets: recent, more accurate state-of-the-art multi-modal models for visual question-answering or visual dialog tend to perceive the visual data less than their predecessors. This is concerning as answers are hence increasingly inferred from textual cues only. Using the perceptual score also helps to analyze model biases by decomposing the score into data subset contributions. We hope to spur a discussion on the perceptiveness of multi-modal models and also hope to encourage the community working on multi-modal classifiers to start quantifying perceptiveness via the proposed perceptual score.  ",
    "authors": [
      "Gat, Itai",
      "Schwartz, Idan",
      "Schwing, Alex"
    ]
  },
  {
    "id": "b5200c6107fc3d41d19a2b66835c3974",
    "title": "PiRank: Scalable Learning To Rank via Differentiable Sorting",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b5200c6107fc3d41d19a2b66835c3974-Paper.pdf",
    "abstract": "A key challenge with machine learning approaches for ranking is the gap between the performance metrics of interest and the surrogate loss functions that can be optimized with gradient-based methods. This gap arises because ranking metrics typically involve a sorting operation which is not differentiable w.r.t. the model parameters. Prior works have proposed surrogates that are loosely related to ranking metrics or simple smoothed versions thereof, and often fail to scale to real-world applications. We propose PiRank, a new class of differentiable surrogates for ranking, which employ a continuous, temperature-controlled relaxation to the sorting operator based on NeuralSort [1]. We show that PiRank exactly recovers the desired metrics in the limit of zero temperature and further propose a divide-and-conquer extension that scales favorably to large list sizes, both in theory and practice. Empirically, we demonstrate the role of larger list sizes during training and show that PiRank significantly improves over comparable approaches on publicly available Internet-scale learning-to-rank benchmarks.",
    "authors": [
      "Swezey, Robin",
      "Grover, Aditya",
      "Charron, Bruno",
      "Ermon, Stefano"
    ]
  },
  {
    "id": "b534ba68236ba543ae44b22bd110a1d6",
    "title": "Deceive D: Adaptive Pseudo Augmentation for GAN Training with Limited Data",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b534ba68236ba543ae44b22bd110a1d6-Paper.pdf",
    "abstract": "Generative adversarial networks (GANs) typically require ample data for training in order to synthesize high-fidelity images. Recent studies have shown that training GANs with limited data remains formidable due to discriminator overfitting, the underlying cause that impedes the generator's convergence. This paper introduces a novel strategy called Adaptive Pseudo Augmentation (APA) to encourage healthy competition between the generator and the discriminator. As an alternative method to existing approaches that rely on standard data augmentations or model regularization, APA alleviates overfitting by employing the generator itself to augment the real data distribution with generated images, which deceives the discriminator adaptively. Extensive experiments demonstrate the effectiveness of APA in improving synthesis quality in the low-data regime. We provide a theoretical analysis to examine the convergence and rationality of our new training strategy. APA is simple and effective. It can be added seamlessly to powerful contemporary GANs, such as StyleGAN2, with negligible computational cost. Code: https://github.com/EndlessSora/DeceiveD.",
    "authors": [
      "Jiang, Liming",
      "Dai, Bo",
      "Wu, Wayne",
      "Loy, Chen Change"
    ]
  },
  {
    "id": "b538f279cb2ca36268b23f557a831508",
    "title": "CoFrNets: Interpretable Neural Architecture Inspired by Continued Fractions",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b538f279cb2ca36268b23f557a831508-Paper.pdf",
    "abstract": "In recent years there has been a considerable amount of research on local post hoc explanations for neural networks. However, work on building interpretable neural architectures has been relatively sparse. In this paper, we present a novel neural architecture, CoFrNet, inspired by the form of continued fractions which are known to have many attractive properties in number theory, such as fast convergence of approximations to real numbers. We show that CoFrNets can be efficiently trained as well as interpreted leveraging their particular functional form. Moreover, we prove that such architectures are universal approximators based on a proof strategy that is different than the typical strategy used to prove universal approximation results for neural networks based on infinite width (or depth), which is likely to be of independent interest. We experiment on nonlinear synthetic functions and are able to accurately model as well as estimate feature attributions and even higher order terms in some cases, which is a testament to the representational power as well as interpretability of such architectures. To further showcase the power of CoFrNets, we experiment on seven real datasets spanning tabular, text and image modalities, and show that they are either comparable or significantly better than other interpretable models and multilayer perceptrons, sometimes approaching the accuracies of state-of-the-art models.",
    "authors": [
      "Puri, Isha",
      "Dhurandhar, Amit",
      "Pedapati, Tejaswini",
      "Shanmugam, Karthikeyan",
      "Wei, Dennis",
      "Varshney, Kush R."
    ]
  },
  {
    "id": "b5488aeff42889188d03c9895255cecc",
    "title": "Iterative Teaching by Label Synthesis",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b5488aeff42889188d03c9895255cecc-Paper.pdf",
    "abstract": "In this paper, we consider the problem of iterative machine teaching, where a teacher provides examples sequentially based on the current iterative learner. In contrast to previous methods that have to scan over the entire pool and select teaching examples from it in each iteration, we propose a label synthesis teaching framework where the teacher randomly selects input teaching examples (e.g., images) and then synthesizes suitable outputs (e.g., labels) for them. We show that this framework can avoid costly example selection while still provably achieving exponential teachability. We propose multiple novel teaching algorithms in this framework. Finally, we empirically demonstrate the value of our framework.",
    "authors": [
      "Liu, Weiyang",
      "Liu, Zhen",
      "Wang, Hanchen",
      "Paull, Liam",
      "Sch\u00f6lkopf, Bernhard",
      "Weller, Adrian"
    ]
  },
  {
    "id": "b578f2a52a0229873fefc2a4b06377fa",
    "title": "Variational Diffusion Models",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b578f2a52a0229873fefc2a4b06377fa-Paper.pdf",
    "abstract": "Diffusion-based generative models have demonstrated a capacity for perceptually impressive synthesis, but can they also be great likelihood-based models? We answer this in the affirmative, and introduce a family of diffusion-based generative models that obtain state-of-the-art likelihoods on standard image density estimation benchmarks. Unlike other diffusion-based models, our method allows for efficient optimization of the noise schedule jointly with the rest of the model. We show that the variational lower bound (VLB) simplifies to a remarkably short expression in terms of the signal-to-noise ratio of the diffused data, thereby improving our theoretical understanding of this model class. Using this insight, we prove an equivalence between several models proposed in the literature. In addition, we show that the continuous-time VLB is invariant to the noise schedule, except for the signal-to-noise ratio at its endpoints. This enables us to learn a noise schedule that minimizes the variance of the resulting VLB estimator, leading to faster optimization. Combining these advances with architectural improvements, we obtain state-of-the-art likelihoods on image density estimation benchmarks, outperforming autoregressive models that have dominated these benchmarks for many years, with often significantly faster optimization. In addition, we show how to use the model as part of a bits-back compression scheme, and demonstrate lossless compression rates close to the theoretical optimum.",
    "authors": [
      "Kingma, Diederik",
      "Salimans, Tim",
      "Poole, Ben",
      "Ho, Jonathan"
    ]
  },
  {
    "id": "b597460c506e8e35fb0cc1c1905dd3bc",
    "title": "FastCorrect: Fast Error Correction with Edit Alignment for Automatic Speech Recognition",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b597460c506e8e35fb0cc1c1905dd3bc-Paper.pdf",
    "abstract": "Error correction techniques have been used to refine the output sentences from automatic speech recognition (ASR) models and achieve a lower word error rate (WER) than original ASR outputs. Previous works usually use a sequence-to-sequence model to correct an ASR output sentence autoregressively, which causes large latency and cannot be deployed in online ASR services. A straightforward solution to reduce latency, inspired by non-autoregressive (NAR) neural machine translation, is to use an NAR sequence generation model for ASR error correction, which, however, comes at the cost of significantly increased ASR error rate. In this paper, observing distinctive error patterns and correction operations (i.e., insertion, deletion, and substitution) in ASR, we propose FastCorrect, a novel NAR error correction model based on edit alignment. In training, FastCorrect aligns each source token from an ASR output sentence to the target tokens from the corresponding ground-truth sentence based on the edit distance between the source and target sentences, and extracts the number of target tokens corresponding to each source token during edition/correction, which is then used to train a length predictor and to adjust the source tokens to match the length of the target sentence for parallel generation. In inference, the token number predicted by the length predictor is used to adjust the source tokens for target sequence generation. Experiments on the public AISHELL-1 dataset and an internal industrial-scale ASR dataset show the effectiveness of FastCorrect for ASR error correction: 1) it speeds up the inference by 6-9 times and maintains the accuracy (8-14% WER reduction) compared with the autoregressive correction model; and 2) it outperforms the popular NAR models adopted in neural machine translation and text edition by a large margin.",
    "authors": [
      "Leng, Yichong",
      "Tan, Xu",
      "Zhu, Linchen",
      "Xu, Jin",
      "Luo, Renqian",
      "Liu, Linquan",
      "Qin, Tao",
      "Li, Xiangyang",
      "Lin, Edward",
      "Liu, Tie-Yan"
    ]
  },
  {
    "id": "b59a51a3c0bf9c5228fde841714f523a",
    "title": "Integrated Latent Heterogeneity and Invariance Learning in Kernel Space",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b59a51a3c0bf9c5228fde841714f523a-Paper.pdf",
    "abstract": "The ability to generalize under distributional shifts is essential to reliable machine learning, while models optimized with empirical risk minimization usually fail on non-$i.i.d$ testing data. Recently, invariant learning methods for out-of-distribution (OOD) generalization propose to find causally invariant relationships with multi-environments. However, modern datasets are frequently multi-sourced without explicit source labels, rendering many invariant learning methods inapplicable. In this paper, we propose Kernelized Heterogeneous Risk Minimization (KerHRM) algorithm, which achieves both the latent heterogeneity exploration and invariant learning in kernel space, and then gives feedback to the original neural network by appointing invariant gradient direction. We theoretically justify our algorithm and empirically validate the effectiveness of our algorithm with extensive experiments.",
    "authors": [
      "Liu, Jiashuo",
      "Hu, Zheyuan",
      "Cui, Peng",
      "Li, Bo",
      "Shen, Zheyan"
    ]
  },
  {
    "id": "b59c21a078fde074a6750e91ed19fb21",
    "title": "Hierarchical Reinforcement Learning with Timed Subgoals",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b59c21a078fde074a6750e91ed19fb21-Paper.pdf",
    "abstract": "Hierarchical reinforcement learning (HRL) holds great potential for sample-efficient learning on challenging long-horizon tasks. In particular, letting a higher level assign subgoals to a lower level has been shown to enable fast learning on difficult problems. However, such subgoal-based methods have been designed with static reinforcement learning environments in mind and consequently struggle with dynamic elements beyond the immediate control of the agent even though they are ubiquitous in real-world problems. In this paper, we introduce Hierarchical reinforcement learning with Timed Subgoals (HiTS), an HRL algorithm that enables the agent to adapt its timing to a dynamic environment by not only specifying what goal state is to be reached but also when. We discuss how communicating with a lower level in terms of such timed subgoals results in a more stable learning problem for the higher level. Our experiments on a range of standard benchmarks and three new challenging dynamic reinforcement learning environments show that our method is capable of sample-efficient learning where an existing state-of-the-art subgoal-based HRL method fails to learn stable solutions.",
    "authors": [
      "G\u00fcrtler, Nico",
      "B\u00fcchler, Dieter",
      "Martius, Georg"
    ]
  },
  {
    "id": "b5b1d9ada94bb80609d21eecf7a2ce7a",
    "title": "Fair Scheduling for Time-dependent Resources",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b5b1d9ada94bb80609d21eecf7a2ce7a-Paper.pdf",
    "abstract": "We study a fair resource scheduling problem, where a set of interval jobs are to be allocated to heterogeneous machines controlled by intellectual agents.Each job is associated with release time, deadline, and processing time such that it can be processed if its complete processing period is between its release time and deadline. The machines gain possibly different utilities by processing different jobs, and all jobs assigned to the same machine should be processed without overlap.We consider two widely studied solution concepts, namely, maximin share fairness and envy-freeness.For both criteria, we discuss the extent to which fair allocations exist and present constant approximation algorithms for various settings. ",
    "authors": [
      "Li, Bo",
      "Li, Minming",
      "Zhang, Ruilong"
    ]
  },
  {
    "id": "b5c01503041b70d41d80e3dbe31bbd8c",
    "title": "SNIPS: Solving Noisy Inverse Problems Stochastically",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b5c01503041b70d41d80e3dbe31bbd8c-Paper.pdf",
    "abstract": "In this work we introduce a novel stochastic algorithm dubbed SNIPS, which draws samples from the posterior distribution of any linear inverse problem, where the observation is assumed to be contaminated by additive white Gaussian noise. Our solution incorporates ideas from Langevin dynamics and Newton's method, and exploits a pre-trained minimum mean squared error (MMSE) Gaussian denoiser. The proposed approach relies on an intricate derivation of the posterior score function that includes a singular value decomposition (SVD) of the degradation operator, in order to obtain a tractable iterative algorithm for the desired sampling. Due to its stochasticity, the algorithm can produce multiple high perceptual quality samples for the same noisy observation. We demonstrate the abilities of the proposed paradigm for image deblurring, super-resolution, and compressive sensing. We show that the samples produced are sharp, detailed and consistent with the given measurements, and their diversity exposes the inherent uncertainty in the inverse problem being solved.",
    "authors": [
      "Kawar, Bahjat",
      "Vaksman, Gregory",
      "Elad, Michael"
    ]
  },
  {
    "id": "b5d62aa6024ab6a65a12c78c4c2d4efc",
    "title": "Stateful ODE-Nets using Basis Function Expansions",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b5d62aa6024ab6a65a12c78c4c2d4efc-Paper.pdf",
    "abstract": "The recently-introduced class of ordinary differential equation networks (ODE-Nets) establishes a fruitful connection between deep learning and dynamical systems. In this work, we reconsider formulations of the weights as continuous-in-depth functions using linear combinations of basis functions which enables us to leverage parameter transformations such as function projections. In turn, this view allows us to formulate a novel stateful ODE-Block that handles stateful layers. The benefits of this new ODE-Block are twofold: first, it enables incorporating meaningful continuous-in-depth batch normalization layers to achieve state-of-the-art performance; second, it enables compressing the weights through a change of basis, without retraining, while maintaining near state-of-the-art performance and reducing both inference time and memory footprint. Performance is demonstrated by applying our stateful ODE-Block to (a) image classification tasks using convolutional units and (b) sentence-tagging tasks using transformer encoder units.",
    "authors": [
      "Queiruga, Alejandro",
      "Erichson, N. Benjamin",
      "Hodgkinson, Liam",
      "Mahoney, Michael W."
    ]
  },
  {
    "id": "b60c5ab647a27045b462934977ccad9a",
    "title": "Beyond the Signs: Nonparametric Tensor Completion via Sign Series",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b60c5ab647a27045b462934977ccad9a-Paper.pdf",
    "abstract": "We consider the problem of tensor estimation from noisy observations with possibly missing entries. A nonparametric approach to tensor completion is developed based on a new model which we coin as sign representable tensors. The model represents the signal tensor of interest using a series of structured sign tensors. Unlike earlier methods, the sign series representation effectively addresses both low- and high-rank signals, while encompassing many existing tensor models---including CP models, Tucker models, single index models, structured tensors with repeating entries---as special cases. We provably reduce the tensor estimation problem to a series of structured classification tasks, and we develop a learning reduction machinery to empower existing low-rank tensor algorithms for more challenging high-rank estimation. Excess risk bounds, estimation errors, and sample complexities are established. We demonstrate the outperformance of our approach over previous methods on two datasets, one on human brain connectivity networks and the other on topic data mining. ",
    "authors": [
      "Lee, Chanwoo",
      "Wang, Miaoyan"
    ]
  },
  {
    "id": "b613e70fd9f59310cf0a8d33de3f2800",
    "title": "Functional Variational Inference based on Stochastic Process Generators",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b613e70fd9f59310cf0a8d33de3f2800-Paper.pdf",
    "abstract": "Bayesian inference in the space of functions has been an important topic for Bayesian modeling in the past. In this paper, we propose a new solution to this problem called Functional Variational Inference (FVI). In FVI, we minimize a divergence in function space between the variational distribution and the posterior process. This is done by using as functional variational family a new class of flexible distributions called Stochastic Process Generators (SPGs), which are cleverly designed so that the functional ELBO can be estimated efficiently using analytic solutions and mini-batch sampling. FVI can be applied to stochastic process priors when random function samples from those priors are available. Our experiments show that FVI consistently outperforms weight-space and function space VI methods on several tasks, which validates the effectiveness of our approach.",
    "authors": [
      "Ma, Chao",
      "Hern\u00e1ndez-Lobato, Jos\u00e9 Miguel"
    ]
  },
  {
    "id": "b618c3210e934362ac261db280128c22",
    "title": "TTT++: When Does Self-Supervised Test-Time Training Fail or Thrive?",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b618c3210e934362ac261db280128c22-Paper.pdf",
    "abstract": "Test-time training (TTT) through self-supervised learning (SSL) is an emerging paradigm to tackle distributional shifts. Despite encouraging results, it remains unclear when this approach thrives or fails. In this work, we first provide an in-depth look at its limitations and show that TTT can possibly deteriorate, instead of improving, the test-time performance in the presence of severe distribution shifts. To address this issue, we introduce a test-time feature alignment strategy utilizing offline feature summarization and online moment matching, which regularizes adaptation without revisiting training data. We further scale this strategy in the online setting through batch-queue decoupling to enable robust moment estimates even with limited batch size. Given aligned feature distributions, we then shed light on the strong potential of TTT by theoretically analyzing its performance post adaptation. This analysis motivates our use of more informative self-supervision in the form of contrastive learning for visual recognition problems. We empirically demonstrate that our modified version of test-time training, termed TTT++, outperforms state-of-the-art methods by significant margins on several benchmarks. Our result indicates that storing and exploiting extra information, in addition to model parameters, can be a promising direction towards robust test-time adaptation.",
    "authors": [
      "Liu, Yuejiang",
      "Kothari, Parth",
      "van Delft, Bastien",
      "Bellot-Gurlet, Baptiste",
      "Mordan, Taylor",
      "Alahi, Alexandre"
    ]
  },
  {
    "id": "b61a560ed1b918340a0ddd00e08c990e",
    "title": "Double Machine Learning Density Estimation for Local Treatment Effects with Instruments",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b61a560ed1b918340a0ddd00e08c990e-Paper.pdf",
    "abstract": "Local treatment effects are a common quantity found throughout the empirical sciences that measure the treatment effect among those who comply with what they are assigned. Most of the literature is focused on estimating the average of such quantity, which is called the ``local average treatment effect (LATE)'' [Imbens and Angrist, 1994]). In this work, we study how to estimate the density of the local treatment effect, which is naturally more informative than its average. Specifically, we develop two families of methods for this task, namely, kernel-smoothing and model-based approaches. The kernel-smoothing-based approach estimates the density through some smooth kernel functions. The model-based approach estimates the density by projecting it onto a finite-dimensional density class. For both approaches, we derive the corresponding double/debiased machine learning-based estimators [Chernozhukov et al., 2018]. We further study the asymptotic convergence rates of the estimators and show that they are robust to the biases in nuisance function estimation. The use of the proposed methods is illustrated through both synthetic and a real dataset called 401(k).",
    "authors": [
      "Jung, Yonghan",
      "Tian, Jin",
      "Bareinboim, Elias"
    ]
  },
  {
    "id": "b6417f112bd27848533e54885b66c288",
    "title": "Dirichlet Energy Constrained Learning for Deep Graph Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b6417f112bd27848533e54885b66c288-Paper.pdf",
    "abstract": "Graph neural networks (GNNs) integrate deep architectures and topological structure modeling in an effective way. However, the performance of existing GNNs would decrease significantly when they stack many layers, because of the over-smoothing issue. Node embeddings tend to converge to similar vectors when GNNs keep recursively aggregating the representations of neighbors. To enable deep GNNs, several methods have been explored recently. But they are developed from either techniques in convolutional neural networks or heuristic strategies. There is no generalizable and theoretical principle to guide the design of deep GNNs. To this end, we analyze the bottleneck of deep GNNs by leveraging the Dirichlet energy of node embeddings, and propose a generalizable principle to guide the training of deep GNNs. Based on it, a novel deep GNN framework -- Energetic Graph Neural Networks (EGNN) is designed. It could provide lower and upper constraints in terms of Dirichlet energy at each layer to avoid over-smoothing. Experimental results demonstrate that EGNN achieves state-of-the-art performance by using deep layers.",
    "authors": [
      "Zhou, Kaixiong",
      "Huang, Xiao",
      "Zha, Daochen",
      "Chen, Rui",
      "Li, Li",
      "Choi, Soo-Hyun",
      "Hu, Xia"
    ]
  },
  {
    "id": "b6846b0186a035fcc76b1b1d26fd42fa",
    "title": "Accelerating Robotic Reinforcement Learning via Parameterized Action Primitives",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b6846b0186a035fcc76b1b1d26fd42fa-Paper.pdf",
    "abstract": "Despite the potential of reinforcement learning (RL) for building general-purpose robotic systems, training  RL agents to solve robotics tasks still remains challenging due to the difficulty of exploration in purely continuous action spaces. Addressing this problem is an active area of research with the majority of focus on improving RL methods via better optimization or more efficient exploration. An alternate but important component to consider improving is the interface of the RL algorithm with the robot. In this work, we manually specify a library of robot action primitives (RAPS), parameterized with arguments that are learned by an RL policy. These parameterized primitives are expressive, simple to implement, enable efficient exploration and can be transferred across robots, tasks and environments. We perform a thorough empirical study across challenging tasks in three distinct domains with image input and a sparse terminal reward. We find that our simple change to the action interface substantially improves both the learning efficiency and task performance irrespective of the underlying RL algorithm, significantly outperforming prior methods which learn skills from offline expert data.",
    "authors": [
      "Dalal, Murtaza",
      "Pathak, Deepak",
      "Salakhutdinov, Russ R."
    ]
  },
  {
    "id": "b691334ccf10d4ab144d672f7783c8a3",
    "title": " Boosted CVaR Classification",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b691334ccf10d4ab144d672f7783c8a3-Paper.pdf",
    "abstract": "Many modern machine learning tasks require models with high tail performance, i.e. high performance over the worst-off samples in the dataset. This problem has been widely studied in fields such as algorithmic fairness, class imbalance, and risk-sensitive decision making. A popular approach to maximize the model's tail performance is to minimize the CVaR (Conditional Value at Risk) loss, which computes the average risk over the tails of the loss. However, for classification tasks where models are evaluated by the zero-one loss, we show that if the classifiers are deterministic, then the minimizer of the average zero-one loss also minimizes the CVaR zero-one loss, suggesting that CVaR loss minimization is not helpful without additional assumptions. We circumvent this negative result by minimizing the CVaR loss over randomized classifiers, for which the minimizers of the average zero-one loss and the CVaR zero-one loss are no longer the same, so minimizing the latter can lead to better tail performance. To learn such randomized classifiers, we propose the Boosted CVaR Classification framework which is motivated by a direct relationship between CVaR and a classical boosting algorithm called LPBoost. Based on this framework, we design an algorithm called $\\alpha$-AdaLPBoost. We empirically evaluate our proposed algorithm on four benchmark datasets and show that it achieves higher tail performance than deterministic model training methods.",
    "authors": [
      "Zhai, Runtian",
      "Dan, Chen",
      "Suggala, Arun",
      "Kolter, J. Zico",
      "Ravikumar, Pradeep"
    ]
  },
  {
    "id": "b6cda17abb967ed28ec9610137aa45f7",
    "title": "Disentangled Contrastive Learning on Graphs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b6cda17abb967ed28ec9610137aa45f7-Paper.pdf",
    "abstract": "Recently, self-supervised learning for graph neural networks (GNNs) has attracted considerable attention because of their notable successes in learning the representation of graph-structure data. However, the formation of a real-world graph typically arises from the highly complex interaction of many latent factors. The existing self-supervised learning methods for GNNs are inherently holistic and neglect the entanglement of the latent factors, resulting in the learned representations suboptimal for downstream tasks and difficult to be interpreted. Learning disentangled graph representations with self-supervised learning poses great challenges and remains largely ignored by the existing literature. In this paper, we introduce the Disentangled Graph Contrastive Learning (DGCL) method, which is able to learn disentangled graph-level representations with self-supervision. In particular, we first identify the latent factors of the input graph and derive its factorized representations. Each of the factorized representations describes a latent and disentangled aspect pertinent to a specific latent factor of the graph. Then we propose a novel factor-wise discrimination objective in a contrastive learning manner, which can force the factorized representations to independently reflect the expressive information from different latent factors. Extensive experiments on both synthetic and real-world datasets demonstrate the superiority of our method against several state-of-the-art baselines.",
    "authors": [
      "Li, Haoyang",
      "Wang, Xin",
      "Zhang, Ziwei",
      "Yuan, Zehuan",
      "Li, Hang",
      "Zhu, Wenwu"
    ]
  },
  {
    "id": "b6f8dc086b2d60c5856e4ff517060392",
    "title": "Widening the Pipeline in Human-Guided Reinforcement Learning with Explanation and Context-Aware Data Augmentation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b6f8dc086b2d60c5856e4ff517060392-Paper.pdf",
    "abstract": "Human explanation (e.g., in terms of feature importance) has been recently used to extend the communication channel between human and agent in interactive machine learning. Under this setting, human trainers provide not only the ground truth but also some form of explanation. However, this kind of human guidance was only investigated in supervised learning tasks, and it remains unclear how to best incorporate this type of human knowledge into deep reinforcement learning. In this paper, we present the first study of using human visual explanations in human-in-the-loop reinforcement learning (HIRL). We focus on the task of learning from feedback, in which the human trainer not only gives binary evaluative \"good\" or \"bad\" feedback for queried state-action pairs, but also provides a visual explanation by annotating relevant features in images. We propose EXPAND (EXPlanation AugmeNted feeDback) to encourage the model to encode task-relevant features through a context-aware data augmentation that only perturbs irrelevant features in human salient information. We choose five tasks, namely Pixel-Taxi and four Atari games, to evaluate the performance and sample efficiency of this approach. We show that our method significantly outperforms methods leveraging human explanation that are adapted from supervised learning, and Human-in-the-loop RL baselines that only utilize evaluative feedback.",
    "authors": [
      "Guan, Lin",
      "Verma, Mudit",
      "Guo, Suna (Sihang)",
      "Zhang, Ruohan",
      "Kambhampati, Subbarao"
    ]
  },
  {
    "id": "b7087c1f4f89e63af8d46f3b20271153",
    "title": "SOLQ: Segmenting Objects by Learning Queries",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b7087c1f4f89e63af8d46f3b20271153-Paper.pdf",
    "abstract": "In this paper, we propose an end-to-end framework for instance segmentation. Based on the recently introduced DETR, our method, termed SOLQ, segments objects by learning unified queries. In SOLQ, each query represents one object and has multiple representations: class, location and mask. The object queries learned perform classification, box regression and mask encoding simultaneously in an unified vector form. During training phase, the mask vectors encoded are supervised by the compression coding of raw spatial masks. In inference time,mask vectors produced can be directly transformed to spatial masks by the inverse process of compression coding. Experimental results show that SOLQ can achieve state-of-the-art performance, surpassing most of existing approaches. Moreover, the joint learning of unified query representation can greatly improve the detection performance of DETR. We hope our SOLQ can serve as a strong baseline for the Transformer-based instance segmentation.",
    "authors": [
      "Dong, Bin",
      "Zeng, Fangao",
      "Wang, Tiancai",
      "Zhang, Xiangyu",
      "Wei, Yichen"
    ]
  },
  {
    "id": "b7a8486459730bea9569414ef76cf03f",
    "title": "Extending Lagrangian and Hamiltonian Neural Networks with Differentiable Contact Models",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b7a8486459730bea9569414ef76cf03f-Paper.pdf",
    "abstract": "The incorporation of appropriate inductive bias plays a critical role in learning dynamics from data. A growing body of work has been exploring ways to enforce energy conservation in the learned dynamics by encoding Lagrangian or Hamiltonian dynamics into the neural network architecture. These existing approaches are based on differential equations, which do not allow discontinuity in the states and thereby limit the class of systems one can learn. However, in reality, most physical systems, such as legged robots and robotic manipulators, involve contacts and collisions, which introduce discontinuities in the states. In this paper, we introduce a differentiable contact model, which can capture contact mechanics: frictionless/frictional, as well as elastic/inelastic. This model can also accommodate inequality constraints, such as limits on the joint angles. The proposed contact model extends the scope of Lagrangian and Hamiltonian neural networks by allowing simultaneous learning of contact and system properties. We demonstrate this framework on a series of challenging 2D and 3D physical systems with different coefficients of restitution and friction. The learned dynamics can be used as a differentiable physics simulator for downstream gradient-based optimization tasks, such as planning and control.",
    "authors": [
      "Zhong, Yaofeng Desmond",
      "Dey, Biswadip",
      "Chakraborty, Amit"
    ]
  },
  {
    "id": "b7da6669894867f04b8727876a69ffc0",
    "title": "Best-case lower bounds in online learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b7da6669894867f04b8727876a69ffc0-Paper.pdf",
    "abstract": "Much of the work in online learning focuses on the study of sublinear upper bounds on the regret. In this work, we initiate the study of best-case lower bounds in online convex optimization, wherein we bound the largest \\emph{improvement} an algorithm can obtain relative to the single best action in hindsight. This problem is motivated by the goal of better understanding the adaptivity of a learning algorithm. Another motivation comes from fairness: it is known that best-case lower bounds are instrumental in obtaining algorithms for decision-theoretic online learning (DTOL) that satisfy a notion of group fairness. Our contributions are a general method to provide best-case lower bounds in Follow The Regularized Leader (FTRL) algorithms with time-varying regularizers, which we use to show that best-case lower bounds are of the same order as existing upper regret bounds: this includes situations with a fixed learning rate, decreasing learning rates, timeless methods, and adaptive gradient methods. In stark contrast, we show that the linearized version of FTRL can attain negative linear regret. Finally, in DTOL with two experts and binary losses, we fully characterize the best-case sequences, which provides a finer understanding of the best-case lower bounds.",
    "authors": [
      "Guzm\u00e1n, Crist\u00f3bal",
      "Mehta, Nishant",
      "Mortazavi, Ali"
    ]
  },
  {
    "id": "b7f7ada7d848002260ee5eb7d8835709",
    "title": "A Comprehensively Tight Analysis of Gradient Descent for PCA",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b7f7ada7d848002260ee5eb7d8835709-Paper.pdf",
    "abstract": "We study the Riemannian gradient method for PCA on which a crucial fact is that despite the simplicity of the considered setting, i.e., deterministic version of Krasulina's method, the convergence rate has not been well-understood yet. In this work, we provide a general tight analysis for the gap-dependent rate at $O(\\frac{1}{\\Delta}\\log\\frac{1}{\\epsilon})$ that holds for any real symmetric matrix. More importantly, when the gap $\\Delta$ is significantly smaller than the target accuracy $\\epsilon$ on the objective sub-optimality of the final solution, the rate of this type is actually not tight any more, which calls for a worst-case rate. We further give the first worst-case analysis that achieves a rate of convergence at $O(\\frac{1}{\\epsilon}\\log\\frac{1}{\\epsilon})$. The two analyses naturally roll out a comprehensively tight convergence rate at $O(\\frac{1}{\\max\\{\\Delta,\\epsilon\\}}\\hskip-.3em\\log\\frac{1}{\\epsilon})$. Particularly, our gap-dependent analysis suggests a new promising learning rate for stochastic variance reduced PCA algorithms. Experiments are conducted to confirm our findings as well.",
    "authors": [
      "Xu, Zhiqiang",
      "Li, Ping"
    ]
  },
  {
    "id": "b80ba73857eed2a36dc7640e2310055a",
    "title": "On Robust Optimal Transport: Computational Complexity and Barycenter Computation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b80ba73857eed2a36dc7640e2310055a-Paper.pdf",
    "abstract": "We consider robust variants of the standard optimal transport, named robust optimal transport, where marginal constraints are relaxed via Kullback-Leibler divergence. We show that Sinkhorn-based algorithms can approximate the optimal cost of robust optimal transport in $\\widetilde{\\mathcal{O}}(\\frac{n^2}{\\varepsilon})$ time, in which $n$ is the number of supports of the probability distributions and $\\varepsilon$ is the desired error. Furthermore, we investigate a fixed-support robust barycenter problem between $m$ discrete probability distributions with at most $n$ number of supports and develop an approximating algorithm based on iterative Bregman projections (IBP). For the specific case $m = 2$, we show that this algorithm can approximate the optimal barycenter value in $\\widetilde{\\mathcal{O}}(\\frac{mn^2}{\\varepsilon})$ time, thus being better than the previous complexity $\\widetilde{\\mathcal{O}}(\\frac{mn^2}{\\varepsilon^2})$ of the IBP algorithm for approximating the Wasserstein barycenter.",
    "authors": [
      "Le, Khang",
      "Nguyen, Huy",
      "Nguyen, Quang M",
      "Pham, Tung",
      "Bui, Hung",
      "Ho, Nhat"
    ]
  },
  {
    "id": "b8102d1fa5df93e62cf26cd4400a0727",
    "title": "Asymptotically Best Causal Effect Identification with Multi-Armed Bandits",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b8102d1fa5df93e62cf26cd4400a0727-Paper.pdf",
    "abstract": "This paper considers the problem of selecting a formula for identifying a causal quantity of interest among a set of available formulas. We assume an online setting in which the investigator may alter the data collection mechanism in a data-dependent way with the aim of identifying the formula with lowest asymptotic variance in as few samples as possible. We formalize this setting by using the best-arm-identification bandit framework where the standard goal of learning the arm with the lowest loss is replaced with the goal of learning the arm that will produce the best estimate. We introduce new tools for constructing finite-sample confidence bounds on estimates of the asymptotic variance that account for the estimation of potentially complex nuisance functions, and adapt the best-arm-identification algorithms of LUCB and Successive Elimination to use these bounds. We validate our method by providing upper bounds on the sample complexity and an empirical study on artificially generated data.",
    "authors": [
      "Malek, Alan",
      "Chiappa, Silvia"
    ]
  },
  {
    "id": "b87039703fe79778e9f140b78621d7fb",
    "title": "Learning rule influences recurrent network representations but not attractor structure in decision-making tasks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b87039703fe79778e9f140b78621d7fb-Paper.pdf",
    "abstract": "Recurrent neural networks (RNNs) are popular tools for studying computational dynamics in neurobiological circuits. However, due to the dizzying array of design choices, it is unclear if computational dynamics unearthed from RNNs provide reliable neurobiological inferences. Understanding the effects of design choices on RNN computation is valuable in two ways. First, invariant properties that persist in RNNs across a wide range of design choices are more likely to be candidate neurobiological mechanisms. Second, understanding what design choices lead to similar dynamical solutions reduces the burden of imposing that all design choices be totally faithful replications of biology. We focus our investigation on how RNN learning rule and task design affect RNN computation. We trained large populations of RNNs with different, but commonly used, learning rules on decision-making tasks inspired by neuroscience literature. For relatively complex tasks, we find that attractor topology is invariant to the choice of learning rule, but representational geometry is not. For simple tasks, we find that attractor topology depends on task input noise. However, when a task becomes increasingly complex, RNN attractor topology becomes invariant to input noise. Together, our results suggest that RNN dynamics are robust across learning rules but can be sensitive to the training task design, especially for simpler tasks.",
    "authors": [
      "McMahan, Brandon",
      "Kleinman, Michael",
      "Kao, Jonathan"
    ]
  },
  {
    "id": "b8b12f949378552c21f28deff8ba8eb6",
    "title": "Few-Shot Segmentation via Cycle-Consistent Transformer",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b8b12f949378552c21f28deff8ba8eb6-Paper.pdf",
    "abstract": "Few-shot segmentation aims to train a segmentation model that can fast adapt to novel classes with few exemplars. The conventional training paradigm is to learn to make predictions on query images conditioned on the features from support images. Previous methods only utilized the semantic-level prototypes of support images as the conditional information. These methods cannot utilize all pixel-wise support information for the query predictions, which is however critical for the segmentation task. In this paper, we focus on utilizing pixel-wise relationships between support and target images to facilitate the few-shot semantic segmentation task. We design a novel Cycle-Consistent Transformer (CyCTR) module to aggregate pixel-wise support features into query ones. CyCTR performs cross-attention between features from different images, i.e. support and query images. We observe that there may exist unexpected irrelevant pixel-level support features. Directly performing cross-attention may aggregate these features from support to query and bias the query features. Thus, we propose using a novel cycle-consistent attention mechanism to filter out possible harmful support features and encourage query features to attend to the most informative pixels from support images. Experiments on all few-shot segmentation benchmarks demonstrate that our proposed CyCTR leads to remarkable improvement compared to previous state-of-the-art methods. Specifically, on Pascal-5^i and COCO-20^i datasets, we achieve 66.6% and 45.6% mIoU for 5-shot segmentation, outperforming previous state-of-the-art by 4.6% and 7.1% respectively.",
    "authors": [
      "Zhang, Gengwei",
      "Kang, Guoliang",
      "Yang, Yi",
      "Wei, Yunchao"
    ]
  },
  {
    "id": "b8b2926bd27d4307569ad119b6025f94",
    "title": "DropGNN: Random Dropouts Increase the Expressiveness of Graph Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b8b2926bd27d4307569ad119b6025f94-Paper.pdf",
    "abstract": "This paper studies Dropout Graph Neural Networks (DropGNNs), a new approach that aims to overcome the limitations of standard GNN frameworks. In DropGNNs, we execute multiple runs of a GNN on the input graph, with some of the nodes randomly and independently dropped in each of these runs. Then, we combine the results of these runs to obtain the final result. We prove that DropGNNs can distinguish various graph neighborhoods that cannot be separated by message passing GNNs. We derive theoretical bounds for the number of runs required to ensure a reliable distribution of dropouts, and we prove several properties regarding the expressive capabilities and limits of DropGNNs. We experimentally validate our theoretical findings on expressiveness. Furthermore, we show that DropGNNs perform competitively on established GNN benchmarks.",
    "authors": [
      "Papp, P\u00e1l Andr\u00e1s",
      "Martinkus, Karolis",
      "Faber, Lukas",
      "Wattenhofer, Roger"
    ]
  },
  {
    "id": "b8c4c8b2271787e2f78b5fe2ce193caa",
    "title": "Photonic Differential Privacy with Direct Feedback Alignment",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b8c4c8b2271787e2f78b5fe2ce193caa-Paper.pdf",
    "abstract": "Optical Processing Units (OPUs) -- low-power photonic chips dedicated to large scale random projections -- have been used in previous work to train deep neural networks using Direct Feedback Alignment (DFA), an effective alternative to backpropagation. Here, we demonstrate how to leverage the intrinsic noise of optical random projections to build a differentially private DFA mechanism, making OPUs a solution of choice to provide a \\emph{private-by-design} training. We provide a theoretical analysis of our adaptive privacy mechanism, carefully measuring how the noise of optical random projections propagates in the process and gives rise to provable Differential Privacy. Finally, we conduct experiments demonstrating the ability of our learning procedure to achieve solid end-task performance. ",
    "authors": [
      "Ohana, Ruben",
      "Medina, Hamlet",
      "Launay, Julien",
      "Cappelli, Alessandro",
      "Poli, Iacopo",
      "Ralaivola, Liva",
      "Rakotomamonjy, Alain"
    ]
  },
  {
    "id": "b9009beb804fa097c04d226a8ba5102e",
    "title": "Searching Parameterized AP Loss for Object Detection",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b9009beb804fa097c04d226a8ba5102e-Paper.pdf",
    "abstract": "Loss functions play an important role in training deep-network-based object detectors. The most widely used evaluation metric for object detection is Average Precision (AP), which captures the performance of localization and classification sub-tasks simultaneously. However, due to the non-differentiable nature of the AP metric, traditional object detectors adopt separate differentiable losses for the two sub-tasks. Such a mis-alignment issue may well lead to performance degradation. To address this, existing works seek to design surrogate losses for the AP metric manually, which requires expertise and may still be sub-optimal. In this paper, we propose Parameterized AP Loss, where parameterized functions are introduced to substitute the non-differentiable components in the AP calculation. Different AP approximations are thus represented by a family of parameterized functions in a unified formula. Automatic parameter search algorithm is then employed to search for the optimal parameters. Extensive experiments on the COCO benchmark with three different object detectors (i.e., RetinaNet, Faster R-CNN, and Deformable DETR) demonstrate that the proposed Parameterized AP Loss consistently outperforms existing handcrafted losses. Code shall be released.",
    "authors": [
      "Chenxin, Tao",
      "Li, Zizhang",
      "Zhu, Xizhou",
      "Huang, Gao",
      "Liu, Yong",
      "dai, jifeng"
    ]
  },
  {
    "id": "b90c46963248e6d7aab1e0f429743ca0",
    "title": "Fair Exploration via Axiomatic Bargaining",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b90c46963248e6d7aab1e0f429743ca0-Paper.pdf",
    "abstract": "Motivated by the consideration of fairly sharing the cost of exploration between multiple groups in learning problems, we develop the Nash bargaining solution in the context of multi-armed bandits. Specifically, the 'grouped' bandit associated with any multi-armed bandit problem associates, with each time step, a single group from some finite set of groups. The utility gained by a given group under some learning policy is naturally viewed as the reduction in that group's regret relative to the regret that group would have incurred 'on its own'. We derive policies that yield the Nash bargaining solution relative to the set of incremental utilities possible under any policy. We show that on the one hand, the 'price of fairness' under such policies is limited, while on the other hand, regret optimal policies are arbitrarily unfair under generic conditions. Our theoretical development is complemented by a case study on contextual bandits for warfarin dosing where we are concerned with the cost of exploration across multiple races and age groups. ",
    "authors": [
      "Baek, Jackie",
      "Farias, Vivek"
    ]
  },
  {
    "id": "b91a76b0b2fa7ce160212f53f3d2edba",
    "title": "Unifying lower bounds on prediction dimension of convex surrogates",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b91a76b0b2fa7ce160212f53f3d2edba-Paper.pdf",
    "abstract": "The convex consistency dimension of a supervised learning task is the lowest prediction dimension $d$ such that there exists a convex surrogate $L : \\mathbb{R}^d \\times  \\mathcal Y \\to \\mathbb R$ that is consistent for the given task. We present a new tool  based on property elicitation, $d$-flats, for lower-bounding convex consistency dimension. This tool unifies approaches from a variety of domains, including continuous and discrete prediction problems. We use $d$-flats to obtain a new lower bound on the convex consistency dimension of risk measures, resolving an open question due to Frongillo and Kash (NeurIPS 2015). In discrete prediction settings, we show that the $d$-flats approach recovers and even tightens previous lower bounds using feasible subspace dimension.",
    "authors": [
      "Finocchiaro, Jessica",
      "Frongillo, Rafael",
      "Waggoner, Bo"
    ]
  },
  {
    "id": "b91b1facf3b3a7890177f02ac188f14c",
    "title": "Ultrahyperbolic Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b91b1facf3b3a7890177f02ac188f14c-Paper.pdf",
    "abstract": "Riemannian space forms, such as the Euclidean space, sphere and hyperbolic space, are popular and powerful representation spaces in machine learning. For instance, hyperbolic geometry is appropriate to represent graphs without cycles and has been used to extend Graph Neural Networks. Recently, some pseudo-Riemannian space forms that generalize both hyperbolic and spherical geometries have been exploited to learn a specific type of nonparametric embedding called ultrahyperbolic. The lack of geodesic between every pair of ultrahyperbolic points makes the task of learning parametric models (e.g., neural networks) difficult. This paper introduces a method to learn parametric models in ultrahyperbolic space. We experimentally show the relevance of our approach in the tasks of graph and node classification. ",
    "authors": [
      "Law, Marc"
    ]
  },
  {
    "id": "b922ede9c9eb9eabec1c1fecbdecb45d",
    "title": " NeuroMLR: Robust & Reliable Route Recommendation on Road Networks ",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b922ede9c9eb9eabec1c1fecbdecb45d-Paper.pdf",
    "abstract": "Predicting the most likely route from a source location to a destination is a core functionality in mapping services. Although the problem has been studied in the literature, two key limitations remain to be addressed. First, our study reveals that a significant portion of the routes recommended by existing methods fail to reach the destination. Second, existing techniques are transductive in nature; hence, they fail to recommend routes if unseen roads are encountered at inference time. In this paper, we address these limitations through an inductive algorithm called NeuroMLR. NeuroMLR learns a generative model from historical trajectories by conditioning on three explanatory factors: the current location, the destination, and real-time traffic conditions. The conditional distributions are learned through a novel combination of Lipschitz embedding with Graph Convolutional Networks (GCN) using historical trajectory data. Through in-depth experiments on real-world datasets, we establish that NeuroMLR imparts significant improvement in accuracy over the state of the art. More importantly, NeuroMLR generalizes dramatically better to unseen data and the recommended routes reach the destination with much higher likelihood than existing techniques.",
    "authors": [
      "Jain, Jayant",
      "Bagadia, Vrittika",
      "Manchanda, Sahil",
      "Ranu, Sayan"
    ]
  },
  {
    "id": "b943325cc7b7422d2871b345bf9b067f",
    "title": "Risk Bounds and Calibration for a Smart Predict-then-Optimize Method",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b943325cc7b7422d2871b345bf9b067f-Paper.pdf",
    "abstract": "The predict-then-optimize framework is fundamental in practical stochastic decision-making problems:  first predict unknown parameters of an optimization model, then solve the problem using the predicted values. A natural loss function in this setting is defined by measuring the decision error induced by the predicted parameters, which was named the Smart Predict-then-Optimize (SPO) loss by Elmachtoub and Grigas [2021]. Since the SPO loss is typically nonconvex and possibly discontinuous, Elmachtoub and Grigas [2021] introduced a convex surrogate, called the SPO+ loss, that importantly accounts for the underlying structure of the optimization model. In this paper, we greatly expand upon the consistency results for the SPO+ loss provided by Elmachtoub and Grigas [2021]. We develop risk bounds and uniform calibration results for the SPO+ loss relative to the SPO loss, which provide a quantitative way to transfer the excess surrogate risk to excess true risk. By combining our risk bounds with generalization bounds, we show that the empirical minimizer of the SPO+ loss achieves low excess true risk with high probability. We first demonstrate these results in the case when the feasible region of the underlying optimization problem is a polyhedron, and then we show that the results can be strengthened substantially when the feasible region is a level set of a strongly convex function. We perform experiments to empirically demonstrate the strength of the SPO+ surrogate, as compared to standard $\\ell_1$ and squared $\\ell_2$ prediction error losses, on portfolio allocation and cost-sensitive multi-class classification problems.",
    "authors": [
      "Liu, Heyuan",
      "Grigas, Paul"
    ]
  },
  {
    "id": "b950ea26ca12daae142bd74dba4427c8",
    "title": "Three-dimensional spike localization and improved motion correction for Neuropixels recordings",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b950ea26ca12daae142bd74dba4427c8-Paper.pdf",
    "abstract": "Neuropixels (NP) probes are dense linear multi-electrode arrays that have rapidly become essential tools for studying the electrophysiology of large neural populations.  Unfortunately, a number of challenges remain in analyzing the large datasets output by these probes.  Here we introduce several new methods for extracting useful spiking information from NP probes.  First, we use a simple point neuron model, together with a neural-network denoiser, to efficiently map spikes detected on the probe into three-dimensional localizations.  Previous methods localized spikes in two dimensions only; we show that the new localization approach is significantly more robust and provides an improved feature set for clustering spikes according to neural identity (``spike sorting\").  Next, we apply a Poisson denoising method to the resulting three-dimensional point-cloud representation of the data, and show that the resulting 3D images can be accurately registered over time, leading to improved tracking of time-varying neural activity over the probe, and in turn, crisper estimates of neural clusters over time. The code to reproduce our results and an example neuropixels dataset is provided in the supplementary material.",
    "authors": [
      "Boussard, Julien",
      "Varol, Erdem",
      "Lee, Hyun Dong",
      "Dethe, Nishchal",
      "Paninski, Liam"
    ]
  },
  {
    "id": "b98249b38337c5088bbc660d8f872d6a",
    "title": "Semi-Supervised Semantic Segmentation via Adaptive Equalization Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b98249b38337c5088bbc660d8f872d6a-Paper.pdf",
    "abstract": "Due to the limited and even imbalanced data, semi-supervised semantic segmentation tends to have poor performance on some certain categories, e.g., tailed categories in Cityscapes dataset which exhibits a long-tailed label distribution. Existing approaches almost all neglect this problem, and treat categories equally. Some popular approaches such as consistency regularization or pseudo-labeling may even harm the learning of under-performing categories, that the predictions or pseudo labels of these categories could be too inaccurate to guide the learning on the unlabeled data. In this paper, we look into this problem, and propose a novel framework for semi-supervised semantic segmentation, named adaptive equalization learning (AEL). AEL adaptively balances the training of well and badly performed categories, with a confidence bank to dynamically track category-wise performance during training. The confidence bank is leveraged as an indicator to tilt training towards under-performing categories, instantiated in three strategies: 1) adaptive Copy-Paste and CutMix data augmentation approaches which give more chance for under-performing categories to be copied or cut; 2) an adaptive data sampling approach to encourage pixels from under-performing category to be sampled; 3) a simple yet effective re-weighting method to alleviate the training noise raised by pseudo-labeling. Experimentally, AEL outperforms the state-of-the-art methods by a large margin on the Cityscapes and Pascal VOC benchmarks under various data partition protocols. Code is available at https://github.com/hzhupku/SemiSeg-AEL.",
    "authors": [
      "Hu, Hanzhe",
      "Wei, Fangyun",
      "Hu, Han",
      "Ye, Qiwei",
      "Cui, Jinshi",
      "Wang, Liwei"
    ]
  },
  {
    "id": "b986700c627db479a4d9460b75de7222",
    "title": "On the Bias-Variance-Cost Tradeoff of Stochastic Optimization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b986700c627db479a4d9460b75de7222-Paper.pdf",
    "abstract": "We consider stochastic optimization when one only has access to biased stochastic oracles of the objective, and obtaining stochastic gradients with low biases comes at high costs. This setting captures a variety of optimization paradigms widely used in machine learning, such as conditional stochastic optimization, bilevel optimization, and distributionally robust optimization. We examine a family of multi-level Monte Carlo (MLMC) gradient methods that exploit a delicate trade-off among the bias, the variance, and the oracle cost. We provide a systematic study of their convergences and total computation complexities for strongly convex, convex, and nonconvex objectives, and demonstrate their superiority over the naive biased stochastic gradient method. Moreover, when applied to conditional stochastic optimization, the MLMC gradient methods significantly improve the best-known sample complexity in the literature. ",
    "authors": [
      "Hu, Yifan",
      "Chen, Xin",
      "He, Niao"
    ]
  },
  {
    "id": "b9acb4ae6121c941324b2b1d3fac5c30",
    "title": "Averaging on the Bures-Wasserstein manifold: dimension-free convergence of gradient descent",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b9acb4ae6121c941324b2b1d3fac5c30-Paper.pdf",
    "abstract": "We study first-order optimization algorithms for computing the barycenter of Gaussian distributions with respect to the optimal transport metric. Although the objective is geodesically non-convex, Riemannian gradient descent empirically converges rapidly, in fact faster than off-the-shelf methods such as Euclidean gradient descent and SDP solvers. This stands in stark contrast to the best-known theoretical results, which depend exponentially on the dimension. In this work, we prove new geodesic convexity results which provide stronger control of the iterates, yielding a dimension-free convergence rate. Our techniques also enable the analysis of two related notions of averaging, the entropically-regularized barycenter and the geometric median, providing the first convergence guarantees for these problems.",
    "authors": [
      "Altschuler, Jason",
      "Chewi, Sinho",
      "Gerber, Patrik R",
      "Stromme, Austin"
    ]
  },
  {
    "id": "b9ed18a301c9f3d183938c451fa183df",
    "title": "Reinforcement Learning in Newcomblike Environments",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b9ed18a301c9f3d183938c451fa183df-Paper.pdf",
    "abstract": "Newcomblike decision problems have been studied extensively in the decision theory literature, but they have so far been largely absent in the reinforcement learning literature. In this paper we study value-based reinforcement learning algorithms in the Newcomblike setting, and answer some of the fundamental theoretical questions about the behaviour of such algorithms in these environments. We show that a value-based reinforcement learning agent cannot converge to a policy that is not \\emph{ratifiable}, i.e., does not only choose actions that are optimal given that policy. This gives us a powerful tool for reasoning about the limit behaviour of agents -- for example, it lets us show that there are Newcomblike environments in which a reinforcement learning agent cannot converge to any optimal policy. We show that a ratifiable policy always exists in our setting, but that there are cases in which a reinforcement learning agent normally cannot converge to it (and hence cannot converge at all). We also prove several results about the possible limit behaviours of agents in cases where they do not converge to any policy.",
    "authors": [
      "Bell, James",
      "Linsefors, Linda",
      "Oesterheld, Caspar",
      "Skalse, Joar"
    ]
  },
  {
    "id": "b9f35816f460ab999cbc168c4da26ff3",
    "title": "Comprehensive Knowledge Distillation with Causal Intervention",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/b9f35816f460ab999cbc168c4da26ff3-Paper.pdf",
    "abstract": "Knowledge distillation (KD) addresses model compression by distilling knowledge from a large model (teacher) to a smaller one (student). The existing distillation approaches mainly focus on using different criteria to align the sample representations learned by the student and the teacher, while they fail to transfer the class representations. Good class representations can benefit the sample representation learning by shaping the sample representation distribution. On the other hand, the existing approaches enforce the student to fully imitate the teacher while ignoring the fact that the teacher is typically not perfect. Although the teacher has learned rich and powerful representations, it also contains unignorable bias knowledge which is usually induced by the context prior (e.g., background) in the training data. To address these two issues, in this paper, we propose comprehensive, interventional distillation (CID) that captures both sample and class representations from the teacher while removing the bias with causal intervention. Different from the existing literature that uses the softened logits of the teacher as the training targets, CID considers the softened logits as the context information of an image, which is further used to remove the biased knowledge based on causal inference. Keeping the good representations while removing the bad bias enables CID to have a better generalization ability on test data and a better transferability across different datasets against the existing state-of-the-art approaches, which is demonstrated by extensive experiments on several benchmark datasets.",
    "authors": [
      "Deng, Xiang",
      "Zhang, Zhongfei"
    ]
  },
  {
    "id": "ba3c5fe1d6d6708b5bffaeb6942b7e04",
    "title": "Reinforcement Learning with Latent Flow",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ba3c5fe1d6d6708b5bffaeb6942b7e04-Paper.pdf",
    "abstract": "Temporal information is  essential to learning effective policies with Reinforcement Learning (RL). However, current state-of-the-art RL algorithms either assume that such information is given as part of the state space or, when learning from pixels, use the simple heuristic of frame-stacking to implicitly capture temporal information present in the image observations. This heuristic is in contrast to the current paradigm in video classification architectures, which utilize explicit encodings of temporal information through methods such as optical flow and two-stream architectures to achieve state-of-the-art performance. Inspired by leading video classification architectures, we introduce the Flow of Latents for Reinforcement Learning (Flare), a network architecture for RL that explicitly encodes temporal information through latent vector differences. We show that Flare recovers optimal performance in state-based RL without explicit access to the state velocity, solely with positional state information. Flare is the most sample efficient model-free pixel-based RL algorithm on the DeepMind Control suite when evaluated on the 500k and 1M step benchmarks across 5 challenging control tasks, and, when used with Rainbow DQN, outperforms the competitive baseline on Atari games at 100M time step benchmark across 8 challenging games. ",
    "authors": [
      "Shang, Wenling",
      "Wang, Xiaofei",
      "Srinivas, Aravind",
      "Rajeswaran, Aravind",
      "Gao, Yang",
      "Abbeel, Pieter",
      "Laskin, Misha"
    ]
  },
  {
    "id": "ba3c736667394d5082f86f28aef38107",
    "title": "Understanding How Encoder-Decoder Architectures Attend",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ba3c736667394d5082f86f28aef38107-Paper.pdf",
    "abstract": "Encoder-decoder networks with attention have proven to be a powerful way to solve many sequence-to-sequence tasks. In these networks, attention aligns encoder and decoder states and is often used for visualizing network behavior. However, the mechanisms used by networks to generate appropriate attention matrices are still mysterious. Moreover, how these mechanisms vary depending on the particular architecture used for the encoder and decoder (recurrent, feed-forward, etc.) are also not well understood. In this work, we investigate how encoder-decoder networks solve different sequence-to-sequence tasks. We introduce a way of decomposing hidden states over a sequence into temporal (independent of input) and input-driven (independent of sequence position) components. This reveals how attention matrices are formed: depending on the task requirements, networks rely more heavily on either the temporal or input-driven components. These findings hold across both recurrent and feed-forward architectures despite their differences in forming the temporal components. Overall, our results provide new insight into the inner workings of attention-based encoder-decoder networks.",
    "authors": [
      "Aitken, Kyle",
      "Ramasesh, Vinay",
      "Cao, Yuan",
      "Maheswaranathan, Niru"
    ]
  },
  {
    "id": "ba3c95c2962d3aab2f6e667932daa3c5",
    "title": "Latent Execution for Neural Program Synthesis Beyond Domain-Specific Languages",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ba3c95c2962d3aab2f6e667932daa3c5-Paper.pdf",
    "abstract": "Program synthesis from input-output (IO) examples has been a long-standing challenge. While recent works demonstrated limited success on domain-specific languages (DSL), it remains highly challenging to apply them to real-world programming languages, such as C. Due to complicated syntax and token variation, there are three major challenges: (1) unlike many DSLs, programs in languages like C need to compile first and are not executed via interpreters; (2) the program search space grows exponentially when the syntax and semantics of the programming language become more complex; and (3) collecting a large-scale dataset of real-world programs is non-trivial. As a first step to address these challenges, we propose LaSynth and show its efficacy in a restricted-C domain (i.e., C code with tens of tokens, with sequential, branching, loop and simple arithmetic operations but no library call). More specifically, LaSynth learns the latent representation to approximate the execution of partially generated programs, even if they are incomplete in syntax (addressing (1)). The learned execution significantly improves the performance of next token prediction over existing approaches, facilitating search (addressing (2)). Finally, once trained with randomly generated ground-truth programs and their IO pairs, LaSynth can synthesize more concise programs that resemble human-written code. Furthermore, retraining our model with these synthesized programs yields better performance with fewer samples for both Karel and C program synthesis, indicating the promise of leveraging the learned program synthesizer to improve the dataset quality for input-output program synthesis (addressing (3)). When evaluating on whether the program execution outputs match the IO pairs, LaSynth achieves 55.2% accuracy on generating simple C code with tens of tokens including loops and branches, outperforming existing approaches without executors by around 20%.",
    "authors": [
      "Chen, Xinyun",
      "Song, Dawn",
      "Tian, Yuandong"
    ]
  },
  {
    "id": "ba530cdf0a884348613f2aaa3a5ba5e8",
    "title": "Two steps to risk sensitivity",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ba530cdf0a884348613f2aaa3a5ba5e8-Paper.pdf",
    "abstract": "Distributional reinforcement learning (RL) \u2013 in which agents learn about all the possible long-term consequences of their actions, and not just the expected value \u2013 is of great recent interest. One of the most important affordances of a distributional view is facilitating a modern, measured, approach to risk when outcomes are not completely certain. By contrast, psychological and neuroscientific investigations into decision making under risk have utilized a variety of more venerable theoretical models such as prospect theory that lack axiomatically desirable properties such as coherence. Here, we consider a particularly relevant risk measure for modeling human and animal planning, called conditional value-at-risk (CVaR), which quantifies worst-case outcomes (e.g., vehicle accidents or predation). We first adopt a conventional distributional approach to CVaR in a sequential setting and reanalyze the choices of human decision-makers in the well-known two-step task, revealing substantial risk aversion that had been lurking under stickiness and perseveration. We then consider a further critical property of risk sensitivity, namely time consistency, showing alternatives to this form of CVaR that enjoy this desirable characteristic. We use simulations to examine settings in which the various forms differ in ways that have implications for human and animal planning and behavior.",
    "authors": [
      "Gagne, Christopher",
      "Dayan, Peter"
    ]
  },
  {
    "id": "ba9fab001f67381e56e410575874d967",
    "title": "DECAF:  Generating Fair Synthetic Data Using Causally-Aware Generative Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ba9fab001f67381e56e410575874d967-Paper.pdf",
    "abstract": "Machine learning models have been criticized for reflecting unfair biases in the training data.  Instead of solving for this by introducing fair learning algorithms directly, we focus on generating fair synthetic data, such that any downstream learner is fair. Generating fair synthetic data from unfair data - while remaining truthful to the underlying data-generating process (DGP) - is non-trivial. In this paper, we introduce DECAF: a GAN-based fair synthetic data generator for tabular data.  With DECAF we embed the DGP explicitly as a structural causal model in the input layers of the generator, allowing each variable to be reconstructed conditioned on its causal parents.  This procedure enables inference time debiasing, where biased edges can be strategically removed for satisfying user-defined fairness requirements. The DECAF framework is versatile and compatible with several popular definitions of fairness. In our experiments, we show that DECAF successfully removes undesired bias and - in contrast to existing methods - is capable of generating high-quality synthetic data. Furthermore, we provide theoretical guarantees on the generator's convergence and the fairness of downstream models.",
    "authors": [
      "van Breugel, Boris",
      "Kyono, Trent",
      "Berrevoets, Jeroen",
      "van der Schaar, Mihaela"
    ]
  },
  {
    "id": "bac49b876d5dfc9cd169c22ef5178ca7",
    "title": "EvoGrad: Efficient Gradient-Based Meta-Learning and Hyperparameter Optimization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/bac49b876d5dfc9cd169c22ef5178ca7-Paper.pdf",
    "abstract": "Gradient-based meta-learning and hyperparameter optimization have seen significant progress recently, enabling practical end-to-end training of neural networks together with many hyperparameters. Nevertheless, existing approaches are relatively expensive as they need to compute second-order derivatives and store a longer computational graph. This cost prevents scaling them to larger network architectures. We present EvoGrad, a new approach to meta-learning that draws upon evolutionary techniques to more efficiently compute hypergradients. EvoGrad estimates hypergradient with respect to hyperparameters without calculating second-order gradients, or storing a longer computational graph, leading to significant improvements in  efficiency. We evaluate EvoGrad on three substantial recent meta-learning applications, namely cross-domain few-shot learning with feature-wise transformations, noisy label learning with Meta-Weight-Net and low-resource cross-lingual learning with meta representation transformation. The results show that EvoGrad significantly improves efficiency and enables scaling meta-learning to bigger architectures such as from ResNet10 to ResNet34.",
    "authors": [
      "Bohdal, Ondrej",
      "Yang, Yongxin",
      "Hospedales, Timothy"
    ]
  },
  {
    "id": "bacadc62d6e67d7897cef027fa2d416c",
    "title": "Biological learning in key-value memory networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/bacadc62d6e67d7897cef027fa2d416c-Paper.pdf",
    "abstract": "In neuroscience, classical Hopfield networks are the standard biologically plausible model of long-term memory, relying on Hebbian plasticity for storage and attractor dynamics for recall. In contrast, memory-augmented neural networks in machine learning commonly use a key-value mechanism to store and read out memories in a single step. Such augmented networks achieve impressive feats of memory compared to traditional variants, yet their biological relevance is unclear. We propose an implementation of basic key-value memory that stores inputs using a combination of biologically plausible three-factor plasticity rules. The same rules are recovered when network parameters are meta-learned. Our network performs on par with classical Hopfield networks on autoassociative memory tasks and can be naturally extended to continual recall, heteroassociative memory, and sequence learning. Our results suggest a compelling alternative to the classical Hopfield network as a model of biological long-term memory.",
    "authors": [
      "Tyulmankov, Danil",
      "Fang, Ching",
      "Vadaparty, Annapurna",
      "Yang, Guangyu Robert"
    ]
  },
  {
    "id": "baf4f1a5938b8d520b328c13b51ccf11",
    "title": "Correlated Stochastic Block Models: Exact Graph Matching with Applications to Recovering Communities",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/baf4f1a5938b8d520b328c13b51ccf11-Paper.pdf",
    "abstract": "We consider the task of learning latent community structure from multiple correlated networks. First, we study the problem of learning the latent vertex correspondence between two edge-correlated stochastic block models, focusing on the regime where the average degree is logarithmic in the number of vertices. We derive the precise information-theoretic threshold for exact recovery: above the threshold there exists an estimator that outputs the true correspondence with probability close to 1, while below it no estimator can recover the true correspondence with probability bounded away from 0. As an application of our results, we show how one can exactly recover the latent communities using \\emph{multiple} correlated graphs in parameter regimes where it is information-theoretically impossible to do so using just a single graph.",
    "authors": [
      "Racz, Miklos",
      "Sridhar, Anirudh"
    ]
  },
  {
    "id": "bb1443cc31d7396bf73e7858cea114e1",
    "title": "Twice regularized MDPs and the equivalence between robustness and regularization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/bb1443cc31d7396bf73e7858cea114e1-Paper.pdf",
    "abstract": "Robust Markov decision processes (MDPs) aim to handle changing or partially known system dynamics. To solve them, one typically resorts to robust optimization methods. However, this significantly increases computational complexity and limits scalability in both learning and planning. On the other hand, regularized MDPs show more stability in policy learning without impairing time complexity. Yet, they generally do not encompass uncertainty in the model dynamics. In this work, we aim to learn robust MDPs using regularization. We first show that regularized MDPs are a particular instance of robust MDPs with uncertain reward. We thus establish that policy iteration on reward-robust MDPs can have the same time complexity as on regularized MDPs. We further extend this relationship to MDPs with uncertain transitions: this leads to a regularization term with an additional dependence on the value function. We finally generalize regularized MDPs to twice regularized MDPs  (R${}^2$ MDPs), i.e., MDPs with $\\textit{both}$ value and policy regularization. The corresponding Bellman operators enable developing policy iteration schemes with convergence and robustness guarantees. It also reduces planning and learning in robust MDPs to regularized MDPs.",
    "authors": [
      "Derman, Esther",
      "Geist, Matthieu",
      "Mannor, Shie"
    ]
  },
  {
    "id": "bb57db42f77807a9c5823bd8c2d9aaef",
    "title": "Nearly Minimax Optimal Reinforcement Learning for Discounted MDPs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/bb57db42f77807a9c5823bd8c2d9aaef-Paper.pdf",
    "abstract": " We study the reinforcement learning problem for discounted Markov Decision Processes (MDPs) under the tabular setting. We propose a model-based algorithm named UCBVI-$\\gamma$, which is based on the \\emph{optimism in the face of uncertainty principle} and the Bernstein-type bonus. We show that UCBVI-$\\gamma$ achieves an $\\tilde{O}\\big({\\sqrt{SAT}}/{(1-\\gamma)^{1.5}}\\big)$ regret, where $S$ is the number of states, $A$ is the number of actions, $\\gamma$ is the discount factor and $T$ is the number of steps. In addition,  we construct a class of hard MDPs and show that for any algorithm, the expected regret is at least $\\tilde{\\Omega}\\big({\\sqrt{SAT}}/{(1-\\gamma)^{1.5}}\\big)$. Our upper bound matches the minimax lower bound up to logarithmic factors, which suggests that UCBVI-$\\gamma$ is nearly minimax optimal for discounted MDPs.",
    "authors": [
      "He, Jiafan",
      "Zhou, Dongruo",
      "Gu, Quanquan"
    ]
  },
  {
    "id": "bb836c01cdc9120a9c984c525e4b1a4a",
    "title": "Sparse Deep Learning: A New Framework Immune to Local Traps and Miscalibration",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/bb836c01cdc9120a9c984c525e4b1a4a-Paper.pdf",
    "abstract": "Deep learning has powered recent successes of artificial intelligence (AI). However, the deep neural network, as the basic model of deep learning,  has suffered from issues such as local traps and miscalibration. In this paper, we provide a new framework for sparse deep learning, which has the above issues addressed in a coherent way. In particular, we lay down a theoretical foundation for sparse deep learning and propose prior annealing algorithms for learning sparse neural networks. The former has successfully tamed the sparse deep neural network into the framework of statistical modeling, enabling prediction uncertainty correctly quantified. The latter can be asymptotically guaranteed to converge to the global optimum, enabling the validity of the down-stream statistical inference. Numerical result indicates the superiority of the proposed method compared to the existing ones. ",
    "authors": [
      "Sun, Yan",
      "Xiong, Wenjun",
      "Liang, Faming"
    ]
  },
  {
    "id": "bbc92a647199b832ec90d7cf57074e9e",
    "title": "Calibrating Predictions to Decisions: A Novel Approach to Multi-Class Calibration",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/bbc92a647199b832ec90d7cf57074e9e-Paper.pdf",
    "abstract": "When facing uncertainty, decision-makers want predictions they can trust. A machine learning provider can convey confidence to decision-makers by guaranteeing their predictions are distribution calibrated--- amongst the inputs that receive a predicted vector of class probabilities q, the actual distribution over classes is given by q. For multi-class prediction problems, however, directly optimizing predictions under distribution calibration tends to be infeasible, requiring sample complexity that grows exponentially in the number of classes C. In this work, we introduce a new notion---decision calibration---that requires the predicted distribution and true distribution over classes to be ``indistinguishable'' to downstream decision-makers. This perspective gives a new characterization of distribution calibration: a predictor is distribution calibrated if and only if it is decision calibrated with respect to all decision-makers. Our main result shows that under a mild restriction, unlike distribution calibration, decision calibration is actually feasible. We design a recalibration algorithm that provably achieves decision calibration efficiently, provided that the decision-makers have a bounded number of actions (e.g., polynomial in C). We validate our recalibration algorithm empirically: compared to existing methods, decision calibration improves decision-making on skin lesion and ImageNet classification with modern neural network predictors.",
    "authors": [
      "Zhao, Shengjia",
      "Kim, Michael",
      "Sahoo, Roshni",
      "Ma, Tengyu",
      "Ermon, Stefano"
    ]
  },
  {
    "id": "bc37e109d92bdc1ea71da6c919d54907",
    "title": "Lower Bounds and Optimal Algorithms for Smooth and Strongly Convex Decentralized Optimization Over Time-Varying Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/bc37e109d92bdc1ea71da6c919d54907-Paper.pdf",
    "abstract": "We consider the task of minimizing the sum of smooth and strongly convex functions stored in a decentralized manner across the nodes of a communication network whose links are allowed to change in time. We solve two fundamental problems for this task. First, we establish {\\em the first lower bounds} on the number of decentralized communication rounds and the number of local computations required to find an $\\epsilon$-accurate solution. Second, we design two {\\em optimal algorithms} that attain these lower bounds: (i) a variant of the recently proposed algorithm ADOM (Kovalev et al, 2021) enhanced via a multi-consensus subroutine, which is optimal in the case when access to the dual gradients is assumed, and (ii) a novel algorithm, called ADOM+, which is optimal in the case when access to the primal gradients is assumed. We corroborate the theoretical efficiency of these algorithms by performing an experimental comparison with existing state-of-the-art methods.",
    "authors": [
      "Kovalev, Dmitry",
      "Gasanov, Elnur",
      "Gasnikov, Alexander",
      "Richtarik, Peter"
    ]
  },
  {
    "id": "bc573864331a9e42e4511de6f678aa83",
    "title": "Testing Probabilistic Circuits",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/bc573864331a9e42e4511de6f678aa83-Paper.pdf",
    "abstract": "Probabilistic circuits (PCs) are a powerful modeling framework for representing tractable probability distributions over combinatorial spaces. In machine learning and probabilistic programming, one is often interested in understanding whether the distributions learned using PCs are close to the desired distribution. Thus, given two probabilistic circuits, a fundamental problem of interest is to determine whether their distributions are close to each other.The primary contribution of this paper is a closeness test for PCs with respect to the total variation distance metric. Our algorithm utilizes two common PC queries, counting and sampling. In particular, we provide a poly-time probabilistic algorithm to check the closeness of two PCs, when the PCs support tractable approximate counting and sampling. We demonstrate the practical efficiency of our algorithmic framework via a detailed experimental evaluation of a prototype implementation against a set of 375 PC benchmarks. We find that our test correctly decides the closeness of all 375 PCs within 3600 seconds. ",
    "authors": [
      "Pote, Yash Pralhad",
      "Meel, Kuldeep S"
    ]
  },
  {
    "id": "bc5fcb0018cecacba559dc512740091b",
    "title": "Pseudo-Spherical Contrastive Divergence",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/bc5fcb0018cecacba559dc512740091b-Paper.pdf",
    "abstract": "Energy-based models (EBMs) offer flexible distribution parametrization. However, due to the intractable partition function, they are typically trained via contrastive divergence for maximum likelihood estimation. In this paper, we propose pseudo-spherical contrastive divergence (PS-CD) to generalize maximum likelihood learning of EBMs. PS-CD is derived from the maximization of a family of strictly proper homogeneous scoring rules, which avoids the computation of the intractable partition function and provides a generalized family of learning objectives that include contrastive divergence as a special case. Moreover, PS-CD allows us to flexibly choose various learning objectives to train EBMs without additional  computational cost or variational minimax optimization. Theoretical analysis on the proposed method and extensive experiments on both synthetic data and commonly used image datasets demonstrate the effectiveness and modeling flexibility of PS-CD, as well as its robustness to data contamination, thus showing its superiority over maximum likelihood and $f$-EBMs.",
    "authors": [
      "Yu, Lantao",
      "Song, Jiaming",
      "Song, Yang",
      "Ermon, Stefano"
    ]
  },
  {
    "id": "bc6d753857fe3dd4275dff707dedf329",
    "title": "NORESQA: A Framework for Speech Quality Assessment using Non-Matching References",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/bc6d753857fe3dd4275dff707dedf329-Paper.pdf",
    "abstract": "The perceptual task of speech quality assessment (SQA) is a challenging task for machines to do. Objective SQA methods that rely on the availability of the corresponding clean reference have been the primary go-to approaches for SQA. Clearly, these methods fail in real-world scenarios where the ground truth clean references are not available. In recent years, non-intrusive methods that train neural networks to predict ratings or scores have attracted much attention, but they suffer from several shortcomings such as lack of robustness, reliance on labeled data for training and so on. In this work, we propose a new direction for speech quality assessment. Inspired by human's innate ability to compare and assess the quality of speech signals even when they have non-matching contents, we propose a novel framework that predicts a subjective relative quality score for the given speech signal with respect to any provided reference without using any subjective data. We show that neural networks trained using our framework produce scores that correlate well with subjective mean opinion scores (MOS) and are also competitive to methods such as DNSMOS, which explicitly relies on MOS from humans for training networks. Moreover, our method also provides a natural way to embed quality-related information in neural networks, which we show is helpful for downstream tasks such as speech enhancement. ",
    "authors": [
      "Manocha, Pranay",
      "Xu, Buye",
      "Kumar, Anurag"
    ]
  },
  {
    "id": "bc6dc48b743dc5d013b1abaebd2faed2",
    "title": "AFEC: Active Forgetting of Negative Transfer in Continual Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/bc6dc48b743dc5d013b1abaebd2faed2-Paper.pdf",
    "abstract": "Continual learning aims to learn a sequence of tasks from dynamic data distributions. Without accessing to the old training samples, knowledge transfer from the old tasks to each new task is difficult to determine, which might be either positive or negative. If the old knowledge interferes with the learning of a new task, i.e., the forward knowledge transfer is negative, then precisely remembering the old tasks will further aggravate the interference, thus decreasing the performance of continual learning. By contrast, biological neural networks can actively forget the old knowledge that conflicts with the learning of a new experience, through regulating the learning-triggered synaptic expansion and synaptic convergence. Inspired by the biological active forgetting, we propose to actively forget the old knowledge that limits the learning of new tasks to benefit continual learning. Under the framework of Bayesian continual learning, we develop a novel approach named Active Forgetting with synaptic Expansion-Convergence (AFEC). Our method dynamically expands parameters to learn each new task and then selectively combines them, which is formally consistent with the underlying mechanism of biological active forgetting. We extensively evaluate AFEC on a variety of continual learning benchmarks, including CIFAR-10 regression tasks, visual classification tasks and Atari reinforcement tasks, where AFEC effectively improves the learning of new tasks and achieves the state-of-the-art performance in a plug-and-play way. ",
    "authors": [
      "Wang, Liyuan",
      "Zhang, Mingtian",
      "Jia, Zhongfan",
      "Li, Qian",
      "Bao, Chenglong",
      "Ma, Kaisheng",
      "Zhu, Jun",
      "Zhong, Yi"
    ]
  },
  {
    "id": "bcb3303a96a92dc38c12992941de7627",
    "title": "Heterogeneous Multi-player Multi-armed Bandits: Closing the Gap and Generalization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/bcb3303a96a92dc38c12992941de7627-Paper.pdf",
    "abstract": "Despite the significant interests and many progresses in decentralized multi-player multi-armed bandits (MP-MAB) problems in recent years, the regret gap to the natural centralized lower bound in the heterogeneous MP-MAB setting remains open. In this paper, we propose BEACON -- Batched Exploration with Adaptive COmmunicatioN -- that closes this gap. BEACON accomplishes this goal with novel contributions in implicit communication and efficient exploration. For the former, we propose a novel adaptive differential communication (ADC) design that significantly improves the implicit communication efficiency. For the latter, a carefully crafted batched exploration scheme is developed to enable incorporation of the combinatorial upper confidence bound (CUCB) principle. We then generalize the existing linear-reward MP-MAB problems, where the system reward is always the sum of individually collected rewards, to a new MP-MAB problem where the system reward is a general (nonlinear) function of individual rewards. We extend BEACON to solve this problem and prove a logarithmic regret. BEACON bridges the algorithm design and regret analysis of combinatorial MAB (CMAB) and MP-MAB, two largely disjointed areas in MAB, and the results in this paper suggest that this previously ignored connection is worth further investigation.",
    "authors": [
      "Shi, Chengshuai",
      "Xiong, Wei",
      "Shen, Cong",
      "Yang, Jing"
    ]
  },
  {
    "id": "bcb41ccdc4363c6848a1d760f26c28a0",
    "title": "SWAD: Domain Generalization by Seeking Flat Minima",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/bcb41ccdc4363c6848a1d760f26c28a0-Paper.pdf",
    "abstract": "Domain generalization (DG) methods aim to achieve generalizability to an unseen target domain by using only training data from the source domains. Although a variety of DG methods have been proposed, a recent study shows that under a fair evaluation protocol, called DomainBed, the simple empirical risk minimization (ERM) approach works comparable to or even outperforms previous methods. Unfortunately, simply solving ERM on a complex, non-convex loss function can easily lead to sub-optimal generalizability by seeking sharp minima. In this paper, we theoretically show that finding flat minima results in a smaller domain generalization gap. We also propose a simple yet effective method, named Stochastic Weight Averaging Densely (SWAD), to find flat minima. SWAD finds flatter minima and suffers less from overfitting than does the vanilla SWA by a dense and overfit-aware stochastic weight sampling strategy. SWAD shows state-of-the-art performances on five DG benchmarks, namely PACS, VLCS, OfficeHome, TerraIncognita, and DomainNet, with consistent and large margins of +1.6% averagely on out-of-domain accuracy. We also compare SWAD with conventional generalization methods, such as data augmentation and consistency regularization methods, to verify that the remarkable performance improvements are originated from by seeking flat minima, not from better in-domain generalizability. Last but not least, SWAD is readily adaptable to existing DG methods without modification; the combination of SWAD and an existing DG method further improves DG performances. Source code is available at https://github.com/khanrc/swad.",
    "authors": [
      "Cha, Junbum",
      "Chun, Sanghyuk",
      "Lee, Kyungjae",
      "Cho, Han-Cheol",
      "Park, Seunghyun",
      "Lee, Yunsung",
      "Park, Sungrae"
    ]
  },
  {
    "id": "bcc0d400288793e8bdcd7c19a8ac0c2b",
    "title": "Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/bcc0d400288793e8bdcd7c19a8ac0c2b-Paper.pdf",
    "abstract": "Extending the forecasting time is a critical demand for real applications, such as extreme weather early warning and long-term energy consumption planning. This paper studies the long-term forecasting problem of time series. Prior Transformer-based models adopt various self-attention mechanisms to discover the long-range dependencies. However, intricate temporal patterns of the long-term future prohibit the model from finding reliable dependencies. Also, Transformers have to adopt the sparse versions of point-wise self-attentions for long series efficiency, resulting in the information utilization bottleneck. Going beyond Transformers, we design Autoformer as a novel decomposition architecture with an Auto-Correlation mechanism. We break with the pre-processing convention of series decomposition and renovate it as a basic inner block of deep models. This design empowers Autoformer with progressive decomposition capacities for complex time series. Further, inspired by the stochastic process theory, we design the Auto-Correlation mechanism based on the series periodicity, which conducts the dependencies discovery and representation aggregation at the sub-series level. Auto-Correlation outperforms self-attention in both efficiency and accuracy. In long-term forecasting, Autoformer yields state-of-the-art accuracy, with a 38% relative improvement on six benchmarks, covering five practical applications: energy, traffic, economics, weather and disease. Code is available at this repository: https://github.com/thuml/Autoformer.",
    "authors": [
      "Wu, Haixu",
      "Xu, Jiehui",
      "Wang, Jianmin",
      "Long, Mingsheng"
    ]
  },
  {
    "id": "bcc2bdb799f873f02080ae277f291da1",
    "title": "Predicting Event Memorability from Contextual Visual Semantics",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/bcc2bdb799f873f02080ae277f291da1-Paper.pdf",
    "abstract": "Episodic event memory is a key component of human cognition. Predicting event memorability,i.e., to what extent an event is recalled, is a tough challenge in memory research and has profound implications for artificial intelligence. In this study, we investigate factors that affect event memorability according to a cued recall process. Specifically, we explore whether event memorability is contingent on the event context, as well as the intrinsic visual attributes of image cues. We design a novel experiment protocol and conduct a large-scale experiment with 47 elder subjects over 3 months.  Subjects\u2019 memory of life events is tested in a cued recall process. Using advanced visual analytics methods, we build a first-of-its-kind event memorability dataset (called R3) with rich information about event context and visual semantic features. Furthermore, we propose a contextual event memory network (CEMNet) that tackles multi-modal input to predict item-wise event memorability, which outperforms competitive benchmarks.  The findings inform deeper understanding of episodic event memory, and open up a new avenue for prediction of human episodic memory.  Source code is available at https://github.com/ffzzy840304/Predicting-Event-Memorability.",
    "authors": [
      "Xu, Qianli",
      "Fang, Fen",
      "Molino, Ana",
      "Subbaraju, Vigneshwaran",
      "Lim, Joo-Hwee"
    ]
  },
  {
    "id": "bcd0049c35799cdf57d06eaf2eb3cff6",
    "title": "Achieving Forgetting Prevention and Knowledge Transfer in Continual Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/bcd0049c35799cdf57d06eaf2eb3cff6-Paper.pdf",
    "abstract": "Continual learning (CL) learns a sequence of tasks incrementally with the goal of achieving two main objectives: overcoming catastrophic forgetting (CF) and encouraging knowledge transfer (KT) across tasks. However, most existing techniques focus only on overcoming CF and have no mechanism to encourage KT, and thus do not do well in KT. Although several papers have tried to deal with both CF and KT, our experiments show that they suffer from serious CF when the tasks do not have much shared knowledge. Another observation is that most current CL methods do not use pre-trained models, but it has been shown that such models can significantly improve the end task performance. For example, in natural language processing, fine-tuning a BERT-like pre-trained language model is one of the most effective approaches. However, for CL, this approach suffers from serious CF. An interesting question is how to make the best use of pre-trained models for CL. This paper proposes a novel model called CTR to solve these problems. Our experimental results demonstrate the effectiveness of CTR",
    "authors": [
      "Ke, Zixuan",
      "Liu, Bing",
      "Ma, Nianzu",
      "Xu, Hu",
      "Shu, Lei"
    ]
  },
  {
    "id": "bd33f02c4e28615b5af2d24703e066d5",
    "title": "Bandits with many optimal arms",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/bd33f02c4e28615b5af2d24703e066d5-Paper.pdf",
    "abstract": "We consider a stochastic bandit problem with a possibly infinite number of arms. We write $p^*$ for the proportion of optimal arms and $\\Delta$ for the minimal mean-gap between optimal and sub-optimal arms. We characterize the optimal learning rates both in the cumulative regret setting, and in the best-arm identification setting in terms of the problem parameters $T$ (the budget), $p^*$ and $\\Delta$. For the objective of minimizing the cumulative regret, we provide a lower bound of order $\\Omega(\\log(T)/(p^*\\Delta))$ and a UCB-style algorithm with matching upper bound up to a factor of $\\log(1/\\Delta)$. Our algorithm needs $p^*$ to calibrate its parameters, and we prove that this knowledge is necessary, since adapting to $p^*$ in this setting is impossible. For best-arm identification we also provide a lower bound of order $\\Omega(\\exp(-cT\\Delta^2p^*))$ on the probability of outputting a sub-optimal arm where $c>0$ is an absolute constant. We also provide an elimination algorithm with an upper bound matching the lower bound up to a factor of order $\\log(T)$ in the exponential, and that does not need $p^*$ or $\\Delta$ as parameter. Our results apply directly to the three related problems of competing against the $j$-th best arm, identifying an $\\epsilon$ good arm, and finding an arm with mean larger than a quantile of a known order.",
    "authors": [
      "de Heide, Rianne",
      "Cheshire, James",
      "M\u00e9nard, Pierre",
      "Carpentier, Alexandra"
    ]
  },
  {
    "id": "bd4a6d0563e0604510989eb8f9ff71f5",
    "title": "Combiner: Full Attention Transformer with Sparse Computation Cost",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/bd4a6d0563e0604510989eb8f9ff71f5-Paper.pdf",
    "abstract": "Transformers provide a class of expressive architectures that are extremely effective for sequence modeling. However, the key limitation of transformers is their quadratic memory and time complexity $\\mathcal{O}(L^2)$ with respect to the sequence length in attention layers, which restricts application in extremely long sequences. Most existing approaches leverage sparsity or low-rank assumptions in the attention matrix to reduce cost, but sacrifice expressiveness. Instead, we propose Combiner, which provides full attention capability in each attention head while maintaining low computation and memory complexity. The key idea is to treat the self-attention mechanism as a conditional expectation over embeddings at each location, and approximate the conditional distribution with a structured factorization. Each location can attend to all other locations, either via direct attention, or through indirect attention to abstractions, which are again conditional expectations of embeddings from corresponding local regions. We show that most sparse attention patterns used in existing sparse transformers are able to inspire the design of such factorization for full attention, resulting in the same sub-quadratic cost ($\\mathcal{O}(L\\log(L))$ or $\\mathcal{O}(L\\sqrt{L})$). Combiner is a drop-in replacement for attention layers in existing transformers and can be easily implemented in common frameworks. An experimental evaluation on both autoregressive and bidirectional sequence tasks demonstrates the effectiveness of this approach, yielding state-of-the-art results on several image and text modeling tasks.",
    "authors": [
      "Ren, Hongyu",
      "Dai, Hanjun",
      "Dai, Zihang",
      "Yang, Mengjiao",
      "Leskovec, Jure",
      "Schuurmans, Dale",
      "Dai, Bo"
    ]
  },
  {
    "id": "bd686fd640be98efaae0091fa301e613",
    "title": "Geometry Processing with Neural Fields",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/bd686fd640be98efaae0091fa301e613-Paper.pdf",
    "abstract": "Most existing geometry processing algorithms use meshes as the default shape representation.  Manipulating meshes, however, requires one to maintain high quality in the surface discretization.  For example, changing the topology of a mesh usually requires additional procedures such as remeshing. This paper instead proposes the use of neural fields for geometry processing. Neural fields can compactly store complicated shapes without spatial discretization.   Moreover, neural fields are infinitely differentiable, which allows them to be optimized for objectives that involve higher-order derivatives.  This raises the question: can geometry processing be done entirely using neural fields? We introduce loss functions and architectures to show that some of the most challenging geometry processing tasks, such as deformation and filtering, can be done with neural fields. Experimental results show that our methods are on par with the well-established mesh-based methods without committing to a particular surface discretization. Code is available at https://github.com/stevenygd/NFGP.",
    "authors": [
      "Yang, Guandao",
      "Belongie, Serge",
      "Hariharan, Bharath",
      "Koltun, Vladlen"
    ]
  },
  {
    "id": "bdc6c33585d0cf5d2a8cb83141cd037f",
    "title": "Contextual Recommendations and Low-Regret Cutting-Plane Algorithms",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/bdc6c33585d0cf5d2a8cb83141cd037f-Paper.pdf",
    "abstract": "We consider the following variant of contextual linear bandits motivated by routing applications in navigational engines  and recommendation systems. We wish to learn a hidden $d$-dimensional value $w^*$. Every round, we are presented with a subset $\\mathcal{X}_t \\subseteq \\mathbb{R}^d$ of possible actions. If we choose (i.e. recommend to the user) action $x_t$, we obtain utility $\\langle x_t, w^* \\rangle$ but only learn the identity of the best action $\\arg\\max_{x \\in \\X_t} \\langle x, w^* \\rangle$.We design algorithms for this problem which achieve regret $O(d\\log T)$ and $\\exp(O(d \\log d))$. To accomplish this, we design novel cutting-plane algorithms with low \u201cregret\u201d -- the total distance between the true point $w^*$ and the hyperplanes the separation oracle returns. We also consider the variant where we are allowed to provide a list of several recommendations. In this variant, we give an algorithm with $O(d^2 \\log d)$ regret and list size $\\poly(d)$. Finally, we construct nearly tight algorithms for a weaker variant of this problem where the learner only learns the identity of an action that is better than the recommendation. Our results rely on new algorithmic techniques in convex geometry (including a variant of Steiner\u2019s formula for the centroid of a convex set) which may be of independent interest. ",
    "authors": [
      "Gollapudi, Sreenivas",
      "Guruganesh, Guru",
      "Kollias, Kostas",
      "Manurangsi, Pasin",
      "Leme, Renato",
      "Schneider, Jon"
    ]
  },
  {
    "id": "be1bc7997695495f756312886f566110",
    "title": "Speech Separation Using an Asynchronous Fully Recurrent Convolutional Neural Network",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/be1bc7997695495f756312886f566110-Paper.pdf",
    "abstract": "Recent advances in the design of neural network architectures, in particular those specialized in modeling sequences, have provided significant improvements in speech separation performance. In this work, we propose to use a bio-inspired architecture called Fully Recurrent Convolutional Neural Network (FRCNN) to solve the separation task. This model contains bottom-up, top-down and lateral connections to fuse information processed at various time-scales represented by stages. In contrast to the traditional approach updating stages in parallel, we propose to first update the stages one by one in the bottom-up direction, then fuse information from adjacent stages simultaneously and finally fuse information from all stages to the bottom stage together. Experiments showed that this  asynchronous updating scheme achieved significantly better results with much fewer parameters than the traditional synchronous updating scheme on speech separation.  In addition, the proposed model achieved competitive or better results with high efficiency as compared to other state-of-the-art approaches on two benchmark datasets. ",
    "authors": [
      "Hu, Xiaolin",
      "Li, Kai",
      "Zhang, Weiyi",
      "Luo, Yi",
      "Lemercier, Jean-Marie",
      "Gerkmann, Timo"
    ]
  },
  {
    "id": "be26abe76fb5c8a4921cf9d3e865b454",
    "title": "Reinforcement Learning Enhanced Explainer for Graph Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/be26abe76fb5c8a4921cf9d3e865b454-Paper.pdf",
    "abstract": "Graph neural networks (GNNs) have recently emerged as revolutionary technologies for machine learning tasks on graphs. In GNNs, the graph structure is generally incorporated with node representation via the message passing scheme, making the explanation much more challenging. Given a trained GNN model, a GNN explainer aims to identify a most influential subgraph to interpret the prediction of an instance (e.g., a node or a graph), which is essentially a combinatorial optimization problem over graph. The existing works solve this problem by continuous relaxation or search-based heuristics. But they suffer from key issues such as violation of message passing and hand-crafted heuristics, leading to inferior interpretability. To address these issues, we propose a RL-enhanced GNN explainer, RG-Explainer, which consists of three main components: starting point selection, iterative graph generation and stopping criteria learning. RG-Explainer could construct a connected explanatory subgraph by sequentially adding nodes from the boundary of the current generated graph, which is consistent with the message passing scheme. Further, we design an effective seed locator to select the starting point, and learn stopping criteria to generate superior explanations. Extensive experiments on both synthetic and real datasets show that RG-Explainer outperforms state-of-the-art GNN explainers. Moreover, RG-Explainer can be applied in the inductive setting, demonstrating its better generalization ability. ",
    "authors": [
      "Shan, Caihua",
      "Shen, Yifei",
      "Zhang, Yao",
      "Li, Xiang",
      "Li, Dongsheng"
    ]
  },
  {
    "id": "be3159ad04564bfb90db9e32851ebf9c",
    "title": "NAS-Bench-x11 and the Power of Learning Curves",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/be3159ad04564bfb90db9e32851ebf9c-Paper.pdf",
    "abstract": "While early research in neural architecture search (NAS) required extreme computational resources, the recent releases of tabular and surrogate benchmarks have greatly increased the speed and reproducibility of NAS research. However, two of the most popular benchmarks do not provide the full training information for each architecture. As a result, on these benchmarks it is not possible to evaluate many types of multi-fidelity algorithms, such as learning curve extrapolation, that require evaluating architectures at arbitrary epochs. In this work, we present a method using singular value decomposition and noise modeling to create surrogate benchmarks, NAS-Bench-111, NAS-Bench-311, and NAS-Bench-NLP11, that output the full training information for each architecture, rather than just the final validation accuracy. We demonstrate the power of using the full training information by introducing a learning curve extrapolation framework to modify single-fidelity algorithms, showing that it leads to improvements over popular single-fidelity algorithms which claimed to be state-of-the-art upon release.",
    "authors": [
      "Yan, Shen",
      "White, Colin",
      "Savani, Yash",
      "Hutter, Frank"
    ]
  },
  {
    "id": "be315e7f05e9f13629031915fe87ad44",
    "title": "Observation-Free Attacks on Stochastic Bandits",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/be315e7f05e9f13629031915fe87ad44-Paper.pdf",
    "abstract": "We study data corruption attacks on stochastic multi arm bandit algorithms. Existing attack methodologies assume that the attacker can observe the multi arm bandit algorithm's realized behavior which is in contrast to the adversaries modeled in the robust multi arm bandit algorithms literature. To the best of our knowledge, we develop the first data corruption attack on stochastic multi arm bandit algorithms which works without observing the algorithm's realized behavior. Through this attack, we also discover a sufficient condition for a stochastic multi arm bandit algorithm to be susceptible to adversarial data corruptions. We show that any bandit algorithm that makes decisions just using the empirical mean reward, and the number of times that arm has been pulled in the past can suffer from linear regret under data corruption attacks. We further show that various popular stochastic multi arm bandit algorithms such UCB, $\\epsilon$-greedy and Thompson Sampling satisfy this sufficient condition and are thus prone to data corruption attacks. We further analyze the behavior of our attack for these algorithms and show that using only $o(T)$ corruptions, our attack can force these algorithms to select a potentially non-optimal target arm preferred by the attacker for all but $o(T)$ rounds. ",
    "authors": [
      "Xu, Yinglun",
      "Kumar, Bhuvesh",
      "Abernethy, Jacob D."
    ]
  },
  {
    "id": "be37ff14df68192d976f6ce76c6cbd15",
    "title": "Learning Disentangled Behavior Embeddings",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/be37ff14df68192d976f6ce76c6cbd15-Paper.pdf",
    "abstract": "To understand the relationship between behavior and neural activity, experiments in neuroscience often include an animal performing a repeated behavior such as a motor task. Recent progress in computer vision and deep learning has shown great potential in the automated analysis of behavior by leveraging large and high-quality video datasets. In this paper, we design Disentangled Behavior Embedding (DBE) to learn robust behavioral embeddings from unlabeled, multi-view, high-resolution behavioral videos across different animals and multiple sessions. We further combine DBE with a stochastic temporal model to propose Variational Disentangled Behavior Embedding (VDBE), an end-to-end approach that learns meaningful discrete behavior representations and generates interpretable behavioral videos. Our models learn consistent behavior representations by explicitly disentangling the dynamic behavioral factors (pose) from time-invariant, non-behavioral nuisance factors (context) in a deep autoencoder, and exploit the temporal structures of pose dynamics. Compared to competing approaches, DBE and VDBE enjoy superior performance on downstream tasks such as fine-grained behavioral motif generation and behavior decoding.",
    "authors": [
      "Shi, Changhao",
      "Schwartz, Sivan",
      "Levy, Shahar",
      "Achvat, Shay",
      "Abboud, Maisan",
      "Ghanayim, Amir",
      "Schiller, Jackie",
      "Mishne, Gal"
    ]
  },
  {
    "id": "be3e9d3f7d70537357c67bb3f4086846",
    "title": "The Sensory Neuron as a Transformer: Permutation-Invariant Neural Networks for Reinforcement Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/be3e9d3f7d70537357c67bb3f4086846-Paper.pdf",
    "abstract": "In complex systems, we often observe complex global behavior emerge from a collection of agents interacting with each other in their environment, with each individual agent acting only on locally available information, without knowing the full picture. Such systems have inspired development of artificial intelligence algorithms in areas such as swarm optimization and cellular automata. Motivated by the emergence of collective behavior from complex cellular systems, we build systems that feed each sensory input from the environment into distinct, but identical neural networks, each with no fixed relationship with one another. We show that these sensory networks can be trained to integrate information received locally, and through communication via an attention mechanism, can collectively produce a globally coherent policy. Moreover, the system can still perform its task even if the ordering of its inputs is randomly permuted several times during an episode. These permutation invariant systems also display useful robustness and generalization properties that are broadly applicable. Interactive demo and videos of our results: https://attentionneuron.github.io",
    "authors": [
      "Tang, Yujin",
      "Ha, David"
    ]
  },
  {
    "id": "be767243ca8f574c740fb4c26cc6dceb",
    "title": "Fast Extra Gradient Methods for Smooth Structured Nonconvex-Nonconcave Minimax Problems",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/be767243ca8f574c740fb4c26cc6dceb-Paper.pdf",
    "abstract": "Modern minimax problems, such as generative adversarial network and adversarial training, are often under a nonconvex-nonconcave setting, and developing an efficient method for such setting is of interest. Recently, two variants of the extragradient (EG) method are studied in that direction. First, a two-time-scale variant of the EG, named EG+, was proposed under a smooth structured nonconvex-nonconcave setting, with a slow $\\mathcal{O}(1/k)$ rate on the squared gradient norm, where $k$ denotes the number of iterations. Second, another variant of EG with an anchoring technique, named extra anchored gradient (EAG), was studied under a smooth convex-concave setting, yielding a fast $\\mathcal{O}(1/k^2)$ rate on the squared gradient norm. Built upon EG+ and EAG, this paper proposes a two-time-scale EG with anchoring, named fast extragradient (FEG), that has a fast $\\mathcal{O}(1/k^2)$ rate on the squared gradient norm for smooth structured nonconvex-nonconcave problems; the corresponding saddle-gradient operator satisfies the negative comonotonicity condition. This paper further develops its backtracking line-search version, named FEG-A, for the case where the problem parameters are not available. The stochastic analysis of FEG is also provided.",
    "authors": [
      "Lee, Sucheol",
      "Kim, Donghwan"
    ]
  },
  {
    "id": "becc353586042b6dbcc42c1b794c37b6",
    "title": "Analysis of Sensing Spectral for Signal Recovery under a Generalized Linear Model",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/becc353586042b6dbcc42c1b794c37b6-Paper.pdf",
    "abstract": "We consider a nonlinear inverse problem $\\mathbf{y}= f(\\mathbf{Ax})$, where observations $\\mathbf{y} \\in \\mathbb{R}^m$ are the componentwise nonlinear transformation of $\\mathbf{Ax} \\in \\mathbb{R}^m$, $\\mathbf{x} \\in \\mathbb{R}^n$ is the signal of interest and $\\mathbf{A}$ is a known linear mapping. By properly specifying the nonlinear processing function, this model can be particularized to many signal processing problems, including compressed sensing and phase retrieval. Our main goal in this paper is to understand the impact of sensing matrices, or more specifically the spectrum of sensing matrices, on the difficulty of recovering $\\mathbf{x}$ from $\\mathbf{y}$. Towards this goal, we study the performance of one of the most successful recovery methods, i.e. the expectation propagation algorithm (EP). We define a notion for the spikiness of the spectrum of $\\mathbf{A}$ and show the importance of this measure in the performance of the EP. Whether the spikiness of the spectrum can hurt or help the recovery performance of EP depends on $f$. We define certain quantities based on the function $f$ that enables us to describe the impact of the spikiness of the spectrum on EP recovery. Based on our framework, we are able to show that for instance, in phase-retrieval problems, matrices with spikier spectrums are better for EP, while in 1-bit compressed sensing problems, less spiky (flatter) spectrums offer better recoveries. Our results unify and substantially generalize the existing results that compare sub-Gaussian and orthogonal matrices, and provide a platform toward designing optimal sensing systems.",
    "authors": [
      "Ma, Junjie",
      "Xu, Ji",
      "Maleki, Arian"
    ]
  },
  {
    "id": "bef4d169d8bddd17d68303877a3ea945",
    "title": "Revisiting ResNets: Improved Training and Scaling Strategies",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/bef4d169d8bddd17d68303877a3ea945-Paper.pdf",
    "abstract": "Novel computer vision architectures monopolize the spotlight, but the impact of the model architecture is often conflated with simultaneous changes to training methodology and scaling strategies.Our work revisits the canonical ResNet and studies these three aspects in an effort to disentangle them. Perhaps surprisingly, we find that training and scaling strategies may matter more than architectural changes, and further, that the resulting ResNets match recent state-of-the-art models. We show that the best performing scaling strategy depends on the training regime and offer two new scaling strategies: (1) scale model depth in regimes where overfitting can occur (width scaling is preferable otherwise); (2) increase image resolution more slowly than previously recommended.Using improved training and scaling strategies, we design a family of ResNet architectures, ResNet-RS, which are 1.7x - 2.7x faster than EfficientNets on TPUs, while achieving similar accuracies on ImageNet. In a large-scale semi-supervised learning setup, ResNet-RS achieves 86.2% top-1 ImageNet accuracy, while being 4.7x faster than EfficientNet-NoisyStudent. The training techniques improve transfer performance on a suite of downstream tasks (rivaling state-of-the-art self-supervised algorithms) and extend to video classification on Kinetics-400. We recommend practitioners use these simple revised ResNets as baselines for future research.",
    "authors": [
      "Bello, Irwan",
      "Fedus, William",
      "Du, Xianzhi",
      "Cubuk, Ekin Dogus",
      "Srinivas, Aravind",
      "Lin, Tsung-Yi",
      "Shlens, Jonathon",
      "Zoph, Barret"
    ]
  },
  {
    "id": "bf1b2f4b901c21a1d8645018ea9aeb05",
    "title": "Sparse Flows: Pruning Continuous-depth Models",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/bf1b2f4b901c21a1d8645018ea9aeb05-Paper.pdf",
    "abstract": "Continuous deep learning architectures enable learning of flexible probabilistic models for predictive modeling as neural ordinary differential equations (ODEs), and for generative modeling as continuous normalizing flows. In this work, we design a framework to decipher the internal dynamics of these continuous depth models by pruning their network architectures. Our empirical results suggest that pruning improves generalization for neural ODEs in generative modeling. We empirically show that the improvement is because pruning helps avoid mode-collapse and flatten the loss surface. Moreover, pruning finds efficient neural ODE representations with up to 98% less parameters compared to the original network, without loss of accuracy. We hope our results will invigorate further research into the performance-size trade-offs of modern continuous-depth models.",
    "authors": [
      "Liebenwein, Lucas",
      "Hasani, Ramin",
      "Amini, Alexander",
      "Rus, Daniela"
    ]
  },
  {
    "id": "bf25356fd2a6e038f1a3a59c26687e80",
    "title": "Spectrum-to-Kernel Translation for Accurate Blind Image Super-Resolution",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/bf25356fd2a6e038f1a3a59c26687e80-Paper.pdf",
    "abstract": "Deep-learning based Super-Resolution (SR) methods have exhibited promising performance under non-blind setting where blur kernel is known; however, blur kernels of Low-Resolution (LR) images in different practical applications are usually unknown. It may lead to a significant performance drop  when degradation process of training images  deviates from that of real images. In this paper, we propose a novel blind SR framework to super-resolve LR images degraded by arbitrary blur kernel with accurate kernel estimation in frequency domain. To our best knowledge, this is the first deep learning method which conducts blur kernel estimation in frequency domain. Specifically, we first demonstrate that feature representation in frequency domain is more conducive for blur kernel reconstruction than in spatial domain. Next, we present a Spectrum-to-Kernel (S$2$K) network to estimate general blur kernels in diverse forms. We use a conditional GAN (CGAN) combined with SR-oriented optimization target to learn the end-to-end translation from degraded images' spectra to unknown kernels. Extensive experiments on both synthetic and real-world images demonstrate that our proposed method sufficiently reduces blur kernel estimation error, thus enables the off-the-shelf non-blind SR methods to work under blind setting effectively, and achieves superior performance over state-of-the-art blind SR methods, averagely by 1.39dB, 0.48dB (Gaussian kernels) and 6.15dB, 4.57dB (motion kernels) for scales $2\\times$ and $4\\times$ respectively.",
    "authors": [
      "Tao, Guangpin",
      "Ji, Xiaozhong",
      "Wang, Wenzhuo",
      "Chen, Shuo",
      "Lin, Chuming",
      "Cao, Yun",
      "Lu, Tong",
      "Luo, Donghao",
      "Tai, Ying"
    ]
  },
  {
    "id": "bf40f0ab4e5e63171dd16036913ae828",
    "title": "On the Rate of Convergence of Regularized Learning in Games: From Bandits and Uncertainty to Optimism and Beyond",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/bf40f0ab4e5e63171dd16036913ae828-Paper.pdf",
    "abstract": "In this paper, we examine the convergence rate of a wide range of regularized methods for learning in games. To that end, we propose a unified algorithmic template that we call \u201cfollow the generalized leader\u201d (FTGL), and which includes asspecial cases the canonical \u201cfollow the regularized leader\u201d algorithm, its optimistic variants, extra-gradient schemes, and many others. The proposed framework is also sufficiently flexible to account for several different feedback models \u2013 fromfull information to bandit feedback. In this general setting, we show that FTGL algorithms converge locally to strict Nash equilibria at a rate which does not depend on the level of uncertainty faced by the players, but only on the geometry of the regularizer near the equilibrium. In particular, we show that algorithms based on entropic regularization \u2013 like the exponential weights algorithm \u2013 enjoy a linear convergence rate, while Euclidean projection methods converge to equilibrium in a finite number of iterations, even with bandit feedback.",
    "authors": [
      "Giannou, Angeliki",
      "Vlatakis-Gkaragkounis, Emmanouil-Vasileios",
      "Mertikopoulos, Panayotis"
    ]
  },
  {
    "id": "bf499a12e998d178afd964adf64a60cb",
    "title": "SLAPS: Self-Supervision Improves Structure Learning for Graph Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/bf499a12e998d178afd964adf64a60cb-Paper.pdf",
    "abstract": "Graph neural networks (GNNs) work well when the graph structure is provided. However, this structure may not always be available in real-world applications. One solution to this problem is to infer a task-specific latent structure and then apply a GNN to the inferred graph. Unfortunately, the space of possible graph structures grows super-exponentially with the number of nodes and so the task-specific supervision may be insufficient for learning both the structure and the GNN parameters. In this work, we propose the Simultaneous Learning of Adjacency and GNN Parameters with Self-supervision, or SLAPS, a method that provides more supervision for inferring a graph structure through self-supervision. A comprehensive experimental study demonstrates that SLAPS scales to large graphs with hundreds of thousands of nodes and outperforms several models that have been proposed to learn a task-specific graph structure on established benchmarks.",
    "authors": [
      "Fatemi, Bahare",
      "El Asri, Layla",
      "Kazemi, Seyed Mehran"
    ]
  },
  {
    "id": "bf5cd8b2509011b9502a72296edc14a0",
    "title": "Aligning Pretraining for Detection via Object-Level Contrastive Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/bf5cd8b2509011b9502a72296edc14a0-Paper.pdf",
    "abstract": "Image-level contrastive representation learning has proven to be highly effective as a generic model for transfer learning.  Such generality for transfer learning, however, sacrifices specificity if we are interested in a certain downstream task. We argue that this could be sub-optimal and thus advocate a design principle which encourages alignment between the self-supervised pretext task and the downstream task. In this paper, we follow this principle with a pretraining method specifically designed for the task of object detection. We attain alignment in the following three aspects: 1) object-level representations are introduced via selective search bounding boxes as object proposals; 2) the pretraining network architecture incorporates the same dedicated modules used in the detection pipeline (e.g. FPN); 3) the pretraining is equipped with object detection properties such as object-level translation invariance and scale invariance. Our method, called Selective Object COntrastive learning (SoCo), achieves state-of-the-art results for transfer performance on COCO detection using a Mask R-CNN framework. Code is available at https://github.com/hologerry/SoCo.",
    "authors": [
      "Wei, Fangyun",
      "Gao, Yue",
      "Wu, Zhirong",
      "Hu, Han",
      "Lin, Stephen"
    ]
  },
  {
    "id": "bf65417dcecc7f2b0006e1f5793b7143",
    "title": "Double/Debiased Machine Learning for Dynamic Treatment Effects",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/bf65417dcecc7f2b0006e1f5793b7143-Paper.pdf",
    "abstract": "We consider the estimation of treatment effects in settings when multiple treatments are assigned over time and treatments can have a causal effect on future outcomes. We propose an extension of the double/debiased machine learning framework to estimate the dynamic effects of treatments and apply it to a concrete linear Markovian high-dimensional state space model and to general structural nested mean models. Our method allows the use of arbitrary machine learning methods to control for the high dimensional state, subject to a mean square error guarantee, while still allowing parametric estimation and construction of confidence intervals for the dynamic treatment effect parameters of interest.  Our method is based on a sequential regression peeling process, which we show can be equivalently interpreted as a Neyman orthogonal moment estimator. This allows us to show root-n asymptotic normality of the estimated causal effects.",
    "authors": [
      "Lewis, Greg",
      "Syrgkanis, Vasilis"
    ]
  },
  {
    "id": "bfd2308e9e75263970f8079115edebbd",
    "title": "Local Disentanglement in Variational Auto-Encoders Using Jacobian $L_1$ Regularization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/bfd2308e9e75263970f8079115edebbd-Paper.pdf",
    "abstract": "There have been many recent advances in representation learning; however, unsupervised representation learning can still struggle with model identification issues related to rotations of the latent space. Variational Auto-Encoders (VAEs) and their extensions such as $\\beta$-VAEs have been shown to improve local alignment of latent variables with PCA directions, which can help to improve model disentanglement under some conditions. Borrowing inspiration from Independent Component Analysis (ICA) and sparse coding, we propose applying an $L_1$ loss to the VAE's generative Jacobian during training to encourage local latent variable alignment with independent factors of variation in images of multiple objects or images with multiple parts. We demonstrate our results on a variety of datasets, giving qualitative and quantitative results using information theoretic and modularity measures that show our added $L_1$ cost encourages local axis alignment of the latent representation with individual factors of variation.",
    "authors": [
      "Rhodes, Travers",
      "Lee, Daniel"
    ]
  },
  {
    "id": "c00193e70e8e27e70601b26161b4ae86",
    "title": "Design of Experiments for Stochastic Contextual Linear Bandits",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c00193e70e8e27e70601b26161b4ae86-Paper.pdf",
    "abstract": "In the stochastic linear contextual bandit setting there exist several minimax procedures for exploration with policies that are reactive to the data being acquired. In practice, there can be a significant engineering overhead to deploy these algorithms, especially when the dataset is collected in a distributed fashion or when a human in the loop is needed to implement a different policy. Exploring with a single non-reactive policy is beneficial in such cases. Assuming some batch contexts are available, we design a single stochastic policy to collect a good dataset from which a near-optimal policy can be extracted. We present a theoretical analysis as well as numerical experiments on both synthetic and real-world datasets.",
    "authors": [
      "Zanette, Andrea",
      "Dong, Kefan",
      "Lee, Jonathan N",
      "Brunskill, Emma"
    ]
  },
  {
    "id": "c04c19c2c2474dbf5f7ac4372c5b9af1",
    "title": "Encoding Spatial Distribution of Convolutional Features for Texture Representation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c04c19c2c2474dbf5f7ac4372c5b9af1-Paper.pdf",
    "abstract": "Existing convolutional neural networks (CNNs) often use global average pooling (GAP) to aggregate feature maps into a single representation. However, GAP cannot well characterize complex distributive patterns of spatial features while such patterns play an important role in texture-oriented applications, e.g., material recognition and ground terrain classification. In the context of texture representation, this paper addressed the issue by proposing Fractal Encoding (FE), a feature encoding module grounded by multi-fractal geometry. Considering a CNN feature map as a union of level sets of points lying in the 2D space, FE characterizes their spatial layout via a local-global hierarchical fractal analysis which examines the multi-scale power behavior on each level set. This enables a CNN to encode the regularity on the spatial arrangement of image features, leading to a robust yet discriminative spectrum descriptor. In addition, FE has trainable parameters for data adaptivity and can be easily incorporated into existing CNNs for end-to-end training. We applied FE to ResNet-based texture classification and retrieval, and demonstrated its effectiveness on several benchmark datasets.",
    "authors": [
      "Xu, Yong",
      "Li, Feng",
      "Chen, Zhile",
      "Liang, Jinxiu",
      "Quan, Yuhui"
    ]
  },
  {
    "id": "c055dcc749c2632fd4dd806301f05ba6",
    "title": "Training Certifiably Robust Neural Networks with Efficient Local Lipschitz Bounds",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c055dcc749c2632fd4dd806301f05ba6-Paper.pdf",
    "abstract": "Certified robustness is a desirable property for deep neural networks in safety-critical applications, and popular training algorithms can certify robustness of a neural network by computing a global bound on its Lipschitz constant. However, such a bound is often loose: it tends to over-regularize the neural network and degrade its natural accuracy. A tighter Lipschitz bound may provide a better tradeoff between natural and certified accuracy, but is generally hard to compute exactly due to non-convexity of the network. In this work, we propose an efficient and trainable \\emph{local} Lipschitz upper bound by considering the interactions between activation functions (e.g. ReLU) and weight matrices. Specifically, when computing the induced norm of a weight matrix, we eliminate the corresponding rows and columns where the activation function is guaranteed to be a constant in the neighborhood of each given data point, which provides a provably tighter bound than the global Lipschitz constant of the neural network. Our method can be used as a plug-in module to tighten the Lipschitz bound in many certifiable training algorithms. Furthermore, we propose to clip activation functions (e.g., ReLU and MaxMin) with a learnable upper threshold and a sparsity loss to assist the network to achieve an even tighter local Lipschitz bound. Experimentally, we show that our method consistently outperforms state-of-the-art methods in both clean and certified accuracy on MNIST, CIFAR-10 and TinyImageNet datasets with various network architectures.",
    "authors": [
      "Huang, Yujia",
      "Zhang, Huan",
      "Shi, Yuanyuan",
      "Kolter, J. Zico",
      "Anandkumar, Anima"
    ]
  },
  {
    "id": "c058f544c737782deacefa532d9add4c",
    "title": "Average-Reward Learning and Planning with Options",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c058f544c737782deacefa532d9add4c-Paper.pdf",
    "abstract": "We extend the options framework for temporal abstraction in reinforcement learning from discounted Markov decision processes (MDPs) to average-reward MDPs. Our contributions include general convergent off-policy inter-option learning algorithms, intra-option algorithms for learning values and models, as well as sample-based planning variants of our learning algorithms. Our algorithms and convergence proofs extend those recently developed by Wan, Naik, and Sutton. We also extend the notion of option-interrupting behaviour from the discounted to the average-reward formulation. We show the efficacy of the proposed algorithms with experiments on a continuing version of the Four-Room domain. ",
    "authors": [
      "Wan, Yi",
      "Naik, Abhishek",
      "Sutton, Rich"
    ]
  },
  {
    "id": "c0cccc24dd23ded67404f5e511c342b0",
    "title": "SSAL: Synergizing between Self-Training and Adversarial Learning for Domain Adaptive Object Detection",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c0cccc24dd23ded67404f5e511c342b0-Paper.pdf",
    "abstract": "We study adapting trained object detectors to unseen domains manifesting significant variations of object appearance, viewpoints and backgrounds. Most current methods align domains by either using image or instance-level feature alignment in an adversarial fashion. This often suffers due to the presence of unwanted background and as such lacks class-specific alignment. A common remedy to promote class-level alignment is to use high confidence predictions on the unlabelled domain as pseudo labels. These high confidence predictions are often fallacious since the model is poorly calibrated under domain shift. In this paper, we propose to leverage model\u2019s predictive uncertainty to strike the right balance between adversarial feature alignment and class-level alignment. Specifically, we measure predictive uncertainty on class assignments and the bounding box predictions. Model predictions with low uncertainty are used to generate pseudo-labels for self-supervision, whereas the ones with higher uncertainty are used to generate tiles for an adversarial feature alignment stage. This synergy between tiling around the uncertain object regions and generating pseudo-labels from highly certain object regions allows us to capture both the image and instance level context during the model adaptation stage. We perform extensive experiments covering various domain shift scenarios. Our approach improves upon existing state-of-the-art methods with visible margins.",
    "authors": [
      "Munir, Muhammad Akhtar",
      "Khan, Muhammad Haris",
      "Sarfraz, M.",
      "Ali, Mohsen"
    ]
  },
  {
    "id": "c0e19ce0dbabbc0d17a4f8d4324cc8e3",
    "title": "Counterexample Guided RL Policy Refinement Using Bayesian Optimization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c0e19ce0dbabbc0d17a4f8d4324cc8e3-Paper.pdf",
    "abstract": "Constructing Reinforcement Learning (RL) policies that adhere to safety requirements is an emerging field of study. RL agents learn via trial and error with an objective to optimize a reward signal. Often policies that are designed to accumulate rewards do not satisfy safety specifications. We present a methodology for counterexample guided refinement of a trained RL policy against a given safety specification. Our approach has two main components. The first component is an approach to discover failure trajectories using Bayesian optimization over multiple parameters of uncertainty from a policy learnt in a model-free setting. The second component selectively modifies the failure points of the policy using gradient-based updates. The approach has been tested on several RL environments, and we demonstrate that the policy can be made to respect the safety specifications through such targeted changes.",
    "authors": [
      "Gangopadhyay, Briti",
      "Dasgupta, Pallab"
    ]
  },
  {
    "id": "c0f168ce8900fa56e57789e2a2f2c9d0",
    "title": "Stable, Fast and Accurate: Kernelized Attention with Relative Positional Encoding",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c0f168ce8900fa56e57789e2a2f2c9d0-Paper.pdf",
    "abstract": "The attention module, which is a crucial component in Transformer, cannot scale efficiently to long sequences due to its quadratic complexity. Many works focus on approximating the dot-then-exponentiate softmax function in the original attention, leading to sub-quadratic or even linear-complexity Transformer architectures. However, we show that these methods cannot be applied to more powerful attention modules that go beyond the dot-then-exponentiate style, e.g., Transformers with relative positional encoding (RPE). Since in many state-of-the-art models, relative positional encoding is used as default, designing efficient Transformers that can incorporate RPE is appealing. In this paper, we propose a novel way to accelerate attention calculation for Transformers with RPE on top of the kernelized attention. Based upon the observation that relative positional encoding forms a Toeplitz matrix, we mathematically show that kernelized attention with RPE can be calculated efficiently using Fast Fourier Transform (FFT). With FFT, our method achieves $\\mathcal{O}(n\\log n)$ time complexity. Interestingly, we further demonstrate that properly using relative positional encoding can mitigate the training instability problem of vanilla kernelized attention. On a wide range of tasks, we empirically show that our models can be trained from scratch without any optimization issues. The learned model performs better than many efficient Transformer variants and is faster than standard Transformer in the long-sequence regime.",
    "authors": [
      "Luo, Shengjie",
      "Li, Shanda",
      "Cai, Tianle",
      "He, Di",
      "Peng, Dinglan",
      "Zheng, Shuxin",
      "Ke, Guolin",
      "Wang, Liwei",
      "Liu, Tie-Yan"
    ]
  },
  {
    "id": "c0f52c6624ae1359e105c8a5d8cd956a",
    "title": "Learning in Non-Cooperative Configurable Markov Decision Processes",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c0f52c6624ae1359e105c8a5d8cd956a-Paper.pdf",
    "abstract": "The Configurable Markov Decision Process framework includes two entities: a Reinforcement Learning agent and a configurator that can modify some environmental parameters to improve the agent's performance. This presupposes that the two actors have the same reward functions. What if the configurator does not have the same intentions as the agent? This paper introduces the Non-Cooperative Configurable Markov Decision Process, a setting that allows having two (possibly different) reward functions for the configurator and the agent. Then, we consider an online learning problem, where the configurator has to find the best among a finite set of possible configurations. We propose two learning algorithms to minimize the configurator's expected regret, which exploits the problem's structure, depending on the agent's feedback. While a naive application of the UCB algorithm yields a regret that grows indefinitely over time, we show that our approach suffers only bounded regret. Furthermore, we empirically show the performance of our algorithm in simulated domains.",
    "authors": [
      "Ramponi, Giorgia",
      "Metelli, Alberto Maria",
      "Concetti, Alessandro",
      "Restelli, Marcello"
    ]
  },
  {
    "id": "c0f6fb5d3a389de216345e490469145e",
    "title": "Identification of Partially Observed Linear Causal Models: Graphical Conditions for the Non-Gaussian and Heterogeneous Cases",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c0f6fb5d3a389de216345e490469145e-Paper.pdf",
    "abstract": "In causal discovery, linear non-Gaussian acyclic models (LiNGAMs) have been studied extensively. While the causally sufficient case is well understood, in many real problems the observed variables are not causally related. Rather, they are generated by latent variables, such as confounders and mediators, which may themselves be causally related. Existing results on the identification of the causal structure among the latent variables often require very strong graphical assumptions. In this paper, we consider partially observed linear models with either non-Gaussian or heterogeneous errors. In that case we give two graphical conditions which are necessary for identification of the causal structure. These conditions are closely related to sparsity of the causal edges. Together with one additional condition on the coefficients, which holds generically for any graph, the two graphical conditions are also sufficient for identifiability. These new conditions can be satisfied even when there is a large number of latent variables. We demonstrate the validity of our results on synthetic data.",
    "authors": [
      "Adams, Jeffrey",
      "Hansen, Niels",
      "Zhang, Kun"
    ]
  },
  {
    "id": "c0f971d8cd24364f2029fcb9ac7b71f5",
    "title": "DIB-R++: Learning to Predict Lighting and Material with a Hybrid Differentiable Renderer",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c0f971d8cd24364f2029fcb9ac7b71f5-Paper.pdf",
    "abstract": "We consider the challenging problem of predicting intrinsic object properties from a single image by exploiting differentiable renderers. Many previous learning-based approaches for inverse graphics adopt rasterization-based renderers and assume naive lighting and material models, which often fail to account for non-Lambertian, specular reflections commonly observed in the wild. In this work, we propose DIBR++, a hybrid differentiable renderer which supports these photorealistic  effects by combining rasterization and ray-tracing, taking the advantage of their respective strengths---speed and realism. Our renderer incorporates environmental lighting and spatially-varying material models to efficiently approximate light transport, either through direct estimation or via spherical basis functions. Compared to more advanced physics-based differentiable renderers leveraging path tracing, DIBR++ is highly performant due to its compact and expressive shading model, which enables easy integration with learning frameworks for geometry, reflectance and lighting prediction from a single image without requiring any ground-truth. We experimentally demonstrate that our approach achieves superior material and lighting disentanglement on synthetic and real data compared to existing rasterization-based approaches and showcase several artistic applications including material editing and relighting. ",
    "authors": [
      "Chen, Wenzheng",
      "Litalien, Joey",
      "Gao, Jun",
      "Wang, Zian",
      "Fuji Tsang, Clement",
      "Khamis, Sameh",
      "Litany, Or",
      "Fidler, Sanja"
    ]
  },
  {
    "id": "c115ba9e04ab27fbbb664f932112246d",
    "title": "Coresets for Time Series Clustering",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c115ba9e04ab27fbbb664f932112246d-Paper.pdf",
    "abstract": "We study the problem of constructing coresets for clustering problems with time series data.  This problem has gained importance across many fields including biology, medicine, and economics due to the proliferation of sensors facilitating real-time measurement and rapid drop in storage costs.  In particular, we consider the setting where the time series data on $N$ entities is generated from a Gaussian mixture model with autocorrelations over $k$ clusters in $\\mathbb{R}^d$. Our main contribution is an algorithm to construct coresets for the maximum likelihood objective for this mixture model. Our algorithm is efficient, and under a mild boundedness assumption on the covariance matrices of the underlying Gaussians, the size of the coreset is independent of the number of entities $N$ and the number of observations for each entity, and depends only polynomially on $k$, $d$ and $1/\\varepsilon$, where $\\varepsilon$ is the error parameter.  We empirically assess the performance of our coreset with synthetic data. ",
    "authors": [
      "Huang, Lingxiao",
      "Sudhir, K",
      "Vishnoi, Nisheeth"
    ]
  },
  {
    "id": "c11abfd29e4d9b4d4b566b01114d8486",
    "title": "A Variational Perspective on Diffusion-Based Generative Models and Score Matching",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c11abfd29e4d9b4d4b566b01114d8486-Paper.pdf",
    "abstract": "Discrete-time diffusion-based generative models and score matching methods have shown promising results in modeling high-dimensional image data. Recently, Song et al. (2021) show that diffusion processes that transform data into noise can be reversed via learning the score function, i.e. the gradient of the log-density of the perturbed data. They propose to plug the learned score function into an inverse formula to define a generative diffusion process. Despite the empirical success, a theoretical underpinning of this procedure is still lacking. In this work, we approach the (continuous-time) generative diffusion directly and derive a variational framework for likelihood estimation, which includes continuous-time normalizing flows as a special case, and can be seen as an infinitely deep variational autoencoder. Under this framework, we show that minimizing the score-matching loss is equivalent to maximizing a lower bound of the likelihood of the plug-in reverse SDE proposed by Song et al. (2021), bridging the theoretical gap.",
    "authors": [
      "Huang, Chin-Wei",
      "Lim, Jae Hyun",
      "Courville, Aaron C."
    ]
  },
  {
    "id": "c1619d2ad66f7629c12c87fe21d32a58",
    "title": "Online Active Learning with Surrogate Loss Functions",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c1619d2ad66f7629c12c87fe21d32a58-Paper.pdf",
    "abstract": "We derive a novel active learning algorithm in the streaming setting for binary classification tasks. The algorithm leverages weak labels to minimize the number of label requests, and trains a model to optimize a surrogate loss on a resulting set of labeled and weak-labeled points. Our algorithm jointly admits two crucial properties: theoretical guarantees in the general agnostic setting and a strong empirical performance. Our theoretical analysis shows that the algorithm attains favorable generalization and label complexity bounds, while our empirical study on 18 real-world datasets demonstrate that the algorithm outperforms standard baselines, including the Margin Algorithm, or  Uncertainty Sampling, a high-performing active learning algorithm favored by practitioners.",
    "authors": [
      "DeSalvo, Giulia",
      "Gentile, Claudio",
      "Thune, Tobias Sommer"
    ]
  },
  {
    "id": "c164bbc9d6c72a52c599bbb43d8db8e1",
    "title": "Does Preprocessing Help Training Over-parameterized Neural Networks?",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c164bbc9d6c72a52c599bbb43d8db8e1-Paper.pdf",
    "abstract": "Deep neural networks have achieved impressive performance in many areas. Designing a fast and provable method for training neural networks is a fundamental question in machine learning. The classical training method requires paying $\\Omega(mnd)$ cost for both forward computation and backward computation, where $m$ is the width of the neural network, and we are given $n$ training points in $d$-dimensional space. In this paper, we propose two novel preprocessing ideas to bypass this $\\Omega(mnd)$ barrier:* First, by preprocessing the initial weights of the neural networks, we can train the neural network in $\\widetilde{O}(m^{1-\\Theta(1/d)} n d)$ cost per iteration.* Second, by preprocessing the input data points, we can train neural network in $\\widetilde{O} (m^{4/5} nd )$ cost per iteration.From the technical perspective, our result is a sophisticated combination of tools in different fields, greedy-type convergence analysis in optimization, sparsity observation in practical work, high-dimensional geometric search in data structure, concentration and anti-concentration in probability. Our results also provide theoretical insights for a large number of previously established fast training methods.In addition, our classical algorithm can be generalized to the Quantum computation model. Interestingly, we can get a similar sublinear cost per iteration but avoid preprocessing initial weights or input data points.",
    "authors": [
      "Song, Zhao",
      "Yang, Shuo",
      "Zhang, Ruizhe"
    ]
  },
  {
    "id": "c1722a7941d61aad6e651a35b65a9c3e",
    "title": "Causal Influence Detection for Improving Efficiency in Reinforcement Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c1722a7941d61aad6e651a35b65a9c3e-Paper.pdf",
    "abstract": "Many reinforcement learning (RL) environments consist of independent entities that interact sparsely. In such environments, RL agents have only limited influence over other entities in any particular situation. Our idea in this work is that learning can be efficiently guided by knowing when and what the agent can influence with its actions. To achieve this, we introduce a measure of situation-dependent causal influence based on conditional mutual information and show that it can reliably detect states of influence. We then propose several ways to integrate this measure into RL algorithms to improve exploration and off-policy learning. All modified algorithms show strong increases in data efficiency on robotic manipulation tasks.",
    "authors": [
      "Seitzer, Maximilian",
      "Sch\u00f6lkopf, Bernhard",
      "Martius, Georg"
    ]
  },
  {
    "id": "c1b70d965ca504aa751ddb62ad69c63f",
    "title": "LADA: Look-Ahead Data Acquisition via Augmentation for Deep Active Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c1b70d965ca504aa751ddb62ad69c63f-Paper.pdf",
    "abstract": "Active learning effectively collects data instances for training deep learning models when the labeled dataset is limited and the annotation cost is high. Data augmentation is another effective technique to enlarge the limited amount of labeled instances. The scarcity of labeled dataset leads us to consider the integration of data augmentation and active learning. One possible approach is a pipelined combination, which selects informative instances via the acquisition function and generates virtual instances from the selected instances via augmentation. However, this pipelined approach would not guarantee the informativeness of the virtual instances. This paper proposes Look-Ahead Data Acquisition via augmentation, or LADA framework, that looks ahead the effect of data augmentation in the process of acquisition. LADA jointly considers both 1) unlabeled data instance to be selected and 2) virtual data instance to be generated by data augmentation, to construct the acquisition function. Moreover, to generate maximally informative virtual instances, LADA optimizes the data augmentation policy to maximize the predictive acquisition score, resulting in the proposal of InfoSTN and InfoMixup. The experimental results of LADA show a significant improvement over the recent augmentation and acquisition baselines that were independently applied.",
    "authors": [
      "Kim, Yoon-Yeong",
      "Song, Kyungwoo",
      "Jang, JoonHo",
      "Moon, Il-chul"
    ]
  },
  {
    "id": "c1b8bf9e071c0dabb899e7a27f353762",
    "title": "Policy Optimization in Adversarial MDPs: Improved Exploration via Dilated Bonuses",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c1b8bf9e071c0dabb899e7a27f353762-Paper.pdf",
    "abstract": "Policy optimization is a widely-used method in reinforcement learning. Due to its local-search nature, however, theoretical guarantees on global optimality often rely on extra assumptions on the Markov Decision Processes (MDPs) that bypass the challenge of global exploration. To eliminate the need of such assumptions, in this work, we develop a general solution that adds dilated bonuses to the policy update to facilitate global exploration. To showcase the power and generality of this technique, we apply it to several episodic MDP settings with adversarial losses and bandit feedback, improving and generalizing the state-of-the-art. Specifically, in the tabular case, we obtain $\\widetilde{\\mathcal{O}}(\\sqrt{T})$ regret where $T$ is the number of episodes, improving the $\\widetilde{\\mathcal{O}}({T}^{\\frac{2}{3}})$ regret bound by Shani et al. [2020]. When the number of states is infinite, under the assumption that the state-action values are linear in some low-dimensional features, we obtain $\\widetilde{\\mathcal{O}}({T}^{\\frac{2}{3}})$ regret with the help of a simulator, matching the result of Neu and Olkhovskaya [2020] while importantly removing the need of an exploratory policy that their algorithm requires. To our knowledge, this is the first algorithm with sublinear regret for linear function approximation with adversarial losses, bandit feedback, and no exploratory assumptions. Finally, we also discuss how to further improve the regret or remove the need of a simulator using dilated bonuses, when an exploratory policy is available.",
    "authors": [
      "Luo, Haipeng",
      "Wei, Chen-Yu",
      "Lee, Chung-Wei"
    ]
  },
  {
    "id": "c1d53b7a97707b5cd1815c8d228d8ef1",
    "title": "Multiclass versus Binary Differentially Private PAC Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c1d53b7a97707b5cd1815c8d228d8ef1-Paper.pdf",
    "abstract": "We show a generic reduction from multiclass differentially private PAC learning to binary private PAC learning. We apply this transformation to a recently proposed binary private PAC learner to obtain a private multiclass learner with sample complexity that has a polynomial dependence on the multiclass Littlestone dimension and a poly-logarithmic dependence on the number of classes. This yields a doubly exponential improvement in the dependence on both parameters over learners from previous work. Our proof extends the notion of $\\Psi$-dimension defined in work of Ben-David et al. [JCSS, 1995] to the online setting and explores its general properties.",
    "authors": [
      "Sivakumar, Satchit",
      "Bun, Mark",
      "Gaboardi, Marco"
    ]
  },
  {
    "id": "c1e39d912d21c91dce811d6da9929ae8",
    "title": "Adversarially Robust Change Point Detection",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c1e39d912d21c91dce811d6da9929ae8-Paper.pdf",
    "abstract": "Change point detection is becoming increasingly popular in many application areas. On one hand, most of the theoretically-justified methods are investigated in an ideal setting without model violations, or merely robust against identical heavy-tailed noise distribution across time and/or against isolate outliers; on the other hand, we are aware that there have been exponentially growing attacks from adversaries, who may pose systematic contamination on data to purposely create spurious change points or disguise true change points. In light of the timely need for a change point detection method that is robust against adversaries, we start with, arguably, the simplest univariate mean change point detection problem. The adversarial attacks are formulated through the Huber $\\varepsilon$-contamination framework, which in particular allows the contamination distributions to be different at each time point. In this paper, we demonstrate a phase transition phenomenon in change point detection. This detection boundary is a function of the contamination proportion~$\\varepsilon$ and is the first time shown in the literature. In addition, we derive the minimax-rate optimal localisation error rate, quantifying the cost of accuracy in terms of the contamination proportion. We propose a computationally feasible method, matching the minimax lower bound under certain conditions, saving for logarithmic factors. Extensive numerical experiments are conducted with comparisons to robust change point detection methods in the existing literature.  ",
    "authors": [
      "Li, Mengchu",
      "Yu, Yi"
    ]
  },
  {
    "id": "c1fea270c48e8079d8ddf7d06d26ab52",
    "title": "Cycle Self-Training for Domain Adaptation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c1fea270c48e8079d8ddf7d06d26ab52-Paper.pdf",
    "abstract": "Mainstream approaches for unsupervised domain adaptation (UDA) learn domain-invariant representations to narrow the domain shift, which are empirically effective but theoretically challenged by the hardness or impossibility theorems. Recently, self-training has been gaining momentum in UDA, which exploits unlabeled target data by training with target pseudo-labels. However, as corroborated in this work, under distributional shift, the pseudo-labels can be unreliable in terms of their large discrepancy from target ground truth. In this paper, we propose Cycle Self-Training (CST), a principled self-training algorithm that explicitly enforces pseudo-labels to generalize across domains. CST cycles between a forward step and a reverse step until convergence. In the forward step, CST generates target pseudo-labels with a source-trained classifier. In the reverse step, CST trains a target classifier using target pseudo-labels, and then updates the shared representations to make the target classifier perform well on the source data. We introduce the Tsallis entropy as a confidence-friendly regularization to improve the quality of target pseudo-labels. We analyze CST theoretically under realistic assumptions, and provide hard cases where CST recovers target ground truth, while both invariant feature learning and vanilla self-training fail. Empirical results indicate that CST significantly improves over the state-of-the-arts on visual recognition and sentiment analysis benchmarks.",
    "authors": [
      "Liu, Hong",
      "Wang, Jianmin",
      "Long, Mingsheng"
    ]
  },
  {
    "id": "c203d8a151612acf12457e4d67635a95",
    "title": "Novel Visual Category Discovery with Dual Ranking Statistics and Mutual Knowledge Distillation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c203d8a151612acf12457e4d67635a95-Paper.pdf",
    "abstract": "In this paper, we tackle the problem of novel visual category discovery, i.e., grouping unlabelled images from new classes into different semantic partitions by leveraging a labelled dataset that contains images from other different but relevant categories.  This is a more realistic and challenging setting than conventional semi-supervised learning. We propose a two-branch learning framework for this problem, with one branch focusing on local part-level information and the other branch focusing on overall characteristics. To transfer knowledge from the labelled data to the unlabelled, we propose using dual ranking statistics on both branches to generate pseudo labels for training on the unlabelled data. We further introduce a mutual knowledge distillation method to allow information exchange and encourage agreement between the two branches for discovering new categories, allowing our model to enjoy the benefits of global and local features. We comprehensively evaluate our method on public benchmarks for generic object classification, as well as the more challenging datasets for fine-grained visual recognition, achieving state-of-the-art performance.",
    "authors": [
      "Zhao, Bingchen",
      "Han, Kai"
    ]
  },
  {
    "id": "c203e4a1bdef9372cb9864bfc9b511cc",
    "title": "Stochastic Anderson Mixing for Nonconvex Stochastic Optimization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c203e4a1bdef9372cb9864bfc9b511cc-Paper.pdf",
    "abstract": "Anderson mixing (AM) is an acceleration method for fixed-point iterations. Despite its success and wide usage in scientific computing, the convergence theory of AM remains unclear, and its applications to machine learning problems are not well explored. In this paper, by introducing damped projection and adaptive regularization to the classical AM, we propose a Stochastic Anderson Mixing (SAM) scheme to solve nonconvex stochastic optimization problems. Under mild assumptions, we establish the convergence theory of SAM, including the almost sure convergence to stationary points and the worst-case iteration complexity. Moreover, the complexity bound can be improved when randomly choosing an iterate as the output. To further accelerate the convergence, we incorporate a variance reduction technique into the proposed SAM. We also propose a preconditioned mixing strategy for SAM which can empirically achieve faster convergence or better generalization ability. Finally, we apply the SAM method to train various neural networks including the vanilla CNN, ResNets, WideResNet, ResNeXt, DenseNet and LSTM. Experimental results on image classification and language model demonstrate the advantages of our method.",
    "authors": [
      "Wei, Fuchao",
      "Bao, Chenglong",
      "Liu, Yang"
    ]
  },
  {
    "id": "c21f4ce780c5c9d774f79841b81fdc6d",
    "title": "Sample-Efficient Reinforcement Learning for Linearly-Parameterized MDPs with a Generative Model",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c21f4ce780c5c9d774f79841b81fdc6d-Paper.pdf",
    "abstract": "The curse of dimensionality is a widely known issue in reinforcement learning (RL). In the tabular setting where the state space $\\mathcal{S}$ and the action space $\\mathcal{A}$ are both finite, to obtain a near optimal policy with sampling access to a generative model, the minimax optimal sample complexity scales linearly with $|\\mathcal{S}|\\times|\\mathcal{A}|$, which can be prohibitively large when $\\mathcal{S}$ or $\\mathcal{A}$ is large. This paper considers a Markov decision process (MDP) that admits a set of state-action features, which can linearly express (or approximate) its probability transition kernel. We show that a model-based approach (resp.$~$Q-learning) provably learns an $\\varepsilon$-optimal policy (resp.$~$Q-function) with high probability as soon as the sample size exceeds the order of $\\frac{K}{(1-\\gamma)^{3}\\varepsilon^{2}}$ (resp.$~$$\\frac{K}{(1-\\gamma)^{4}\\varepsilon^{2}}$), up to some logarithmic factor. Here $K$ is the feature dimension and $\\gamma\\in(0,1)$ is the discount factor of the MDP. Both sample complexity bounds are provably tight, and our result for the model-based approach matches the minimax lower bound. Our results show that for arbitrarily large-scale MDP, both the model-based approach and Q-learning are sample-efficient when $K$ is relatively small, and hence the title of this paper.",
    "authors": [
      "Wang, Bingyan",
      "Yan, Yuling",
      "Fan, Jianqing"
    ]
  },
  {
    "id": "c236337b043acf93c7df397fdb9082b3",
    "title": "NN-Baker: A Neural-network Infused Algorithmic Framework for Optimization Problems on Geometric Intersection Graphs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c236337b043acf93c7df397fdb9082b3-Paper.pdf",
    "abstract": "Recent years have witnessed a surge of approaches to use neural networks to help tackle combinatorial optimization problems, including graph optimization problems. However, theoretical understanding of such approaches remains limited. In this paper, we consider the geometric setting, where graphs are induced by points in a fixed dimensional Euclidean space. We show that several graph optimization problems can be approximated by an algorithm that is polynomial in graph size n via a framework we propose, call the Baker-paradigm. More importantly, a key advantage of the Baker-paradigm is that it decomposes the input problem into (at most linear number of) small sub-problems of fixed sizes (independent of the size of the input). For the family of such fixed-size sub-problems, we can now design neural networks with universal approximation guarantees to solve them. This leads to a mixed algorithmic-ML framework, which we call NN-Baker that has the capacity to approximately solve a family of graph optimization problems (e.g, maximum independent set and minimum vertex cover) in time linear to input graph size, and only polynomial to approximation parameter. We instantiate our NN-Baker by a CNN version and GNN version, and demonstrate the effectiveness and efficiency of our approach via a range of experiments.",
    "authors": [
      "McCarty, Evan",
      "Zhao, Qi",
      "Sidiropoulos, Anastasios",
      "Wang, Yusu"
    ]
  },
  {
    "id": "c2368d3d45705a56e51ec5940e187f8d",
    "title": "A Note on Sparse Generalized Eigenvalue Problem",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c2368d3d45705a56e51ec5940e187f8d-Paper.pdf",
    "abstract": "The sparse generalized eigenvalue problem (SGEP) aims to find the leading eigenvector with sparsity structure. SGEP plays an important role in statistical learning and has wide applications including, but not limited to, sparse principal component analysis, sparse canonical correlation analysis  and sparse Fisher discriminant analysis, etc. Due to the sparsity constraint, the solution of SGEP entails interesting properties from both numerical and statistical perspectives. In this paper, we provide a detailed sensitivity analysis for SGEP and establish the rate-optimal perturbation bound under the sparse setting. Specifically, we show that the bound is related to the perturbation/noise level and the recovery of the true support of the leading eigenvector as well. We also investigate the estimator of SGEP via imposing a non-convex regularization. Such estimator can achieve the optimal error rate and can recover the sparsity structure as well. Extensive numerical experiments corroborate our theoretical findings via using alternating direction method of multipliers (ADMM)-based computational method.",
    "authors": [
      "Cai, Yunfeng",
      "Fang, Guanhua",
      "Li, Ping"
    ]
  },
  {
    "id": "c2626d850c80ea07e7511bbae4c76f4b",
    "title": "RMIX: Learning Risk-Sensitive Policies for Cooperative Reinforcement Learning Agents",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c2626d850c80ea07e7511bbae4c76f4b-Paper.pdf",
    "abstract": "Current value-based multi-agent reinforcement learning methods optimize individual Q values to guide individuals' behaviours via centralized training with decentralized execution (CTDE). However, such expected, i.e., risk-neutral, Q value is not sufficient even with CTDE due to the randomness of rewards and the uncertainty in environments, which causes the failure of these methods to train coordinating agents in complex environments. To address these issues, we propose RMIX, a novel cooperative MARL method with the Conditional Value at Risk (CVaR) measure over the learned distributions of individuals' Q values. Specifically, we first learn the return distributions of individuals to analytically calculate CVaR for decentralized execution. Then, to handle the temporal nature of the stochastic outcomes during executions, we propose a dynamic risk level predictor for risk level tuning. Finally, we optimize the CVaR policies with CVaR values used to estimate the target in TD error during centralized training and the CVaR values are used as auxiliary local rewards to update the local distribution via Quantile Regression loss. Empirically, we show that our method outperforms many state-of-the-art methods on various multi-agent risk-sensitive navigation scenarios and challenging StarCraft II cooperative tasks, demonstrating enhanced coordination and revealing improved sample efficiency.",
    "authors": [
      "Qiu, Wei",
      "Wang, Xinrun",
      "Yu, Runsheng",
      "Wang, Rundong",
      "He, Xu",
      "An, Bo",
      "Obraztsova, Svetlana",
      "Rabinovich, Zinovi"
    ]
  },
  {
    "id": "c26820b8a4c1b3c2aa868d6d57e14a79",
    "title": "Optimal Policies Tend To Seek Power",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c26820b8a4c1b3c2aa868d6d57e14a79-Paper.pdf",
    "abstract": "Some researchers speculate that intelligent reinforcement learning (RL) agents would be incentivized to seek resources and power in pursuit of the objectives we specify for them. Other researchers point out that RL agents need not have human-like power-seeking instincts. To clarify this discussion, we develop the first formal theory of the statistical tendencies of optimal policies. In the context of Markov decision processes, we prove that certain environmental symmetries are sufficient for optimal policies to tend to seek power over the environment. These symmetries exist in many environments in which the agent can be shut down or destroyed. We prove that in these environments, most reward functions make it optimal to seek power by keeping a range of options available and, when maximizing average reward, by navigating towards larger sets of potential terminal states.",
    "authors": [
      "Turner, Alex",
      "Smith, Logan",
      "Shah, Rohin",
      "Critch, Andrew",
      "Tadepalli, Prasad"
    ]
  },
  {
    "id": "c2839bed26321da8b466c80a032e4714",
    "title": "Catalytic Role Of Noise And Necessity Of Inductive Biases In The Emergence Of Compositional Communication",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c2839bed26321da8b466c80a032e4714-Paper.pdf",
    "abstract": "Communication is compositional if complex signals can be represented as a combination of simpler subparts. In this paper, we theoretically show that inductive biases on both the training framework and the data are needed to develop a compositional communication.  Moreover, we prove that compositionality spontaneously arises in the signaling games, where agents communicate over a noisy channel.  We experimentally confirm that a range of noise levels, which depends on the model and the data, indeed promotes compositionality. Finally, we provide a comprehensive study of this dependence and report results in terms of recently studied compositionality metrics: topographical similarity, conflict count, and context independence.",
    "authors": [
      "Kuci\u0144ski, \u0141ukasz",
      "Korbak, Tomasz",
      "Ko\u0142odziej, Pawe\u0142",
      "Mi\u0142o\u015b, Piotr"
    ]
  },
  {
    "id": "c2937f3a1b3a177d2408574da0245a19",
    "title": "PLUR: A Unifying, Graph-Based View of Program Learning, Understanding, and Repair",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c2937f3a1b3a177d2408574da0245a19-Paper.pdf",
    "abstract": "Machine learning for understanding and editing source code has recently attracted significant interest, with many developments in new models, new code representations, and new tasks.This proliferation can appear disparate and disconnected, making each approach seemingly unique and incompatible, thus obscuring the core machine learning challenges and contributions.In this work, we demonstrate that the landscape can be significantly simplified by taking a general approach of mapping a graph to a sequence of tokens and pointers.Our main result is to show that 16 recently published tasks of different shapes can be cast in this form, based on which a single model architecture achieves near or above state-of-the-art results on nearly all tasks, outperforming custom models like code2seq and alternative generic models like Transformers.This unification further enables multi-task learning and a series of cross-cutting experiments about the importance of different modeling choices for code understanding and repair tasks.The full framework, called PLUR, is easily extensible to more tasks, and will be open-sourced (https://github.com/google-research/plur).",
    "authors": [
      "Chen, Zimin",
      "Hellendoorn, Vincent J",
      "Lamblin, Pascal",
      "Maniatis, Petros",
      "Manzagol, Pierre-Antoine",
      "Tarlow, Daniel",
      "Moitra, Subhodeep"
    ]
  },
  {
    "id": "c2c2a04512b35d13102459f8784f1a2d",
    "title": "COCO-LM: Correcting and Contrasting Text Sequences for Language Model Pretraining",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c2c2a04512b35d13102459f8784f1a2d-Paper.pdf",
    "abstract": "We present a self-supervised learning framework, COCO-LM, that pretrains Language Models by COrrecting and COntrasting corrupted text sequences. Following ELECTRA-style pretraining, COCO-LM employs an auxiliary language model to corrupt text sequences, upon which it constructs two new tasks for pretraining the main model. The first token-level task, Corrective Language Modeling, is to detect and correct tokens replaced by the auxiliary model, in order to better capture token-level semantics. The second sequence-level task, Sequence Contrastive Learning, is to align text sequences originated from the same source input while ensuring uniformity in the representation space. Experiments on GLUE and SQuAD demonstrate that COCO-LM not only outperforms recent state-of-the-art pretrained models in accuracy, but also improves pretraining efficiency. It achieves the MNLI accuracy of ELECTRA with 50% of its pretraining GPU hours. With the same pretraining steps of standard base/large-sized models, COCO-LM outperforms the previous best models by 1+ GLUE average points.",
    "authors": [
      "Meng, Yu",
      "Xiong, Chenyan",
      "Bajaj, Payal",
      "tiwary, saurabh",
      "Bennett, Paul",
      "Han, Jiawei",
      "SONG, XIA"
    ]
  },
  {
    "id": "c2c701fe341a7756ca7fd4eaa83ff63f",
    "title": "Minibatch and Momentum Model-based Methods for Stochastic Weakly Convex Optimization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c2c701fe341a7756ca7fd4eaa83ff63f-Paper.pdf",
    "abstract": "Stochastic model-based methods have received increasing attention lately due to their appealing robustness to the stepsize selection and provable efficiency guarantee. We make two important extensions for improving model-based methods on stochastic weakly convex optimization. First, we propose new minibatch model- based methods by involving a set of samples to approximate the model function in each iteration. For the first time, we show that stochastic algorithms achieve linear speedup over the batch size even for non-smooth and non-convex (particularly, weakly convex) problems. To this end, we develop a novel sensitivity analysis of the proximal mapping involved in each algorithm iteration. Our analysis appears to be of independent interests in more general settings. Second, motivated by the success of momentum stochastic gradient descent, we propose a new stochastic extrapolated model-based method, greatly extending the classic Polyak momentum technique to a wider class of stochastic algorithms for weakly convex optimization. The rate of convergence to some natural stationarity condition is established over a fairly flexible range of extrapolation terms.While mainly focusing on weakly convex optimization, we also extend our work to convex optimization. We apply the minibatch and extrapolated model-based methods to stochastic convex optimization, for which we provide a new complexity bound and promising linear speedup in batch size. Moreover, an accelerated model-based method based on Nesterov\u2019s momentum is presented, for which we establish an optimal complexity bound for reaching optimality.",
    "authors": [
      "Deng, Qi",
      "Gao, Wenzhi"
    ]
  },
  {
    "id": "c2e06e9a80370952f6ec5463c77cbace",
    "title": "XDO: A Double Oracle Algorithm for Extensive-Form Games",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c2e06e9a80370952f6ec5463c77cbace-Paper.pdf",
    "abstract": "Policy Space Response Oracles (PSRO) is a reinforcement learning (RL) algorithm for two-player zero-sum games that has been empirically shown to find approximate Nash equilibria in large games. Although PSRO is guaranteed to converge to an approximate Nash equilibrium and can handle continuous actions, it may take an exponential number of iterations as the number of information states (infostates) grows. We propose Extensive-Form Double Oracle (XDO), an extensive-form double oracle algorithm for two-player zero-sum games that is guaranteed to converge to an approximate Nash equilibrium linearly in the number of infostates. Unlike PSRO, which mixes best responses at the root of the game, XDO mixes best responses at every infostate. We also introduce Neural XDO (NXDO), where the best response is learned through deep RL. In tabular experiments on Leduc poker, we find that XDO achieves an approximate Nash equilibrium in a number of iterations an order of magnitude smaller than PSRO. Experiments on a modified Leduc poker game and Oshi-Zumo show that tabular XDO achieves a lower exploitability than CFR with the same amount of computation. We also find that NXDO outperforms PSRO and NFSP on a sequential multidimensional continuous-action game. NXDO is the first deep RL method that can find an approximate Nash equilibrium in high-dimensional continuous-action sequential games.",
    "authors": [
      "McAleer, Stephen",
      "Lanier, JB",
      "Wang, Kevin A",
      "Baldi, Pierre",
      "Fox, Roy"
    ]
  },
  {
    "id": "c2f32522a84d5e6357e6abac087f1b0b",
    "title": "Active Assessment of Prediction Services as Accuracy Surface Over Attribute Combinations",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c2f32522a84d5e6357e6abac087f1b0b-Paper.pdf",
    "abstract": "Our goal is to evaluate the accuracy of a black-box classification model, not as a single aggregate on a given test data distribution, but as a surface over a large number of combinations of attributes characterizing multiple test data distributions.  Such attributed accuracy measures become important as machine learning models get deployed as a service, where the training data distribution is hidden from clients, and different clients may be interested in diverse regions of the data distribution. We present Attributed Accuracy Assay (AAA) --- a Gaussian Process (GP)-based probabilistic estimator for such an accuracy surface. Each attribute combination, called an 'arm' is associated with a Beta density from which the service's accuracy is sampled.  We expect the GP to smooth the parameters of the Beta density over related arms to mitigate sparsity. We show that obvious application of GPs cannot address the challenge of heteroscedastic uncertainty over a huge attribute space that is sparsely and unevenly populated. In response, we present two enhancements: pooling sparse observations, and regularizing the scale parameter of the Beta densities. After introducing these innovations, we establish the effectiveness of AAA both in terms of its estimation accuracy and exploration efficiency, through extensive experiments and analysis.",
    "authors": [
      "Piratla, Vihari",
      "Chakrabarti, Soumen",
      "Sarawagi, Sunita"
    ]
  },
  {
    "id": "c2f599841f21aaefeeabd2a60ef7bfe8",
    "title": "A mechanistic multi-area recurrent network model of decision-making",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c2f599841f21aaefeeabd2a60ef7bfe8-Paper.pdf",
    "abstract": "Recurrent neural networks (RNNs) trained on neuroscience-based tasks have been widely used as models for cortical areas performing analogous tasks. However, very few tasks involve a single cortical area, and instead require the coordination of multiple brain areas. Despite the importance of multi-area computation, there is a limited understanding of the principles underlying such computation. We propose to use multi-area RNNs with neuroscience-inspired architecture constraints to derive key features of multi-area computation. In particular, we show that incorporating multiple areas and Dale's Law is critical for biasing the networks to learn biologically plausible solutions. Additionally, we leverage the full observability of the RNNs to show that output-relevant information is preferentially propagated between areas. These results suggest that cortex uses modular computation to generate minimal sufficient representations of task information. More broadly, our results suggest that constrained multi-area RNNs can produce experimentally testable hypotheses for computations that occur within and across multiple brain areas, enabling new insights into distributed computation in neural systems.",
    "authors": [
      "Kleinman, Michael",
      "Chandrasekaran, Chandramouli",
      "Kao, Jonathan"
    ]
  },
  {
    "id": "c3008b2c6f5370b744850a98a95b73ad",
    "title": "Learning to Compose Visual Relations",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c3008b2c6f5370b744850a98a95b73ad-Paper.pdf",
    "abstract": "The visual world around us can be described as a structured set of objects and their associated relations. An image of a room may be conjured given only the description of the underlying objects and their associated relations. While there has been significant work on designing deep neural networks which may compose individual objects together, less work has been done on composing the individual relations between objects. A principal difficulty is that while the placement of objects is mutually independent, their relations are entangled and dependent on each other. To circumvent this issue, existing works primarily compose relations by utilizing a holistic encoder, in the form of text or graphs. In this work, we instead propose to represent each relation as an unnormalized density (an energy-based model), enabling us to compose separate relations in a factorized manner. We show that such a factorized decomposition allows the model to both generate and edit scenes that have multiple sets of relations more faithfully. We further show that decomposition enables our model to effectively understand the underlying relational scene structure.",
    "authors": [
      "Liu, Nan",
      "Li, Shuang",
      "Du, Yilun",
      "Tenenbaum, Josh",
      "Torralba, Antonio"
    ]
  },
  {
    "id": "c315f0320b7cd4ec85756fac52d78076",
    "title": "Identity testing for Mallows model",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c315f0320b7cd4ec85756fac52d78076-Paper.pdf",
    "abstract": "In this paper, we devise identity tests for ranking data that is generated from Mallows model both in the \\emph{asymptotic} and \\emph{non-asymptotic} settings. First we consider the case when the central ranking is known, and devise two algorithms for testing the spread parameter of the Mallows model. The first one is obtained by constructing a Uniformly Most Powerful Unbiased (UMPU) test in the asymptotic setting and then converting it into a sample-optimal non-asymptotic identity test. The resulting test is, however, impractical even for medium sized data, because it requires computing the distribution of the sufficient statistic. The second non-asymptotic test is derived from an optimal learning algorithm for the Mallows model. This test is both easy to compute and is sample-optimal for a wide range of parameters. Next, we consider testing Mallows models for the unknown central ranking case. This case can be tackled in the asymptotic setting by introducing a bias that exponentially decays with the sample size. We support all our findings with extensive numerical experiments and show that the proposed tests scale gracefully with the number of items to be ranked.",
    "authors": [
      "Busa-Fekete, R\u00f3bert",
      "Fotakis, Dimitris",
      "Szorenyi, Balazs",
      "Zampetakis, Emmanouil"
    ]
  },
  {
    "id": "c3395dd46c34fa7fd8d729d8cf88b7a8",
    "title": "Bandits with Knapsacks beyond the Worst Case",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c3395dd46c34fa7fd8d729d8cf88b7a8-Paper.pdf",
    "abstract": "Bandits with Knapsacks (BwK) is a general model for multi-armed bandits under supply/budget constraints. While worst-case regret bounds for BwK are well-understood, we present three results that go beyond the worst-case perspective. First, we provide upper and lower bounds which amount to a full characterization for logarithmic, instance-dependent regret rates.Second, we consider \"simple regret\" in BwK, which tracks algorithm's performance in a given round, and prove that it is small in all but a few rounds. Third, we provide a \"generalreduction\" from BwK to bandits which takes advantage of some known helpful structure, and apply this reduction to combinatorial semi-bandits, linear contextual bandits, and multinomial-logit bandits. Our results build on the BwK algorithm from prior work, providing new analyses thereof.",
    "authors": [
      "Sankararaman, Karthik Abinav",
      "Slivkins, Aleksandrs"
    ]
  },
  {
    "id": "c344336196d5ec19bd54fd14befdde87",
    "title": "Closing the loop in medical decision support by understanding clinical decision-making: A case study on organ transplantation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c344336196d5ec19bd54fd14befdde87-Paper.pdf",
    "abstract": "Significant effort has been placed on developing decision support tools to improve patient care. However, drivers of real-world clinical decisions in complex medical scenarios are not yet well-understood, resulting in substantial gaps between these tools and practical applications. In light of this, we highlight that more attention on understanding clinical decision-making is required both to elucidate current clinical practices and to enable effective human-machine interactions. This is imperative in high-stakes scenarios with scarce available resources. Using organ transplantation as a case study, we formalize the desiderata of methods for understanding clinical decision-making. We show that most existing machine learning methods are insufficient to meet these requirements and propose iTransplant, a novel data-driven framework to learn the factors affecting decisions on organ offers in an instance-wise fashion directly from clinical data, as a possible solution. Through experiments on real-world liver transplantation data from OPTN, we demonstrate the use of iTransplant to: (1) discover which criteria are most important to clinicians for organ offer acceptance; (2) identify patient-specific organ preferences of clinicians allowing automatic patient stratification;  and (3) explore variations in transplantation practices between different transplant centers. Finally, we emphasize that the insights gained by iTransplant can be used to inform the development of future decision support tools.",
    "authors": [
      "Qin, Yuchao",
      "Imrie, Fergus",
      "H\u00fcy\u00fck, Alihan",
      "Jarrett, Daniel",
      "gimson, alexander",
      "van der Schaar, Mihaela"
    ]
  },
  {
    "id": "c348616cd8a86ee661c7c98800678fad",
    "title": "Change Point Detection via Multivariate Singular Spectrum Analysis",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c348616cd8a86ee661c7c98800678fad-Paper.pdf",
    "abstract": "The objective of change point detection (CPD) is to detect significant and abrupt changes in the dynamics of the underlying system of interest through multivariate time series observations. In this work, we develop and analyze an algorithm for CPD that is inspired by a variant of the classical singular spectrum analysis (SSA) approach for time series by combining it with the classical cumulative sum (CUSUM) statistic from sequential hypothesis testing. In particular, we model the underlying dynamics of multivariate time series observations through the spatio-temporal model introduced recently in the multivariate SSA (mSSA) literature. The change point in such a setting corresponds to a change in the underlying spatio-temporal model. As the primary contributions of this work, we develop an algorithm based on CUSUM-statistic to detect such change points in an online fashion. We extend the analysis of CUSUM statistics, traditionally done for the setting of independent observations, to the dependent setting of (multivariate) time series under the spatio-temporal model. Specifically, for a given parameter $h > 0$, our method achieves the following desirable trade-off: when a change happens, it detects it within $O(h)$ time delay on average, while in the absence of change, it does not declare false detection for at least $\\exp(\\Omega(h))$ time length on average. We conduct empirical experiments using benchmark and synthetic datasets. We find that the proposed method performs competitively or outperforms the state-of-the-art change point detection methods across datasets. ",
    "authors": [
      "Alanqary, Arwa",
      "Alomar, Abdullah",
      "Shah, Devavrat"
    ]
  },
  {
    "id": "c3810d4a9513b028fc0f2a83cb6d7b50",
    "title": "Meta-learning to Improve Pre-training",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c3810d4a9513b028fc0f2a83cb6d7b50-Paper.pdf",
    "abstract": "Pre-training (PT) followed by fine-tuning (FT) is an effective method for training neural networks, and has led to significant performance improvements in many domains.  PT can incorporate various design choices such as task and data reweighting strategies, augmentation policies, and noise models, all of which can significantly impact the quality of representations learned. The hyperparameters introduced by these strategies therefore must be tuned appropriately. However, setting the values of these hyperparameters is challenging. Most existing methods either struggle to scale to high dimensions, are too slow and memory-intensive, or cannot be directly applied to the two-stage PT and FT learning process. In this work, we propose an efficient, gradient-based algorithm to meta-learn PT hyperparameters. We formalize the PT hyperparameter optimization problem and propose a novel method to obtain PT hyperparameter gradients by combining implicit differentiation and backpropagation through unrolled optimization. We demonstrate that our method improves predictive performance on two real-world domains. First, we optimize high-dimensional task weighting hyperparameters for multitask pre-training on protein-protein interaction graphs and improve AUROC by up to 3.9%. Second, we optimize a data augmentation neural network for self-supervised PT with SimCLR on electrocardiography data and improve AUROC by up to 1.9%.",
    "authors": [
      "Raghu, Aniruddh",
      "Lorraine, Jonathan",
      "Kornblith, Simon",
      "McDermott, Matthew",
      "Duvenaud, David K."
    ]
  },
  {
    "id": "c39b9a47811f1eaf3244a63ae8c22734",
    "title": "Fair Sparse Regression with Clustering: An Invex Relaxation for a Combinatorial Problem",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c39b9a47811f1eaf3244a63ae8c22734-Paper.pdf",
    "abstract": "In this paper, we study the problem of fair sparse regression on a biased dataset where bias depends upon a hidden binary attribute. The presence of a hidden attribute adds an extra layer of complexity to the problem by combining sparse regression and clustering with unknown binary labels. The corresponding optimization problem is combinatorial, but we propose a novel relaxation of it as an invex optimization problem. To the best of our knowledge, this is the first invex relaxation for a combinatorial problem. We show that the inclusion of the debiasing/fairness constraint in our model has no adverse effect on the performance. Rather, it enables the recovery of the hidden attribute. The support of our recovered regression parameter vector matches exactly with the true parameter vector. Moreover, we simultaneously solve the clustering problem by recovering the exact value of the hidden attribute for each sample. Our method uses carefully constructed primal dual witnesses to provide theoretical guarantees for the combinatorial problem. To that end, we show that the sample complexity of our method is logarithmic in terms of the dimension of the regression parameter vector.",
    "authors": [
      "Barik, Adarsh",
      "Honorio, Jean"
    ]
  },
  {
    "id": "c3a690be93aa602ee2dc0ccab5b7b67e",
    "title": "Probabilistic Margins for Instance Reweighting in Adversarial Training",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c3a690be93aa602ee2dc0ccab5b7b67e-Paper.pdf",
    "abstract": "Reweighting adversarial data during training has been recently shown to improve adversarial robustness, where data closer to the current decision boundaries are regarded as more critical and given larger weights. However, existing methods measuring the closeness are not very reliable: they are discrete and can take only a few values, and they are path-dependent, i.e., they may change given the same start and end points with different attack paths. In this paper, we propose three types of probabilistic margin (PM), which are continuous and path-independent, for measuring the aforementioned closeness and reweighing adversarial data. Specifically, a PM is defined as the difference between two estimated class-posterior probabilities, e.g., such a probability of the true label minus the probability of the most confusing label given some natural data. Though different PMs capture different geometric properties, all three PMs share a negative correlation with the vulnerability of data: data with larger/smaller PMs are safer/riskier and should have smaller/larger weights. Experiments demonstrated that PMs are reliable and PM-based reweighting methods outperformed state-of-the-art counterparts.",
    "authors": [
      "wang, qizhou",
      "Liu, Feng",
      "Han, Bo",
      "Liu, Tongliang",
      "Gong, Chen",
      "Niu, Gang",
      "Zhou, Mingyuan",
      "Sugiyama, Masashi"
    ]
  },
  {
    "id": "c3c617a9b80b3ae1ebd868b0017cc349",
    "title": "Unbalanced Optimal Transport through Non-negative Penalized Linear Regression",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c3c617a9b80b3ae1ebd868b0017cc349-Paper.pdf",
    "abstract": "This paper addresses the problem of Unbalanced Optimal Transport (UOT) in which the marginal conditions are relaxed (using weighted penalties in lieu of equality) and no additional regularization is enforced on the OT plan. In this context, we show that the corresponding optimization problem can be reformulated as a non-negative penalized linear regression problem. This reformulation allows us to propose novel algorithms inspired from inverse problems and nonnegative matrix factorization. In particular, we consider majorization-minimization which leads in our setting to efficient multiplicative updates for a variety of penalties. Furthermore, we derive for the first time an efficient algorithm to compute the regularization path of UOT with quadratic penalties. The proposed algorithm provides a continuity of piece-wise linear OT plans converging to the solution of balanced OT (corresponding to infinite penalty weights). We perform several numerical experiments on simulated and real data illustrating the new algorithms, and provide a detailed discussion about more sophisticated optimization tools that can further be used to solve OT problems thanks to our reformulation. ",
    "authors": [
      "Chapel, Laetitia",
      "Flamary, R\u00e9mi",
      "Wu, Haoran",
      "F\u00e9votte, C\u00e9dric",
      "Gasso, Gilles"
    ]
  },
  {
    "id": "c3e0c62ee91db8dc7382bde7419bb573",
    "title": "The Difficulty of Passive Learning in Deep Reinforcement Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c3e0c62ee91db8dc7382bde7419bb573-Paper.pdf",
    "abstract": "Learning to act from observational data without active environmental interaction is a well-known challenge in Reinforcement Learning (RL). Recent approaches involve constraints on the learned policy or conservative updates, preventing strong deviations from the state-action distribution of the dataset. Although these methods are evaluated using non-linear function approximation, theoretical justifications are mostly limited to the tabular or linear cases. Given the impressive results of deep reinforcement learning, we argue for a need to more clearly understand the challenges in this setting.In the vein of Held & Hein's classic 1963 experiment, we propose the \"tandem learning\" experimental paradigm which facilitates our empirical analysis of the difficulties in offline reinforcement learning. We identify function approximation in conjunction with fixed data distributions as the strongest factors, thereby extending but also challenging hypotheses stated in past work. Our results provide relevant insights for offline deep reinforcement learning, while also shedding new light on phenomena observed in the online case of learning control.",
    "authors": [
      "Ostrovski, Georg",
      "Castro, Pablo Samuel",
      "Dabney, Will"
    ]
  },
  {
    "id": "c404a5adbf90e09631678b13b05d9d7a",
    "title": "Intriguing Properties of Vision Transformers",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c404a5adbf90e09631678b13b05d9d7a-Paper.pdf",
    "abstract": "Vision transformers (ViT) have demonstrated impressive performance across numerous machine vision tasks. These models are based on multi-head self-attention mechanisms that can flexibly attend to a sequence of image patches to encode contextual cues. An important question is how such flexibility (in attending image-wide context conditioned on a given patch) can facilitate handling nuisances in natural images e.g., severe occlusions, domain shifts, spatial permutations, adversarial and natural perturbations. We systematically study this question via an extensive set of experiments encompassing three ViT families and provide comparisons with a high-performing convolutional neural network (CNN). We show and analyze the following intriguing properties of ViT: (a)Transformers are highly robust to severe occlusions, perturbations and domain shifts, e.g., retain as high as 60% top-1 accuracy on ImageNet even after randomly occluding 80% of the image content. (b)The robustness towards occlusions is not due to texture bias, instead we show that ViTs are significantly less biased towards local textures, compared to CNNs. When properly trained to encode shape-based features, ViTs demonstrate shape recognition capability comparable to that of human visual system, previously unmatched in the literature. (c)Using ViTs to encode shape representation leads to an interesting consequence of accurate semantic segmentation without pixel-level supervision. (d)Off-the-shelf features from a single ViT model can be combined to create a feature ensemble,  leading to high accuracy rates across a range of classification datasets in both traditional and few-shot learning paradigms.  We show effective features of ViTs are due to flexible and dynamic receptive fields possible via self-attention mechanisms. Our code will be publicly released.",
    "authors": [
      "Naseer, Muhammad Muzammal",
      "Ranasinghe, Kanchana",
      "Khan, Salman H",
      "Hayat, Munawar",
      "Shahbaz Khan, Fahad",
      "Yang, Ming-Hsuan"
    ]
  },
  {
    "id": "c429429bf1f2af051f2021dc92a8ebea",
    "title": "PartialFed: Cross-Domain Personalized Federated Learning via Partial Initialization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c429429bf1f2af051f2021dc92a8ebea-Paper.pdf",
    "abstract": "The burst of applications empowered by massive data have aroused unprecedented privacy concerns in AI society. Currently, data confidentiality protection has been one core issue during deep model training. Federated Learning (FL), which enables privacy-preserving training across multiple silos, gained rising popularity for its parameter-only communication. However, previous works have shown that FL revealed a significant performance drop if the data distributions are heterogeneous among different clients, especially when the clients have cross-domain characteristic, such as traffic, aerial and in-door. To address this challenging problem, we propose a novel idea, PartialFed, which loads a subset of the global model\u2019s parameters rather than loading the entire model used in most previous works. We first validate our algorithm with manually decided loading strategies inspired by various expert priors, named PartialFed-Fix. Then we develop PartialFed-Adaptive, which automatically selects personalized loading strategy for each client. The superiority of our algorithm is proved by demonstrating the new state-of-the-art results on cross-domain federated classification and detection. In particular, solely by initializing a small fraction of layers locally, we improve the performance of FedAvg on Office-Home and UODB by 4.88% and 2.65%, respectively. Further studies show that the adaptive strategy performs significantly better on domains with large deviation, e.g. improves AP50 by 4.03% and 4.89% on aerial and medical image detection compared to FedAvg. ",
    "authors": [
      "Sun, Benyuan",
      "Huo, Hongxing",
      "YANG, YI",
      "Bai, Bo"
    ]
  },
  {
    "id": "c42af2fa7356818e0389593714f59b52",
    "title": "Adaptive Diffusion in Graph Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c42af2fa7356818e0389593714f59b52-Paper.pdf",
    "abstract": "The success of graph neural networks (GNNs) largely relies on the process of aggregating information from neighbors defined by the input graph structures. Notably, message passing based GNNs, e.g., graph convolutional networks, leverage the immediate neighbors of each node during the aggregation process, and recently, graph diffusion convolution (GDC) is proposed to expand the propagation neighborhood by leveraging generalized graph diffusion. However, the neighborhood size in GDC is manually tuned for each graph by conducting grid search over the validation set, making its generalization practically limited. To address this issue, we propose the adaptive diffusion convolution (ADC) strategy to automatically learn the optimal neighborhood size from the data. Furthermore, we break the conventional assumption that all GNN layers and feature channels (dimensions) should use the same neighborhood for propagation. We design strategies to enable ADC to learn a dedicated propagation neighborhood for each GNN layer and each feature channel, making the GNN architecture fully coupled with graph structures---the unique property that differs GNNs from traditional neural networks. By directly plugging ADC into existing GNNs, we observe consistent and significant outperformance over both GDC and their vanilla versions across various datasets, demonstrating the improved model capacity brought by automatically learning unique neighborhood size per layer and per channel in GNNs. ",
    "authors": [
      "Zhao, Jialin",
      "Dong, Yuxiao",
      "Ding, Ming",
      "Kharlamov, Evgeny",
      "Tang, Jie"
    ]
  },
  {
    "id": "c44bebb973e14fe539676e0e9155b121",
    "title": "Recurrent Submodular Welfare and Matroid Blocking Semi-Bandits",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c44bebb973e14fe539676e0e9155b121-Paper.pdf",
    "abstract": "A recent line of research focuses on the study of stochastic multi-armed bandits (MAB), in the case where temporal correlations of specific structure are imposed between the player's actions and the reward distributions of the arms. These correlations lead to (sub-)optimal solutions that exhibit interesting dynamical patterns -- a phenomenon that yields new challenges both from an algorithmic as well as a learning perspective. In this work, we extend the above direction to a combinatorial semi-bandit setting and study a variant of stochastic MAB, where arms are subject to matroid constraints and each arm becomes unavailable (blocked) for a fixed number of rounds after each play. A natural common generalization of the state-of-the-art for blocking bandits, and that for matroid bandits, only guarantees a $\\frac{1}{2}$-approximation for general matroids. In this paper we develop the novel technique of correlated (interleaved) scheduling, which allows us to obtain a polynomial-time $(1 - \\frac{1}{e})$-approximation algorithm (asymptotically and in expectation) for any matroid. Along the way, we discover an interesting connection to a variant of Submodular Welfare Maximization, for which we provide (asymptotically) matching upper and lower approximability bounds. In the case where the mean arm rewards are unknown, our technique naturally decouples the scheduling from the learning problem, and thus allows to control the $(1-\\frac{1}{e})$-approximate regret of a UCB-based adaptation of our online algorithm.",
    "authors": [
      "Papadigenopoulos, Orestis",
      "Caramanis, Constantine"
    ]
  },
  {
    "id": "c460dc0f18fc309ac07306a4a55d2fd6",
    "title": "Representer Point Selection via Local Jacobian Expansion for Post-hoc Classifier Explanation of Deep Neural Networks and Ensemble Models",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c460dc0f18fc309ac07306a4a55d2fd6-Paper.pdf",
    "abstract": "Explaining the influence of training data on deep neural network predictions is a critical tool for debugging models through data curation.  A recent tractable and appealing approach for this task was provided via the concept of Representer Point Selection (RPS), i.e. a method the leverages the dual form of $l_2$ regularized optimization in the last layer of the neural network to identify the contribution of training points to the prediction.  However, two key drawbacks of RPS are that they (i) lead to disagreement between the originally trained network and the RP regularized network modification and (ii) often yield a static ranking of training data for the same class, independent of the data being classified.  Inspired by the RPS approach, we propose an alternative method based on a local Jacobian Taylor expansion (LJE) of the Jacobian.We empirically compared RPS-LJE with the original RPS-$l_2$ on image classification (with ResNet), text classification recurrent neural networks (with Bi-LSTM), and tabular classification (with XGBoost) tasks.Quantitatively, we show that RPS-LJE slightly outperforms RPS-$l_2$ and other state-of-the-art data explanation methods by up to 3\\% on a data debugging task.  Qualitatively, we observe that RPS-LJE provides individualized explanations for each test data point rather than the class-specific static ranking of points in the original approach.  Overall, RPS-LJE represents a novel approach to RPS that provides a  powerful tool for data-oriented explanation and debugging.",
    "authors": [
      "Sui, Yi",
      "Wu, Ga",
      "Sanner, Scott"
    ]
  },
  {
    "id": "c46489a2d5a9a9ecfc53b17610926ddd",
    "title": "Editing a classifier by rewriting its prediction rules",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c46489a2d5a9a9ecfc53b17610926ddd-Paper.pdf",
    "abstract": "We propose a methodology for modifying the behavior of a classifier by directly rewriting its prediction rules. Our method requires virtually no additional data collection and can be applied to a variety of settings, including adapting a model to new environments, and modifying it to ignore spurious features.",
    "authors": [
      "Santurkar, Shibani",
      "Tsipras, Dimitris",
      "Elango, Mahalaxmi",
      "Bau, David",
      "Torralba, Antonio",
      "Madry, Aleksander"
    ]
  },
  {
    "id": "c467978aaae44a0e8054e174bc0da4bb",
    "title": "How Modular should Neural Module Networks Be for Systematic Generalization?",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c467978aaae44a0e8054e174bc0da4bb-Paper.pdf",
    "abstract": "Neural Module Networks (NMNs) aim at Visual Question Answering (VQA) via composition of modules that tackle a sub-task. NMNs are a promising strategy to achieve systematic generalization, i.e., overcoming biasing factors in the training distribution. However, the aspects of NMNs that facilitate systematic generalization are not fully understood. In this paper, we demonstrate that the degree of modularity of the NMN have large influence on systematic generalization. In a series of experiments on three VQA datasets (VQA-MNIST, SQOOP, and CLEVR-CoGenT), our results reveal that tuning the degree of modularity, especially at the image encoder stage, reaches substantially higher systematic generalization. These findings lead to new NMN architectures that outperform previous ones in terms of systematic generalization.",
    "authors": [
      "D'Amario, Vanessa",
      "Sasaki, Tomotake",
      "Boix, Xavier"
    ]
  },
  {
    "id": "c47e93742387750baba2e238558fa12d",
    "title": "Contrast and Mix: Temporal Contrastive Video Domain Adaptation with Background Mixing",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c47e93742387750baba2e238558fa12d-Paper.pdf",
    "abstract": "Unsupervised domain adaptation which aims to adapt models trained on a labeled source domain to a completely unlabeled target domain has attracted much attention in recent years. While many domain adaptation techniques have been proposed for images, the problem of unsupervised domain adaptation in videos remains largely underexplored. In this paper, we introduce Contrast and Mix (CoMix), a new contrastive learning framework that aims to learn discriminative invariant feature representations for unsupervised video domain adaptation. First, unlike existing methods that rely on adversarial learning for feature alignment, we utilize temporal contrastive learning to bridge the domain gap by maximizing the similarity between encoded representations of an unlabeled video at two different speeds as well as minimizing the similarity between different videos played at different speeds. Second, we propose a novel extension to the temporal contrastive loss by using background mixing that allows additional positives per anchor, thus adapting contrastive learning to leverage action semantics shared across both domains. Moreover, we also integrate a supervised contrastive learning objective using target pseudo-labels to enhance discriminability of the latent space for video domain adaptation. Extensive experiments on several benchmark datasets demonstrate the superiority of our proposed approach over state-of-the-art methods. Project page: https://cvir.github.io/projects/comix.",
    "authors": [
      "Sahoo, Aadarsh",
      "Shah, Rutav",
      "Panda, Rameswar",
      "Saenko, Kate",
      "Das, Abir"
    ]
  },
  {
    "id": "c4b8bb990423f770dd7f26ff79168416",
    "title": "The Flip Side of the Reweighted Coin: Duality of Adaptive Dropout and Regularization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c4b8bb990423f770dd7f26ff79168416-Paper.pdf",
    "abstract": "Among the most successful methods for sparsifying deep (neural) networks are those that adaptively mask the network weights throughout training. By examining this masking, or dropout, in the linear case, we uncover a duality between such adaptive methods and regularization through the so-called \u201c\u03b7-trick\u201d that casts both as iteratively reweighted optimizations. We show that any dropout strategy that adapts to the weights in a monotonic way corresponds to an effective subquadratic regularization penalty, and therefore leads to sparse solutions. We obtain the effective penalties for several popular sparsification strategies, which are remarkably similar to classical penalties commonly used in sparse optimization. Considering variational dropout as a case study, we demonstrate similar empirical behavior between the adaptive dropout method and classical methods on the task of deep network sparsification, validating our theory.",
    "authors": [
      "LeJeune, Daniel",
      "Javadi, Hamid",
      "Baraniuk, Richard"
    ]
  },
  {
    "id": "c4bf1e24f3e6f92ca9dfd9a7a1a1049c",
    "title": "Active Learning of Convex Halfspaces on Graphs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c4bf1e24f3e6f92ca9dfd9a7a1a1049c-Paper.pdf",
    "abstract": "We systematically study the query complexity of learning geodesically convex halfspaces on graphs. Geodesic convexity is a natural generalisation of Euclidean convexity and allows the definition of convex sets and halfspaces on graphs. We prove an upper bound on the query complexity linear in the treewidth and the minimum hull set size but only logarithmic in the diameter. We show tight lower bounds along well-established separation axioms and identify the Radon number as a central parameter of the query complexity and the VC dimension. While previous bounds typically depend on the cut size of the labelling, all parameters in our bounds can be computed from the unlabelled graph. We provide evidence that ground-truth communities in real-world graphs are often convex and empirically compare our proposed approach with other active learning algorithms.",
    "authors": [
      "Thiessen, Maximilian",
      "Gaertner, Thomas"
    ]
  },
  {
    "id": "c4ca4238a0b923820dcc509a6f75849b",
    "title": "Differentiable Spike: Rethinking Gradient-Descent for Training Spiking Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c4ca4238a0b923820dcc509a6f75849b-Paper.pdf",
    "abstract": "Spiking Neural Networks (SNNs) have emerged as a biology-inspired method mimicking the spiking nature of brain neurons. This bio-mimicry derives SNNs' energy efficiency of inference on neuromorphic hardware. However, it also causes an intrinsic disadvantage in training high-performing SNNs from scratch since the discrete spike prohibits the gradient calculation. To overcome this issue, the surrogate gradient (SG) approach has been proposed as a continuous relaxation. Yet the heuristic choice of SG leaves it vacant how the SG benefits the SNN training. In this work, we first theoretically study the gradient descent problem in SNN training and introduce finite difference gradient to quantitatively analyze the training behavior of SNN. Based on the introduced finite difference gradient, we propose a new family of Differentiable Spike (Dspike) functions that can adaptively evolve during training to find the optimal shape and smoothness for gradient estimation. Extensive experiments over several popular network structures show that training SNN with Dspike consistently outperforms the state-of-the-art training methods. For example, on the CIFAR10-DVS classification task, we can train a spiking ResNet-18 and achieve 75.4% top-1 accuracy with 10 time steps. ",
    "authors": [
      "Li, Yuhang",
      "Guo, Yufei",
      "Zhang, Shanghang",
      "Deng, Shikuang",
      "Hai, Yongqing",
      "Gu, Shi"
    ]
  },
  {
    "id": "c4d2ce3f3ebb5393a77c33c0cd95dc93",
    "title": "Probabilistic Entity Representation Model for Reasoning over Knowledge Graphs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c4d2ce3f3ebb5393a77c33c0cd95dc93-Paper.pdf",
    "abstract": "Logical reasoning over Knowledge Graphs (KGs) is a fundamental technique that can provide an efficient querying mechanism over large and incomplete databases. Current approaches employ spatial geometries such as boxes to learn query representations that encompass the answer entities and model the logical operations of projection and intersection. However, their geometry is restrictive and leads to non-smooth strict boundaries, which further results in ambiguous answer entities. Furthermore, previous works propose transformation tricks to handle unions which results in non-closure and, thus, cannot be chained in a stream. In this paper, we propose a Probabilistic Entity Representation Model (PERM) to encode entities as a Multivariate Gaussian density with mean and covariance parameters to capture its semantic position and smooth decision boundary, respectively. Additionally, we also define the closed logical operations of projection, intersection, and union that can be aggregated using an end-to-end objective function. On the logical query reasoning problem, we demonstrate that the proposed PERM significantly outperforms the state-of-the-art methods on various public benchmark KG datasets on standard evaluation metrics. We also evaluate PERM\u2019s competence on a COVID-19 drug-repurposing case study and show that our proposed work is able to recommend drugs with substantially better F1 than current methods. Finally, we demonstrate the working of our PERM\u2019s query answering process through a low-dimensional visualization of the Gaussian representations.",
    "authors": [
      "Choudhary, Nurendra",
      "Rao, Nikhil",
      "Katariya, Sumeet",
      "Subbian, Karthik",
      "Reddy, Chandan"
    ]
  },
  {
    "id": "c4de8ced6214345614d33fb0b16a8acd",
    "title": "Black Box Probabilistic Numerics",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c4de8ced6214345614d33fb0b16a8acd-Paper.pdf",
    "abstract": "Probabilistic numerics casts numerical tasks, such the numerical solution of differential equations, as inference problems to be solved. One approach is to model the unknown quantity of interest as a random variable, and to constrain this variable using data generated during the course of a traditional numerical method. However, data may be nonlinearly related to the quantity of interest, rendering the proper conditioning of random variables difficult and limiting the range of numerical tasks that can be addressed. Instead, this paper proposes to construct probabilistic numerical methods based only on the final output from a traditional method. A convergent sequence of approximations to the quantity of interest constitute a dataset, from which the limiting quantity of interest can be extrapolated, in a probabilistic analogue of Richardson\u2019s deferred approach to the limit. This black box approach (1) massively expands the range of tasks to which probabilistic numerics can be applied, (2) inherits the features and performance of state-of-the-art numerical methods, and (3) enables provably higher orders of convergence to be achieved. Applications are presented for nonlinear ordinary and partial differential equations, as well as for eigenvalue problems\u2014a setting for which no probabilistic numerical methods have yet been developed.",
    "authors": [
      "Teymur, Onur",
      "Foley, Christopher",
      "Breen, Philip",
      "Karvonen, Toni",
      "Oates, Chris J."
    ]
  },
  {
    "id": "c4f2c88e16a579900657c18726641c81",
    "title": "Interpolation can hurt robust generalization even when there is no noise",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c4f2c88e16a579900657c18726641c81-Paper.pdf",
    "abstract": "Numerous recent works show that overparameterization implicitly reduces variance for min-norm interpolators and max-margin classifiers. These findings suggest that ridge regularization has vanishing benefits in high dimensions.  We challenge this narrative by showing that, even in the absence of noise, avoiding interpolation through ridge regularization can significantly improve generalization.  We prove this phenomenon for the robust risk of both linear regression and classification, and hence provide the first theoretical result on \\emph{robust overfitting}.",
    "authors": [
      "Donhauser, Konstantin",
      "Tifrea, Alexandru",
      "Aerni, Michael",
      "Heckel, Reinhard",
      "Yang, Fanny"
    ]
  },
  {
    "id": "c559da2ba967eb820766939a658022c8",
    "title": "On the Equivalence between Neural Network and Support Vector Machine",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c559da2ba967eb820766939a658022c8-Paper.pdf",
    "abstract": "Recent research shows that the dynamics of an infinitely wide neural network (NN) trained by gradient descent can be characterized by Neural Tangent Kernel (NTK) \\citep{jacot2018neural}. Under the squared loss, the infinite-width NN trained by gradient descent with an infinitely small learning rate is equivalent to kernel regression with NTK \\citep{arora2019exact}. However, the equivalence is only known for ridge regression currently \\citep{arora2019harnessing}, while the equivalence between NN and other kernel machines (KMs), e.g. support vector machine (SVM), remains unknown. Therefore, in this work, we propose to establish the equivalence between NN and SVM, and specifically, the infinitely wide NN trained by soft margin loss and the standard soft margin SVM with NTK trained by subgradient descent. Our main theoretical results include establishing the equivalence between NN and a broad family of $\\ell_2$ regularized KMs with finite-width bounds, which cannot be handled by prior work, and showing that every finite-width NN trained by such regularized loss functions is approximately a KM. Furthermore, we demonstrate our theory can enable three practical applications, including (i) \\textit{non-vacuous} generalization bound of NN via the corresponding KM; (ii) \\textit{nontrivial} robustness certificate for the infinite-width NN (while existing robustness verification methods would provide vacuous bounds); (iii) intrinsically more robust infinite-width NNs than those from previous kernel regression.",
    "authors": [
      "Chen, Yilan",
      "Huang, Wei",
      "Nguyen, Lam",
      "Weng, Tsui-Wei"
    ]
  },
  {
    "id": "c5aa65949d20f6b20e1a922c13d974e7",
    "title": "Learning Semantic Representations to Verify Hardware Designs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c5aa65949d20f6b20e1a922c13d974e7-Paper.pdf",
    "abstract": "Verification is a serious bottleneck in the industrial hardware design cycle, routinely requiring person-years of effort. Practical verification relies on a \"best effort\" process that simulates the design on test inputs. This suggests a new research question: Can this simulation data be exploited to learn a continuous representation of a hardware design that allows us to predict its functionality? As a first approach to this new problem, we introduce Design2Vec, a deep architecture that learns semantic abstractions of hardware designs. The key idea is to work at a higher level of abstraction than the gate or the bit level, namely the Register Transfer Level (RTL), which is somewhat analogous to software source code, and can be represented by a graph that incorporates control and data flow. This allows us to learn representations of RTL syntax and semantics using a graph neural network. We apply these representations to several tasks within verification, including predicting what cover points of the design will be exercised by a test, and generating new tests that will exercise desired cover points. We evaluate Design2Vec on three real-world hardware designs, including an industrial chip used in commercial data centers. Our results demonstrate that Design2Vec dramatically outperforms baseline approaches that do not incorporate the RTL semantics, scales to industrial designs, and can generate tests that exercise design points that are currently hard to cover with manually written tests by design verification experts.",
    "authors": [
      "Vasudevan, Shobha",
      "Jiang, Wenjie (Joe)",
      "Bieber, David",
      "Singh, Rishabh",
      "shojaei, hamid",
      "Ho, C. Richard",
      "Sutton, Charles"
    ]
  },
  {
    "id": "c5ab6cebaca97f7171139e4d414ff5a6",
    "title": "Rebooting ACGAN: Auxiliary Classifier GANs with Stable Training",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c5ab6cebaca97f7171139e4d414ff5a6-Paper.pdf",
    "abstract": "Conditional Generative Adversarial Networks (cGAN) generate realistic images by incorporating class information into GAN. While one of the most popular cGANs is an auxiliary classifier GAN with softmax cross-entropy loss (ACGAN), it is widely known that training ACGAN is challenging as the number of classes in the dataset increases. ACGAN also tends to generate easily classifiable samples with a lack of diversity. In this paper, we introduce two cures for ACGAN. First, we identify that gradient exploding in the classifier can cause an undesirable collapse in early training, and projecting input vectors onto a unit hypersphere can resolve the problem. Second, we propose the Data-to-Data Cross-Entropy loss (D2D-CE) to exploit relational information in the class-labeled dataset. On this foundation, we propose the Rebooted Auxiliary Classifier Generative Adversarial Network (ReACGAN). The experimental results show that ReACGAN achieves state-of-the-art generation results on CIFAR10, Tiny-ImageNet, CUB200, and ImageNet datasets. We also verify that ReACGAN benefits from differentiable augmentations and that D2D-CE harmonizes with StyleGAN2 architecture. Model weights and a software package that provides implementations of representative cGANs and all experiments in our paper are available at https://github.com/POSTECH-CVLab/PyTorch-StudioGAN.",
    "authors": [
      "Kang, Minguk",
      "Shim, Woohyeon",
      "Cho, Minsu",
      "Park, Jaesik"
    ]
  },
  {
    "id": "c5c1cb0bebd56ae38817b251ad72bedb",
    "title": "Towards a Theoretical Framework of Out-of-Distribution Generalization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c5c1cb0bebd56ae38817b251ad72bedb-Paper.pdf",
    "abstract": "Generalization to out-of-distribution (OOD) data is one of the central problems in modern machine learning. Recently, there is a surge of attempts to propose algorithms that mainly build upon the idea of extracting invariant features. Although intuitively reasonable, theoretical understanding of what kind of invariance can guarantee OOD generalization is still limited, and generalization to arbitrary out-of-distribution is clearly impossible. In this work, we take the first step towards rigorous and quantitative definitions of 1) what is OOD; and 2) what does it mean by saying an OOD problem is learnable. We also introduce a new concept of expansion function, which characterizes to what extent the variance is amplified in the test domains over the training domains, and therefore give a quantitative meaning of invariant features. Based on these, we prove an OOD generalization error bound. It turns out that OOD generalization largely depends on the expansion function. As recently pointed out by Gulrajani & Lopez-Paz (2020), any OOD learning algorithm without a model selection module is incomplete. Our theory naturally induces a model selection criterion. Extensive experiments on benchmark OOD datasets demonstrate that our model selection criterion has a significant advantage over baselines.",
    "authors": [
      "Ye, Haotian",
      "Xie, Chuanlong",
      "Cai, Tianle",
      "Li, Ruichen",
      "Li, Zhenguo",
      "Wang, Liwei"
    ]
  },
  {
    "id": "c5c3d4fe6b2cc463c7d7ecba17cc9de7",
    "title": "Slice Sampling Reparameterization Gradients",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c5c3d4fe6b2cc463c7d7ecba17cc9de7-Paper.pdf",
    "abstract": "Many probabilistic modeling problems in machine learning use gradient-based optimization in which the objective takes the form of an expectation. These problems can be challenging when the parameters to be optimized determine the probability distribution under which the expectation is being taken, as the na\\\"ive Monte Carlo procedure is not differentiable. Reparameterization gradients make it possible to efficiently perform optimization of these Monte Carlo objectives by transforming the expectation to be differentiable, but the approach is typically limited to distributions with simple forms and tractable normalization constants. Here we describe how to differentiate samples from slice sampling to compute \\textit{slice sampling reparameterization gradients}, enabling a richer class of Monte Carlo objective functions to be optimized. Slice sampling is a Markov chain Monte Carlo algorithm for simulating samples from probability distributions; it only requires a density function that can be evaluated point-wise up to a normalization constant, making it applicable to a variety of inference problems and unnormalized models. Our approach is based on the observation that when the slice endpoints are known, the sampling path is a deterministic and differentiable function of the pseudo-random variables, since the algorithm is rejection-free. We evaluate the method on synthetic examples and apply it to a variety of applications with reparameterization of unnormalized probability distributions. ",
    "authors": [
      "Zoltowski, David",
      "Cai, Diana",
      "Adams, Ryan P."
    ]
  },
  {
    "id": "c5d215777c229704a7862de577d40a73",
    "title": "Multi-Label Learning with Pairwise Relevance Ordering",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c5d215777c229704a7862de577d40a73-Paper.pdf",
    "abstract": "Precisely annotating objects with multiple labels is costly and has become a critical bottleneck in real-world multi-label classification tasks. Instead, deciding the relative order of label pairs is obviously less laborious than collecting exact labels. However, the supervised information of pairwise relevance ordering is less informative than exact labels. It is thus an important challenge to effectively learn with such weak supervision. In this paper, we formalize this problem as a novel learning framework, called multi-label learning with pairwise relevance ordering (PRO). We show that the unbiased estimator of classification risk can be derived with a cost-sensitive loss only from PRO examples. Theoretically, we provide the estimation error bound for the proposed estimator and further prove that it is consistent with respective to the commonly used ranking loss. Empirical studies on multiple datasets and metrics validate the effectiveness of the proposed method.",
    "authors": [
      "Xie, Ming-Kun",
      "Huang, Sheng-Jun"
    ]
  },
  {
    "id": "c61aed648da48aa3893fb3eaadd88a7f",
    "title": "Sampling  with Trusthworthy Constraints:  A Variational Gradient Framework   ",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c61aed648da48aa3893fb3eaadd88a7f-Paper.pdf",
    "abstract": "Sampling-based inference and learning techniques, especially Bayesian inference, provide an essential approach to handling uncertainty in machine learning (ML). As these techniques are increasingly used in daily life, it becomes essential to safeguard the ML systems with various trustworthy-related constraints, such as fairness, safety, interpretability. Mathematically, enforcing these constraints in probabilistic inference can be cast into sampling from intractable distributions subject to general nonlinear constraints, for which practical efficient algorithms are still largely missing. In this work, we propose a family of constrained sampling algorithms which generalize Langevin Dynamics (LD) and Stein Variational Gradient Descent (SVGD) to incorporate a moment constraint specified by a general nonlinear function. By exploiting the gradient flow structure of LD and SVGD, we derive two types of algorithms for handling constraints, including a primal-dual gradient approach and the constraint controlled gradient descent approach. We investigate the continuous-time mean-field limit of these algorithms and show that they have O(1/t) convergence under mild conditions. Moreover, the LD variant converges linearly assuming that a log Sobolev like inequality holds. Various numerical experiments are conducted to demonstrate the efficiency of our algorithms in trustworthy settings.",
    "authors": [
      "Liu, Xingchao",
      "Tong, Xin",
      "Liu, Qiang"
    ]
  },
  {
    "id": "c622c085c04eadc473f08541b255320e",
    "title": "Robust and Decomposable Average Precision for Image Retrieval",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c622c085c04eadc473f08541b255320e-Paper.pdf",
    "abstract": "In image retrieval, standard evaluation metrics rely on score ranking, e.g. average precision (AP). In this paper, we introduce a method for robust and decomposable average precision (ROADMAP) addressing two major challenges for end-to-end training of deep neural networks with AP: non-differentiability and non-decomposability.Firstly, we propose a new differentiable approximation of the rank function, which provides an upper bound of the AP loss and ensures robust training. Secondly, we design a simple yet effective loss function to reduce the decomposability gap between the AP in the whole training set and its averaged batch approximation, for which we provide theoretical guarantees.Extensive experiments conducted on three image retrieval datasets show that ROADMAP outperforms several recent AP approximation methods and highlight the importance of our two contributions. Finally, using ROADMAP for training deep models yields very good performances, outperforming state-of-the-art results on the three datasets.Code and instructions to reproduce our results will be made publicly available at https://github.com/elias-ramzi/ROADMAP.",
    "authors": [
      "Ramzi, Elias",
      "THOME, Nicolas",
      "Rambour, Cl\u00e9ment",
      "Audebert, Nicolas",
      "Bitot, Xavier"
    ]
  },
  {
    "id": "c688defd45ad6638febd469adb09ddf7",
    "title": "Fast rates for prediction with limited expert advice",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c688defd45ad6638febd469adb09ddf7-Paper.pdf",
    "abstract": "We investigate the problem of minimizing the excess generalization error with respect to the best expert prediction in a finite family in the stochastic setting,  under limited access to information. We consider that the learner has only access to a limited number of expert advices per training round, as well as for prediction. Assuming that the loss function is Lipschitz and strongly convex, we show that if we are allowed to see the advice of only one expert per round in the training phase, or to use the advice of only one expert for prediction in the test phase, the worst-case excess risk is ${\\Omega}(1/\\sqrt{T})$ with probability lower bounded by a constant. However, if we are allowed to see at least two actively chosen expert advices per training round and use at least two experts for prediction, the fast rate $\\mathcal{O}(1/T)$ can be achieved. We design novel algorithms achieving this rate in this setting, and in the setting where the learner have a budget constraint on the total number of observed experts advices,  and give precise instance-dependent bounds on the number of training rounds needed to achieve a given generalization error precision.",
    "authors": [
      "Saad, El Mehdi",
      "Blanchard, Gilles"
    ]
  },
  {
    "id": "c68bd9055776bf38d8fc43c0ed283678",
    "title": "Probabilistic Transformer For Time Series Analysis",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c68bd9055776bf38d8fc43c0ed283678-Paper.pdf",
    "abstract": "Generative modeling of multivariate time series has remained challenging partly due to the complex, non-deterministic dynamics across long-distance timesteps. In this paper, we propose deep probabilistic methods that combine state-space models (SSMs) with transformer architectures. In contrast to previously proposed SSMs, our approaches use attention mechanism to model non-Markovian dynamics in the latent space and avoid recurrent neural networks entirely. We also extend our models to include several layers of stochastic variables organized in a hierarchy for further expressiveness. Compared to transformer models, ours are probabilistic, non-autoregressive, and capable of generating diverse long-term forecasts with uncertainty estimates. Extensive experiments show that our models consistently outperform competitive baselines on various tasks and datasets, including time series forecasting and human motion prediction.",
    "authors": [
      "Tang, Binh",
      "Matteson, David S"
    ]
  },
  {
    "id": "c6a01432c8138d46ba39957a8250e027",
    "title": "A Hierarchical Reinforcement Learning Based Optimization Framework for Large-scale Dynamic Pickup and Delivery Problems",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c6a01432c8138d46ba39957a8250e027-Paper.pdf",
    "abstract": "The Dynamic Pickup and Delivery Problem (DPDP) is an essential problem in the logistics domain, which is NP-hard. The objective is to dynamically schedule vehicles among multiple sites to serve the online generated orders such that the overall transportation cost could be minimized. The critical challenge of DPDP is the orders are not known a priori, i.e., the orders are dynamically generated in real-time. To address this problem, existing methods partition the overall DPDP into fixed-size sub-problems by caching online generated orders and solve each sub-problem, or on this basis to utilize the predicted future orders to optimize each sub-problem further. However, the solution quality and efficiency of these methods are unsatisfactory, especially when the problem scale is very large. In this paper, we propose a novel hierarchical optimization framework to better solve large-scale DPDPs. Specifically, we design an upper-level agent to dynamically partition the DPDP into a series of sub-problems with different scales to optimize vehicles routes towards globally better solutions. Besides, a lower-level agent is designed to efficiently solve each sub-problem by incorporating the strengths of classical operational research-based methods with reinforcement learning-based policies. To verify the effectiveness of the proposed framework, real historical data is collected from the order dispatching system of Huawei Supply Chain Business Unit and used to build a functional simulator. Extensive offline simulation and online testing conducted on the industrial order dispatching system justify the superior performance of our framework over existing baselines.",
    "authors": [
      "Ma, Yi",
      "Hao, Xiaotian",
      "Hao, Jianye",
      "Lu, Jiawen",
      "Liu, Xing",
      "Xialiang, Tong",
      "Yuan, Mingxuan",
      "Li, Zhigang",
      "Tang, Jie",
      "Meng, Zhaopeng"
    ]
  },
  {
    "id": "c6b8c8d762da15fa8dbbdfb6baf9e260",
    "title": "Spatio-Temporal Variational Gaussian Processes",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c6b8c8d762da15fa8dbbdfb6baf9e260-Paper.pdf",
    "abstract": "We introduce a scalable approach to Gaussian process inference that combines spatio-temporal filtering with natural gradient variational inference, resulting in a non-conjugate GP method for multivariate data that scales linearly with respect to time. Our natural gradient approach enables application of parallel filtering and smoothing, further reducing the temporal span complexity to be logarithmic in the number of time steps. We derive a sparse approximation that constructs a state-space model over a reduced set of spatial inducing points, and show that for separable Markov kernels the full and sparse cases exactly recover the standard variational GP, whilst exhibiting favourable computational properties. To further improve the spatial scaling we propose a mean-field assumption of independence between spatial locations which, when coupled with sparsity and parallelisation, leads to an efficient and accurate method for large spatio-temporal problems.",
    "authors": [
      "Hamelijnck, Oliver",
      "Wilkinson, William",
      "Loppi, Niki",
      "Solin, Arno",
      "Damoulas, Theodoros"
    ]
  },
  {
    "id": "c6d4eb15f1e84a36eff58eca3627c82e",
    "title": "MERLOT: Multimodal Neural Script Knowledge Models",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c6d4eb15f1e84a36eff58eca3627c82e-Paper.pdf",
    "abstract": "As humans, we understand events in the visual world contextually, performing multimodal reasoning across time to make inferences about the past, present, and future. We introduce MERLOT, a model that learns multimodal script knowledge by watching millions of YouTube videos with transcribed speech -- in an entirely label-free, self-supervised manner. By pretraining with a mix of both frame-level (spatial) and video-level (temporal) objectives, our model not only learns to match images to temporally corresponding words, but also to contextualize what is happening globally over time. As a result, MERLOT exhibits strong out-of-the-box representations of temporal commonsense, and achieves state-of-the-art performance on 12 different video QA datasets when finetuned. It also transfers well to the world of static images, allowing models to reason about the dynamic context behind visual scenes. On Visual Commonsense Reasoning, MERLOT~answers questions correctly with 80.6\\% accuracy, outperforming state-of-the-art models of similar size by over 3\\%, even those that make heavy use of auxiliary supervised data (like object bounding boxes).Ablation analyses demonstrate the complementary importance of: 1) training on videos versus static images; 2) scaling the magnitude and diversity of the pretraining video corpus; and 3) using diverse objectives that encourage full-stack multimodal reasoning, from the recognition to cognition level.",
    "authors": [
      "Zellers, Rowan",
      "Lu, Ximing",
      "Hessel, Jack",
      "Yu, Youngjae",
      "Park, Jae Sung",
      "Cao, Jize",
      "Farhadi, Ali",
      "Choi, Yejin"
    ]
  },
  {
    "id": "c6f798b844366ccd65d99bc7f31e0e02",
    "title": "Fast Approximate Dynamic Programming for Infinite-Horizon Markov Decision Processes",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c6f798b844366ccd65d99bc7f31e0e02-Paper.pdf",
    "abstract": "In this study, we consider the infinite-horizon, discounted cost, optimal control of stochastic nonlinear systems with separable cost and constraints in the state and input variables. Using the linear-time Legendre transform, we propose a novel numerical scheme for implementation of the corresponding value iteration (VI) algorithm in the conjugate domain. Detailed analyses of the convergence, time complexity, and error of the proposed algorithm are provided. In particular, with a discretization of size $X$ and $U$ for the state and input spaces, respectively, the proposed approach reduces the time complexity of each iteration in the VI algorithm from $O(XU)$ to $O(X+U)$, by replacing the minimization operation in the primal domain with a simple addition in the conjugate domain.",
    "authors": [
      "Sharifi Kolarijani, Mohamad Amin",
      "Max, Gyula",
      "Mohajerin Esfahani, Peyman M."
    ]
  },
  {
    "id": "c705112d1ec18b97acac7e2d63973424",
    "title": "Adaptive Risk Minimization: Learning to Adapt to Domain Shift",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c705112d1ec18b97acac7e2d63973424-Paper.pdf",
    "abstract": "A fundamental assumption of most machine learning algorithms is that the training and test data are drawn from the same underlying distribution. However, this assumption is violated in almost all practical applications: machine learning systems are regularly tested under distribution shift, due to changing temporal correlations, atypical end users, or other factors. In this work, we consider the problem setting of domain generalization, where the training data are structured into domains and there may be multiple test time shifts, corresponding to new domains or domain distributions. Most prior methods aim to learn a single robust model or invariant feature space that performs well on all domains. In contrast, we aim to learn models that adapt at test time to domain shift using unlabeled test points. Our primary contribution is to introduce the framework of adaptive risk minimization (ARM), in which models are directly optimized for effective adaptation to shift by learning to adapt on the training domains. Compared to prior methods for robustness, invariance, and adaptation, ARM methods provide performance gains of 1-4% test accuracy on a number of image classification problems exhibiting domain shift.",
    "authors": [
      "Zhang, Marvin",
      "Marklund, Henrik",
      "Dhawan, Nikita",
      "Gupta, Abhishek",
      "Levine, Sergey",
      "Finn, Chelsea"
    ]
  },
  {
    "id": "c71df24045cfddab4a963d3ac9bdc9a3",
    "title": "Learning State Representations from Random Deep Action-conditional Predictions",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c71df24045cfddab4a963d3ac9bdc9a3-Paper.pdf",
    "abstract": "Our main contribution in this work is an empirical finding that random General Value Functions (GVFs), i.e., deep action-conditional predictions---random both in what feature of observations they predict as well as in the sequence of actions the predictions are conditioned upon---form good auxiliary tasks for reinforcement learning (RL) problems. In particular, we show that random deep action-conditional predictions when used as auxiliary tasks yield state representations that produce control performance competitive with state-of-the-art hand-crafted auxiliary tasks like value prediction, pixel control, and CURL in both Atari and DeepMind Lab tasks. In another set of experiments we stop the gradients from the RL part of the network to the state representation learning part of the network and show, perhaps surprisingly, that the auxiliary tasks alone are sufficient to learn state representations good enough to outperform an end-to-end trained actor-critic baseline. We opensourced our code at https://github.com/Hwhitetooth/random_gvfs.",
    "authors": [
      "Zheng, Zeyu",
      "Veeriah, Vivek",
      "Vuorio, Risto",
      "Lewis, Richard L",
      "Singh, Satinder"
    ]
  },
  {
    "id": "c74214a3877c4d8297ac96217d5189b7",
    "title": "Mixability made efficient: Fast online multiclass logistic regression",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c74214a3877c4d8297ac96217d5189b7-Paper.pdf",
    "abstract": "Mixability has been shown to be a powerful tool to obtain algorithms with optimal regret. However, the resulting methods often suffer from high computational complexity which has reduced their practical applicability. For example, in the case of multiclass logistic regression, the aggregating forecaster (see Foster et al. 2018) achieves a regret of $O(\\log(Bn))$ whereas Online Newton Step achieves $O(e^B\\log(n))$ obtaining a double exponential gain in $B$ (a bound on the norm of comparative functions). However, this high statistical performance is at the price of a prohibitive computational complexity $O(n^{37})$.In this paper, we use quadratic surrogates to make aggregating forecasters more efficient. We show that the resulting algorithm has still high statistical performance for a large class of losses. In particular, we derive an algorithm for multiclass regression with a regret bounded by $O(B\\log(n))$ and computational complexity of only $O(n^4)$.",
    "authors": [
      "J\u00e9z\u00e9quel, R\u00e9mi",
      "Gaillard, Pierre",
      "Rudi, Alessandro"
    ]
  },
  {
    "id": "c74c4bf0dad9cbae3d80faa054b7d8ca",
    "title": "Tracking People with 3D Representations",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c74c4bf0dad9cbae3d80faa054b7d8ca-Paper.pdf",
    "abstract": "We present a novel approach for tracking multiple people in video. Unlike past approaches which employ 2D representations, we focus on using 3D representations of people, located in three-dimensional space. To this end, we develop a method, Human Mesh and Appearance Recovery (HMAR) which in addition to extracting the 3D geometry of the person as a SMPL mesh, also extracts appearance as a texture map on the triangles of the mesh. This serves as a 3D representation for appearance that is robust to viewpoint and pose changes. Given a video clip, we first detect bounding boxes corresponding to people, and for each one, we extract 3D appearance, pose, and location information using HMAR. These embedding vectors are then sent to a transformer, which performs spatio-temporal aggregation of the representations over the duration of the sequence. The similarity of the resulting representations is used to solve for associations that assigns each person to a tracklet. We evaluate our approach on the Posetrack, MuPoTs and AVA datasets.  We find that 3D representations are more effective than 2D representations for tracking in these settings, and we obtain state-of-the-art performance. Code and results are available at: https://brjathu.github.io/T3DP.",
    "authors": [
      "Rajasegaran, Jathushan",
      "Pavlakos, Georgios",
      "Kanazawa, Angjoo",
      "Malik, Jitendra"
    ]
  },
  {
    "id": "c7502c55f8db540625b59d9a42638520",
    "title": "Off-Policy Risk Assessment in Contextual Bandits",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c7502c55f8db540625b59d9a42638520-Paper.pdf",
    "abstract": "Even when unable to run experiments, practitioners can evaluate prospective policies, using previously logged data. However, while the bandits literature has adopted a diverse set of objectives, most research on off-policy evaluation to date focuses on the expected reward. In this paper, we introduce Lipschitz risk functionals, a broad class of objectives that subsumes conditional value-at-risk (CVaR), variance, mean-variance, many distorted risks, and CPT risks, among others. We propose Off-Policy Risk Assessment (OPRA), a framework that first estimates a target policy's CDF and then generates plugin estimates for any collection of Lipschitz risks, providing finite sample guarantees that hold simultaneously over the entire class. We instantiate OPRA with both importance sampling and doubly robust estimators. Our primary theoretical contributions are (i) the first uniform concentration inequalities for both CDF estimators in contextual bandits and (ii) error bounds on our Lipschitz risk estimates, which all converge at a rate of $O(1/\\sqrt{n})$.",
    "authors": [
      "Huang, Audrey",
      "Leqi, Liu",
      "Lipton, Zachary",
      "Azizzadenesheli, Kamyar"
    ]
  },
  {
    "id": "c7558e9d1f956b016d1fdba7ea132378",
    "title": "Adaptive Denoising via GainTuning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c7558e9d1f956b016d1fdba7ea132378-Paper.pdf",
    "abstract": "Deep convolutional neural networks (CNNs) for image denoising are typically trained on large datasets. These models achieve the current state of the art, but they do not generalize well to data that deviate from the training distribution. Recent work has shown that it is possible to train denoisers on a single noisy image. These models adapt to the features of the test image, but their performance is limited by the small amount of information used to train them. Here we propose \"GainTuning'', a methodology by which CNN models pre-trained on large datasets can be adaptively and selectively adjusted for individual test images. To avoid overfitting, GainTuning optimizes a single multiplicative scaling parameter (the \u201cGain\u201d) of each channel in the convolutional layers of the CNN. We show that GainTuning improves state-of-the-art CNNs on standard image-denoising benchmarks, boosting their denoising performance on nearly every image in a held-out test set. These adaptive improvements are even more substantial for test images differing systematically from the training data, either in noise level or image type. We illustrate the potential of adaptive GainTuning in a scientific application to transmission-electron-microscope images, using a CNN that is pre-trained on synthetic data. In contrast to the existing methodology, GainTuning is able to faithfully reconstruct the structure of catalytic nanoparticles from these data at extremely low signal-to-noise ratios. ",
    "authors": [
      "Mohan, Sreyas",
      "Vincent, Joshua L",
      "Manzorro, Ramon",
      "Crozier, Peter",
      "Fernandez-Granda, Carlos",
      "Simoncelli, Eero"
    ]
  },
  {
    "id": "c77bfda61a0204d445185053e6a9a8fe",
    "title": "Optimal Sketching for Trace Estimation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c77bfda61a0204d445185053e6a9a8fe-Paper.pdf",
    "abstract": "Matrix trace estimation is ubiquitous in machine learning applications and has traditionally relied on Hutchinson's method, which requires $O(\\log(1/\\delta)/\\epsilon^2)$ matrix-vector product queries to achieve a $(1 \\pm \\epsilon)$-multiplicative approximation to $\\text{trace}(A)$ with failure probability $\\delta$ on positive-semidefinite input matrices $A$. Recently, the Hutch++ algorithm was proposed, which reduces the number of matrix-vector queries from $O(1/\\epsilon^2)$ to the optimal $O(1/\\epsilon)$, and the algorithm succeeds with constant probability. However, in the high probability setting, the non-adaptive Hutch++ algorithm suffers an extra $O(\\sqrt{\\log(1/\\delta)})$ multiplicative factor in its query complexity. Non-adaptive methods are important, as they correspond to sketching algorithms, which are mergeable, highly parallelizable, and provide low-memory streaming algorithms as well as low-communication distributed protocols. In this work, we close the gap between non-adaptive and adaptive algorithms, showing that even non-adaptive algorithms can achieve $O(\\sqrt{\\log(1/\\delta)}/\\epsilon + \\log(1/\\delta))$ matrix-vector products. In addition, we prove matching lower bounds demonstrating that, up to a $\\log \\log(1/\\delta)$ factor, no further improvement in the dependence on $\\delta$ or $\\epsilon$ is possible by any non-adaptive algorithm. Finally, our experiments demonstrate the superior performance of our sketch over the adaptive Hutch++ algorithm, which is less parallelizable, as well as over the non-adaptive Hutchinson's method.",
    "authors": [
      "Jiang, Shuli",
      "Pham, Hai",
      "Woodruff, David",
      "Zhang, Richard"
    ]
  },
  {
    "id": "c793b3be8f18731f2a4c627fb3c6c63d",
    "title": "Estimating Multi-cause Treatment Effects via Single-cause Perturbation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c793b3be8f18731f2a4c627fb3c6c63d-Paper.pdf",
    "abstract": "Most existing methods for conditional average treatment effect estimation are designed to estimate the effect of a single cause - only one variable can be intervened on at one time. However, many applications involve simultaneous intervention on multiple variables, which leads to multi-cause treatment effect problems. The multi-cause problem is challenging because one needs to overcome the confounding bias for a large number of treatment groups, each with a different cause combination. The combinatorial nature of the problem also leads to severe data scarcity - we only observe one factual outcome out of many potential outcomes. In this work, we propose Single-cause Perturbation (SCP), a novel two-step procedure to estimate the multi-cause treatment effect. SCP starts by augmenting the observational dataset with the estimated potential outcomes under single-cause interventions. It then performs covariate adjustment on the augmented dataset to obtain the estimator. SCP is agnostic to the exact choice of algorithm in either step. We show formally that the procedure is valid under standard assumptions in causal inference. We demonstrate the performance gain of SCP on extensive synthetic and semi-synthetic experiments.",
    "authors": [
      "Qian, Zhaozhi",
      "Curth, Alicia",
      "van der Schaar, Mihaela"
    ]
  },
  {
    "id": "c7a9f13a6c0940277d46706c7ca32601",
    "title": "Be Confident! Towards Trustworthy Graph Neural Networks via Confidence Calibration",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c7a9f13a6c0940277d46706c7ca32601-Paper.pdf",
    "abstract": "Despite Graph Neural Networks (GNNs) have achieved remarkable accuracy, whether the results are trustworthy is still unexplored. Previous studies suggest that many modern neural networks are over-confident on the predictions, however, surprisingly, we discover that GNNs are primarily in the opposite direction, i.e., GNNs are under-confident. Therefore, the confidence calibration for GNNs is highly desired. In this paper, we propose a novel trustworthy GNN model by designing a topology-aware post-hoc calibration function. Specifically, we first verify that the confidence distribution in a graph has homophily property, and this finding inspires us to design a calibration GNN model (CaGCN) to learn the calibration function. CaGCN is able to obtain a unique transformation from logits of GNNs to the calibrated confidence for each node, meanwhile, such transformation is able to preserve the order between classes, satisfying the accuracy-preserving property. Moreover, we apply the calibration GNN to self-training framework, showing that more trustworthy pseudo labels can be obtained with the calibrated confidence and further improve the performance. Extensive experiments demonstrate the effectiveness of our proposed model in terms of both calibration and accuracy.",
    "authors": [
      "Wang, Xiao",
      "Liu, Hongrui",
      "Shi, Chuan",
      "Yang, Cheng"
    ]
  },
  {
    "id": "c7b90b0fc23725f299b47c5224e6ec0d",
    "title": "Learning Riemannian metric for disease progression modeling",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c7b90b0fc23725f299b47c5224e6ec0d-Paper.pdf",
    "abstract": "Linear mixed-effect models provide a natural baseline for estimating disease progression using longitudinal data. They provide interpretable models at the cost of modeling assumptions on the progression profiles and their variability across subjects. A significant improvement is to embed the data in a Riemannian manifold and learn patient-specific trajectories distributed around a central geodesic. A few interpretable parameters characterize subject trajectories at the cost of a prior choice of the metric, which determines the shape of the trajectories. We extend this approach by learning the metric from the data allowing more flexibility while keeping the interpretability. Specifically, we learn the metric as the push-forward of the Euclidean metric by a diffeomorphism. This diffeomorphism is estimated iteratively as the composition of radial basis functions belonging to a reproducible kernel Hilbert space. The metric update allows us to improve the forecasting of imaging and clinical biomarkers in the Alzheimer\u2019s Disease Neuroimaging Initiative (ADNI) cohort. Our results compare favorably to the 56 methods benchmarked in the TADPOLE challenge.",
    "authors": [
      "Gruffaz, Samuel",
      "Poulet, Pierre-Emmanuel",
      "Maheux, Etienne",
      "Jedynak, Bruno",
      "DURRLEMAN, Stanley"
    ]
  },
  {
    "id": "c7c3e78e3c9d26cc1158a8735d548eaa",
    "title": "Bias and variance of the Bayesian-mean decoder",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c7c3e78e3c9d26cc1158a8735d548eaa-Paper.pdf",
    "abstract": "Perception, in theoretical neuroscience, has been modeled as the encoding of external stimuli into internal signals, which are then decoded. The Bayesian mean is an important decoder, as it is optimal for purposes of both estimation and discrimination. We present widely-applicable approximations to the bias and to the variance of the Bayesian mean, obtained under the minimal and biologically-relevant assumption that the encoding results from a series of independent, though not necessarily identically-distributed, signals. Simulations substantiate the accuracy of our approximations in the small-noise regime. The bias of the Bayesian mean comprises two components: one driven by the prior, and one driven by the precision of the encoding. If the encoding is 'efficient', the two components have opposite effects; their relative strengths are determined by the objective that the encoding optimizes. The experimental literature on perception reports both 'Bayesian' biases directed towards prior expectations, and opposite, 'anti-Bayesian' biases. We show that different tasks are indeed predicted to yield such contradictory biases, under a consistently-optimal encoding-decoding model. Moreover, we recover Wei and Stocker's \"law of human perception\", a relation between the bias of the Bayesian mean and the derivative of its variance, and show how the coefficient of proportionality in this law depends on the task at hand. Our results provide a parsimonious theory of optimal perception under constraints, in which encoding and decoding are adapted both to the prior and to the task faced by the observer.",
    "authors": [
      "Prat-Carrabin, Arthur",
      "Woodford, Michael"
    ]
  },
  {
    "id": "c80bcf42c220b8f5c41f85344242f1b0",
    "title": "MIRACLE: Causally-Aware Imputation via Learning Missing Data Mechanisms",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c80bcf42c220b8f5c41f85344242f1b0-Paper.pdf",
    "abstract": "Missing data is an important problem in machine learning practice. Starting from the premise that imputation methods should preserve the causal structure of the data, we develop a regularization scheme that encourages any baseline imputation method to be causally consistent with the underlying data generating mechanism. Our proposal is a causally-aware imputation algorithm (MIRACLE). MIRACLE iteratively refines the imputation of a baseline by simultaneously modeling the missingness generating mechanism, encouraging imputation to be consistent with the causal structure of the data. We conduct extensive experiments on synthetic and a variety of publicly available datasets to show that MIRACLE is able to consistently improve imputation over a variety of benchmark methods across all three missingness scenarios: at random, completely at random, and not at random.",
    "authors": [
      "Kyono, Trent",
      "Zhang, Yao",
      "Bellot, Alexis",
      "van der Schaar, Mihaela"
    ]
  },
  {
    "id": "c81e155d85dae5430a8cee6f2242e82c",
    "title": "Efficient Training of Visual Transformers with Small Datasets",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c81e155d85dae5430a8cee6f2242e82c-Paper.pdf",
    "abstract": "Visual Transformers (VTs) are emerging as an architectural paradigm alternative to Convolutional networks (CNNs). Differently from CNNs, VTs can capture global relations between image elements and they potentially have a larger representation capacity. However, the lack of the typical convolutional inductive bias makes these models more data hungry than common CNNs. In fact, some local properties of the visual domain which are embedded in the CNN architectural design, in VTs should be learned from samples. In this paper, we empirically analyse different VTs, comparing their robustness in a small training set regime, and we show that, despite having a comparable accuracy when trained on ImageNet, their performance on smaller datasets can be largely different. Moreover, we propose an auxiliary self-supervised task which can extract additional information from images with only a negligible computational overhead. This task encourages the VTs to learn  spatial relations within an image and makes the VT training much more robust when training data is scarce. Our task is used jointly with the standard (supervised) training and it does not depend on specific architectural choices, thus it can be easily plugged in the existing VTs. Using an extensive evaluation with different VTs and datasets, we show that our method can improve (sometimes dramatically) the final accuracy of the VTs. Our code is available at: https://github.com/yhlleo/VTs-Drloc.",
    "authors": [
      "Liu, Yahui",
      "Sangineto, Enver",
      "Bi, Wei",
      "Sebe, Nicu",
      "Lepri, Bruno",
      "Nadai, Marco"
    ]
  },
  {
    "id": "c82836ed448c41094025b4a872c5341e",
    "title": "Small random initialization is akin to spectral learning: Optimization and generalization guarantees for overparameterized low-rank matrix reconstruction",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c82836ed448c41094025b4a872c5341e-Paper.pdf",
    "abstract": "Recently there has been significant theoretical progress on understanding the convergence and generalization of gradient-based methods on nonconvex losses with overparameterized models. Nevertheless, many aspects of optimization and generalization and in particular the critical role of small random initialization are not fully understood. In this paper, we take a step towards demystifying this role by proving that small random initialization followed by a few iterations of gradient descent behaves akin to popular spectral methods. We also show that this implicit spectral bias from small random initialization, which is provably more prominent for overparameterized models, also puts the gradient descent iterations on a particular trajectory towards solutions that are not only globally optimal but also generalize well. Concretely, we focus on the problem of reconstructing a low-rank matrix from a few measurements via a natural nonconvex formulation. In this setting, we show that the trajectory of the gradient descent iterations from small random initialization can be approximately decomposed into three phases: (I) a spectral or alignment phase where we show that that the iterates have an implicit spectral bias akin to spectral initialization allowing us to show that at the end of this phase the column space of the iterates and the underlying low-rank matrix are sufficiently aligned, (II) a saddle avoidance/refinement phase where we show that the trajectory of the gradient iterates moves away from certain degenerate saddle points, and (III) a local refinement phase where we show that after avoiding the saddles the iterates converge quickly to the underlying low-rank matrix. Underlying our analysis are insights for the analysis of overparameterized nonconvex optimization schemes that may have implications for computational problems beyond low-rank reconstruction.",
    "authors": [
      "St\u00f6ger, Dominik",
      "Soltanolkotabi, Mahdi"
    ]
  },
  {
    "id": "c8461bf13fca8a2b9912ab2eb1668e4b",
    "title": "Efficient Combination of Rematerialization and Offloading for Training DNNs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c8461bf13fca8a2b9912ab2eb1668e4b-Paper.pdf",
    "abstract": "Rematerialization and offloading are two well known strategies to save memory during the training phase of deep neural networks, allowing data scientists to consider larger models, batch sizes or higher resolution data. Rematerialization trades memory for computation time, whereas Offloading trades memory for data movements. As these two resources are independent, it is appealing to consider the simultaneous combination of both strategies to save even more memory. We precisely model the costs and constraints corresponding to Deep Learning frameworks such as PyTorch or Tensorflow, we propose optimal algorithms to find a valid sequence of memory-constrained operations and finally, we evaluate the performance of proposed algorithms on realistic networks and computation platforms. Our experiments show that the possibility to offload can remove one third of the overhead of rematerialization, and that together they can reduce the memory used for activations by a factor 4 to 6, with an overhead below 20%.",
    "authors": [
      "Beaumont, Olivier",
      "Eyraud-Dubois, Lionel",
      "Shilova, Alena"
    ]
  },
  {
    "id": "c8512d142a2d849725f31a9a7a361ab9",
    "title": "Particle Cloud Generation with Message Passing Generative Adversarial Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c8512d142a2d849725f31a9a7a361ab9-Paper.pdf",
    "abstract": "In high energy physics (HEP), jets are collections of correlated particles produced ubiquitously in particle collisions such as those at the CERN Large Hadron Collider (LHC). Machine learning (ML)-based generative models, such as generative adversarial networks (GANs), have the potential to significantly accelerate LHC jet simulations. However, despite jets having a natural representation as a set of particles in momentum-space, a.k.a. a particle cloud, there exist no generative models applied to such a dataset. In this work, we introduce a new particle cloud dataset (JetNet), and apply to it existing point cloud GANs. Results are evaluated using (1) 1-Wasserstein distances between high- and low-level feature distributions, (2) a newly developed Fr\u00e9chet ParticleNet Distance, and (3) the coverage and (4) minimum matching distance metrics. Existing GANs are found to be inadequate for physics applications, hence we develop a new message passing GAN (MPGAN), which outperforms existing point cloud GANs on virtually every metric and shows promise for use in HEP. We propose JetNet as a novel point-cloud-style dataset for the ML community to experiment with, and set MPGAN as a benchmark to improve upon for future generative models. Additionally, to facilitate research and improve accessibility and reproducibility in this area, we release the open-source JetNet Python package with interfaces for particle cloud datasets, implementations for evaluation and loss metrics, and more tools for ML in HEP development.",
    "authors": [
      "Kansal, Raghav",
      "Duarte, Javier",
      "Su, Hao",
      "Orzari, Breno",
      "Tomei, Thiago",
      "Pierini, Maurizio",
      "Touranakou, Mary",
      "vlimant, jean-roch",
      "Gunopulos, Dimitrios"
    ]
  },
  {
    "id": "c85b2ea9a678e74fdc8bafe5d0707c31",
    "title": "CoFiNet: Reliable Coarse-to-fine Correspondences for Robust PointCloud Registration",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c85b2ea9a678e74fdc8bafe5d0707c31-Paper.pdf",
    "abstract": "We study the problem of extracting correspondences between a pair of point clouds for registration. For correspondence retrieval, existing works benefit from matching sparse keypoints detected from dense points but usually struggle to guarantee their repeatability. To address this issue, we present CoFiNet - Coarse-to-Fine Network which extracts hierarchical correspondences from coarse to fine without keypoint detection. On a coarse scale and guided by a weighting scheme, our model firstly learns to match down-sampled nodes whose vicinity points share more overlap, which significantly shrinks the search space of a consecutive stage. On a finer scale, node proposals are consecutively expanded to patches that consist of groups of points together with associated descriptors. Point correspondences are then refined from the overlap areas of corresponding patches, by a density-adaptive matching module capable to deal with varying point density. Extensive evaluation of CoFiNet on both indoor and outdoor standard benchmarks shows our superiority over existing methods. Especially on 3DLoMatch where point clouds share less overlap, CoFiNet significantly outperforms state-of-the-art approaches by at least 5% on Registration Recall, with at most two-third of their parameters.",
    "authors": [
      "Yu, Hao",
      "Li, Fu",
      "Saleh, Mahdi",
      "Busam, Benjamin",
      "Ilic, Slobodan"
    ]
  },
  {
    "id": "c8877cff22082a16395a57e97232bb6f",
    "title": "Partial success in closing the gap between human and machine vision",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c8877cff22082a16395a57e97232bb6f-Paper.pdf",
    "abstract": "A few years ago, the first CNN surpassed human performance on ImageNet. However, it soon became clear that machines lack robustness on more challenging test cases, a major obstacle towards deploying machines \"in the wild\" and towards obtaining better computational models of human visual perception. Here we ask: Are we making progress in closing the gap between human and machine vision? To answer this question, we tested human observers on a broad range of out-of-distribution (OOD) datasets, recording 85,120 psychophysical trials across 90 participants. We then investigated a range of promising machine learning developments that crucially deviate from standard supervised CNNs along three axes: objective function (self-supervised, adversarially trained, CLIP language-image training), architecture (e.g. vision transformers), and dataset size (ranging from 1M to 1B).Our findings are threefold. (1.) The longstanding distortion robustness gap between humans and CNNs is closing, with the best models now exceeding human feedforward performance on most of the investigated OOD datasets. (2.) There is still a substantial image-level consistency gap, meaning that humans make different errors than models. In contrast, most models systematically agree in their categorisation errors, even substantially different ones like contrastive self-supervised vs. standard supervised models. (3.) In many cases, human-to-model consistency improves when training dataset size is increased by one to three orders of magnitude. Our results give reason for cautious optimism: While there is still much room for improvement, the behavioural difference between human and machine vision is narrowing. In order to measure future progress, 17 OOD datasets with image-level human behavioural data and evaluation code are provided as a toolbox and benchmark at: https://github.com/bethgelab/model-vs-human/",
    "authors": [
      "Geirhos, Robert",
      "Narayanappa, Kantharaju",
      "Mitzkus, Benjamin",
      "Thieringer, Tizian",
      "Bethge, Matthias",
      "Wichmann, Felix A.",
      "Brendel, Wieland"
    ]
  },
  {
    "id": "c88d8d0a6097754525e02c2246d8d27f",
    "title": "LLC: Accurate, Multi-purpose Learnt Low-dimensional Binary Codes",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c88d8d0a6097754525e02c2246d8d27f-Paper.pdf",
    "abstract": "Learning binary representations of instances and classes is a classical problem with several high potential applications. In modern settings, the compression of high-dimensional neural representations to low-dimensional binary codes is a challenging task and often require large bit-codes to be accurate. In this work, we propose a novel method for $\\textbf{L}$earning $\\textbf{L}$ow-dimensional binary $\\textbf{C}$odes $(\\textbf{LLC})$ for instances as well as classes. Our method does ${\\textit{not}}$ require any side-information, like annotated attributes or label meta-data, and learns extremely low-dimensional binary codes ($\\approx 20$ bits for ImageNet-1K). The learnt codes are super-efficient while still ensuring $\\textit{nearly optimal}$ classification accuracy for ResNet50 on ImageNet-1K. We demonstrate that the learnt codes capture intrinsically important features in the data, by discovering an intuitive taxonomy over classes. We further quantitatively measure the quality of our codes by applying it to the efficient image retrieval as well as out-of-distribution (OOD) detection problems. For ImageNet-100 retrieval problem, our learnt binary codes outperform $16$ bit HashNet using only $10$ bits and also are as accurate as $10$ dimensional real representations. Finally, our learnt binary codes can perform OOD detection, out-of-the-box, as accurately as a baseline that needs $\\approx3000$ samples to tune its threshold, while we require ${\\textit{none}}$. Code is open-sourced at https://github.com/RAIVNLab/LLC.",
    "authors": [
      "Kusupati, Aditya",
      "Wallingford, Matthew",
      "Ramanujan, Vivek",
      "Somani, Raghav",
      "Park, Jae Sung",
      "Pillutla, Krishna",
      "Jain, Prateek",
      "Kakade, Sham",
      "Farhadi, Ali"
    ]
  },
  {
    "id": "c900ced7451da79502d29aa37ebb7b60",
    "title": "Analytic Insights into Structure and Rank of Neural Network Hessian Maps",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c900ced7451da79502d29aa37ebb7b60-Paper.pdf",
    "abstract": "The Hessian of a neural network captures parameter interactions through second-order derivatives of the loss. It is a fundamental object of study, closely tied to various problems in deep learning, including model design, optimization, and generalization. Most prior work has been empirical, typically focusing on low-rank approximations and heuristics that are blind to the network structure.  In contrast, we develop theoretical tools to analyze the range of the Hessian map, which provide us with a precise understanding of its rank deficiency and the structural reasons behind it. This yields exact formulas and tight upper bounds for the Hessian rank of deep linear networks --- allowing for an elegant interpretation in terms of rank deficiency. Moreover, we demonstrate that our bounds remain faithful as an estimate of the numerical Hessian rank, for a larger class of models such as rectified and hyperbolic tangent networks. Further, we also investigate the implications of model architecture (e.g.~width, depth, bias) on the rank deficiency. Overall, our work provides novel insights into the source and extent of redundancy in overparameterized neural networks.",
    "authors": [
      "Singh, Sidak Pal",
      "Bachmann, Gregor",
      "Hofmann, Thomas"
    ]
  },
  {
    "id": "c902b497eb972281fb5b4e206db38ee6",
    "title": "Well-tuned Simple Nets Excel on Tabular Datasets",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c902b497eb972281fb5b4e206db38ee6-Paper.pdf",
    "abstract": "Tabular datasets are the last \"unconquered castle\" for deep learning, with traditional ML methods like Gradient-Boosted Decision Trees still performing strongly even against recent specialized neural architectures. In this paper, we hypothesize that the key to boosting the performance of neural networks lies in rethinking the joint and simultaneous application of a large set of modern regularization techniques. As a result, we propose regularizing plain Multilayer Perceptron (MLP) networks by searching for the optimal combination/cocktail of 13 regularization techniques for each dataset using a joint optimization over the decision on which regularizers to apply and their subsidiary hyperparameters. We empirically assess the impact of these regularization cocktails for MLPs in a large-scale empirical study comprising 40 tabular datasets and demonstrate that (i) well-regularized plain MLPs significantly outperform recent state-of-the-art specialized neural network architectures, and (ii) they even outperform strong traditional ML methods, such as XGBoost.",
    "authors": [
      "Kadra, Arlind",
      "Lindauer, Marius",
      "Hutter, Frank",
      "Grabocka, Josif"
    ]
  },
  {
    "id": "c91591a8d461c2869b9f535ded3e213e",
    "title": "POODLE: Improving Few-shot Learning via Penalizing Out-of-Distribution Samples",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c91591a8d461c2869b9f535ded3e213e-Paper.pdf",
    "abstract": "In this work, we propose to use out-of-distribution samples, i.e., unlabeled samples coming from outside the target classes, to improve few-shot learning. Specifically, we exploit the easily available out-of-distribution samples to drive the classifier to avoid irrelevant features by maximizing the distance from prototypes to out-of-distribution samples while minimizing that of in-distribution samples (i.e., support, query data). Our approach is simple to implement, agnostic to feature extractors, lightweight without any additional cost for pre-training, and applicable to both inductive and transductive settings. Extensive experiments on various standard benchmarks demonstrate that the proposed method consistently improves the performance of pretrained networks with different architectures.",
    "authors": [
      "Le, Duong",
      "Nguyen, Khoi Duc",
      "Nguyen, Khoi",
      "Tran, Quoc-Huy",
      "Nguyen, Rang",
      "Hua, Binh-Son"
    ]
  },
  {
    "id": "c92a10324374fac681719d63979d00fe",
    "title": "Combinatorial Pure Exploration with Bottleneck Reward Function",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c92a10324374fac681719d63979d00fe-Paper.pdf",
    "abstract": "In this paper, we study the Combinatorial Pure Exploration problem with the Bottleneck reward function (CPE-B) under the fixed-confidence (FC) and fixed-budget (FB) settings.In CPE-B, given a set of base arms and a collection of subsets of base arms (super arms) following a certain combinatorial constraint, a learner sequentially plays a base arm and observes its random reward, with the objective of finding the optimal super arm with the maximum bottleneck value, defined as the minimum expected reward of the base arms contained in the super arm.CPE-B captures a variety of practical scenarios such as network routing in communication networks, and its unique challenges fall on how to utilize the bottleneck property to save samples and achieve the statistical optimality. None of the existing CPE studies (most of them assume linear rewards) can be adapted to solve such challenges, and thus we develop brand-new techniques to handle them.For the FC setting, we propose novel algorithms with optimal sample complexity for a broad family of instances and establish a matching lower bound to demonstrate the optimality (within a logarithmic factor).For the FB setting, we design an algorithm which achieves the state-of-the-art error probability guarantee and is the first to run efficiently on fixed-budget path instances, compared to existing CPE algorithms. Our experimental results on the top-$k$, path and matching instances validate the empirical superiority of the proposed algorithms over their baselines.",
    "authors": [
      "Du, Yihan",
      "Kuroki, Yuko",
      "Chen, Wei"
    ]
  },
  {
    "id": "c950cde9b3f83f41721788e3315a14a3",
    "title": "Densely connected normalizing flows",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c950cde9b3f83f41721788e3315a14a3-Paper.pdf",
    "abstract": "Normalizing flows are bijective mappings between inputs and latent representations with a fully factorized distribution. They are very attractive due to exact likelihood evaluation and efficient sampling. However, their effective capacity is often insufficient since the bijectivity constraint limits the model width. We address this issue by incrementally padding intermediate representations with noise. We precondition the noise in accordance with previous invertible units, which we describe as cross-unit coupling. Our invertible glow-like modules increase the model expressivity by fusing a densely connected block with Nystr\u00f6m self-attention. We refer to our architecture as DenseFlow since both cross-unit and intra-module couplings rely on dense connectivity. Experiments show significant improvements due to the proposed contributions and reveal state-of-the-art density estimation under moderate computing budgets.",
    "authors": [
      "Grci\u0107, Matej",
      "Grubi\u0161i\u0107, Ivan",
      "\u0160egvi\u0107, Sini\u0161a"
    ]
  },
  {
    "id": "c952ce98517ac529c60744ac28364b03",
    "title": "Snowflake: Scaling GNNs to high-dimensional continuous control via parameter freezing",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c952ce98517ac529c60744ac28364b03-Paper.pdf",
    "abstract": "Recent research has shown that graph neural networks (GNNs) can learn policies for locomotion control that are as effective as a typical multi-layer perceptron (MLP), with superior transfer and multi-task performance. However, results have so far been limited to training on small agents, with the performance of GNNs deteriorating rapidly as the number of sensors and actuators grows. A key motivation for the use of GNNs in the supervised learning setting is their applicability to large graphs, but this benefit has not yet been realised for locomotion control. We show that poor scaling in GNNs is a result of increasingly unstable policy updates, caused by overfitting in parts of the network during training. To combat this, we introduce Snowflake, a GNN training method for high-dimensional continuous control that freezes parameters in selected parts of the network. Snowflake significantly boosts the performance of GNNs for locomotion control on large agents, now matching the performance of MLPs while offering superior transfer properties.",
    "authors": [
      "Blake, Charles",
      "Kurin, Vitaly",
      "Igl, Maximilian",
      "Whiteson, Shimon"
    ]
  },
  {
    "id": "c96c08f8bb7960e11a1239352a479053",
    "title": "Subgame solving without common knowledge",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c96c08f8bb7960e11a1239352a479053-Paper.pdf",
    "abstract": "In imperfect-information games, subgame solving is significantly more challenging than in perfect-information games, but in the last few years, such techniques have been developed. They were the key ingredient to the milestone of superhuman play in no-limit Texas hold'em poker. Current subgame-solving techniques analyze the entire common-knowledge closure of the player's current information set, that is, the smallest set of nodes within which it is common knowledge that the current node lies. While this is acceptable in games like poker where the common-knowledge closure is relatively small, many practical games have more complex information structure, which renders the common-knowledge closure impractically large to enumerate or even reasonably approximate. We introduce an approach that overcomes this obstacle, by instead working with only low-order knowledge. Our approach allows an agent, upon arriving at an infoset, to basically prune any node that is no longer reachable, thereby massively reducing the game tree size relative to the common-knowledge subgame. We prove that, as is, our approach can increase exploitability compared to the blueprint strategy. However, we develop three avenues by which safety can be guaranteed. First, safety is guaranteed if the results of subgame solves are incorporated back into the blueprint. Second, we provide a method where safety is achieved by limiting the infosets at which subgame solving is performed. Third, we prove that our approach, when applied at every infoset reached during play, achieves a weaker notion of equilibrium, which we coin affine equilibrium, and which may be of independent interest. We show that affine equilibria cannot be exploited by any Nash strategy of the opponent, so an opponent who wishes to exploit must open herself to counter-exploitation. Even without the safety-guaranteeing additions, experiments on medium-sized games show that our approach always reduced exploitability in practical games even when applied at every infoset, and a depth-limited version of it led to---to our knowledge---the first strong AI for the challenge problem dark chess.",
    "authors": [
      "Zhang, Brian",
      "Sandholm, Tuomas"
    ]
  },
  {
    "id": "c96ebeee051996333b6d70b2da6191b0",
    "title": "Fair Algorithms for Multi-Agent Multi-Armed Bandits",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c96ebeee051996333b6d70b2da6191b0-Paper.pdf",
    "abstract": "We propose a multi-agent variant of the classical multi-armed bandit problem, in which there are $N$ agents and $K$ arms, and pulling an arm generates a (possibly different) stochastic reward for each agent. Unlike the classical multi-armed bandit problem, the goal is not to learn the \"best arm\"; indeed, each agent may perceive a different arm to be the best for her personally. Instead, we seek to learn a fair distribution over the arms. Drawing on a long line of research in economics and computer science, we use the Nash social welfare as our notion of fairness. We design multi-agent variants of three classic multi-armed bandit algorithms and show that they achieve sublinear regret, which is now measured in terms of the lost Nash social welfare. We also extend a classical lower bound, establishing the optimality of one of our algorithms.",
    "authors": [
      "Hossain, Safwan",
      "Micha, Evi",
      "Shah, Nisarg"
    ]
  },
  {
    "id": "c97e7a5153badb6576d8939469f58336",
    "title": "VAST: Value Function Factorization with Variable Agent Sub-Teams",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c97e7a5153badb6576d8939469f58336-Paper.pdf",
    "abstract": "Value function factorization (VFF) is a popular approach to cooperative multi-agent reinforcement learning in order to learn local value functions from global rewards. However, state-of-the-art VFF is limited to a handful of agents in most domains. We hypothesize that this is due to the flat factorization scheme, where the VFF operator becomes a performance bottleneck with an increasing number of agents. Therefore, we propose VFF with variable agent sub-teams (VAST). VAST approximates a factorization for sub-teams which can be defined in an arbitrary way and vary over time, e.g., to adapt to different situations. The sub-team values are then linearly decomposed for all sub-team members. Thus, VAST can learn on a more focused and compact input representation of the original VFF operator. We evaluate VAST in three multi-agent domains and show that VAST can significantly outperform state-of-the-art VFF, when the number of agents is sufficiently large.",
    "authors": [
      "Phan, Thomy",
      "Ritz, Fabian",
      "Belzner, Lenz",
      "Altmann, Philipp",
      "Gabor, Thomas",
      "Linnhoff-Popien, Claudia"
    ]
  },
  {
    "id": "c9dd73f5cb96486f5e1e0680e841a550",
    "title": "On the Stochastic Stability of Deep Markov Models",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c9dd73f5cb96486f5e1e0680e841a550-Paper.pdf",
    "abstract": "Deep Markov models (DMM) are generative models which are scalable and expressive generalization of Markov models for representation, learning, and inference problems. However, the fundamental stochastic stability guarantees of such models have not been thoroughly investigated. In this paper, we present a novel stability analysis method and provide sufficient conditions of DMM's stochastic stability.  The proposed stability analysis is based on the contraction of probabilistic maps modeled by deep neural networks. We make connections between the spectral properties of neural network's weights and different types of used activation function on the stability and overall dynamic behavior of DMMs with Gaussian distributions. Based on the theory, we propose a few practical methods for designing constrained DMMs with guaranteed stability. We empirically substantiate our theoretical results via intuitive numerical experiments using the proposed stability constraints.",
    "authors": [
      "Drgona, Jan",
      "Mukherjee, Sayak",
      "Zhang, Jiaxin",
      "Liu, Frank",
      "Halappanavar, Mahantesh"
    ]
  },
  {
    "id": "c9e5c2b59d98488fe1070e744041ea0e",
    "title": "Multiwavelet-based Operator Learning for Differential Equations",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c9e5c2b59d98488fe1070e744041ea0e-Paper.pdf",
    "abstract": "The solution of a partial differential equation can be obtained by computing the inverse operator map between the input and the solution space. Towards this end, we introduce a $\\textit{multiwavelet-based neural operator learning scheme}$ that compresses the associated operator's kernel using fine-grained wavelets. By explicitly embedding the inverse multiwavelet filters, we learn the projection of the kernel onto fixed multiwavelet polynomial bases. The projected kernel is trained at multiple scales derived from using repeated computation of multiwavelet transform. This allows learning the complex dependencies at various scales and results in a resolution-independent scheme. Compare to the prior works, we exploit the fundamental properties of the operator's kernel which enable numerically efficient representation. We perform experiments on the Korteweg-de Vries (KdV) equation, Burgers' equation, Darcy Flow, and Navier-Stokes equation. Compared with the existing neural operator approaches, our model shows significantly higher accuracy and achieves state-of-the-art in a range of datasets. For the time-varying equations, the proposed method exhibits a ($2X-10X$) improvement ($0.0018$ ($0.0033$) relative $L2$ error for Burgers' (KdV) equation). By learning the mappings between function spaces, the proposed method has the ability to find the solution of a high-resolution input after learning from lower-resolution data.",
    "authors": [
      "Gupta, Gaurav",
      "Xiao, Xiongye",
      "Bogdan, Paul"
    ]
  },
  {
    "id": "c9f06258da6455f5bf50c5b9260efeff",
    "title": "Intermediate Layers Matter in Momentum Contrastive Self Supervised Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c9f06258da6455f5bf50c5b9260efeff-Paper.pdf",
    "abstract": "We show that bringing intermediate layers' representations of two augmented versions of an image closer together in self-supervised learning helps to improve the momentum contrastive (MoCo) method. To this end, in addition to the contrastive loss, we minimize the mean squared error between the intermediate layer representations or make their cross-correlation matrix closer to an identity matrix. Both loss objectives either outperform standard MoCo, or achieve similar performances on three diverse medical imaging datasets: NIH-Chest Xrays, Breast Cancer Histopathology, and Diabetic Retinopathy. The gains of the improved MoCo are especially large in a low-labeled data regime (e.g. 1% labeled data) with an average gain of 5% across three datasets. We analyze the models trained using our novel approach via feature similarity analysis and layer-wise probing. Our analysis reveals that models trained via our approach have higher feature reuse compared to a standard MoCo and learn informative features earlier in the network. Finally, by comparing the output probability distribution of models fine-tuned on small versus large labeled data, we conclude that our proposed method of pre-training leads to lower Kolmogorov\u2013Smirnov distance, as compared to a standard MoCo. This provides additional evidence that our proposed method learns more informative features in the pre-training phase which could be leveraged in a low-labeled data regime.",
    "authors": [
      "Kaku, Aakash",
      "Upadhya, Sahana",
      "Razavian, Narges"
    ]
  },
  {
    "id": "ca460332316d6da84b08b9bcf39b687b",
    "title": "An Efficient Pessimistic-Optimistic Algorithm for Stochastic Linear Bandits with General Constraints",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ca460332316d6da84b08b9bcf39b687b-Paper.pdf",
    "abstract": "This paper considers stochastic linear bandits with general nonlinear constraints. The objective is to maximize the expected cumulative reward over horizon $T$ subject to a set of constraints in each round $\\tau\\leq T$. We propose a pessimistic-optimistic algorithm for this problem, which is efficient in two aspects. First, the algorithm yields $\\tilde{\\cal O}\\left(\\left(\\frac{K^{0.75}}{\\delta}+d\\right)\\sqrt{\\tau}\\right)$ (pseudo) regret in round $\\tau\\leq T,$ where $K$ is the number of constraints, $d$ is the dimension of the reward feature space, and $\\delta$ is a Slater's constant; and  {\\em zero}  constraint violation in any round $\\tau>\\tau',$ where $\\tau'$ is  {\\em independent} of horizon $T.$ Second, the algorithm is computationally efficient. Our algorithm is based on the primal-dual approach in optimization and includes two components. The primal component is similar to unconstrained stochastic linear bandits (our algorithm uses the linear upper confidence bound algorithm (LinUCB)). The computational complexity of the dual component depends on the number of constraints, but is independent of the sizes of the contextual space, the action space, and the feature space. Thus, the computational complexity of our algorithm is similar to LinUCB for unconstrained stochastic linear bandits.",
    "authors": [
      "Liu, Xin",
      "Li, Bin",
      "Shi, Pengyi",
      "Ying, Lei"
    ]
  },
  {
    "id": "ca4b5656b7e193e6bb9064c672ac8dce",
    "title": "Efficiently Learning One Hidden Layer ReLU Networks From Queries",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ca4b5656b7e193e6bb9064c672ac8dce-Paper.pdf",
    "abstract": "While the problem of PAC learning neural networks from samples has received considerable attention in recent years, in certain settings like model extraction attacks, it is reasonable to imagine having more than just the ability to observe random labeled examples. Motivated by this, we consider the following problem: given \\emph{black-box query access} to a neural network $F$, recover $F$ up to some error. Formally, we show that if $F$ is an arbitrary one hidden layer neural network with ReLU activations, there is an algorithm with query complexity and runtime polynomial in all parameters which outputs a network $F\u2019$ achieving low square loss relative to $F$ with respect to the Gaussian measure. While a number of works in the security literature have proposed and empirically demonstrated the effectiveness of certain algorithms for this problem, ours is to the best of our knowledge the first provable guarantee in this vein.",
    "authors": [
      "Chen, Sitan",
      "Klivans, Adam",
      "Meka, Raghu"
    ]
  },
  {
    "id": "ca5fbbbddd0c0ff6c01f782c60c9d1b5",
    "title": "Learning Nonparametric Volterra Kernels with Gaussian Processes",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ca5fbbbddd0c0ff6c01f782c60c9d1b5-Paper.pdf",
    "abstract": "This paper introduces a method for the nonparametric Bayesian learning of nonlinear operators, through the use of the Volterra series with kernels represented using Gaussian processes (GPs), which we term the nonparametric Volterra kernels model (NVKM). When the input function to the operator is unobserved and has a GP prior, the NVKM constitutes a powerful method for both single and multiple output regression, and can be viewed as a nonlinear and nonparametric latent force model. When the input function is observed, the NVKM can be used to perform Bayesian system identification. We use recent advances in efficient sampling of explicit functions from GPs to map process realisations through the Volterra series without resorting to numerical integration, allowing scalability through doubly stochastic variational inference, and avoiding the need for Gaussian approximations of the output processes. We demonstrate the performance of the model for both multiple output regression and system identification using standard benchmarks.",
    "authors": [
      "Ross, Magnus",
      "Smith, Michael T",
      "\u00c1lvarez, Mauricio"
    ]
  },
  {
    "id": "ca6ab34959489659f8c3776aaf1f8efd",
    "title": "DiBS: Differentiable Bayesian Structure Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ca6ab34959489659f8c3776aaf1f8efd-Paper.pdf",
    "abstract": "Bayesian structure learning allows inferring Bayesian network structure from data while reasoning about the epistemic uncertainty---a key element towards enabling active causal discovery and designing interventions in real world systems. In this work, we propose a general, fully differentiable framework for Bayesian structure learning (DiBS) that operates in the continuous space of a latent probabilistic graph representation. Contrary to existing work, DiBS is agnostic to the form of the local conditional distributions and allows for joint posterior inference of both the graph structure and the conditional distribution parameters. This makes our formulation directly applicable to posterior inference of nonstandard Bayesian network models, e.g., with nonlinear dependencies encoded by neural networks. Using DiBS, we devise an efficient, general purpose variational inference method for approximating distributions over structural models. In evaluations on simulated and real-world data, our method significantly outperforms related approaches to joint posterior inference.",
    "authors": [
      "Lorch, Lars",
      "Rothfuss, Jonas",
      "Sch\u00f6lkopf, Bernhard",
      "Krause, Andreas"
    ]
  },
  {
    "id": "ca8a2d76a5bcc212226417361a5f0740",
    "title": "Nonparametric estimation of continuous DPPs with kernel methods",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ca8a2d76a5bcc212226417361a5f0740-Paper.pdf",
    "abstract": "Determinantal Point Process (DPPs) are statistical models for repulsive point patterns. Both sampling and inference are tractable for DPPs, a rare feature among models with negative dependence that explains their popularity in machine learning and spatial statistics. Parametric and nonparametric inference methods have been proposed in the finite case, i.e. when the point patterns live in a finite ground set. In the continuous case, only parametric methods have been investigated, while nonparametric maximum likelihood for DPPs -- an optimization problem over trace-class operators -- has remained an open question. In this paper, we show that a restricted version of this maximum likelihood (MLE) problem falls within the scope of a recent representer theorem for nonnegative functions in an RKHS. This leads to a finite-dimensional problem, with strong statistical ties to the original MLE. Moreover, we propose, analyze, and demonstrate a fixed point algorithm to solve this finite-dimensional problem. Finally, we also provide a controlled estimate of the correlation kernel of the DPP, thus providing more interpretability.",
    "authors": [
      "Fanuel, Micha\u00ebl",
      "Bardenet, R\u00e9mi"
    ]
  },
  {
    "id": "ca91c5464e73d3066825362c3093a45f",
    "title": "FINE Samples for Learning with Noisy Labels",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ca91c5464e73d3066825362c3093a45f-Paper.pdf",
    "abstract": "Modern deep neural networks (DNNs) become frail when the datasets contain noisy (incorrect) class labels. Robust techniques in the presence of noisy labels can be categorized into two folds: developing noise-robust functions or using noise-cleansing methods by detecting the noisy data. Recently, noise-cleansing methods have been considered as the most competitive noisy-label learning algorithms. Despite their success, their noisy label detectors are often based on heuristics more than a theory, requiring a robust classifier to predict the noisy data with loss values. In this paper, we propose a novel detector for filtering label noise. Unlike most existing methods, we focus on each data's latent representation dynamics and measure the alignment between the latent distribution and each representation using the eigen decomposition of the data gram matrix. Our framework, coined as filtering noisy instances via their eigenvectors (FINE), provides a robust detector with derivative-free simple methods having theoretical guarantees. Under our framework, we propose three applications of the FINE: sample-selection approach, semi-supervised learning approach, and collaboration with noise-robust loss functions. Experimental results show that the proposed methods consistently outperform corresponding baselines for all three applications on various benchmark datasets.",
    "authors": [
      "Kim, Taehyeon",
      "Ko, Jongwoo",
      "Cho, sangwook",
      "Choi, JinHwan",
      "Yun, Se-Young"
    ]
  },
  {
    "id": "ca9541826e97c4530b07dda2eba0e013",
    "title": "Residual2Vec: Debiasing graph embedding with random graphs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ca9541826e97c4530b07dda2eba0e013-Paper.pdf",
    "abstract": "Graph embedding maps a graph into a convenient vector-space representation for graph analysis and machine learning applications. Many graph embedding methods hinge on a sampling of context nodes based on random walks. However, random walks can be a biased sampler due to the structural properties of graphs. Most notably, random walks are biased by the degree of each node, where a node is sampled proportionally to its degree. The implication of such biases has not been clear, particularly in the context of graph representation learning. Here, we investigate the impact of the random walks' bias on graph embedding and propose residual2vec, a general graph embedding method that can debias various structural biases in graphs by using random graphs. We demonstrate that this debiasing not only improves link prediction and clustering performance but also allows us to explicitly model salient structural properties in graph embedding.",
    "authors": [
      "Kojaku, Sadamori",
      "Yoon, Jisung",
      "Constantino, Isabel",
      "Ahn, Yong-Yeol"
    ]
  },
  {
    "id": "caaa29eab72b231b0af62fbdff89bfce",
    "title": "Benign Overfitting in Multiclass Classification: All Roads Lead to Interpolation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/caaa29eab72b231b0af62fbdff89bfce-Paper.pdf",
    "abstract": "The growing literature on \"benign overfitting\" in overparameterized models has been mostly restricted to regression or binary classification settings; however, most success stories of modern machine learning have been recorded in multiclass settings. Motivated by this discrepancy, we study benign overfitting in multiclass linear classification. Specifically, we consider the following popular training algorithms on separable data: (i) empirical risk minimization (ERM) with cross-entropy loss, which converges to the multiclass support vector machine (SVM) solution; (ii) ERM with least-squares loss, which converges to the min-norm interpolating (MNI) solution; and, (iii) the one-vs-all SVM classifier. Our first key finding is that under a simple sufficient condition, all three algorithms lead to classifiers that interpolate the training data and have equal accuracy. When the data is generated from Gaussian mixtures or a multinomial logistic model, this condition holds under high enough effective overparameterization. Second, we derive novel error bounds on the accuracy of the MNI classifier, thereby showing that all three training algorithms lead to benign overfitting under sufficient overparameterization. Ultimately, our analysis shows that good generalization is possible for SVM solutions beyond the realm in which typical margin-based bounds apply.",
    "authors": [
      "Wang, Ke",
      "Muthukumar, Vidya",
      "Thrampoulidis, Christos"
    ]
  },
  {
    "id": "cacbf64b8a464fa1974da1eb0aa92851",
    "title": "Instance-Dependent Bounds for Zeroth-order Lipschitz Optimization with Error Certificates",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cacbf64b8a464fa1974da1eb0aa92851-Paper.pdf",
    "abstract": "We study the problem of zeroth-order (black-box) optimization of a Lipschitz function $f$ defined on a compact subset $\\mathcal{X}$ of $\\mathbb{R}^d$, with the additional constraint that algorithms must certify the accuracy of their recommendations. We characterize the optimal number of evaluations of any Lipschitz function $f$ to find and certify an approximate maximizer of $f$ at accuracy $\\varepsilon$. Under a weak assumption on $\\mathcal{X}$, this optimal sample complexity is shown to be nearly proportional to the integral $\\int_{\\mathcal{X}} \\mathrm{d}\\boldsymbol{x}/( \\max(f) - f(\\boldsymbol{x}) + \\varepsilon )^d$. This result, which was only (and partially) known in dimension $d=1$, solves an open problem dating back to 1991. In terms of techniques, our upper bound relies on a packing bound by Bouttier et al. (2020) for the Piyavskii-Shubert algorithm that we link to the above integral. We also show that a certified version of the computationally tractable DOO algorithm matches these packing and integral bounds. Our instance-dependent lower bound differs from traditional worst-case lower bounds in the Lipschitz setting and relies on a local worst-case analysis that could likely prove useful for other learning tasks.",
    "authors": [
      "Bachoc, Francois",
      "Cesari, Tom",
      "Gerchinovitz, S\u00e9bastien"
    ]
  },
  {
    "id": "cb2653f548f8709598e8b5156738cc51",
    "title": "Training Neural Networks with Fixed Sparse Masks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cb2653f548f8709598e8b5156738cc51-Paper.pdf",
    "abstract": "During typical gradient-based training of deep neural networks, all of the model's parameters are updated at each iteration. Recent work has shown that it is possible to update only a small subset of the model's parameters during training, which can alleviate storage and communication requirements. In this paper, we show that it is possible to induce a fixed sparse mask on the model\u2019s parameters that selects a subset to update over many iterations. Our method constructs the mask out of the $k$ parameters with the largest Fisher information as a simple approximation as to which parameters are most important for the task at hand. In experiments on parameter-efficient transfer learning and distributed training, we show that our approach matches or exceeds the performance of other methods for training with sparse updates while being more efficient in terms of memory usage and communication costs. We release our code publicly to promote further applications of our approach.",
    "authors": [
      "Sung, Yi-Lin",
      "Nair, Varun",
      "Raffel, Colin A."
    ]
  },
  {
    "id": "cb3213ada48302953cb0f166464ab356",
    "title": "VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cb3213ada48302953cb0f166464ab356-Paper.pdf",
    "abstract": "We present a framework for learning multimodal representations from unlabeled data using convolution-free Transformer architectures. Specifically, our Video-Audio-Text Transformer (VATT) takes raw signals as inputs and extracts multimodal representations that are rich enough to benefit a variety of downstream tasks. We train VATT end-to-end from scratch using multimodal contrastive losses and evaluate its performance by the downstream tasks of video action recognition, audio event classification, image classification, and text-to-video retrieval. Furthermore, we study a modality-agnostic single-backbone Transformer by sharing weights among the three modalities. We show that the convolution-free VATT outperforms state-of-the-art ConvNet-based architectures in the downstream tasks. Especially, VATT's vision Transformer achieves the top-1 accuracy of 82.1% on Kinetics-400, 83.6% on Kinetics-600, 72.7% on Kinetics-700, and 41.1% on Moments in Time, new records while avoiding supervised pre-training. Transferring to image classification leads to 78.7% top-1 accuracy on ImageNet compared to 64.7% by training the same Transformer from scratch, showing the generalizability of our model despite the domain gap between videos and images. VATT's audio Transformer also sets a new record on waveform-based audio event recognition by achieving the mAP of 39.4% on AudioSet without any supervised pre-training.",
    "authors": [
      "Akbari, Hassan",
      "Yuan, Liangzhe",
      "Qian, Rui",
      "Chuang, Wei-Hong",
      "Chang, Shih-Fu",
      "Cui, Yin",
      "Gong, Boqing"
    ]
  },
  {
    "id": "cb77649f5d53798edfa0ff40dae46322",
    "title": "Analyzing the Generalization Capability of SGLD Using Properties of Gaussian Channels",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cb77649f5d53798edfa0ff40dae46322-Paper.pdf",
    "abstract": "Optimization is a key component for training machine learning models and has a strong impact on their generalization. In this paper, we consider a particular optimization method---the stochastic gradient Langevin dynamics (SGLD) algorithm---and investigate the generalization of models trained by SGLD. We derive a new generalization bound by connecting SGLD with Gaussian channels found in information and communication theory. Our bound can be computed from the training data and incorporates the variance of gradients for quantifying a particular kind of \"sharpness\" of the loss landscape. We also consider a closely related algorithm with SGLD, namely differentially private SGD (DP-SGD). We prove that the generalization capability of DP-SGD can be amplified by iteration. Specifically, our bound can be sharpened by including a time-decaying factor if the DP-SGD algorithm outputs the last iterate while keeping other iterates hidden. This decay factor enables the contribution of early iterations to our bound to reduce with time and is established by strong data processing inequalities---a fundamental tool in information theory. We demonstrate our bound through numerical experiments, showing that it can predict the behavior of the true generalization gap.",
    "authors": [
      "Wang, Hao",
      "Huang, Yizhe",
      "Gao, Rui",
      "Calmon, Flavio"
    ]
  },
  {
    "id": "cb7c403aa312160380010ee3dd4bfc53",
    "title": "Learning to Schedule Heuristics in Branch and Bound",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cb7c403aa312160380010ee3dd4bfc53-Paper.pdf",
    "abstract": "Primal heuristics play a crucial role in exact solvers for Mixed Integer Programming (MIP). While solvers are guaranteed to find optimal solutions given sufficient time, real-world applications typically require finding good solutions early on in the search to enable fast decision-making. While much of MIP research focuses on designing effective heuristics, the question of how to manage multiple MIP heuristics in a solver has not received equal attention. Generally, solvers follow hard-coded rules derived from empirical testing on broad sets of instances. Since the performance of heuristics is problem-dependent, using these general rules for a particular problem might not yield the best performance. In this work, we propose the first data-driven framework for scheduling heuristics in an exact MIP solver. By learning from data describing the performance of primal heuristics, we obtain a problem-specific schedule of heuristics that collectively find many solutions at minimal cost. We formalize the learning task and propose an efficient algorithm for computing such a schedule. Compared to the default settings of a state-of-the-art academic MIP solver, we are able to reduce the average primal integral by up to 49% on two classes of challenging instances.",
    "authors": [
      "Chmiela, Antonia",
      "Khalil, Elias",
      "Gleixner, Ambros",
      "Lodi, Andrea",
      "Pokutta, Sebastian"
    ]
  },
  {
    "id": "cb8da6767461f2812ae4290eac7cbc42",
    "title": "On Training Implicit Models",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cb8da6767461f2812ae4290eac7cbc42-Paper.pdf",
    "abstract": "This paper focuses on training implicit models of infinite layers. Specifically, previous works employ implicit differentiation and solve the exact gradient for the backward propagation. However, is it necessary to compute such an exact but expensive gradient for training? In this work, we propose a novel gradient estimate for implicit models, named phantom gradient, that 1) forgoes the costly computation of the exact gradient; and 2) provides an update direction empirically preferable to the implicit model training. We theoretically analyze the condition under which an ascent direction of the loss landscape could be found and provide two specific instantiations of the phantom gradient based on the damped unrolling and Neumann series. Experiments on large-scale tasks demonstrate that these lightweight phantom gradients significantly accelerate the backward passes in training implicit models by roughly 1.7 $\\times$ and even boost the performance over approaches based on the exact gradient on ImageNet.",
    "authors": [
      "Geng, Zhengyang",
      "Zhang, Xin-Yu",
      "Bai, Shaojie",
      "Wang, Yisen",
      "Lin, Zhouchen"
    ]
  },
  {
    "id": "cba0a4ee5ccd02fda0fe3f9a3e7b89fe",
    "title": "MLP-Mixer: An all-MLP Architecture for Vision",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cba0a4ee5ccd02fda0fe3f9a3e7b89fe-Paper.pdf",
    "abstract": "Convolutional Neural Networks (CNNs) are the go-to model for computer vision. Recently, attention-based networks, such as the Vision Transformer, have also become popular. In this paper we show that while convolutions and attention are both sufficient for good performance, neither of them are necessary. We present MLP-Mixer, an architecture based exclusively on multi-layer perceptrons (MLPs). MLP-Mixer contains two types of layers: one with MLPs applied independently to image patches (i.e. \"mixing\" the per-location features), and one with MLPs applied across patches (i.e. \"mixing\" spatial information). When trained on large datasets, or with modern regularization schemes, MLP-Mixer attains competitive scores on image classification benchmarks, with pre-training and inference cost comparable to state-of-the-art models. We hope that these results spark further research beyond the realms of well established CNNs and Transformers.",
    "authors": [
      "Tolstikhin, Ilya O.",
      "Houlsby, Neil",
      "Kolesnikov, Alexander",
      "Beyer, Lucas",
      "Zhai, Xiaohua",
      "Unterthiner, Thomas",
      "Yung, Jessica",
      "Steiner, Andreas",
      "Keysers, Daniel",
      "Uszkoreit, Jakob",
      "Lucic, Mario",
      "Dosovitskiy, Alexey"
    ]
  },
  {
    "id": "cbb6a3b884f4f88b3a8e3d44c636cbd8",
    "title": "A Framework to Learn with Interpretation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cbb6a3b884f4f88b3a8e3d44c636cbd8-Paper.pdf",
    "abstract": "To tackle interpretability in deep learning, we present a novel framework to jointly learn a predictive model and its associated interpretation model. The interpreter provides both local and global interpretability about the predictive model in terms of human-understandable high level attribute functions, with minimal loss of accuracy. This is achieved by a dedicated architecture and well chosen regularization penalties. We seek for a small-size dictionary of high level attribute functions that take as inputs the outputs of selected hidden layers and whose outputs feed a linear classifier. We impose strong conciseness on the activation of attributes with an entropy-based criterion while enforcing fidelity to both inputs and outputs of the predictive model. A detailed pipeline to visualize the learnt features is also developed. Moreover, besides generating interpretable models by design, our approach can be specialized to provide post-hoc interpretations for a pre-trained neural network. We validate our approach against several state-of-the-art methods on multiple datasets and show its efficacy on both kinds of tasks.",
    "authors": [
      "Parekh, Jayneel",
      "Mozharovskyi, Pavlo",
      "d'Alch\u00e9-Buc, Florence"
    ]
  },
  {
    "id": "cbcb58ac2e496207586df2854b17995f",
    "title": "One Loss for All: Deep Hashing with a Single Cosine Similarity based Learning Objective",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cbcb58ac2e496207586df2854b17995f-Paper.pdf",
    "abstract": "A deep hashing model typically has two main learning objectives: to make the learned binary hash codes discriminative and to minimize a quantization error. With further constraints such as bit balance and code orthogonality, it is not uncommon for existing models to employ a large number (>4) of losses. This leads to difficulties in model training and subsequently impedes their effectiveness. In this work, we propose a novel deep hashing model with only $\\textit{a single learning objective}$. Specifically,  we show that maximizing the cosine similarity between the continuous codes and their corresponding $\\textit{binary orthogonal codes}$ can ensure both hash code discriminativeness and quantization error minimization. Further, with this learning objective, code balancing can be achieved by simply using a  Batch Normalization (BN) layer and multi-label classification is also straightforward with label smoothing. The result is a one-loss deep hashing model that removes all the hassles of tuning the weights of various losses. Importantly,  extensive experiments show that our model is highly effective, outperforming the state-of-the-art multi-loss hashing models on three large-scale instance retrieval benchmarks, often by significant margins. ",
    "authors": [
      "Hoe, Jiun Tian",
      "Ng, Kam Woh",
      "Zhang, Tianyu",
      "Chan, Chee Seng",
      "Song, Yi-Zhe",
      "Xiang, Tao"
    ]
  },
  {
    "id": "cbef46321026d8404bc3216d4774c8a9",
    "title": "Fast and accurate randomized algorithms for low-rank tensor decompositions",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cbef46321026d8404bc3216d4774c8a9-Paper.pdf",
    "abstract": "Low-rank Tucker and CP tensor decompositions are powerful tools in data analytics. The widely used alternating least squares (ALS) method, which solves a sequence of over-determined least squares subproblems, is costly for large and sparse tensors. We propose a fast and accurate sketched ALS algorithm for Tucker decomposition, which solves a sequence of sketched rank-constrained linear least squares subproblems. Theoretical sketch size upper bounds are provided to achieve $O(\\epsilon)$ relative error for each subproblem with two sketching techniques, TensorSketch and leverage score sampling. Experimental results show that this new ALS algorithm, combined with a new initialization scheme based on the randomized range finder, yields decomposition accuracy comparable to the standard higher-order orthogonal iteration (HOOI) algorithm. The new algorithm achieves up to $22.0\\%$ relative decomposition residual improvement compared to the state-of-the-art sketched randomized algorithm for Tucker decomposition of various synthetic and real datasets. This Tucker-ALS algorithm is further used to accelerate CP decomposition, by using randomized Tucker compression followed by CP decomposition of the Tucker core tensor. Experimental results show that this algorithm not only converges faster, but also yields more accurate CP decompositions. ",
    "authors": [
      "Ma, Linjian",
      "Solomonik, Edgar"
    ]
  },
  {
    "id": "cc06a6150b92e17dd3076a0f0f9d2af4",
    "title": "Communication-efficient SGD: From Local SGD to One-Shot Averaging",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cc06a6150b92e17dd3076a0f0f9d2af4-Paper.pdf",
    "abstract": "We consider speeding up stochastic gradient descent (SGD) by parallelizing it across multiple workers. We assume the same data set is shared among $N$ workers, who can take SGD steps and coordinate with a central server. While it is possible to obtain a linear reduction in the variance by averaging all the stochastic gradients at every step, this requires a lot of communication between the workers and the server, which can dramatically reduce the gains from parallelism.The Local SGD method, proposed and analyzed in the earlier literature, suggests machines should make many local steps between such communications. While the initial analysis of Local SGD showed it needs $\\Omega ( \\sqrt{T} )$ communications for $T$ local gradient steps in order for the error to scale proportionately to $1/(NT)$, this has been successively improved in a string of papers, with the state of the art requiring  $\\Omega \\left( N \\left( \\mbox{ poly} (\\log T) \\right) \\right)$ communications. In this paper, we suggest a Local SGD scheme that communicates less overall by communicating less frequently as the number of iterations grows.  Our analysis shows that this can achieve an error that scales as $1/(NT)$ with a number of communications that is completely independent of $T$. In particular, we show that $\\Omega(N)$ communications are sufficient. Empirical evidence suggests this bound is close to tight as we further show that $\\sqrt{N}$ or $N^{3/4}$ communications fail to achieve linear speed-up in simulations. Moreover, we show that under mild assumptions, the main of which is twice differentiability on any neighborhood of the optimal solution, one-shot averaging which only uses a single round of communication can also achieve the optimal convergence rate asymptotically.",
    "authors": [
      "Spiridonoff, Artin",
      "Olshevsky, Alex",
      "Paschalidis, Yannis"
    ]
  },
  {
    "id": "cc1aa436277138f61cda703991069eaf",
    "title": "Memory Efficient Meta-Learning with Large Images",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cc1aa436277138f61cda703991069eaf-Paper.pdf",
    "abstract": "Meta learning approaches to few-shot classification are computationally efficient at test time, requiring just a few optimization steps or single forward pass to learn a new task, but they remain highly memory-intensive to train. This limitation arises because a task's entire support set, which can contain up to 1000 images, must be processed before an optimization step can be taken. Harnessing the performance gains offered by large images thus requires either parallelizing the meta-learner across multiple GPUs, which may not be available, or trade-offs between task and image size when memory constraints apply. We improve on both options by proposing LITE, a general and memory efficient episodic training scheme that enables meta-training on large tasks composed of large images on a single GPU. We achieve this by observing that the gradients for a task can be decomposed into a sum of gradients over the task's training images. This enables us to perform a forward pass on a task's entire training set but realize significant memory savings by back-propagating only a random subset of these images which we show is an unbiased approximation of the full gradient. We use LITE to train meta-learners and demonstrate new state-of-the-art accuracy on the real-world ORBIT benchmark and 3 of the 4 parts of the challenging VTAB+MD benchmark relative to leading meta-learners. LITE also enables meta-learners to be competitive with transfer learning approaches but at a fraction of the test-time computational cost, thus serving as a counterpoint to the recent narrative that transfer learning is all you need for few-shot classification.",
    "authors": [
      "Bronskill, John",
      "Massiceti, Daniela",
      "Patacchiola, Massimiliano",
      "Hofmann, Katja",
      "Nowozin, Sebastian",
      "Turner, Richard"
    ]
  },
  {
    "id": "cc225865b743ecc91c4743259813f604",
    "title": "On the Power of Differentiable Learning versus PAC and SQ Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cc225865b743ecc91c4743259813f604-Paper.pdf",
    "abstract": "We study the power of learning via mini-batch stochastic gradient descent (SGD) on the loss of a differentiable model or neural network, and ask what learning problems can be learnt using this paradigm. We show that SGD can always simulate\u00a0learning with statistical queries (SQ), but its ability to go beyond that depends on the precision $\\rho$ of the gradients and the minibatch size $b$. With fine enough precision relative to minibatch size, namely when $b \\rho$ is small enough, SGD can go beyond SQ learning and simulate any sample-based learning algorithm and thus its learning power is equivalent to that of PAC learning;\u00a0this extends prior work that achieved this result for $b=1$.\u00a0Moreover,\u00a0with polynomially many bits of precision (i.e. when $\\rho$ is exponentially small), SGD can simulate PAC learning regardless of the batch size. On the other hand, when $b \\rho^2$ is large enough, the power of SGD is equivalent to that of SQ learning.",
    "authors": [
      "Abbe, Emmanuel",
      "Kamath, Pritish",
      "Malach, Eran",
      "Sandon, Colin",
      "Srebro, Nathan"
    ]
  },
  {
    "id": "cc298d5bc587e1b650f80e10449ee9d5",
    "title": "Can we globally optimize cross-validation loss? Quasiconvexity in ridge regression",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cc298d5bc587e1b650f80e10449ee9d5-Paper.pdf",
    "abstract": "Models like LASSO and ridge regression are extensively used in practice due to their interpretability, ease of use, and strong theoretical guarantees. Cross-validation (CV) is widely used for hyperparameter tuning in these models, but do practical methods minimize the true out-of-sample loss? A recent line of research promises to show that the optimum of the CV loss matches the optimum of the out-of-sample loss (possibly after simple corrections). It remains to show how tractable it is to minimize the CV loss.In the present paper, we show that, in the case of ridge regression, the CV loss may fail to be quasiconvex and thus may have multiple local optima. We can guarantee that the CV loss is quasiconvex in at least one case: when the spectrum of the covariate matrix is nearly flat and the noise in the observed responses is not too high. More generally, we show that quasiconvexity status is independent of many properties of the observed data (response norm, covariate-matrix right singular vectors and singular-value scaling) and has a complex dependence on the few that remain. We empirically confirm our theory using simulated experiments.",
    "authors": [
      "Stephenson, Will",
      "Frangella, Zachary",
      "Udell, Madeleine",
      "Broderick, Tamara"
    ]
  },
  {
    "id": "cc3f5463bc4d26bc38eadc8bcffbc654",
    "title": "Adaptive Proximal Gradient Methods for Structured Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cc3f5463bc4d26bc38eadc8bcffbc654-Paper.pdf",
    "abstract": "We consider the training of structured neural networks where the regularizer can be non-smooth and possibly non-convex. While popular machine learning libraries have resorted to stochastic (adaptive) subgradient approaches, the use of proximal gradient methods in the stochastic setting has been little explored and warrants further study, in particular regarding the incorporation of adaptivity. Towards this goal, we present a general framework of stochastic proximal gradient descent methods that allows for arbitrary positive preconditioners and lower semi-continuous regularizers. We derive two important instances of our framework: (i) the first proximal version of \\textsc{Adam}, one of the most popular adaptive SGD algorithm, and (ii) a revised version of ProxQuant for quantization-specific regularizers, which improves upon the original approach by incorporating the effect of preconditioners in the proximal mapping computations. We provide convergence guarantees for our framework and show that adaptive gradient methods can have faster convergence in terms of constant than vanilla SGD for sparse data. Lastly, we demonstrate the superiority of stochastic proximal methods compared to subgradient-based approaches via extensive experiments. Interestingly, our results indicate that the benefit of proximal approaches over sub-gradient counterparts is more pronounced for non-convex regularizers than for convex ones.",
    "authors": [
      "Yun, Jihun",
      "Lozano, Aurelie C.",
      "Yang, Eunho"
    ]
  },
  {
    "id": "cc4af25fa9d2d5c953496579b75f6f6c",
    "title": "Discovering and Achieving Goals via World Models",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cc4af25fa9d2d5c953496579b75f6f6c-Paper.pdf",
    "abstract": "How can artificial agents learn to solve many diverse tasks in complex visual environments without any supervision? We decompose this question into two challenges: discovering new goals and learning to reliably achieve them. Our proposed agent, Latent Explorer Achiever (LEXA), addresses both challenges by learning a world model from image inputs and using it to train an explorer and an achiever policy via imagined rollouts. Unlike prior methods that explore by reaching previously visited states, the explorer plans to discover unseen surprising states through foresight, which are then used as diverse targets for the achiever to practice. After the unsupervised phase, LEXA solves tasks specified as goal images zero-shot without any additional learning. LEXA substantially outperforms previous approaches to unsupervised goal reaching, both on prior benchmarks and on a new challenging benchmark with 40 test tasks spanning across four robotic manipulation and locomotion domains. LEXA further achieves goals that require interacting with multiple objects in sequence. Project page: https://orybkin.github.io/lexa/",
    "authors": [
      "Mendonca, Russell",
      "Rybkin, Oleh",
      "Daniilidis, Kostas",
      "Hafner, Danijar",
      "Pathak, Deepak"
    ]
  },
  {
    "id": "cc7e2b878868cbae992d1fb743995d8f",
    "title": "Understanding and Improving Early Stopping for Learning with Noisy Labels",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cc7e2b878868cbae992d1fb743995d8f-Paper.pdf",
    "abstract": "The memorization effect of deep neural network (DNN) plays a pivotal role in many state-of-the-art label-noise learning methods.  To exploit this property, the early stopping trick, which stops the optimization at the early stage of training, is usually adopted. Current methods generally decide the early stopping point by considering a DNN as a whole. However, a DNN can be considered as a composition of a series of layers, and we find that the latter layers in a DNN are much more sensitive to label noise, while their former counterparts are quite robust. Therefore, selecting a stopping point for the whole network may make different DNN layers antagonistically affect each other, thus degrading the final performance. In this paper, we propose to separate a DNN into different parts and progressively train them to address this problem. Instead of the early stopping which trains a whole DNN all at once, we initially train former DNN layers by optimizing the DNN with a relatively large number of epochs. During training, we progressively train the latter DNN layers by using a smaller number of epochs with the preceding layers fixed to counteract the impact of noisy labels. We term the proposed method as progressive early stopping (PES). Despite its simplicity, compared with the traditional early stopping, PES can help to obtain more promising and stable results. Furthermore, by combining PES with existing approaches on noisy label training, we achieve state-of-the-art performance on image classification benchmarks. The code is made public at https://github.com/tmllab/PES.",
    "authors": [
      "Bai, Yingbin",
      "Yang, Erkun",
      "Han, Bo",
      "Yang, Yanhua",
      "Li, Jiatong",
      "Mao, Yinian",
      "Niu, Gang",
      "Liu, Tongliang"
    ]
  },
  {
    "id": "cc8090c4d2791cdd9cd2cb3c24296190",
    "title": "Distributionally Robust Imitation Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cc8090c4d2791cdd9cd2cb3c24296190-Paper.pdf",
    "abstract": "We consider the imitation learning problem of learning a policy in a Markov Decision Process (MDP) setting where the reward function is not given, but demonstrations from experts are available. Although the goal of imitation learning is to learn a policy that produces behaviors nearly as good as the experts\u2019 for a desired task, assumptions of consistent optimality for demonstrated behaviors are often violated in practice. Finding a policy that is distributionally robust against noisy demonstrations based on an adversarial construction potentially solves this problem by avoiding optimistic generalizations of the demonstrated data. This paper studies Distributionally Robust Imitation Learning (DRoIL) and establishes a close connection between DRoIL and Maximum Entropy Inverse Reinforcement Learning. We show that DRoIL can be seen as a framework that maximizes a generalized concept of entropy. We develop a novel approach to transform the objective function into a convex optimization problem over a polynomial number of variables for a class of loss functions that are additive over state and action spaces. Our approach lets us optimize both stationary and non-stationary policies and, unlike prevalent previous methods, it does not require repeatedly solving an inner reinforcement learning problem. We experimentally show the significant benefits of DRoIL\u2019s new optimization method on synthetic data and a highway driving environment.",
    "authors": [
      "Bashiri, Mohammad Ali",
      "Ziebart, Brian",
      "Zhang, Xinhua"
    ]
  },
  {
    "id": "cc9b3c69b56df284846bf2432f1cba90",
    "title": "On the Power of Edge Independent Graph Models",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cc9b3c69b56df284846bf2432f1cba90-Paper.pdf",
    "abstract": "Why do many modern neural-network-based graph generative models fail to reproduce typical real-world network characteristics, such as high triangle density?  In this work we study the limitations  of $edge\\ independent\\ random\\ graph\\ models$, in which  each edge is added to the graph independently with some probability. Such models include both the classic Erdos-Renyi and stochastic block models, as well as  modern generative models such as NetGAN, variational graph autoencoders, and CELL.  We prove that subject to a $bounded\\  overlap$ condition, which ensures that the model does not simply memorize a single graph, edge independent models are inherently limited in their ability to generate graphs with high triangle and other subgraph densities. Notably, such high densities are known to appear in real-world social networks and other graphs. We complement our negative results with a simple generative model that balances overlap and accuracy, performing comparably to more complex models in reconstructing many graph statistics. ",
    "authors": [
      "Chanpuriya, Sudhanshu",
      "Musco, Cameron",
      "Sotiropoulos, Konstantinos",
      "Tsourakakis, Charalampos"
    ]
  },
  {
    "id": "cca289d2a4acd14c1cd9a84ffb41dd29",
    "title": "Stochastic Online Linear Regression: the Forward Algorithm to Replace Ridge",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cca289d2a4acd14c1cd9a84ffb41dd29-Paper.pdf",
    "abstract": "We consider the problem of online linear regression in the stochastic setting. We derive high probability regret bounds for online $\\textit{ridge}$ regression and the $\\textit{forward}$ algorithm. This enables us to compare online regression algorithms more accurately and eliminate assumptions of bounded observations and predictions. Our study advocates for the use of the forward algorithm in lieu of ridge due to its enhanced bounds and robustness to the regularization parameter. Moreover, we explain how to integrate it in algorithms involving linear function approximation to remove a boundedness assumption without deteriorating theoretical bounds. We showcase this modification in linear bandit settings where it yields improved regret bounds. Last, we provide numerical experiments to illustrate our results and endorse our intuitions.",
    "authors": [
      "Ouhamma, Reda",
      "Maillard, Odalric-Ambrym",
      "Perchet, Vianney"
    ]
  },
  {
    "id": "ccb421d5f36c5a412816d494b15ca9f6",
    "title": "Dr Jekyll & Mr Hyde: the strange case of off-policy policy updates",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ccb421d5f36c5a412816d494b15ca9f6-Paper.pdf",
    "abstract": "The policy gradient theorem states that the policy should only be updated in states that are visited by the current policy, which leads to insufficient planning in the off-policy states, and thus to convergence to suboptimal policies. We tackle this planning issue by extending the policy gradient theory to policy updates with respect to any state density. Under these generalized policy updates, we show convergence to optimality under a necessary and sufficient condition on the updates\u2019 state densities, and thereby solve the aforementioned planning issue. We also prove asymptotic convergence rates that significantly improve those in the policy gradient literature. To implement the principles prescribed by our theory, we propose an agent, Dr Jekyll & Mr Hyde (J&H), with a double personality: Dr Jekyll purely exploits while Mr Hyde purely explores. J&H\u2019s independent policies allow to record two separate replay buffers: one on-policy (Dr Jekyll\u2019s) and one off-policy (Mr Hyde\u2019s), and therefore to update J&H\u2019s models with a mixture of on-policy and off-policy updates. More than an algorithm, J&H defines principles for actor-critic algorithms to satisfy the requirements we identify in our analysis. We extensively test on finite MDPs where J&H demonstrates a superior ability to recover from converging to a suboptimal policy without impairing its speed of convergence. We also implement a deep version of the algorithm and test it on a simple problem where it shows promising results.",
    "authors": [
      "Laroche, Romain",
      "Tachet des Combes, Remi"
    ]
  },
  {
    "id": "ccce2fab7336b8bc8362d115dec2d5a2",
    "title": "Understanding Adaptive, Multiscale Temporal Integration In Deep Speech Recognition Systems",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ccce2fab7336b8bc8362d115dec2d5a2-Paper.pdf",
    "abstract": "Natural signals such as speech are hierarchically structured across many different timescales, spanning tens (e.g., phonemes) to hundreds (e.g., words) of milliseconds, each of which is highly variable and context-dependent. While deep neural networks (DNNs) excel at recognizing complex patterns from natural signals, relatively little is known about how DNNs flexibly integrate across multiple timescales. Here, we show how a recently developed method for studying temporal integration in biological neural systems \u2013 the temporal context invariance (TCI) paradigm \u2013 can be used to understand temporal integration in DNNs. The method is simple: we measure responses to a large number of stimulus segments presented in two different contexts and estimate the smallest segment duration needed to achieve a context invariant response. We applied our method to understand how the popular DeepSpeech2 model learns to integrate across time in speech. We find that nearly all of the model units, even in recurrent layers, have a compact integration window within which stimuli substantially alter the response and outside of which stimuli have little effect. We show that training causes these integration windows to shrink at early layers and expand at higher layers, creating a hierarchy of integration windows across the network. Moreover, by measuring integration windows for time-stretched/compressed speech, we reveal a transition point, midway through the trained network, where integration windows become yoked to the duration of stimulus structures (e.g., phonemes or words) rather than absolute time. Similar phenomena were observed in a purely recurrent and purely convolutional network although structure-yoked integration was more prominent in the recurrent network. These findings suggest that deep speech recognition systems use a common motif to encode the hierarchical structure of speech: integrating across short, time-yoked windows at early layers and long, structure-yoked windows at later layers. Our method provides a straightforward and general-purpose toolkit for understanding temporal integration in black-box machine learning models.",
    "authors": [
      "Keshishian, Menoua",
      "Norman-Haignere, Samuel",
      "Mesgarani, Nima"
    ]
  },
  {
    "id": "ccdf3864e2fa9089f9eca4fc7a48ea0a",
    "title": "VidLanKD: Improving Language Understanding via Video-Distilled Knowledge Transfer",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ccdf3864e2fa9089f9eca4fc7a48ea0a-Paper.pdf",
    "abstract": "Since visual perception can give rich information beyond text descriptions for world understanding, there has been increasing interest in leveraging visual grounding for language learning. Recently, vokenization (Tan and Bansal, 2020) has attracted attention by using the predictions of a text-to-image retrieval model as labels for language model supervision. Despite its success, the method suffers from approximation error of using finite image labels and the lack of vocabulary diversity of a small image-text dataset. To overcome these limitations, we present VidLanKD, a video-language knowledge distillation method for improving language understanding. We train a multi-modal teacher model on a video-text dataset, and then transfer its knowledge to a student language model with a text dataset. To avoid approximation error, we propose to use different knowledge distillation objectives. In addition, the use of a large-scale video-text dataset helps learn diverse and richer vocabularies. In our experiments, VidLanKD achieves consistent improvements over text-only language models and vokenization models, on several downstream language understanding tasks including GLUE, SQuAD, and SWAG. We also demonstrate the improved world knowledge, physical reasoning, and temporal reasoning capabilities of our model by evaluating on the GLUE-diagnostics, PIQA, and TRACIE datasets. Lastly, we present comprehensive ablation studies as well as visualizations of the learned text-to-video grounding results of our teacher and student language models.",
    "authors": [
      "Tang, Zineng",
      "Cho, Jaemin",
      "Tan, Hao",
      "Bansal, Mohit"
    ]
  },
  {
    "id": "ccf8111910291ba472b385e9c5f59099",
    "title": "Detecting Individual Decision-Making Style: Exploring Behavioral Stylometry in Chess",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ccf8111910291ba472b385e9c5f59099-Paper.pdf",
    "abstract": "The advent of machine learning models that surpass human decision-making ability in complex domains has initiated a movement towards building AI systems that interact with humans. Many building blocks are essential for this activity, with a central one being the algorithmic characterization of human behavior. While much of the existing work focuses on aggregate human behavior, an important long-range goal is to develop behavioral models that specialize to individual people and can differentiate among them.To formalize this process, we study the problem of behavioral stylometry, in which the task is to identify a decision-maker from their decisions alone. We present a transformer-based approach to behavioral stylometry in the context of chess, where one attempts to identify the player who played a set of games. Our method operates in a few-shot classification framework, and can correctly identify a player from among thousands of candidate players with 98% accuracy given only 100 labeled games. Even when trained on amateur play, our method generalises to out-of-distribution samples of Grandmaster players, despite the dramatic differences between amateur and world-class players. Finally, we consider more broadly what our resulting embeddings reveal about human style in chess, as well as the potential ethical implications of powerful methods for identifying individuals from behavioral data. ",
    "authors": [
      "McIlroy-Young, Reid",
      "Wang, Yu",
      "Sen, Siddhartha",
      "Kleinberg, Jon",
      "Anderson, Ashton"
    ]
  },
  {
    "id": "cd0b43eac0392accf3624b7372dec36e",
    "title": "Coupled Gradient Estimators for Discrete Latent Variables",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cd0b43eac0392accf3624b7372dec36e-Paper.pdf",
    "abstract": "Training models with discrete latent variables is challenging due to the high variance of unbiased gradient estimators. While low-variance reparameterization gradients of a continuous relaxation can provide an effective solution, a continuous relaxation is not always available or tractable. Dong et al. (2020) and Yin et al. (2020) introduced a performant estimator that does not rely on continuous relaxations; however, it is limited to binary random variables. We introduce a novel derivation of their estimator based on importance sampling and statistical couplings, which we extend to the categorical setting. Motivated by the construction of a stick-breaking coupling, we introduce gradient estimators based on reparameterizing categorical variables as sequences of binary variables and Rao-Blackwellization. In systematic experiments, we show that our proposed categorical gradient estimators provide state-of-the-art performance, whereas even with additional Rao-Blackwellization previous estimators (Yin et al., 2019) underperform a simpler REINFORCE with a leave-one-out-baseline estimator (Kool et al., 2019).",
    "authors": [
      "Dong, Zhe",
      "Mnih, Andriy",
      "Tucker, George"
    ]
  },
  {
    "id": "cd3afef9b8b89558cd56638c3631868a",
    "title": "AutoGEL: An Automated Graph Neural Network with Explicit Link Information",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cd3afef9b8b89558cd56638c3631868a-Paper.pdf",
    "abstract": "Recently, Graph Neural Networks (GNNs) have gained popularity in a variety of real-world scenarios. Despite the great success, the architecture design of GNNs heavily relies on manual labor. Thus, automated graph neural network (AutoGNN) has attracted interest and attention from the research community, which makes significant performance improvements in recent years. However, existing AutoGNN works mainly adopt an implicit way to model and leverage the link information in the graphs, which is not well regularized to the link prediction task on graphs, and limits the performance of AutoGNN for other graph tasks. In this paper, we present a novel AutoGNN work that explicitly models the link information, abbreviated to AutoGEL. In such a way, AutoGEL can handle the link prediction task and improve the performance of AutoGNNs on the node classification and graph classification task. Moreover, AutoGEL proposes a novel search space containing various design dimensions at both intra-layer and inter-layer designs and adopts a more robust differentiable search algorithm to further improve efficiency and effectiveness. Experimental results on benchmark data sets demonstrate the superiority of AutoGEL on several tasks.",
    "authors": [
      "Wang, Zhili",
      "DI, Shimin",
      "Chen, Lei "
    ]
  },
  {
    "id": "cd755a6c6b699f3262bcc2aa46ab507e",
    "title": "RL for Latent MDPs: Regret Guarantees and a Lower Bound",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cd755a6c6b699f3262bcc2aa46ab507e-Paper.pdf",
    "abstract": "In this work, we consider the regret minimization problem for reinforcement learning in latent Markov Decision Processes (LMDP). In an LMDP, an MDP is randomly drawn from a set of $M$ possible MDPs at the beginning of the interaction, but the identity of the chosen MDP is not revealed to the agent. We first show that a general instance of LMDPs requires at least $\\Omega((SA)^M)$ episodes to even approximate the optimal policy. Then, we consider sufficient assumptions under which learning good policies requires polynomial number of episodes. We show that the key link is a notion of separation between the MDP system dynamics. With sufficient separation, we provide an efficient algorithm with local guarantee, {\\it i.e.,} providing a sublinear regret guarantee when we are given a good initialization. Finally, if we are given standard statistical sufficiency assumptions common in the Predictive State Representation (PSR) literature (e.g., \\cite{boots2011online}) and a reachability assumption, we show that the need for initialization can be removed. ",
    "authors": [
      "Kwon, Jeongyeol",
      "Efroni, Yonathan",
      "Caramanis, Constantine",
      "Mannor, Shie"
    ]
  },
  {
    "id": "cd7c230fc5deb01ff5f7b1be1acef9cf",
    "title": "Adaptive Sampling for Minimax Fair Classification",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cd7c230fc5deb01ff5f7b1be1acef9cf-Paper.pdf",
    "abstract": "Machine learning models trained on uncurated datasets can often end up adversely affecting inputs belonging to underrepresented groups. To address this issue, we consider the problem of adaptively constructing training sets which allow us to learn classifiers that are fair in a {\\em minimax} sense. We first propose an adaptive sampling algorithm based on the principle of \\emph{optimism}, and derive theoretical bounds on its performance. We also propose heuristic extensions of this algorithm suitable for application to large scale, practical problems. Next, by deriving algorithm independent lower-bounds for a specific class of problems, we show that the performance achieved by our adaptive scheme cannot be improved in general. We then validate the benefits of adaptively constructing training sets via experiments on synthetic tasks with logistic regression classifiers, as well as on several real-world tasks using convolutional neural networks (CNNs).",
    "authors": [
      "Shekhar, Shubhanshu",
      "Fields, Greg",
      "Ghavamzadeh, Mohammad",
      "Javidi, Tara"
    ]
  },
  {
    "id": "cd81cfd0a3397761fac44ddbe5ec3349",
    "title": "Structured in Space, Randomized in Time: Leveraging Dropout in RNNs for Efficient Training",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cd81cfd0a3397761fac44ddbe5ec3349-Paper.pdf",
    "abstract": "Recurrent Neural Networks (RNNs), more specifically their Long Short-Term Memory (LSTM) variants, have been widely used as a deep learning tool for tackling sequence-based learning tasks in text and speech. Training of such LSTM applications is computationally intensive due to the recurrent nature of hidden state computation that repeats for each time step. While sparsity in Deep Neural Nets has been widely seen as an opportunity for reducing computation time in both training and inference phases, the usage of non-ReLU activation in LSTM RNNs renders the opportunities for such dynamic sparsity associated with neuron activation and gradient values to be limited or non-existent. In this work, we identify dropout induced sparsity for LSTMs as a suitable mode of computation reduction. Dropout is a widely used regularization mechanism, which randomly drops computed neuron values during each iteration of training. We propose to structure dropout patterns, by dropping out the same set of physical neurons within a batch, resulting in column (row) level hidden state sparsity, which are well amenable to computation reduction at run-time in general-purpose SIMD hardware as well as systolic arrays. We provide a detailed analysis of how the dropout-induced sparsity propagates through the different stages of network training and how it can be leveraged in each stage. More importantly, our proposed approach works as a direct replacement for existing dropout-based application settings. We conduct our experiments for three representative NLP tasks: language modelling on the PTB dataset, OpenNMT based machine translation using the IWSLT De-En and En-Vi datasets, and named entity recognition sequence labelling using the CoNLL-2003 shared task. We demonstrate that our proposed approach can be used to translate dropout-based computation reduction into reduced training time, with improvement ranging from 1.23$\\times$ to 1.64$\\times$, without sacrificing the target metric. ",
    "authors": [
      "Sarma, Anup",
      "Singh, Sonali",
      "Jiang, Huaipan",
      "Zhang, Rui",
      "Kandemir, Mahmut",
      "Das, Chita"
    ]
  },
  {
    "id": "cdd0500dc0ef6682fa6ec6d2e6b577c4",
    "title": "Variational Continual Bayesian Meta-Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cdd0500dc0ef6682fa6ec6d2e6b577c4-Paper.pdf",
    "abstract": "Conventional meta-learning considers a set of tasks from a stationary distribution. In contrast, this paper focuses on a more complex online setting, where tasks arrive sequentially and follow a non-stationary distribution. Accordingly, we propose a Variational Continual Bayesian Meta-Learning (VC-BML) algorithm. VC-BML maintains a Dynamic Gaussian Mixture Model for meta-parameters, with the number of component distributions determined by a Chinese Restaurant Process. Dynamic mixtures at the meta-parameter level increase the capability to adapt to diverse tasks due to a larger parameter space, alleviating the negative knowledge transfer problem. To infer posteriors of model parameters, compared to the previously used point estimation method, we develop a more robust posterior approximation method -- structured variational inference for the sake of avoiding forgetting knowledge. Experiments on tasks from non-stationary distributions show that VC-BML is superior in transferring knowledge among diverse tasks and alleviating catastrophic forgetting in an online setting.",
    "authors": [
      "Zhang, Qiang",
      "Fang, Jinyuan",
      "Meng, Zaiqiao",
      "Liang, Shangsong",
      "Yilmaz, Emine"
    ]
  },
  {
    "id": "cdf1035c34ec380218a8cc9a43d438f9",
    "title": "Recognizing Vector Graphics without Rasterization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cdf1035c34ec380218a8cc9a43d438f9-Paper.pdf",
    "abstract": "In this paper, we consider a different data format for images: vector graphics. In contrast to raster graphics which are widely used in image recognition, vector graphics can be scaled up or down into any resolution without aliasing or information loss, due to the analytic representation of the primitives in the document. Furthermore, vector graphics are able to give extra structural information on how low-level elements group together to form high level shapes or structures. These merits of graphic vectors have not been fully leveraged in existing methods.  To explore this data format, we target on the fundamental recognition tasks: object localization and classification. We propose an efficient CNN-free pipeline that does not render the graphic into pixels (i.e. rasterization), and takes textual document of the vector graphics as input, called YOLaT (You Only Look at Text). YOLaT builds multi-graphs to model the structural and spatial information in vector graphics, and a dual-stream graph neural network is proposed to detect objects from the graph. Our experiments show that by directly operating on vector graphics, YOLaT outperforms raster-graphic based object detection baselines in terms of both average precision and efficiency. Code is available at https://github.com/microsoft/YOLaT-VectorGraphicsRecognition. ",
    "authors": [
      "JIANG, XINYANG",
      "LIU, LU",
      "Shan, Caihua",
      "Shen, Yifei",
      "Dong, Xuanyi",
      "Li, Dongsheng"
    ]
  },
  {
    "id": "cdfa4c42f465a5a66871587c69fcfa34",
    "title": "On Episodes, Prototypical Networks, and Few-Shot Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cdfa4c42f465a5a66871587c69fcfa34-Paper.pdf",
    "abstract": "Episodic learning is a popular practice among researchers and practitioners interested in few-shot learning.It consists of organising training in a series of learning problems (or episodes), each divided into a small training and validation subset to mimic the circumstances encountered during evaluation.But is this always necessary?In this paper, we investigate the usefulness of episodic learning in methods which use nonparametric approaches, such as nearest neighbours, at the level of the episode.For these methods, we not only show how the constraints imposed by episodic learning are not necessary, but that they in fact lead to a data-inefficient way of exploiting training batches.We conduct a wide range of ablative experiments with Matching and Prototypical Networks, two of the most popular methods that use nonparametric approaches at the level of the episode.Their \"non-episodic'' counterparts are considerably simpler, have less hyperparameters, and improve their performance in multiple few-shot classification datasets.",
    "authors": [
      "Laenen, Steinar",
      "Bertinetto, Luca"
    ]
  },
  {
    "id": "ce4449660c6523b377b22a1dc2da5556",
    "title": "Pointwise Bounds for Distribution Estimation under Communication Constraints",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ce4449660c6523b377b22a1dc2da5556-Paper.pdf",
    "abstract": "We consider the problem of estimating a $d$-dimensional discrete distribution from its samples observed under a $b$-bit communication constraint. In contrast to most previous results that largely focus on the global minimax error, we study the local behavior of the estimation error and provide \\emph{pointwise} bounds that depend on the target distribution $p$. In particular, we show that the $\\ell_2$ error decays with $O\\left(\\frac{\\lVert p\\rVert_{1/2}}{n2^b}\\vee \\frac{1}{n}\\right)$ when $n$ is sufficiently large, hence it is governed by the \\emph{half-norm} of $p$ instead of the ambient dimension $d$. For the achievability result, we propose a two-round sequentially interactive estimation scheme that achieves this error rate uniformly over all $p$. Our scheme is based on a novel local refinement idea, where we first use a standard global minimax scheme to localize $p$ and then use the remaining samples to locally refine our estimate.We also develop a new local minimax lower bound with (almost) matching $\\ell_2$ error, showing that any interactive scheme must admit a $\\Omega\\left( \\frac{\\lVert p \\rVert_{{(1+\\delta)}/{2}}}{n2^b}\\right)$ $\\ell_2$ error for any $\\delta > 0$ when $n$ is sufficiently large. The lower bound is derived by first finding the best parametric sub-model containing $p$, and then upper bounding the quantized Fisher information under this model. Our upper and lower bounds together indicate that the $\\mathsf{H}_{1/2}(p) = \\log(\\lVert p \\rVert_{{1}/{2}})$ bits of communication is both sufficient and necessary to achieve the optimal (centralized) performance, where $\\mathsf{H}_{{1}/{2}}(p)$ is the R\\'enyi entropy of order $2$. Therefore, under the $\\ell_2$ loss, the correct measure of the local communication complexity at $p$ is its R\\'enyi entropy.",
    "authors": [
      "Chen, Wei-Ning",
      "Kairouz, Peter",
      "Ozgur, Ayfer"
    ]
  },
  {
    "id": "ce6babd060aa46c61a5777902cca78af",
    "title": "CHIP: CHannel Independence-based Pruning for Compact Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ce6babd060aa46c61a5777902cca78af-Paper.pdf",
    "abstract": "Filter pruning has been widely used for neural network compression because of its enabled practical acceleration. To date, most of the existing filter pruning works explore the importance of filters via using intra-channel information. In this paper, starting from an inter-channel perspective, we propose to perform efficient filter pruning using Channel Independence, a metric that measures the correlations among different feature maps. The less independent feature map is interpreted as containing less useful information$/$knowledge, and hence its corresponding filter can be pruned without affecting model capacity. We systematically investigate the quantification metric, measuring scheme and sensitiveness$/$reliability of channel independence in the context of filter pruning. Our evaluation results for different models on various datasets show the superior performance of our approach. Notably, on CIFAR-10 dataset our solution can bring $0.75\\%$ and $0.94\\%$ accuracy increase over baseline ResNet-56 and ResNet-110 models, respectively, and meanwhile the model size and FLOPs are reduced by  $42.8\\%$ and  $47.4\\%$ (for ResNet-56) and $48.3\\%$ and $52.1\\%$ (for ResNet-110), respectively. On ImageNet dataset, our approach can achieve $40.8\\%$ and $44.8\\%$ storage and computation reductions, respectively, with $0.15\\%$ accuracy increase over the baseline ResNet-50 model. The code is available at https://github.com/Eclipsess/CHIP_NeurIPS2021.",
    "authors": [
      "Sui, Yang",
      "Yin, Miao",
      "Xie, Yi",
      "Phan, Huy",
      "Aliari Zonouz, Saman",
      "Yuan, Bo"
    ]
  },
  {
    "id": "ceb0595112db2513b9325a85761b7310",
    "title": "Federated Split Task-Agnostic  Vision Transformer for COVID-19 CXR Diagnosis",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ceb0595112db2513b9325a85761b7310-Paper.pdf",
    "abstract": "Federated learning, which shares the weights of the neural network across clients, is gaining attention in the healthcare sector as it enables training on a large corpus of decentralized data while maintaining data privacy. For example, this enables neural network training for COVID-19 diagnosis on chest X-ray (CXR) images without collecting patient CXR data across multiple hospitals. Unfortunately, the exchange of the weights quickly consumes the network bandwidth if highly expressive network architecture is employed. So-called split learning partially solves this problem by dividing a neural network into a client and a server part, so that the client part of the network takes up less extensive computation resources and bandwidth. However, it is not clear how to find the optimal split without sacrificing the overall network performance. To amalgamate these methods and thereby maximize their distinct strengths, here we show that the Vision Transformer, a recently developed deep learning architecture with straightforward decomposable configuration, is ideally suitable for split learning without sacrificing performance. Even under the non-independent and identically distributed data distribution which emulates a real collaboration between hospitals using CXR datasets from multiple sources, the proposed framework was able to attain performance comparable to data-centralized training. In addition, the proposed framework along with heterogeneous multi-task clients also improves individual task performances including the diagnosis of COVID-19, eliminating the need for sharing large weights with innumerable parameters. Our results affirm the suitability of Transformer for collaborative learning in medical imaging and pave the way forward for future real-world implementations.",
    "authors": [
      "Park, Sangjoon",
      "Kim, Gwanghyun",
      "Kim, Jeongsol",
      "Kim, Boah",
      "Ye, Jong Chul"
    ]
  },
  {
    "id": "cec2346566ba8ecd04bfd992fd193fb3",
    "title": "Active Offline Policy Selection",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cec2346566ba8ecd04bfd992fd193fb3-Paper.pdf",
    "abstract": "This paper addresses the problem of policy selection in domains with abundant logged data, but with a restricted interaction budget. Solving this problem would enable safe evaluation and deployment of offline reinforcement learning policies in industry, robotics, and recommendation domains among others. Several off-policy evaluation (OPE) techniques have been proposed to assess the value of policies using only logged data. However, there is still a big gap between the evaluation by OPE and the full online evaluation in the real environment. Yet, large amounts of online interactions are often not possible in practice. To overcome this problem, we introduce active offline policy selection --- a novel sequential decision approach that combines logged data with online interaction to identify the best policy. This approach uses OPE estimates to warm start the online evaluation. Then, in order to utilize the limited environment interactions wisely we decide which policy to evaluate next based on a Bayesian optimization method with a kernel function that represents policy similarity. We use multiple benchmarks with a large number of candidate policies to show that the proposed approach improves upon state-of-the-art OPE estimates and pure online policy evaluation.",
    "authors": [
      "Konyushova, Ksenia",
      "Chen, Yutian",
      "Paine, Thomas",
      "Gulcehre, Caglar",
      "Paduraru, Cosmin",
      "Mankowitz, Daniel J.",
      "Denil, Misha",
      "de Freitas, Nando"
    ]
  },
  {
    "id": "cecd845e3577efdaaf24eea03af4c033",
    "title": "Unsupervised Representation Transfer for Small Networks: I Believe I Can Distill On-the-Fly",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cecd845e3577efdaaf24eea03af4c033-Paper.pdf",
    "abstract": "A current remarkable improvement of unsupervised visual representation learning is based on heavy networks with large-batch training. While recent methods have greatly reduced the gap between supervised and unsupervised performance of deep models such as ResNet-50, this development has been relatively limited for small models. In this work, we propose a novel unsupervised learning framework for small networks that combines deep self-supervised representation learning and knowledge distillation within one-phase training. In particular, a teacher model is trained to produce consistent cluster assignments between different views of the same image. Simultaneously, a student model is encouraged to mimic the prediction of on-the-fly self-supervised teacher. For effective knowledge transfer, we adopt the idea of domain classifier so that student training is guided by discriminative features invariant to the representational space shift between teacher and student. We also introduce a network driven multi-view generation paradigm to capture rich feature information contained in the network itself. Extensive experiments show that our student models surpass state-of-the-art offline distilled networks even from stronger self-supervised teachers as well as top-performing self-supervised models. Notably, our ResNet-18, trained with ResNet-50 teacher, achieves 68.3% ImageNet Top-1 accuracy on frozen feature linear evaluation, which is only 1.5% below the supervised baseline.",
    "authors": [
      "Choi, Hee Min",
      "Kang, Hyoa",
      "Oh, Dokwan"
    ]
  },
  {
    "id": "cf004fdc76fa1a4f25f62e0eb5261ca3",
    "title": "Understanding Bandits with Graph Feedback",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cf004fdc76fa1a4f25f62e0eb5261ca3-Paper.pdf",
    "abstract": "The bandit problem with graph feedback, proposed in [Mannor and Shamir, NeurIPS 2011], is modeled by a directed graph $G=(V,E)$ where $V$ is the collection of bandit arms, and once an arm is triggered, all its incident arms are observed. A fundamental question is how the structure of the graph affects the min-max regret. We propose the notions of the fractional weak domination number $\\delta^*$ and the $k$-packing independence number capturing upper bound and lower bound for the regret respectively.  We show that the two notions are inherently connected via aligning them with the linear program of the weakly dominating set and its dual --- the fractional vertex packing set respectively. Based on this connection, we utilize the strong duality theorem to prove a general regret upper bound $O\\left(\\left(\\delta^*\\log  |V|\\right)^{\\frac{1}{3}}T^{\\frac{2}{3}}\\right)$ and a lower bound $\\Omega\\left(\\left(\\delta^*/\\alpha\\right)^{\\frac{1}{3}}T^{\\frac{2}{3}}\\right)$ where $\\alpha$ is the integrality gap of the dual linear program. Therefore, our bounds are tight up to a $\\left(\\log |V|\\right)^{\\frac{1}{3}}$ factor on graphs with bounded integrality gap for the vertex packing problem including trees and graphs with bounded degree. Moreover, we show that for several special families of graphs, we can get rid of the $\\left(\\log |V|\\right)^{\\frac{1}{3}}$ factor and establish optimal regret.",
    "authors": [
      "Chen, Houshuang",
      "Huang, zengfeng",
      "Li, Shuai",
      "Zhang, Chihao"
    ]
  },
  {
    "id": "cf0d02ec99e61a64137b8a2c3b03e030",
    "title": "Information-theoretic generalization bounds for black-box learning algorithms",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cf0d02ec99e61a64137b8a2c3b03e030-Paper.pdf",
    "abstract": "We derive information-theoretic generalization bounds for supervised learning algorithms based on the information contained in predictions rather than in the output of the training algorithm. These bounds improve over the existing information-theoretic bounds, are applicable to a wider range of algorithms, and solve two key challenges: (a) they give meaningful results for deterministic algorithms and (b) they are significantly easier to estimate. We show experimentally that the proposed bounds closely follow the generalization gap in practical scenarios for deep learning.",
    "authors": [
      "Harutyunyan, Hrayr",
      "Raginsky, Maxim",
      "Ver Steeg, Greg",
      "Galstyan, Aram"
    ]
  },
  {
    "id": "cf1f78fe923afe05f7597da2be7a3da8",
    "title": "Trash or Treasure? An Interactive Dual-Stream Strategy for Single Image Reflection Separation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cf1f78fe923afe05f7597da2be7a3da8-Paper.pdf",
    "abstract": "Single image reflection separation (SIRS), as a representative blind source separation task, aims to recover two layers, $\\textit{i.e.}$, transmission and reflection, from one mixed observation, which is challenging due to the highly ill-posed nature. Existing deep learning based solutions typically restore the target layers individually, or with some concerns at the end of the output, barely taking into account the interaction across the two streams/branches. In order to utilize information more efficiently, this work presents a general yet simple interactive strategy, namely $\\textit{your trash is my treasure}$ (YTMT), for constructing dual-stream decomposition networks. To be specific, we explicitly enforce the two streams to communicate with each other block-wisely. Inspired by the additive property between the two components, the interactive path can be easily built via transferring, instead of discarding, deactivated information by the ReLU rectifier from one stream to the other. Both ablation studies and experimental results on widely-used SIRS datasets are conducted to demonstrate the efficacy of YTMT, and reveal its superiority over other state-of-the-art alternatives. The implementation is quite simple and our code is publicly available at https://github.com/mingcv/YTMT-Strategy.",
    "authors": [
      "Hu, Qiming",
      "Guo, Xiaojie"
    ]
  },
  {
    "id": "cf2f3fe19ffba462831d7f037a07fc83",
    "title": "Rot-Pro: Modeling Transitivity by Projection in Knowledge Graph Embedding",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cf2f3fe19ffba462831d7f037a07fc83-Paper.pdf",
    "abstract": "Knowledge graph embedding models learn the representations of entities and relations in the knowledge graphs for predicting missing links (relations) between entities. Their effectiveness are deeply affected by the ability of modeling and inferring different relation patterns such as symmetry, asymmetry, inversion, composition and transitivity. Although existing models are already able to model many of these relations patterns, transitivity, a very common relation pattern, is still not been fully supported. In this paper, we first theoretically show that the transitive relations can be modeled with projections. We then propose the Rot-Pro model which combines the projection and relational rotation together. We prove that Rot-Pro can infer all the above relation patterns. Experimental results show that the proposed Rot-Pro model  effectively learns the transitivity pattern and achieves the state-of-the-art results on the link prediction task in the datasets containing transitive relations.",
    "authors": [
      "Song, Tengwei",
      "Luo, Jie",
      "Huang, Lei"
    ]
  },
  {
    "id": "cf708fc1decf0337aded484f8f4519ae",
    "title": "Planning from Pixels in Environments with Combinatorially Hard Search Spaces",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cf708fc1decf0337aded484f8f4519ae-Paper.pdf",
    "abstract": "The ability to form complex plans based on raw visual input is a litmus test for current capabilities of artificial intelligence, as it requires a seamless combination of visual processing and abstract algorithmic execution, two traditionally separate areas of computer science. A recent surge of interest in this field brought advances that yield good performance in tasks ranging from arcade games to continuous control; these methods however do not come without significant issues, such as limited generalization capabilities and difficulties when dealing with combinatorially hard planning instances. Our contribution is two-fold: (i) we present a method that learns to represent its environment as a latent graph and leverages state reidentification to reduce the complexity of finding a good policy from exponential to linear (ii) we introduce a set of lightweight environments with an underlying discrete combinatorial structure in which planning is challenging even for humans. Moreover, we show that our methods achieves strong empirical generalization to variations in the environment, even across highly disadvantaged regimes, such as \u201cone-shot\u201d planning, or in an offline RL paradigm which only provides low-quality trajectories.",
    "authors": [
      "Bagatella, Marco",
      "Ol\u0161\u00e1k, Miroslav",
      "Rol\u00ednek, Michal",
      "Martius, Georg"
    ]
  },
  {
    "id": "cf77e1f8490495e9f8dedceaf372f969",
    "title": "PLUGIn: A simple algorithm for inverting generative models with recovery guarantees",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cf77e1f8490495e9f8dedceaf372f969-Paper.pdf",
    "abstract": "We consider the problem of recovering an unknown latent code vector under a known generative model. For a $d$-layer deep generative network $\\mathcal{G}:\\mathbb{R}^{n_0}\\rightarrow \\mathbb{R}^{n_d}$ with ReLU activation functions, let the observation be $\\mathcal{G}(x)+\\epsilon$ where $\\epsilon$ is noise. We introduce a simple novel algorithm, Partially Linearized Update for Generative Inversion (PLUGIn), to estimate $x$ (and thus $\\mathcal{G}(x)$). We prove that, when weights are Gaussian and layer widths $n_i \\gtrsim 5^i n_0$ (up to log factors), the algorithm converges geometrically to a neighbourhood of $x$ with high probability. Note the inequality on layer widths allows $n_i>n_{i+1}$ when $i\\geq 1$. To our knowledge, this is the first such result for networks with some contractive layers. After a sufficient number of iterations, the estimation errors for both $x$ and $\\mathcal{G}(x)$ are at most in the order of $\\sqrt{4^dn_0/n_d} \\|\\epsilon\\|$. Thus, the algorithm can denoise when the expansion ratio $n_d/n_0$ is large. Numerical experiments on synthetic data and real data are provided to validate our theoretical results and to illustrate that the algorithm can effectively remove artifacts in an image.",
    "authors": [
      "Joshi, Babhru",
      "Li, Xiaowei",
      "Plan, Yaniv",
      "Yilmaz, Ozgur"
    ]
  },
  {
    "id": "cf79ae6addba60ad018347359bd144d2",
    "title": "Modular Gaussian Processes for Transfer Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cf79ae6addba60ad018347359bd144d2-Paper.pdf",
    "abstract": "We present a framework for transfer learning based on modular variational Gaussian processes (GP). We develop a module-based method that having a dictionary of well fitted GPs, each model being characterised by its hyperparameters, pseudo-inputs and their corresponding posterior densities, one could build ensemble GP models without revisiting any data. Our method avoids undesired data centralisation, reduces rising computational costs and allows the transfer of learned uncertainty metrics after training. We exploit the augmentation of high-dimensional integral operators based on the Kullback-Leibler divergence between stochastic processes to introduce an efficient lower bound under all the sparse variational GPs, with different complexity and even likelihood distribution. The method is also valid for multi-output GPs, learning correlations a posteriori between independent modules. Extensive results illustrate the usability of our framework in large-scale and multi-task experiments, also compared with the exact inference methods in the literature.",
    "authors": [
      "Moreno-Mu\u00f1oz, Pablo",
      "Artes, Antonio",
      "\u00c1lvarez, Mauricio"
    ]
  },
  {
    "id": "cf866614b6b18cda13fe699a3a65661b",
    "title": "Neural Human Performer: Learning Generalizable Radiance Fields for Human Performance Rendering",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cf866614b6b18cda13fe699a3a65661b-Paper.pdf",
    "abstract": "In this paper, we aim at synthesizing a free-viewpoint video of an arbitrary human performance using sparse multi-view cameras. Recently, several works have addressed this problem by learning person-specific neural radiance fields (NeRF) to capture the appearance of a particular human. In parallel, some work proposed to use pixel-aligned features to generalize radiance fields to arbitrary new scenes and objects. Adopting such generalization approaches to humans, however, is highly challenging due to the heavy occlusions and dynamic articulations of body parts. To tackle this, we propose Neural Human Performer, a novel approach that learns generalizable neural radiance fields based on a parametric human body model for robust performance capture. Specifically, we first introduce a temporal transformer that aggregates tracked visual features based on the skeletal body motion over time. Moreover, a multi-view transformer is proposed to perform cross-attention between the temporally-fused features and the pixel-aligned features at each time step to integrate observations on the fly from multiple views. Experiments on the ZJU-MoCap and AIST datasets show that our method significantly outperforms recent generalizable NeRF methods on unseen identities and poses.",
    "authors": [
      "Kwon, Youngjoong",
      "Kim, Dahun",
      "Ceylan, Duygu",
      "Fuchs, Henry"
    ]
  },
  {
    "id": "cf8c9be2a4508a24ae92c9d3d379131d",
    "title": "Locally differentially private estimation of functionals of discrete distributions",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cf8c9be2a4508a24ae92c9d3d379131d-Paper.pdf",
    "abstract": "We study the  problem of estimating non-linear functionals of discrete distributions in the context of local differential privacy. The initial data $x_1,\\ldots,x_n \\in[K]$ are supposed i.i.d. and distributed according to an unknown discrete distribution $p = (p_1,\\ldots,p_K)$. Only $\\alpha$-locally differentially private (LDP) samples $z_1,...,z_n$ are publicly available, where the term 'local' means that each $z_i$ is produced using one individual attribute $x_i$. We exhibit privacy mechanisms (PM) that are interactive (i.e. they are allowed to use already published confidential data) or non-interactive. We describe the behavior of the quadratic risk for estimating the power sum functional $F_{\\gamma} = \\sum_{k=1}^K p_k^{\\gamma}$, $\\gamma >0$ as a function of $K, \\, n$ and $\\alpha$. In the non-interactive case, we study twol plug-in type estimators of $F_{\\gamma}$, for all $\\gamma >0$, that are similar to the MLE analyzed by Jiao et al. (2017) in the multinomial model. However, due to the privacy constraint the rates we attain are slower and similar to those obtained in the Gaussian model by Collier et al. (2020). In the sequentially interactive case, we introduce for all $\\gamma >1$ a two-step procedure which attains the parametric rate $(n \\alpha^2)^{-1/2}$ when $\\gamma \\geq 2$.  We give lower bounds results over all $\\alpha-$LDP mechanisms and over all estimators using the private samples.",
    "authors": [
      "Butucea, Cristina",
      "ISSARTEL, Yann"
    ]
  },
  {
    "id": "cf9dc5e4e194fc21f397b4cac9cc3ae9",
    "title": "Asymptotics of representation learning in finite Bayesian neural networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cf9dc5e4e194fc21f397b4cac9cc3ae9-Paper.pdf",
    "abstract": "Recent works have suggested that finite Bayesian neural networks may sometimes outperform their infinite cousins because finite networks can flexibly adapt their internal representations. However, our theoretical understanding of how the learned hidden layer representations of finite networks differ from the fixed representations of infinite networks remains incomplete. Perturbative finite-width corrections to the network prior and posterior have been studied, but the asymptotics of learned features have not been fully characterized. Here, we argue that the leading finite-width corrections to the average feature kernels for any Bayesian network with linear readout and Gaussian likelihood have a largely universal form. We illustrate this explicitly for three tractable network architectures: deep linear fully-connected and convolutional networks, and networks with a single nonlinear hidden layer. Our results begin to elucidate how task-relevant learning signals shape the hidden layer representations of wide Bayesian neural networks. ",
    "authors": [
      "Zavatone-Veth, Jacob",
      "Canatar, Abdulkadir",
      "Ruben, Ben",
      "Pehlevan, Cengiz"
    ]
  },
  {
    "id": "cfa45151ccad6bf11ea146ed563f2119",
    "title": "Adaptive Ensemble Q-learning: Minimizing Estimation Bias via Error Feedback",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cfa45151ccad6bf11ea146ed563f2119-Paper.pdf",
    "abstract": "The ensemble method is a promising way to mitigate the overestimation issue in Q-learning, where multiple function approximators are used to estimate the action values. It is known that the estimation bias hinges heavily on the ensemble size (i.e., the number of  Q-function approximators used in the target), and that determining the 'right' ensemble size is highly nontrivial, because of the time-varying nature of the function approximation errors during the learning process. To tackle this challenge, we first derive an upper bound and a lower bound on the  estimation bias, based on which the ensemble size is  adapted to drive the bias to be nearly zero, thereby coping with the impact of the time-varying approximation errors accordingly. Motivated by the theoretic findings, we advocate that the ensemble method can be combined with Model Identification Adaptive Control (MIAC) for effective ensemble size adaptation. Specifically, we devise Adaptive Ensemble Q-learning (AdaEQ), a generalized ensemble method with two key steps: (a) approximation error characterization which serves as the feedback for flexibly controlling the ensemble size, and (b) ensemble size adaptation tailored towards minimizing the estimation bias.   Extensive experiments are carried out to show that AdaEQ can  improve the learning performance than the existing methods for the MuJoCo benchmark.",
    "authors": [
      "Wang, Hang",
      "Lin, Sen",
      "Zhang, Junshan"
    ]
  },
  {
    "id": "cfc5d9422f0c8f8ad796711102dbe32b",
    "title": "Domain Adaptation with Invariant Representation Learning: What Transformations to Learn?",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cfc5d9422f0c8f8ad796711102dbe32b-Paper.pdf",
    "abstract": "Unsupervised domain adaptation, as a prevalent transfer learning setting, spans many real-world applications. With the increasing representational power and applicability of neural networks, state-of-the-art domain adaptation methods make use of deep architectures to map the input features $X$ to a latent representation $Z$ that has the same marginal  distribution across domains. This has been shown to be insufficient for generating optimal representation for classification, and to find conditionally invariant representations, usually strong assumptions are needed. We provide reasoning why when the supports of the source and target data from overlap, any map of $X$ that is fixed across domains may not be suitable for domain adaptation via invariant features. Furthermore, we develop an efficient technique in which  the optimal map from $X$ to $Z$ also takes domain-specific information as input, in addition to the features $X$. By using the property of minimal changes of causal mechanisms across domains, our model also takes into account the domain-specific information to ensure that the latent representation $Z$ does not discard valuable information about $Y$. We demonstrate the efficacy of our method via synthetic and real-world data experiments. The code is available at: \\texttt{https://github.com/DMIRLAB-Group/DSAN}.",
    "authors": [
      "Stojanov, Petar",
      "Li, Zijian",
      "Gong, Mingming",
      "Cai, Ruichu",
      "Carbonell, Jaime",
      "Zhang, Kun"
    ]
  },
  {
    "id": "cfe8504bda37b575c70ee1a8276f3486",
    "title": "CSDI: Conditional Score-based Diffusion Models for Probabilistic Time Series Imputation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/cfe8504bda37b575c70ee1a8276f3486-Paper.pdf",
    "abstract": "The imputation of missing values in time series has many applications in healthcare and finance. While autoregressive models are natural candidates for time series imputation, score-based diffusion models have recently outperformed existing counterparts including autoregressive models in many tasks such as image generation and audio synthesis, and would be promising for time series imputation. In this paper, we propose Conditional Score-based Diffusion model (CSDI), a novel time series imputation method that utilizes score-based diffusion models conditioned on observed data. Unlike existing score-based approaches, the conditional diffusion model is explicitly trained for imputation and can exploit correlations between observed values. On healthcare and environmental data, CSDI improves by 40-65% over existing probabilistic imputation methods on popular performance metrics. In addition, deterministic imputation by CSDI reduces the error by 5-20% compared to the state-of-the-art deterministic imputation methods. Furthermore, CSDI can also be applied to time series interpolation and probabilistic forecasting, and is competitive with existing baselines. The code is available at https://github.com/ermongroup/CSDI.",
    "authors": [
      "Tashiro, Yusuke",
      "Song, Jiaming",
      "Song, Yang",
      "Ermon, Stefano"
    ]
  },
  {
    "id": "d010396ca8abf6ead8cacc2c2f2f26c7",
    "title": "Causal Bandits with Unknown Graph Structure",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d010396ca8abf6ead8cacc2c2f2f26c7-Paper.pdf",
    "abstract": "In causal bandit problems the action set consists of interventions on variables of a causal graph. Several researchers have recently studied such bandit problems and pointed out their practical applications. However, all existing works rely on a restrictive and impractical assumption that the learner is given full knowledge of the causal graph structure upfront. In this paper, we develop novel causal bandit algorithms without knowing the causal graph. Our algorithms work well for causal trees, causal forests and a general class of causal graphs. The regret guarantees of our algorithms greatly improve upon those of  standard multi-armed bandit (MAB) algorithms under mild conditions. Lastly, we prove our mild conditions are necessary: without them one cannot do better than standard MAB algorithms.",
    "authors": [
      "Lu, Yangyi",
      "Meisami, Amirhossein",
      "Tewari, Ambuj"
    ]
  },
  {
    "id": "d01eeca8b24321cd2fe89dd85b9beb51",
    "title": "Piper: Multidimensional Planner for DNN Parallelization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d01eeca8b24321cd2fe89dd85b9beb51-Paper.pdf",
    "abstract": "The rapid increase in sizes of state-of-the-art DNN models, and consequently the increase in the compute and memory requirements of model training, has led to the development of many execution schemes such as data parallelism, pipeline model parallelism, tensor (intra-layer) model parallelism, and various memory-saving optimizations. However, no prior work has tackled the highly complex problem of optimally partitioning the DNN computation graph across many accelerators while combining all these parallelism modes and optimizations.In this work, we introduce Piper, an efficient optimization algorithm for this problem that is based on a two-level dynamic programming approach. Our two-level approach is driven by the insight that being given tensor-parallelization techniques for individual layers (e.g., Megatron-LM's splits for transformer layers) significantly reduces the search space and makes the global problem tractable, compared to considering tensor-parallel configurations for the entire DNN operator graph.",
    "authors": [
      "Tarnawski, Jakub M.",
      "Narayanan, Deepak",
      "Phanishayee, Amar"
    ]
  },
  {
    "id": "d02e9bdc27a894e882fa0c9055c99722",
    "title": "Causal Effect Inference for Structured Treatments",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d02e9bdc27a894e882fa0c9055c99722-Paper.pdf",
    "abstract": "We address the estimation of conditional average treatment effects (CATEs) for structured treatments (e.g., graphs, images, texts). Given a weak condition on the effect, we propose the generalized Robinson decomposition, which (i) isolates the causal estimand (reducing regularization bias), (ii) allows one to plug in arbitrary models for learning, and (iii) possesses a quasi-oracle convergence guarantee under mild assumptions. In experiments with small-world and molecular graphs we demonstrate that our approach outperforms prior work in CATE estimation.",
    "authors": [
      "Kaddour, Jean",
      "Zhu, Yuchen",
      "Liu, Qi",
      "Kusner, Matt J.",
      "Silva, Ricardo"
    ]
  },
  {
    "id": "d03a857a23b5285736c4d55e0bb067c8",
    "title": "Efficient hierarchical Bayesian inference for spatio-temporal regression models in neuroimaging",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d03a857a23b5285736c4d55e0bb067c8-Paper.pdf",
    "abstract": "Several problems in neuroimaging and beyond require inference on the parameters of multi-task sparse hierarchical regression models. Examples include M/EEG inverse problems, neural encoding models for task-based fMRI analyses, and climate science. In these domains, both the model parameters to be inferred and the measurement noise may exhibit a complex spatio-temporal structure. Existing work either neglects the temporal structure or leads to computationally demanding inference schemes. Overcoming these limitations, we devise a novel flexible hierarchical Bayesian framework within which the spatio-temporal dynamics of model parameters and noise are modeled to have Kronecker product covariance structure. Inference in our framework is based on majorization-minimization optimization and has guaranteed convergence properties. Our highly efficient algorithms exploit the intrinsic Riemannian geometry of temporal autocovariance matrices. For stationary dynamics described by Toeplitz matrices, the theory of circulant embeddings is employed. We prove convex bounding properties and derive update rules of the resulting algorithms. On both synthetic and real neural data from M/EEG, we demonstrate that our methods lead to improved performance.",
    "authors": [
      "Hashemi, Ali",
      "Gao, Yijing",
      "Cai, Chang",
      "Ghosh, Sanjay",
      "M\u00fcller, Klaus-Robert",
      "Nagarajan, Srikantan",
      "Haufe, Stefan"
    ]
  },
  {
    "id": "d062f3e278a1fbba2303ff5a22e8c75e",
    "title": "Topological Attention for Time Series Forecasting",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d062f3e278a1fbba2303ff5a22e8c75e-Paper.pdf",
    "abstract": "The problem of (point) forecasting univariate time series is considered. Most approaches, ranging from traditional statistical methods to recent learning-based techniques with neural networks, directly operate on raw time series observations. As an extension, we study whether local topological properties, as captured via persistent homology, can serve as a reliable signal that provides complementary information for learning to forecast. To this end, we propose topological attention, which allows attending to local topological features within a time horizon of historical data. Our approach easily integrates into existing end-to-end trainable forecasting models, such as N-BEATS, and, in combination with the latter exhibits state-of-the-art performance on the large-scale M4 benchmark dataset of 100,000 diverse time series from different domains. Ablation experiments, as well as a comparison to recent techniques in a setting where only a single time series is available for training, corroborate the beneficial nature of including local topological information through an attention mechanism.",
    "authors": [
      "Zeng, Sebastian",
      "Graf, Florian",
      "Hofer, Christoph",
      "Kwitt, Roland"
    ]
  },
  {
    "id": "d064bf1ad039ff366564f352226e7640",
    "title": "Local Signal Adaptivity: Provable Feature Learning in Neural Networks Beyond Kernels",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d064bf1ad039ff366564f352226e7640-Paper.pdf",
    "abstract": "Neural networks have been shown to outperform kernel methods in practice (including neural tangent kernels). Most theoretical explanations of this performance gap focus on learning a complex hypothesis class; in some cases, it is unclear whether this hypothesis class captures realistic data. In this work, we propose a related, but alternative, explanation for this performance gap in the image classification setting, based on finding a sparse signal in the presence of noise. Specifically, we prove that, for a simple data distribution with sparse signal amidst high-variance noise, a simple convolutional neural network trained using stochastic gradient descent learns to threshold out the noise and find the signal. On the other hand, the corresponding neural tangent kernel, with a fixed set of predetermined features, is unable to adapt to the signal in this manner. We supplement our theoretical results by demonstrating this phenomenon empirically: in CIFAR-10 and MNIST images with various backgrounds, as the background noise increases in intensity, a CNN's performance stays relatively robust, whereas its corresponding neural tangent kernel sees a notable drop in performance. We therefore propose the \"local signal adaptivity\" (LSA) phenomenon as one explanation for the superiority of neural networks over kernel methods.",
    "authors": [
      "Karp, Stefani",
      "Winston, Ezra",
      "Li, Yuanzhi",
      "Singh, Aarti"
    ]
  },
  {
    "id": "d072677d210ac4c03ba046120f0802ec",
    "title": "IA-RED$^2$: Interpretability-Aware Redundancy Reduction for Vision Transformers",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d072677d210ac4c03ba046120f0802ec-Paper.pdf",
    "abstract": "The self-attention-based model, transformer, is recently becoming the leading backbone in the field of computer vision. In spite of the impressive success made by transformers in a variety of vision tasks, it still suffers from heavy computation and intensive memory costs. To address this limitation, this paper presents an Interpretability-Aware REDundancy REDuction framework (IA-RED$^2$). We start by observing a large amount of redundant computation, mainly spent on uncorrelated input patches, and then introduce an interpretable module to dynamically and gracefully drop these redundant patches. This novel framework is then extended to a hierarchical structure, where uncorrelated tokens at different stages are gradually removed, resulting in a considerable shrinkage of computational cost. We include extensive experiments on both image and video tasks, where our method could deliver up to 1.4x speed-up for state-of-the-art models like DeiT and TimeSformer, by only sacrificing less than 0.7% accuracy. More importantly, contrary to other acceleration approaches, our method is inherently interpretable with substantial visual evidence, making vision transformer closer to a more human-understandable architecture while being lighter. We demonstrate that the interpretability that naturally emerged in our framework can outperform the raw attention learned by the original visual transformer, as well as those generated by off-the-shelf interpretation methods, with both qualitative and quantitative results. Project Page: http://people.csail.mit.edu/bpan/ia-red/.",
    "authors": [
      "Pan, Bowen",
      "Panda, Rameswar",
      "Jiang, Yifan",
      "Wang, Zhangyang",
      "Feris, Rogerio",
      "Oliva, Aude"
    ]
  },
  {
    "id": "d073bb8d0c47f317dd39de9c9f004e9d",
    "title": "Symbolic Regression via Deep Reinforcement Learning Enhanced Genetic Programming Seeding",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d073bb8d0c47f317dd39de9c9f004e9d-Paper.pdf",
    "abstract": "Symbolic regression is the process of identifying mathematical expressions that fit observed output from a black-box process. It is a discrete optimization problem generally believed to be NP-hard. Prior approaches to solving the problem include neural-guided search (e.g. using reinforcement learning) and genetic programming. In this work, we introduce a hybrid neural-guided/genetic programming approach to symbolic regression and other combinatorial optimization problems. We propose a neural-guided component used to seed the starting population of a random restart genetic programming component, gradually learning better starting populations. On a number of common benchmark tasks to recover underlying expressions from a dataset, our method recovers 65% more expressions than a recently published top-performing model using the same experimental setup. We demonstrate that running many genetic programming generations without interdependence on the neural-guided component performs better for symbolic regression than alternative formulations where the two are more strongly coupled. Finally, we introduce a new set of 22 symbolic regression benchmark problems with increased difficulty over existing benchmarks. Source code is provided at www.github.com/brendenpetersen/deep-symbolic-optimization.",
    "authors": [
      "Mundhenk, Terrell",
      "Landajuela, Mikel",
      "Glatt, Ruben",
      "Santiago, Claudio P",
      "faissol, Daniel",
      "Petersen, Brenden K"
    ]
  },
  {
    "id": "d0921d442ee91b896ad95059d13df618",
    "title": "Choose a Transformer: Fourier or Galerkin",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d0921d442ee91b896ad95059d13df618-Paper.pdf",
    "abstract": "In this paper, we apply the self-attention from the state-of-the-art Transformer in Attention Is All You Need for the first time to a data-driven operator learning problem related to partial differential equations. An effort is put together to explain the heuristics of, and to improve the efficacy of the attention mechanism. By employing the operator approximation theory in Hilbert spaces, it is demonstrated for the first time that the softmax normalization in the scaled dot-product attention is sufficient but not necessary. Without softmax, the approximation capacity of a linearized Transformer variant can be proved to be comparable to a Petrov-Galerkin projection layer-wise, and the estimate is independent with respect to the sequence length. A new layer normalization scheme mimicking the Petrov-Galerkin projection is proposed to allow a scaling to propagate through attention layers, which helps the model achieve remarkable accuracy in operator learning tasks with unnormalized data. Finally, we present three operator learning experiments, including the viscid Burgers' equation, an interface Darcy flow, and an inverse interface coefficient identification problem. The newly proposed simple attention-based operator learner, Galerkin Transformer, shows significant improvements in both training cost and evaluation accuracy over its softmax-normalized counterparts.",
    "authors": [
      "Cao, Shuhao"
    ]
  },
  {
    "id": "d0f5edad9ac19abed9e235c0fe0aa59f",
    "title": "A Causal Lens for Controllable Text Generation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d0f5edad9ac19abed9e235c0fe0aa59f-Paper.pdf",
    "abstract": "Controllable text generation concerns two fundamental tasks of wide applications, namely generating text of given attributes (i.e., attribute-conditional generation), and minimally editing existing text to possess desired attributes (i.e., text attribute transfer). Extensive prior work has largely studied the two problems separately, and developed different conditional models which, however, are prone to producing biased text (e.g., various gender stereotypes). This paper proposes to formulate controllable text generation from a principled causal perspective which models the two tasks with a unified framework. A direct advantage of the causal formulation is the use of  rich causality tools to mitigate generation biases and improve control. We treat the two tasks as interventional and counterfactual causal inference based on a structural causal model, respectively. We then apply the framework to the challenging practical setting where confounding factors (that induce spurious correlations) are observable only on a small fraction of data. Experiments show significant superiority of the causal approach over previous conditional models for improved control accuracy and reduced bias.",
    "authors": [
      "Hu, Zhiting",
      "Li, Li Erran"
    ]
  },
  {
    "id": "d14388bb836687ff2b16b7bee6bab182",
    "title": "Differentially Private Multi-Armed Bandits in the Shuffle Model",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d14388bb836687ff2b16b7bee6bab182-Paper.pdf",
    "abstract": "We give an $(\\varepsilon,\\delta)$-differentially private algorithm for the Multi-Armed Bandit (MAB) problem in the shuffle model with a distribution-dependent regret of $O\\left(\\left(\\sum_{a:\\Delta_a>0}\\frac{\\log T}{\\Delta_a}\\right)+\\frac{k\\sqrt{\\log\\frac{1}{\\delta}}\\log T}{\\varepsilon}\\right)$, and a distribution-independent regret of $O\\left(\\sqrt{kT\\log T}+\\frac{k\\sqrt{\\log\\frac{1}{\\delta}}\\log T}{\\varepsilon}\\right)$, where $T$ is the number of rounds, $\\Delta_a$ is the suboptimality gap of the action $a$, and $k$ is the total number of actions. Our upper bound almost matches the regret of the best known algorithms for the centralized model, and significantly outperforms the best known algorithm in the local model.",
    "authors": [
      "Tenenbaum, Jay",
      "Kaplan, Haim",
      "Mansour, Yishay",
      "Stemmer, Uri"
    ]
  },
  {
    "id": "d1588e685562af341ff2448de4b674d1",
    "title": "Dual Adaptivity: A Universal Algorithm for Minimizing the Adaptive Regret of Convex Functions",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d1588e685562af341ff2448de4b674d1-Paper.pdf",
    "abstract": "To deal with changing environments, a new performance measure\u2014adaptive regret, defined as the maximum static regret over any interval, was proposed in online learning. Under the setting of online convex optimization, several algorithms have been successfully developed to minimize the adaptive regret. However, existing algorithms lack universality in the sense that they can only handle one type of convex functions and need apriori knowledge of parameters. By contrast, there exist universal algorithms, such as MetaGrad, that attain optimal static regret for multiple types of convex functions simultaneously. Along this line of research, this paper presents the first universal algorithm for minimizing the adaptive regret of convex functions. Specifically, we borrow the idea of maintaining multiple learning rates in MetaGrad to handle the uncertainty of functions, and utilize the technique of sleeping experts to capture changing environments. In this way, our algorithm automatically adapts to the property of functions (convex, exponentially concave, or strongly convex), as well as the nature of environments (stationary or changing). As a by product, it also allows the type of functions to switch between rounds.",
    "authors": [
      "Zhang, Lijun",
      "Wang, Guanghui",
      "Tu, Wei-Wei",
      "Jiang, Wei",
      "Zhou, Zhi-Hua"
    ]
  },
  {
    "id": "d1942a3ab01eb59220e2b3a46e7ef09d",
    "title": " Learning Hard Optimization Problems: A Data Generation Perspective",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d1942a3ab01eb59220e2b3a46e7ef09d-Paper.pdf",
    "abstract": "Optimization problems are ubiquitous in our societies and are present in almost every segment of the economy. Most of these optimization problems are NP-hard and computationally demanding, often requiring approximate solutions for large-scale instances. Machine learning frameworks that learn to approximate solutions to such hard optimization problems are a potentially promising avenue to address these difficulties, particularly when many closely related problem instances must be solved repeatedly. Supervised learning frameworks can train a model using the outputs of pre-solved instances. However, when the outputs are themselves approximations, when the optimization problem has symmetric solutions, and/or when the solver uses randomization, solutions to closely related instances may exhibit large differences and the learning task can become inherently more difficult. This paper demonstrates this critical challenge, connects the volatility of the training data to the ability of a model to approximate it, and proposes a method for producing (exact or approximate) solutions to optimization problems that are more amenable to supervised learning tasks.  The effectiveness of the method is tested on hard non-linear nonconvex and discrete combinatorial problems.",
    "authors": [
      "Kotary, James",
      "Fioretto, Ferdinando",
      "Van Hentenryck, Pascal"
    ]
  },
  {
    "id": "d1ee59e20ad01cedc15f5118a7626099",
    "title": "Canonical Capsules: Self-Supervised Capsules in Canonical Pose",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d1ee59e20ad01cedc15f5118a7626099-Paper.pdf",
    "abstract": "We propose a self-supervised capsule architecture for 3D point clouds. We compute capsule decompositions of objects through permutation-equivariant attention, and self-supervise the process by training with pairs of randomly rotated objects. Our key idea is to aggregate the attention masks into semantic keypoints, and use these to supervise a decomposition that satisfies the capsule invariance/equivariance properties. This not only enables the training of a semantically consistent decomposition, but also allows us to learn a canonicalization operation that enables object-centric reasoning. To train our neural network we require neither classification labels nor manually-aligned training datasets. Yet, by learning an object-centric representation in a self-supervised manner, our method outperforms the state-of-the-art on 3D point cloud reconstruction, canonicalization, and unsupervised classification.",
    "authors": [
      "Sun, Weiwei",
      "Tagliasacchi, Andrea",
      "Deng, Boyang",
      "Sabour, Sara",
      "Yazdani, Soroosh",
      "Hinton, Geoffrey E.",
      "Yi, Kwang Moo"
    ]
  },
  {
    "id": "d1f255a373a3cef72e03aa9d980c7eca",
    "title": "Characterizing Generalization under Out-Of-Distribution Shifts in Deep Metric Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d1f255a373a3cef72e03aa9d980c7eca-Paper.pdf",
    "abstract": "Deep Metric Learning (DML) aims to find representations suitable for zero-shot transfer to a priori unknown test distributions. However, common evaluation protocols only test a single, fixed data split in which train and test classes are assigned randomly. More realistic evaluations should consider a broad spectrum of distribution shifts with potentially varying degree and difficulty.In this work, we systematically construct train-test splits of increasing difficulty and present the ooDML benchmark to characterize generalization under out-of-distribution shifts in DML. ooDML is designed to probe the generalization performance on much more challenging, diverse train-to-test distribution shifts. Based on our new benchmark, we conduct a thorough empirical analysis of state-of-the-art DML methods. We find that while generalization tends to consistently degrade with difficulty, some methods are better at retaining performance as the distribution shift increases. Finally, we propose few-shot DML as an efficient way to consistently improve generalization in response to unknown test shifts presented in ooDML.",
    "authors": [
      "Milbich, Timo",
      "Roth, Karsten",
      "Sinha, Samarth",
      "Schmidt, Ludwig",
      "Ghassemi, Marzyeh",
      "Ommer, Bjorn"
    ]
  },
  {
    "id": "d1fe173d08e959397adf34b1d77e88d7",
    "title": "Dynamics-regulated kinematic policy for egocentric pose estimation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d1fe173d08e959397adf34b1d77e88d7-Paper.pdf",
    "abstract": "We propose a method for object-aware 3D egocentric pose estimation that tightly integrates kinematics modeling, dynamics modeling, and scene object information. Unlike prior kinematics or dynamics-based approaches where the two components are used disjointly, we synergize the two approaches via dynamics-regulated training. At each timestep, a kinematic model is used to provide a target pose using video evidence and simulation state. Then, a prelearned dynamics model attempts to mimic the kinematic pose in a physics simulator. By comparing the pose instructed by the kinematic model against the pose generated by the dynamics model, we can use their misalignment to further improve the kinematic model. By factoring in the 6DoF pose of objects (e.g., chairs, boxes) in the scene, we demonstrate for the first time, the ability to estimate physically-plausible 3D human-object interactions using a single wearable camera. We evaluate our egocentric pose estimation method in both controlled laboratory settings and real-world scenarios.",
    "authors": [
      "Luo, Zhengyi",
      "Hachiuma, Ryo",
      "Yuan, Ye",
      "Kitani, Kris"
    ]
  },
  {
    "id": "d27b95cac4c27feb850aaa4070cc4675",
    "title": "Never Go Full Batch (in Stochastic Convex Optimization)",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d27b95cac4c27feb850aaa4070cc4675-Paper.pdf",
    "abstract": "We study the generalization performance of $\\text{\\emph{full-batch}}$ optimization algorithms for stochastic convex optimization: these are first-order methods that only access the exact gradient of the empirical risk (rather than gradients with respect to individual data points), that include a wide range of algorithms such as gradient descent, mirror descent, and their regularized and/or accelerated variants. We provide a new separation result showing that, while algorithms such as stochastic gradient descent can generalize and optimize the population risk to within $\\epsilon$ after $O(1/\\epsilon^2)$ iterations, full-batch methods either need at least $\\Omega(1/\\epsilon^4)$ iterations or exhibit a dimension-dependent sample complexity.",
    "authors": [
      "Amir, Idan",
      "Carmon, Yair",
      "Koren, Tomer",
      "Livni, Roi"
    ]
  },
  {
    "id": "d2cd33e9c0236a8c2d8bd3fa91ad3acf",
    "title": "Collaborative Learning in the Jungle (Decentralized, Byzantine, Heterogeneous, Asynchronous and Nonconvex Learning)",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d2cd33e9c0236a8c2d8bd3fa91ad3acf-Paper.pdf",
    "abstract": "We study \\emph{Byzantine collaborative learning}, where $n$ nodes seek to collectively learn from each others' local data. The data distribution may vary from one node to another. No node is trusted, and $f < n$ nodes can behave arbitrarily. We prove that collaborative learning is equivalent to a new form of agreement, which we call \\emph{averaging agreement}. In this problem, nodes start each with an initial vector and seek to approximately agree on a common vector, which is close to the average of honest nodes' initial vectors.  We present two asynchronous solutions to averaging agreement, each we prove optimal according to some dimension. The first, based on the minimum-diameter averaging, requires $n \\geq 6f+1$, but achieves asymptotically the best-possible averaging constant up to a multiplicative constant. The second, based on reliable broadcast and coordinate-wise trimmed mean, achieves optimal Byzantine resilience, i.e.,  $n \\geq 3f+1$. Each of these algorithms induces an optimal Byzantine collaborative learning protocol. In particular, our equivalence yields new impossibility theorems on what any collaborative learning algorithm can achieve in adversarial and heterogeneous environments.",
    "authors": [
      "El-Mhamdi, El Mahdi",
      "Farhadkhani, Sadegh",
      "Guerraoui, Rachid",
      "Guirguis, Arsany",
      "Hoang, L\u00ea-Nguy\u00ean",
      "Rouault, S\u00e9bastien"
    ]
  },
  {
    "id": "d30960ce77e83d896503d43ba249caf7",
    "title": "Not All Low-Pass Filters are Robust in Graph Convolutional Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d30960ce77e83d896503d43ba249caf7-Paper.pdf",
    "abstract": "Graph Convolutional Networks (GCNs) are promising deep learning approaches in learning representations for graph-structured data. Despite the proliferation of such methods, it is well known that they are vulnerable to carefully crafted adversarial attacks on the graph structure. In this paper, we first conduct an adversarial vulnerability analysis based on matrix perturbation theory. We prove that the low- frequency components of the symmetric normalized Laplacian, which is usually used as the convolutional filter in GCNs, could be more robust against structural perturbations when their eigenvalues fall into a certain robust interval. Our results indicate that not all low-frequency components are robust to adversarial attacks and provide a deeper understanding of the relationship between graph spectrum and robustness of GCNs. Motivated by the theory, we present GCN-LFR, a general robust co-training paradigm for GCN-based models, that encourages transferring the robustness of low-frequency components with an auxiliary neural network. To this end, GCN-LFR could enhance the robustness of various kinds of GCN-based models against poisoning structural attacks in a plug-and-play manner. Extensive experiments across five benchmark datasets and five GCN-based models also confirm that GCN-LFR is resistant to the adversarial attacks without compromising on performance in the benign situation.",
    "authors": [
      "Chang, Heng",
      "Rong, Yu",
      "Xu, Tingyang",
      "Bian, Yatao",
      "Zhou, Shiji",
      "Wang, Xin",
      "Huang, Junzhou",
      "Zhu, Wenwu"
    ]
  },
  {
    "id": "d30d0f522a86b3665d8e3a9a91472e28",
    "title": "Counterfactual Maximum Likelihood Estimation for Training Deep Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d30d0f522a86b3665d8e3a9a91472e28-Paper.pdf",
    "abstract": "Although deep learning models have driven state-of-the-art performance on a wide array of tasks, they are prone to spurious correlations that should not be learned as predictive clues. To mitigate this problem, we propose a causality-based training framework to reduce the spurious correlations caused by observed confounders. We give theoretical analysis on the underlying general Structural Causal Model (SCM) and propose to perform Maximum Likelihood Estimation (MLE) on the interventional distribution instead of the observational distribution, namely Counterfactual Maximum Likelihood Estimation (CMLE). As the interventional distribution, in general, is hidden from the observational data, we then derive two different upper bounds of the expected negative log-likelihood and propose two general algorithms, Implicit CMLE and Explicit CMLE, for causal predictions of deep learning models using observational data. We conduct experiments on both simulated data and two real-world tasks: Natural Language Inference (NLI) and Image Captioning. The results show that CMLE methods outperform the regular MLE method in terms of out-of-domain generalization performance and reducing spurious correlations, while maintaining comparable performance on the regular evaluations.",
    "authors": [
      "Wang, Xinyi",
      "Chen, Wenhu",
      "Saxon, Michael",
      "Wang, William Yang"
    ]
  },
  {
    "id": "d324a0cc02881779dcda44a675fdcaaa",
    "title": "Robust Optimization for Multilingual Translation with Imbalanced Data",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d324a0cc02881779dcda44a675fdcaaa-Paper.pdf",
    "abstract": "Multilingual models are parameter-efficient and especially effective in improving low-resource languages by leveraging crosslingual transfer. Despite recent advance in massive multilingual translation with ever-growing model and data, how to effectively train multilingual models has not been well understood. In this paper, we show that a common situation in multilingual training, data imbalance among languages, poses optimization tension between high resource and low resource languages where the found multilingual solution is often sub-optimal for low resources. We show that common training method which upsamples low resources can not robustly optimize population loss with risks of either underfitting high resource languages or overfitting low resource ones. Drawing on recent findings on the geometry of loss landscape and its effect on generalization, we propose a principled optimization algorithm, Curvature Aware Task Scaling (CATS), which adaptively rescales gradients from different tasks with a meta objective of guiding multilingual training to low-curvature neighborhoods with uniformly low loss for all languages. We ran experiments on common benchmarks (TED, WMT and OPUS-100) with varying degrees of data imbalance. CATS effectively improved multilingual optimization and as a result demonstrated consistent gains on low resources ($+0.8$ to $+2.2$ BLEU) without hurting high resources. In addition, CATS is robust to overparameterization and large batch size training, making it a promising training method for massive multilingual models that truly improve low resource languages. ",
    "authors": [
      "Li, Xian",
      "Gong, Hongyu"
    ]
  },
  {
    "id": "d35a29602005cb55aa57a5f683c8e0c2",
    "title": "A/B/n Testing with Control in the Presence of Subpopulations",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d35a29602005cb55aa57a5f683c8e0c2-Paper.pdf",
    "abstract": "Motivated by A/B/n testing applications, we consider a finite set of distributions (called \\emph{arms}), one of which is treated as a \\emph{control}. We assume that the population is stratified into homogeneous subpopulations. At every time step, a subpopulation is sampled and an arm is chosen: the resulting observation is an independent draw from the arm conditioned on the subpopulation. The quality of each arm is assessed through a weighted combination of its subpopulation means. We propose a strategy for sequentially choosing one arm per time step so as to discover as fast as possible which arms, if any, have higher weighted expectation than the control. This strategy is shown to be asymptotically optimal in the following sense: if $\\tau_\\delta$ is the first time when the strategy ensures that it is able to output the correct answer with probability at least $1-\\delta$, then $\\mathbb{E}[\\tau_\\delta]$ grows linearly with $\\log(1/\\delta)$ at the exact optimal rate. This rate is identified in the paper in three different settings: (1) when the experimenter does not observe the subpopulation information, (2) when the subpopulation of each sample is observed but not chosen, and (3) when the experimenter can select the subpopulation from which each response is sampled. We illustrate the efficiency of the proposed strategy with numerical simulations on synthetic and real data collected from an A/B/n experiment.",
    "authors": [
      "Russac, Yoan",
      "Katsimerou, Christina",
      "Bohle, Dennis",
      "Capp\u00e9, Olivier",
      "Garivier, Aur\u00e9lien",
      "Koolen, Wouter M."
    ]
  },
  {
    "id": "d35b05a832e2bb91f110d54e34e2da79",
    "title": "Using Random Effects to Account for High-Cardinality Categorical Features and Repeated Measures in Deep Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d35b05a832e2bb91f110d54e34e2da79-Paper.pdf",
    "abstract": "High-cardinality categorical features are a major challenge for machine learning methods in general and for deep learning in particular. Existing solutions such as one-hot encoding and entity embeddings can be hard to scale when the cardinality is very high, require much space, are hard to interpret or may overfit the data. A special scenario of interest is that of repeated measures, where the categorical feature is the identity of the individual or object, and each object is measured several times, possibly under different conditions (values of the other features). We propose accounting for high-cardinality categorical features as random effects variables in a regression setting, and consequently adopt the corresponding negative log likelihood loss from the linear mixed models (LMM) statistical literature and integrate it in a deep learning framework. We test our model which we call LMMNN on simulated as well as real datasets with a single categorical feature with high cardinality, using various baseline neural networks architectures such as convolutional networks and LSTM, and various applications in e-commerce, healthcare and computer vision. Our results show that treating high-cardinality categorical features as random effects leads to a significant improvement in prediction performance compared to state of the art alternatives. Potential extensions such as accounting for multiple categorical features and classification settings are discussed. Our code and simulations are available at https://github.com/gsimchoni/lmmnn.",
    "authors": [
      "Simchoni, Giora",
      "Rosset, Saharon"
    ]
  },
  {
    "id": "d360a502598a4b64b936683b44a5523a",
    "title": "Learning Debiased Representation via Disentangled Feature Augmentation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d360a502598a4b64b936683b44a5523a-Paper.pdf",
    "abstract": "Image classification models tend to make decisions based on peripheral attributes of data items that have strong correlation with a target variable (i.e., dataset bias). These biased models suffer from the poor generalization capability when evaluated on unbiased datasets. Existing approaches for debiasing often identify and emphasize those samples with no such correlation (i.e., bias-conflicting) without defining the bias type in advance. However, such bias-conflicting samples are significantly scarce in biased datasets, limiting the debiasing capability of these approaches. This paper first presents an empirical analysis revealing that training with \"diverse\" bias-conflicting samples beyond a given training set is crucial for debiasing as well as the generalization capability. Based on this observation, we propose a novel feature-level data augmentation technique in order to synthesize diverse bias-conflicting samples.  To this end, our method learns the disentangled representation of (1) the intrinsic attributes (i.e., those inherently defining a certain class) and (2) bias attributes (i.e., peripheral attributes causing the bias), from a large number of bias-aligned samples, the bias attributes of which have strong correlation with the target variable.  Using the disentangled representation, we synthesize bias-conflicting samples that contain the diverse intrinsic attributes of bias-aligned samples by swapping their latent features. By utilizing these diversified bias-conflicting features during the training, our approach achieves superior classification accuracy and debiasing results against the existing baselines on both synthetic and real-world datasets.",
    "authors": [
      "Lee, Jungsoo",
      "Kim, Eungyeup",
      "Lee, Juyoung",
      "Lee, Jihyeon",
      "Choo, Jaegul"
    ]
  },
  {
    "id": "d367eef13f90793bd8121e2f675f0dc2",
    "title": "Scallop: From Probabilistic Deductive Databases to Scalable Differentiable Reasoning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d367eef13f90793bd8121e2f675f0dc2-Paper.pdf",
    "abstract": "Deep learning and symbolic reasoning are complementary techniques for an intelligent system. However, principled combinations of these techniques have limited scalability, rendering them ill-suited for real-world applications. We propose Scallop, a system that builds upon probabilistic deductive databases, to bridge this gap. The key insight underlying Scallop is a provenance framework that introduces a tunable parameter to specify the level of reasoning granularity. Scallop thereby i) generalizes exact probabilistic reasoning, ii) asymptotically reduces computational cost, and iii) provides relative accuracy guarantees. On a suite of tasks that involve mathematical and logical reasoning, Scallop scales significantly better without sacrificing accuracy compared to DeepProbLog, a principled neural logic programming approach. We also create and evaluate on a real-world Visual Question Answering (VQA) benchmark that requires multi-hop reasoning. Scallop outperforms two VQA-tailored models, a Neural Module Networks based and a transformer based model, by 12.42% and 21.66% respectively.",
    "authors": [
      "Huang, Jiani",
      "Li, Ziyang",
      "Chen, Binghong",
      "Samel, Karan",
      "Naik, Mayur",
      "Song, Le",
      "Si, Xujie"
    ]
  },
  {
    "id": "d37124c4c79f357cb02c655671a432fa",
    "title": "Learning to Synthesize Programs as Interpretable and Generalizable Policies",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d37124c4c79f357cb02c655671a432fa-Paper.pdf",
    "abstract": "Recently, deep reinforcement learning (DRL) methods have achieved impressive performance on tasks in a variety of domains. However, neural network policies produced with DRL methods are not human-interpretable and often have difficulty generalizing to novel scenarios. To address these issues, prior works explore learning programmatic policies that are more interpretable and structured for generalization. Yet, these works either employ limited policy representations (e.g. decision trees, state machines, or predefined program templates) or require stronger supervision (e.g. input/output state pairs or expert demonstrations). We present a framework that instead learns to synthesize a program, which details the procedure to solve a task in a flexible and expressive manner, solely from reward signals. To alleviate the difficulty of learning to compose programs to induce the desired agent behavior from scratch, we propose to first learn a program embedding space that continuously parameterizes diverse behaviors in an unsupervised manner and then search over the learned program embedding space to yield a program that maximizes the return for a given task. Experimental results demonstrate that the proposed framework not only learns to reliably synthesize task-solving programs but also outperforms DRL and program synthesis baselines while producing interpretable and more generalizable policies. We also justify the necessity of the proposed two-stage learning scheme as well as analyze various methods for learning the program embedding. Website at https://clvrai.com/leaps.",
    "authors": [
      "Trivedi, Dweep",
      "Zhang, Jesse",
      "Sun, Shao-Hua",
      "Lim, Joseph J."
    ]
  },
  {
    "id": "d384dec9f5f7a64a36b5c8f03b8a6d92",
    "title": "The functional specialization of visual cortex emerges from training parallel pathways with self-supervised predictive learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d384dec9f5f7a64a36b5c8f03b8a6d92-Paper.pdf",
    "abstract": "The visual system of mammals is comprised of parallel, hierarchical specialized pathways. Different pathways are specialized in so far as they use representations that are more suitable for supporting specific downstream behaviours. In particular, the clearest example is the specialization of the ventral (\"what\") and dorsal (\"where\") pathways of the visual cortex. These two pathways support behaviours related to visual recognition and movement, respectively. To-date, deep neural networks have mostly been used as models of the ventral, recognition pathway. However, it is unknown whether both pathways can be modelled with a single deep ANN. Here, we ask whether a single model with a single loss function can capture the properties of both the ventral and the dorsal pathways. We explore this question using data from mice, who like other mammals, have specialized pathways that appear to support recognition and movement behaviours. We show that when we train a deep neural network architecture with two parallel pathways using a self-supervised predictive loss function, we can outperform other models in fitting mouse visual cortex. Moreover, we can model both the dorsal and ventral pathways. These results demonstrate that a self-supervised predictive learning approach applied to parallel pathway architectures can account for some of the functional specialization seen in mammalian visual systems.",
    "authors": [
      "Bakhtiari, Shahab",
      "Mineault, Patrick",
      "Lillicrap, Timothy",
      "Pack, Christopher",
      "Richards, Blake"
    ]
  },
  {
    "id": "d3aeec875c479e55d1cdeea161842ec6",
    "title": "Adversarial Training Helps Transfer Learning via Better Representations",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d3aeec875c479e55d1cdeea161842ec6-Paper.pdf",
    "abstract": "Transfer learning aims to leverage models pre-trained on source data to efficiently adapt to target setting, where only limited data are available for model fine-tuning. Recent works empirically demonstrate that adversarial training in the source data can improve the ability of models to transfer to new domains. However, why this happens is not known. In this paper, we provide a theoretical model to rigorously analyze how adversarial training helps transfer learning. We show that adversarial training in the source data generates provably better representations, so fine-tuning on top of this representation leads to a more accurate predictor of the target data.  We further demonstrate both theoretically and empirically that semi-supervised learning in the source data can also improve transfer learning by similarly improving the representation. Moreover, performing adversarial training on top of semi-supervised learning can further improve transferability, suggesting that the two approaches have complementary benefits on representations.  We support our theories with experiments on popular data sets and deep learning architectures. ",
    "authors": [
      "Deng, Zhun",
      "Zhang, Linjun",
      "Vodrahalli, Kailas",
      "Kawaguchi, Kenji",
      "Zou, James Y."
    ]
  },
  {
    "id": "d3e2e8f631bd9336ed25b8162aef8782",
    "title": "Improving Coherence and Consistency in Neural Sequence Models with Dual-System, Neuro-Symbolic Reasoning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d3e2e8f631bd9336ed25b8162aef8782-Paper.pdf",
    "abstract": "Human reasoning can be understood as an interplay between two systems: the intuitive and associative (\"System 1\") and the deliberative and logical (\"System 2\"). Neural sequence models---which have been increasingly successful at performing complex, structured tasks---exhibit the advantages and failure modes of System 1: they are fast and learn patterns from data, but are often inconsistent and incoherent. In this work, we seek a lightweight, training-free means of improving existing System 1-like sequence models by adding System 2-inspired logical reasoning. We explore several variations on this theme in which candidate generations from a neural sequence model are examined for logical consistency by a symbolic reasoning module, which can either accept or reject the generations. Our approach uses neural inference to mediate between the neural System 1 and the logical System 2. Results in robust story generation and grounded instruction-following show that this approach can increase the coherence and accuracy of neurally-based generations.",
    "authors": [
      "Nye, Maxwell",
      "Tessler, Michael",
      "Tenenbaum, Josh",
      "Lake, Brenden M."
    ]
  },
  {
    "id": "d3e6cd9f66f2c1d3840ade4161cf7406",
    "title": "Learning the optimal Tikhonov regularizer for inverse problems",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d3e6cd9f66f2c1d3840ade4161cf7406-Paper.pdf",
    "abstract": "In this work, we consider the linear inverse problem $y=Ax+\\varepsilon$, where $A\\colon X\\to Y$ is a known linear operator between the separable Hilbert spaces $X$ and $Y$, $x$ is a random variable in $X$ and $\\epsilon$ is a zero-mean random process in $Y$. This setting covers several inverse problems in imaging including denoising, deblurring, and X-ray tomography. Within the classical framework of regularization, we focus on the case where the regularization functional is not given a priori, but learned from data. Our first result is a characterization of the optimal generalized Tikhonov regularizer, with respect to the mean squared error. We find that it is completely independent of the forward operator $A$ and depends only on the mean and covariance of $x$.Then, we consider the problem of learning the regularizer from a finite training set in two different frameworks: one supervised, based on samples of both $x$ and $y$, and one unsupervised, based only on samples of $x$. In both cases, we prove generalization bounds, under some weak assumptions on the distribution of $x$ and $\\varepsilon$, including the case of sub-Gaussian variables. Our bounds hold in infinite-dimensional spaces, thereby showing that finer and finer discretizations do not make this learning problem harder. The results are validated through numerical simulations.",
    "authors": [
      "Alberti, Giovanni S.",
      "De Vito, Ernesto",
      "Lassas, Matti",
      "Ratti, Luca",
      "Santacesaria, Matteo"
    ]
  },
  {
    "id": "d428d070622e0f4363fceae11f4a3576",
    "title": "NovelD: A Simple yet Effective Exploration Criterion",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d428d070622e0f4363fceae11f4a3576-Paper.pdf",
    "abstract": "Efficient exploration under sparse rewards remains a key challenge in deep reinforcement learning. Previous exploration methods (e.g., RND) have achieved strong results in multiple hard tasks. However, if there are multiple novel areas to explore, these methods often focus quickly on one without sufficiently trying others (like a depth-wise first search manner). In some scenarios (e.g., four corridor environment in Sec 4.2), we observe they explore in one corridor for long and fail to cover all the states. On the other hand, in theoretical RL, with optimistic initialization and the inverse square root of visitation count as a bonus, it won't suffer from this and explores different novel regions alternatively (like a breadth-first search manner). In this paper, inspired by this, we propose a simple but effective criterion called NovelD by weighting every novel area approximately equally. Our algorithm is very simple but yet shows comparable performance or even outperforms multiple SOTA exploration methods in many hard exploration tasks. Specifically, NovelD solves all the static procedurally-generated tasks in Mini-Grid with just 120M environment steps, without any curriculum learning. In comparison, the previous SOTA only solves 50% of them. NovelD also achieves SOTA on multiple tasks in NetHack, a rogue-like game that contains more challenging procedurally-generated environments. In multiple Atari games (e.g., MonteZuma's Revenge, Venture, Gravitar), NovelD outperforms RND. We analyze NovelD thoroughly in MiniGrid and found that empirically it helps the agent explore the environment more uniformly with a focus on exploring beyond the boundary.  ",
    "authors": [
      "Zhang, Tianjun",
      "Xu, Huazhe",
      "Wang, Xiaolong",
      "Wu, Yi",
      "Keutzer, Kurt",
      "Gonzalez, Joseph E.",
      "Tian, Yuandong"
    ]
  },
  {
    "id": "d46e1fcf4c07ce4a69ee07e4134bcef1",
    "title": "On Margin-Based Cluster Recovery with Oracle Queries",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d46e1fcf4c07ce4a69ee07e4134bcef1-Paper.pdf",
    "abstract": "We study an active cluster recovery problem where, given a set of $n$ points and an oracle answering queries like ``are these two points in the same cluster?'', the task is to recover exactly all clusters using as few queries as possible. We begin by introducing a simple but general notion of margin between clusters that captures, as special cases, the margins used in previous works, the classic SVM margin, and standard notions of stability for center-based clusterings. Under our margin assumptions we design algorithms that, in a variety of settings, recover all clusters exactly using only $O(\\log n)$ queries. For $\\mathbb{R}^m$, we give an algorithm that recovers \\emph{arbitrary} convex clusters, in polynomial time, and with a number of queries that is lower than the best existing algorithm by $\\Theta(m^m)$ factors. For general pseudometric spaces, where clusters might not be convex or might not have any notion of shape, we give an algorithm that achieves the $O(\\log n)$ query bound, and is provably near-optimal as a function of the packing number of the space. Finally, for clusterings realized by binary concept classes, we give a combinatorial characterization of recoverability with $O(\\log n)$ queries, and we show that, for many concept classes in $\\mathbb{R}^m$, this characterization is equivalent to our margin condition. Our results show a deep connection between cluster margins and active cluster recoverability.",
    "authors": [
      "Bressan, Marco",
      "Cesa-Bianchi, Nicol\u00f2",
      "Lattanzi, Silvio",
      "Paudice, Andrea"
    ]
  },
  {
    "id": "d494020ff8ec181ef98ed97ac3f25453",
    "title": "Multi-Scale Representation Learning on Proteins",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d494020ff8ec181ef98ed97ac3f25453-Paper.pdf",
    "abstract": "Proteins are fundamental biological entities mediating key roles in cellular function and disease. This paper introduces a multi-scale graph construction of a protein \u2013HoloProt\u2013 connecting surface to structure and sequence. The surface captures coarser details of the protein, while sequence as primary component and structure \u2013comprising secondary and tertiary components\u2013 capture finer details. Our graph encoder then learns a multi-scale representation by allowing each level to integrate the encoding from level(s) below with the graph at that level. We test the learned representation on different tasks, (i.) ligand binding affinity (regression), and (ii.) protein function prediction (classification).On the regression task, contrary to previous methods, our model performs consistently and reliably across different dataset splits, outperforming all baselines on most splits. On the classification task, it achieves a performance close to the top-performing model while using 10x fewer parameters. To improve the memory efficiency of our construction, we segment the multiplex protein surface manifold into molecular superpixels and substitute the surface with these superpixels at little to no performance loss.",
    "authors": [
      "Somnath, Vignesh Ram",
      "Bunne, Charlotte",
      "Krause, Andreas"
    ]
  },
  {
    "id": "d4bad256c73a6b25b86cc9c1a77255b1",
    "title": "Sparse Quadratic Optimisation over the Stiefel Manifold with Application to Permutation Synchronisation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d4bad256c73a6b25b86cc9c1a77255b1-Paper.pdf",
    "abstract": "We address the non-convex optimisation problem of finding a sparse matrix on the Stiefel manifold (matrices with mutually orthogonal columns of unit length) that maximises (or minimises) a quadratic objective function. Optimisation problems on the Stiefel manifold occur for example in spectral relaxations of various combinatorial problems, such as graph matching, clustering, or permutation synchronisation. Although sparsity is a desirable property in such settings, it is mostly neglected in spectral formulations since existing solvers, e.g. based on eigenvalue decomposition, are unable to account for sparsity while at the same time maintaining global optimality guarantees. We fill this gap and propose a simple yet effective sparsity-promoting modification of the Orthogonal Iteration algorithm for finding the dominant eigenspace of a matrix. By doing so, we can guarantee that our method finds a Stiefel matrix that is globally optimal with respect to the quadratic objective function, while in addition being sparse. As a motivating application we consider the task of permutation synchronisation, which can be understood as a constrained clustering problem that has particular relevance for matching multiple images or 3D shapes in computer vision, computer graphics, and beyond. We demonstrate that the proposed approach outperforms previous methods in this domain.",
    "authors": [
      "Bernard, Florian",
      "Cremers, Daniel",
      "Thunberg, Johan"
    ]
  },
  {
    "id": "d4c2e4a3297fe25a71d030b67eb83bfc",
    "title": "Second-Order Neural ODE Optimizer",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d4c2e4a3297fe25a71d030b67eb83bfc-Paper.pdf",
    "abstract": "We propose a novel second-order optimization framework for training the emerging deep continuous-time models, specifically the Neural Ordinary Differential Equations (Neural ODEs). Since their training already involves expensive gradient computation by solving a backward ODE, deriving efficient second-order methods becomes highly nontrivial. Nevertheless, inspired by the recent Optimal Control (OC) interpretation of training deep networks, we show that a specific continuous-time OC methodology, called Differential Programming, can be adopted to derive backward ODEs for higher-order derivatives at the same O(1) memory cost. We further explore a low-rank representation of the second-order derivatives and show that it leads to efficient preconditioned updates with the aid of Kronecker-based factorization. The resulting method \u2013 named SNOpt \u2013 converges much faster than first-order baselines in wall-clock time, and the improvement remains consistent across various applications, e.g. image classification, generative flow, and time-series prediction. Our framework also enables direct architecture optimization, such as the integration time of Neural ODEs, with second-order feedback policies, strengthening the OC perspective as a principled tool of analyzing optimization in deep learning. Our code is available at https://github.com/ghliu/snopt.",
    "authors": [
      "Liu, Guan-Horng",
      "Chen, Tianrong",
      "Theodorou, Evangelos"
    ]
  },
  {
    "id": "d4d8d1ac7e00e9105775a6b660dd3cbb",
    "title": "Graph Neural Networks with Local Graph  Parameters",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d4d8d1ac7e00e9105775a6b660dd3cbb-Paper.pdf",
    "abstract": "Various recent proposals increase the distinguishing power of Graph Neural Networks (GNNs) by propagating features between k-tuples of vertices. The distinguishing power of these \u201chigher-order\u201d GNNs is known to be bounded by the k-dimensional Weisfeiler-Leman (WL) test, yet their O(n^k) memory requirements limit their applicability. Other proposals infuse GNNs with local higher-order graph structural information from the start, hereby inheriting the desirable O(n) memory requirement from GNNs at the cost of a one-time, possibly non-linear, preprocessing step. We propose local graph parameter enabled GNNs as a framework for studying the latter\u00a0kind of approaches and precisely characterize their distinguishing power, in terms of a variant of the WL test, and in terms of the graph structural properties that they can take into account. Local graph parameters can be added to any GNN\u00a0architecture, and are cheap to compute. In terms of expressive power, our proposal lies in the middle of GNNs and their higher-order counterparts. Further, we propose\u00a0several techniques to aide in choosing the right local graph parameters. Our results\u00a0connect GNNs with deep results in finite model theory and finite variable logics. Our experimental evaluation shows that adding local graph parameters often has a\u00a0positive effect for a variety of GNNs, datasets and graph learning tasks. ",
    "authors": [
      "Barcel\u00f3, Pablo",
      "Geerts, Floris",
      "Reutter, Juan",
      "Ryschkov, Maksimilian"
    ]
  },
  {
    "id": "d4dd111a4fd973394238aca5c05bebe3",
    "title": "Closing the Gap: Tighter Analysis of Alternating Stochastic Gradient Methods for Bilevel Problems",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d4dd111a4fd973394238aca5c05bebe3-Paper.pdf",
    "abstract": "Stochastic nested optimization, including stochastic compositional, min-max, and bilevel optimization, is gaining popularity in many machine learning applications. While the three problems share a nested structure, existing works often treat them separately, thus developing problem-specific algorithms and analyses. Among various exciting developments, simple SGD-type updates (potentially on multiple variables) are still prevalent in solving this class of nested problems, but they are believed to have a slower convergence rate than non-nested problems. This paper unifies several SGD-type updates for stochastic nested problems into a single SGD approach that we term ALternating Stochastic gradient dEscenT (ALSET) method. By leveraging the hidden smoothness of the problem, this paper presents a tighter analysis of ALSET for stochastic nested problems. Under the new analysis, to achieve an $\\epsilon$-stationary point of the nested problem, it requires ${\\cal O}(\\epsilon^{-2})$ samples in total. Under certain regularity conditions, applying our results to stochastic compositional, min-max, and reinforcement learning problems either improves or matches the best-known sample complexity in the respective cases. Our results explain why simple SGD-type algorithms in stochastic nested problems all work very well in practice without the need for further modifications. ",
    "authors": [
      "Chen, Tianyi",
      "Sun, Yuejiao",
      "Yin, Wotao"
    ]
  },
  {
    "id": "d516b13671a4179d9b7b458a6ebdeb92",
    "title": "Dense Unsupervised Learning for Video Segmentation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d516b13671a4179d9b7b458a6ebdeb92-Paper.pdf",
    "abstract": "We present a novel approach to unsupervised learning for video object segmentation (VOS). Unlike previous work, our formulation allows to learn dense feature representations directly in a fully convolutional regime. We rely on uniform grid sampling to extract a set of anchors and train our model to disambiguate between them on both inter- and intra-video levels. However, a naive scheme to train such a model results in a degenerate solution. We propose to prevent this with a simple regularisation scheme, accommodating the equivariance property of the segmentation task to similarity transformations. Our training objective admits efficient implementation and exhibits fast training convergence. On established VOS benchmarks, our approach exceeds the segmentation accuracy of previous work despite using significantly less training data and compute power.",
    "authors": [
      "Araslanov, Nikita",
      "Schaub-Meyer, Simone",
      "Roth, Stefan"
    ]
  },
  {
    "id": "d530d454337fb09964237fecb4bea6ce",
    "title": "Charting and Navigating the Space of Solutions for Recurrent Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d530d454337fb09964237fecb4bea6ce-Paper.pdf",
    "abstract": "In recent years Recurrent Neural Networks (RNNs) were successfully used to model the way neural activity drives task-related behavior in animals, operating under the implicit assumption that the obtained solutions are universal. Observations in both neuroscience and machine learning challenge this assumption. Animals can approach a given task with a variety of strategies, and training machine learning algorithms introduces the phenomenon of underspecification. These observations imply that every task is associated with a space of solutions. To date, the structure of this space is not understood, limiting the approach of comparing RNNs with neural data.Here, we characterize the space of solutions associated with various tasks. We first study a simple two-neuron network on a task that leads to multiple solutions. We trace the nature of the final solution back to the network\u2019s initial connectivity and identify discrete dynamical regimes that underlie this diversity. We then examine three neuroscience-inspired tasks: Delayed discrimination, Interval discrimination, and Time reproduction. For each task, we find a rich set of solutions. One layer of variability can be found directly in the neural activity of the networks. An additional layer is uncovered by testing the trained networks' ability to extrapolate, as a perturbation to a system often reveals hidden structure. Furthermore, we relate extrapolation patterns to specific dynamical objects and effective algorithms found by the networks. We introduce a tool to derive the reduced dynamics of networks by generating a compact directed graph describing the essence of the dynamics with regards to behavioral inputs and outputs. Using this representation, we can partition the solutions to each task into a handful of types and show that neural features can partially predict them.Taken together, our results shed light on the concept of the space of solutions and its uses both in Machine learning and in Neuroscience.",
    "authors": [
      "Turner, Elia",
      "Dabholkar, Kabir V",
      "Barak, Omri"
    ]
  },
  {
    "id": "d5397f1497b5cdaad7253fdc92db610b",
    "title": "Fast Training  Method for  Stochastic Compositional Optimization Problems",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d5397f1497b5cdaad7253fdc92db610b-Paper.pdf",
    "abstract": "The stochastic compositional optimization problem covers a wide range of machine learning models, such as sparse additive models and model-agnostic meta-learning.  Thus, it is necessary to develop efficient methods for its optimization. Existing methods for the stochastic compositional optimization problem only focus on the single machine scenario, which is far from satisfactory when data are distributed on different devices. To address this problem, we propose novel decentralized stochastic compositional gradient descent methods to efficiently train the large-scale stochastic compositional optimization problem. To the best of our knowledge, our work is the first one facilitating decentralized training for this kind of problem. Furthermore, we provide the convergence analysis for our methods, which shows that the convergence rate of our methods can achieve linear speedup with respect to the number of devices. At last, we apply our decentralized training methods to the model-agnostic meta-learning problem, and the experimental results confirm the superior performance of our methods. ",
    "authors": [
      "Gao, Hongchang",
      "Huang, Heng"
    ]
  },
  {
    "id": "d56b9fc4b0f1be8871f5e1c40c0067e7",
    "title": "Dual-stream Network for Visual Recognition",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d56b9fc4b0f1be8871f5e1c40c0067e7-Paper.pdf",
    "abstract": "Transformers with remarkable global representation capacities achieve competitive results for visual tasks, but fail to consider high-level local pattern information in input images. In this paper, we present a generic Dual-stream Network  (DS-Net) to fully explore the representation capacity of local and global pattern features for image classification.  Our DS-Net can simultaneously  calculate fine-grained and integrated features and efficiently fuse them. Specifically,  we propose an Intra-scale Propagation module to process two different resolutions in each block and an Inter-Scale Alignment module to perform information interaction across features at dual scales. Besides, we also design a Dual-stream FPN (DS-FPN) to further enhance contextual information for downstream dense predictions. Without bells and whistles, the proposed DS-Net outperforms DeiT-Small by 2.4\\% in terms of top-1 accuracy on ImageNet-1k and achieves state-of-the-art performance over other Vision Transformers and ResNets. For object detection and instance segmentation, DS-Net-Small respectively outperforms ResNet-50 by 6.4\\% and 5.5 \\% in terms of mAP on MSCOCO 2017, and surpasses the previous state-of-the-art scheme, which significantly demonstrates its potential to be a general backbone in vision tasks. The code will be released soon.",
    "authors": [
      "Mao, Mingyuan",
      "gao, peng",
      "Zhang, Renrui",
      "Zheng, Honghui",
      "Ma, Teli",
      "Peng, Yan",
      "Ding, Errui",
      "Zhang, Baochang",
      "Han, Shumin"
    ]
  },
  {
    "id": "d582ac40970f9885836a61d7b2c662e4",
    "title": "Estimating High Order Gradients of the Data Distribution by Denoising",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d582ac40970f9885836a61d7b2c662e4-Paper.pdf",
    "abstract": "The first order derivative of a data density can be estimated efficiently by denoising score matching, and has become an important component in many applications, such as image generation and audio synthesis. Higher order derivatives provide additional local information about the data distribution and enable new applications. Although they can be estimated via automatic differentiation of a learned density model, this can amplify estimation errors and is expensive in high dimensional settings. To overcome these limitations, we propose a method to directly estimate high order derivatives (scores) of a data density from samples. We first show that denoising score matching can be interpreted as a particular case of Tweedie\u2019s formula. By leveraging Tweedie\u2019s formula on higher order moments, we generalize denoising score matching to estimate higher order derivatives. We demonstrate empirically that models trained with the proposed method can approximate second order derivatives more efficiently and accurately than via automatic differentiation. We show that our models can be used to quantify uncertainty in denoising and to improve the mixing speed of Langevin dynamics via Ozaki discretization for sampling synthetic data and natural images.",
    "authors": [
      "Meng, Chenlin",
      "Song, Yang",
      "Li, Wenzhe",
      "Ermon, Stefano"
    ]
  },
  {
    "id": "d58e2f077670f4de9cd7963c857f2534",
    "title": "Machine versus Human Attention in Deep Reinforcement Learning Tasks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d58e2f077670f4de9cd7963c857f2534-Paper.pdf",
    "abstract": "Deep reinforcement learning (RL) algorithms are powerful tools for solving visuomotor decision tasks. However, the trained models are often difficult to interpret, because they are represented as end-to-end deep neural networks.  In this paper, we shed light on the inner workings of such trained models by analyzing the pixels that they attend to during task execution, and comparing them with the pixels attended to by humans executing the same tasks. To this end, we investigate the following two questions that, to the best of our knowledge, have not been previously studied. 1) How similar are the visual representations learned by RL agents and humans when performing the same task? and, 2) How do similarities and differences in these learned representations explain RL agents' performance on these tasks? Specifically, we compare the saliency maps of RL agents against visual attention models of human experts when learning to play Atari games. Further, we analyze how hyperparameters of the deep RL algorithm affect the learned representations and saliency maps of the trained agents. The insights provided have the potential to inform novel algorithms for closing the performance gap between human experts and RL agents.",
    "authors": [
      "Guo, Suna (Sihang)",
      "Zhang, Ruohan",
      "Liu, Bo",
      "Zhu, Yifeng",
      "Ballard, Dana",
      "Hayhoe, Mary",
      "Stone, Peter"
    ]
  },
  {
    "id": "d58f36f7679f85784d8b010ff248f898",
    "title": "Reusing Combinatorial Structure: Faster Iterative Projections over Submodular Base Polytopes",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d58f36f7679f85784d8b010ff248f898-Paper.pdf",
    "abstract": "Optimization algorithms such as projected Newton's method, FISTA,  mirror descent and its variants enjoy near-optimal regret bounds and convergence rates, but suffer from a computational bottleneck of computing ``projections\" in potentially each iteration (e.g., $O(T^{1/2})$ regret of online mirror descent). On the other hand, conditional gradient variants solve a linear optimization in each iteration, but result in suboptimal rates (e.g., $O(T^{3/4})$ regret of online Frank-Wolfe). Motivated by this trade-off in runtime v/s convergence rates, we consider iterative projections of close-by points over widely-prevalent submodular base polytopes $B(f)$. We develop a toolkit to speed up the computation of projections using both discrete and continuous perspectives. We subsequently adapt the away-step Frank-Wolfe algorithm to use this information and enable early termination. For the special case of cardinality based submodular polytopes, we improve the runtime of computing certain Bregman projections by a factor of $\\Omega(n/\\log(n))$. Our theoretical results show orders of magnitude reduction in runtime in preliminary computational experiments.",
    "authors": [
      "Moondra, Jai",
      "Mortagy, Hassan",
      "Gupta, Swati"
    ]
  },
  {
    "id": "d5ade38a2c9f6f073d69e1bc6b6e64c1",
    "title": "Constrained Optimization to Train Neural Networks on Critical and Under-Represented Classes",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d5ade38a2c9f6f073d69e1bc6b6e64c1-Paper.pdf",
    "abstract": "Deep neural networks (DNNs) are notorious for making more mistakes for the classes that have substantially fewer samples than the others during training. Such class imbalance is ubiquitous in clinical applications and very crucial to handle because the classes with fewer samples most often correspond to critical cases (e.g., cancer) where misclassifications can have severe consequences.Not to miss such cases, binary classifiers need to be operated at high True Positive Rates (TPRs) by setting a higher threshold, but this comes at the cost of very high False Positive Rates (FPRs) for problems with class imbalance. Existing methods for learning under class imbalance most often do not take this into account. We argue that prediction accuracy should be improved by emphasizing the reduction of FPRs at high TPRs for problems where misclassification of the positive, i.e. critical, class samples are associated with higher cost.To this end, we pose the training of a DNN for binary classification as a constrained optimization problem and introduce a novel constraint that can be used with existing loss functions to enforce maximal area under the ROC curve (AUC) through prioritizing FPR reduction at high TPR. We solve the resulting constrained optimization problem using an Augmented Lagrangian method (ALM).Going beyond binary, we also propose two possible extensions of the proposed constraint for multi-class classification problems.We present experimental results for image-based binary and multi-class classification applications using an in-house medical imaging dataset, CIFAR10, and CIFAR100. Our results demonstrate that the proposed method improves the baselines in majority of the cases by attaining higher accuracy on critical classes while reducing the misclassification rate for the non-critical class samples.",
    "authors": [
      "Sangalli, Sara",
      "Erdil, Ertunc",
      "H\u00f6tker, Andeas",
      "Donati, Olivio",
      "Konukoglu, Ender"
    ]
  },
  {
    "id": "d5b03d3acb580879f82271ab4885ee5e",
    "title": "Collapsed Variational Bounds for Bayesian Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d5b03d3acb580879f82271ab4885ee5e-Paper.pdf",
    "abstract": "Recent interest in learning large variational Bayesian Neural Networks (BNNs) has been partly hampered by poor predictive performance caused by underfitting, and their performance is known to be very sensitive to the prior over weights. Current practice often fixes the prior parameters to standard values or tunes them using heuristics or cross-validation. In this paper, we treat prior parameters in a distributional way by extending the model and collapsing the variational bound with respect to their posteriors. This leads to novel and tighter Evidence Lower Bounds (ELBOs) for performing variational inference (VI) in BNNs. Our experiments show that the new bounds significantly improve the performance of Gaussian mean-field VI applied to BNNs on a variety of data sets, demonstrating that mean-field VI works well even in deep models. We also find that the tighter ELBOs can be good optimization targets for learning the hyperparameters of hierarchical priors.",
    "authors": [
      "Tomczak, Marcin",
      "Swaroop, Siddharth",
      "Foong, Andrew",
      "Turner, Richard"
    ]
  },
  {
    "id": "d5b3d8dadd770c460b1cde910a711987",
    "title": "Consistent Estimation for PCA and Sparse Regression with Oblivious Outliers",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d5b3d8dadd770c460b1cde910a711987-Paper.pdf",
    "abstract": "We develop machinery to design efficiently computable and \\emph{consistent} estimators, achieving estimation error approaching zero as the number of observations grows, when facing an oblivious adversary that may corrupt responses in all but an $\\alpha$ fraction of the samples.As concrete examples, we investigate two problems: sparse regression and principal component analysis (PCA).For sparse regression, we achieve consistency for optimal sample size $n\\gtrsim (k\\log d)/\\alpha^2$ and optimal error rate $O(\\sqrt{(k\\log d)/(n\\cdot \\alpha^2)})$where $n$ is the number of observations, $d$ is the number of dimensions and $k$ is the sparsity of the parameter vector, allowing the fraction of inliers to be inverse-polynomial in the number of samples.Prior to this work, no estimator was known to be consistent when the fraction of inliers $\\alpha$ is $o(1/\\log \\log n)$, even for (non-spherical) Gaussian design matrices.Results holding under weak design assumptions and in the presence of such general noise have only been shown in dense setting (i.e., general linear regression) very recently by d'Orsi et al.~\\cite{ICML-linear-regression}.In the context of PCA, we attain optimal error guarantees under broad spikiness assumptions on the parameter matrix (usually used in matrix completion). Previous works could obtain non-trivial guarantees only under the assumptions that the measurement noise corresponding to the inliers is polynomially small in $n$ (e.g., Gaussian with variance $1/n^2$).To devise our estimators, we equip the Huber loss with non-smooth regularizers such as the $\\ell_1$ norm or the nuclear norm, and extend d'Orsi et al.'s approach~\\cite{ICML-linear-regression} in a novel way to analyze the loss function.Our machinery appears to be easily applicable to a wide range of estimation problems.We complement these algorithmic results with statistical lower bounds showing that the fraction of inliers that our PCA estimator can deal with is optimal up to a constant factor.",
    "authors": [
      "d'Orsi, Tommaso",
      "Liu, Chih-Hung",
      "Nasser, Rajai",
      "Novikov, Gleb",
      "Steurer, David",
      "Tiegel, Stefan"
    ]
  },
  {
    "id": "d5c8e1ab6fc0bfeb5f29aafa999cdb29",
    "title": "Offline Constrained Multi-Objective Reinforcement Learning via Pessimistic Dual Value Iteration",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d5c8e1ab6fc0bfeb5f29aafa999cdb29-Paper.pdf",
    "abstract": "In constrained multi-objective RL, the goal is to learn a policy that achieves the best performance specified by a multi-objective preference function under a constraint. We focus on the offline setting where the RL agent aims to learn the optimal policy from a given dataset. This scenario is common in real-world applications where interactions with the environment are expensive and the constraint violation is dangerous. For such a setting, we transform the original constrained problem into a  primal-dual formulation, which is solved via dual gradient ascent. Moreover, we propose to combine such an approach with pessimism to overcome the uncertainty in offline data, which leads to our Pessimistic Dual Iteration (PEDI). We establish upper bounds on both the suboptimality and constraint violation for the policy learned by PEDI based on an arbitrary dataset, which proves that PEDI is provably sample efficient. We also specialize PEDI to the setting with linear function approximation. To the best of our knowledge, we propose the first provably efficient constrained multi-objective RL algorithm with offline data without any assumption on the coverage of the dataset.",
    "authors": [
      "Wu, Runzhe",
      "Zhang, Yufeng",
      "Yang, Zhuoran",
      "Wang, Zhaoran"
    ]
  },
  {
    "id": "d5cfead94f5350c12c322b5b664544c1",
    "title": "Absolute Neighbour Difference based Correlation Test for Detecting Heteroscedastic Relationships",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d5cfead94f5350c12c322b5b664544c1-Paper.pdf",
    "abstract": "It is a challenge to detect complicated data relationships thoroughly. Here, we propose a new statistical measure, named the absolute neighbour difference based neighbour correlation coefficient, to detect the associations between variables through examining the heteroscedasticity of the unpredictable variation of dependent variables. Different from previous studies, the new method concentrates on measuring nonfunctional relationships rather than functional or mixed associations. Either used alone or in combination with other measures, it enables not only a convenient test of heteroscedasticity, but also measuring functional and nonfunctional relationships separately that obviously leads to a deeper insight into the data associations. The method is concise and easy to implement that does not rely on explicitly estimating the regression residuals or the dependencies between variables so that it is not restrict to any kind of model assumption. The mechanisms of the correlation test are proved in theory and demonstrated with numerical analyses.",
    "authors": [
      "Zhang, Lifeng"
    ]
  },
  {
    "id": "d5e2c0adad503c91f91df240d0cd4e49",
    "title": "Batch Multi-Fidelity Bayesian Optimization with  Deep Auto-Regressive Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d5e2c0adad503c91f91df240d0cd4e49-Paper.pdf",
    "abstract": "Bayesian optimization (BO) is a powerful approach for optimizing black-box, expensive-to-evaluate functions. To enable a flexible trade-off between the cost and accuracy, many applications allow the function to be evaluated at different fidelities.  In order to reduce the optimization cost while maximizing the benefit-cost ratio,  in this paper we propose Batch Multi-fidelity Bayesian Optimization with Deep Auto-Regressive Networks (BMBO-DARN). We use a set of Bayesian neural networks to construct a fully auto-regressive model, which is expressive enough to capture strong yet complex relationships across all the fidelities, so as to improve the surrogate learning and optimization performance. Furthermore, to enhance the quality and diversity of queries, we develop a simple yet efficient batch querying method, without any combinatorial search over the fidelities. We propose a batch acquisition function based on Max-value Entropy Search (MES) principle, which penalizes highly correlated queries and encourages diversity. We use posterior samples and moment matching to fulfill efficient computation of the acquisition function, and conduct alternating optimization over every fidelity-input pair, which guarantees an improvement at each step.  We demonstrate the advantage of our approach on four real-world  hyperparameter optimization applications.",
    "authors": [
      "Li, Shibo",
      "Kirby, Robert",
      "Zhe, Shandian"
    ]
  },
  {
    "id": "d5eca8dc3820cad9fe56a3bafda65ca1",
    "title": "Mastering Atari Games with Limited Data",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d5eca8dc3820cad9fe56a3bafda65ca1-Paper.pdf",
    "abstract": "Reinforcement learning has achieved great success in many applications. However, sample efficiency remains a key challenge, with prominent methods requiring millions (or even billions) of environment steps to train.  Recently, there has been significant progress in sample efficient image-based RL algorithms; however, consistent human-level performance on the Atari game benchmark remains an elusive goal. We propose a sample efficient model-based visual RL algorithm built on MuZero, which we name EfficientZero. Our method achieves 194.3% mean human performance and 109.0% median performance on the Atari 100k benchmark with only two hours of real-time game experience and outperforms the state SAC in some tasks on the DMControl 100k benchmark. This is the first time an algorithm achieves super-human performance on Atari games with such little data. EfficientZero's performance is also close to DQN's performance at 200 million frames while we consume 500 times less data. EfficientZero's low sample complexity and high performance can bring RL closer to real-world applicability. We implement our algorithm in an easy-to-understand manner and it is available at https://github.com/YeWR/EfficientZero. We hope it will accelerate the research of MCTS-based RL algorithms in the wider community. ",
    "authors": [
      "Ye, Weirui",
      "Liu, Shaohuai",
      "Kurutach, Thanard",
      "Abbeel, Pieter",
      "Gao, Yang"
    ]
  },
  {
    "id": "d5fcc35c94879a4afad61cacca56192c",
    "title": "Dealing With Misspecification In Fixed-Confidence Linear Top-m Identification",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d5fcc35c94879a4afad61cacca56192c-Paper.pdf",
    "abstract": "We study the problem of the identification of m arms with largest means under a fixed error rate $\\delta$ (fixed-confidence Top-m identification), for misspecified linear bandit models. This problem is motivated by practical applications, especially in medicine and recommendation systems, where linear models are popular due to their simplicity and the existence of efficient algorithms, but in which data inevitably deviates from linearity. In this work, we first derive a tractable lower bound on the sample complexity of any $\\delta$-correct algorithm for the general Top-m identification problem. We show that knowing the scale of the deviation from linearity is necessary to exploit the structure of the problem. We then describe the first algorithm for this setting, which is both practical and adapts to the amount of misspecification. We derive an upper bound to its sample complexity which confirms this adaptivity and that matches the lower bound when $\\delta \\rightarrow 0$. Finally, we evaluate our algorithm on both synthetic and real-world data, showing competitive performance with respect to existing baselines.",
    "authors": [
      "R\u00e9da, Cl\u00e9mence",
      "Tirinzoni, Andrea",
      "Degenne, R\u00e9my"
    ]
  },
  {
    "id": "d5ff135377d39f1de7372c95c74dd962",
    "title": "Why Generalization in RL is Difficult: Epistemic POMDPs and Implicit Partial Observability",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d5ff135377d39f1de7372c95c74dd962-Paper.pdf",
    "abstract": "Generalization is a central challenge for the deployment of reinforcement learning (RL) systems in the real world. In this paper, we show that the sequential structure of the RL problem necessitates new approaches to generalization beyond the well-studied techniques used in supervised learning. While supervised learning methods can generalize effectively without explicitly accounting for epistemic uncertainty, we describe why appropriate uncertainty handling can actually be essential in RL. We show that generalization to unseen test conditions from a limited number of training conditions induces a kind of implicit partial observability, effectively turning even fully-observed MDPs into POMDPs. Informed by this observation, we recast the problem of generalization in RL as solving the induced partially observed Markov decision process, which we call the epistemic POMDP. We demonstrate the failure modes of algorithms that do not appropriately handle this partial observability, and suggest a simple ensemble-based technique for approximately solving the partially observed problem. Empirically, we demonstrate that our simple algorithm derived from the epistemic POMDP achieves significant gains in generalization over current methods on the Procgen benchmark suite.",
    "authors": [
      "Ghosh, Dibya",
      "Rahme, Jad",
      "Kumar, Aviral",
      "Zhang, Amy",
      "Adams, Ryan P.",
      "Levine, Sergey"
    ]
  },
  {
    "id": "d61e9e58ae1058322bc169943b39f1d8",
    "title": "Set Prediction in the Latent Space",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d61e9e58ae1058322bc169943b39f1d8-Paper.pdf",
    "abstract": "Set prediction tasks require the matching between predicted set and ground truth set in order to propagate the gradient signal. Recent works have performed this matching in the original feature space thus requiring predefined distance functions. We propose a method for learning the distance function by performing the matching in the latent space learned from encoding networks. This method enables the use of teacher forcing which was not possible previously since matching in the feature space must be computed after the entire output sequence is generated. Nonetheless, a naive implementation of latent set prediction might not converge due to permutation instability. To address this problem, we provide sufficient conditions for permutation stability which begets an algorithm to improve the overall model convergence. Experiments on several set prediction tasks, including image captioning and object detection, demonstrate the effectiveness of our method. ",
    "authors": [
      "Preechakul, Konpat",
      "Piansaddhayanon, Chawan",
      "Naowarat, Burin",
      "Khandhawit, Tirasan",
      "Sriswasdi, Sira",
      "Chuangsuwanich, Ekapol"
    ]
  },
  {
    "id": "d63fbf8c3173730f82b150c5ef38b8ff",
    "title": "Best of Both Worlds: Practical and Theoretically Optimal Submodular Maximization in Parallel",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d63fbf8c3173730f82b150c5ef38b8ff-Paper.pdf",
    "abstract": "For the problem of maximizing a monotone, submodular function with respect to a cardinality constraint $k$ on a ground set of size $n$, we provide an algorithm that achieves the state-of-the-art in both its empirical performance and its theoretical properties, in terms of adaptive complexity, query complexity, and approximation ratio; that is, it obtains, with high probability, query complexity of $O(n)$ in expectation, adaptivity of $O(\\log(n))$, and approximation ratio of nearly $1-1/e$. The main algorithm is assembled from two components which may be of independent interest. The first component of our algorithm, LINEARSEQ, is useful as a preprocessing algorithm to improve the query complexity of many algorithms. Moreover, a variant of LINEARSEQ is shown to have adaptive complexity of $O( \\log (n / k) )$ which is smaller than that of any previous algorithm in the literature. The second component is a parallelizable thresholding procedure THRESHOLDSEQ for adding elements with gain above a constant threshold. Finally, we demonstrate that our main algorithm empirically outperforms, in terms of runtime, adaptive rounds, total queries, and objective values, the previous state-of-the-art algorithm FAST in a comprehensive evaluation with six submodular objective functions.",
    "authors": [
      "Chen, Yixin",
      "Dey, Tonmoy",
      "Kuhnle, Alan"
    ]
  },
  {
    "id": "d6428eecbe0f7dff83fc607c5044b2b9",
    "title": "Fine-grained Generalization Analysis of Inductive Matrix Completion",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d6428eecbe0f7dff83fc607c5044b2b9-Paper.pdf",
    "abstract": "In this paper, we bridge the gap between the state-of-the-art theoretical results for matrix completion with the nuclear norm and their equivalent in \\textit{inductive matrix completion}: (1) In the distribution-free setting, we prove bounds improving the previously best scaling of $O(rd^2)$ to $\\widetilde{O}(d^{3/2}\\sqrt{r})$, where $d$ is the dimension of the side information and $r$ is the rank. (2) We introduce the (smoothed) \\textit{adjusted trace-norm minimization} strategy, an inductive analogue of the weighted trace norm, for which we show guarantees of the order $\\widetilde{O}(dr)$ under arbitrary sampling. In the inductive case, a similar rate was previously achieved only under uniform sampling and for exact recovery. Both our results align with the state of the art in the particular case of standard (non-inductive) matrix completion, where they are known to be tight up to log terms. Experiments further confirm that our strategy outperforms standard inductive matrix completion on various synthetic datasets and real problems, justifying its place as an important tool in the arsenal of methods for matrix completion using side information. ",
    "authors": [
      "Ledent, Antoine",
      "Alves, Rodrigo",
      "Lei, Yunwen",
      "Kloft, Marius"
    ]
  },
  {
    "id": "d645920e395fedad7bbbed0eca3fe2e0",
    "title": "Learning Frequency Domain Approximation for Binary Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d645920e395fedad7bbbed0eca3fe2e0-Paper.pdf",
    "abstract": "Binary neural networks (BNNs) represent original full-precision weights and activations into 1-bit with sign function. Since the gradient of the conventional sign function is almost zero everywhere which cannot be used for back-propagation, several attempts have been proposed to alleviate the optimization difficulty by using approximate gradient. However, those approximations corrupt the main direction of factual gradient. To this end, we propose to estimate the gradient of sign function in the Fourier frequency domain using the combination of sine functions for training BNNs, namely frequency domain approximation (FDA). The proposed approach does not affect the low-frequency information of the original sign function which occupies most of the overall energy, and high-frequency coefficients will be ignored to avoid the huge computational overhead. In addition, we embed a noise adaptation module into the training phase to compensate the approximation error. The experiments on several benchmark datasets and neural architectures illustrate that the binary network learned using our method achieves the state-of-the-art accuracy. Code will be available at https://gitee.com/mindspore/models/tree/master/research/cv/FDA-BNN.",
    "authors": [
      "Xu, Yixing",
      "Han, Kai",
      "Xu, Chang",
      "Tang, Yehui",
      "XU, Chunjing",
      "Wang, Yunhe"
    ]
  },
  {
    "id": "d6539d3b57159babf6a72e106beb45bd",
    "title": "Reformulating Zero-shot Action Recognition for Multi-label Actions",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d6539d3b57159babf6a72e106beb45bd-Paper.pdf",
    "abstract": "The goal of zero-shot action recognition (ZSAR) is to classify action classes which were not previously seen during training. Traditionally, this is achieved by training a network to map, or regress, visual inputs to a semantic space where a nearest neighbor classifier is used to select the closest target class. We argue that this approach is sub-optimal due to the use of nearest neighbor on static semantic space and is ineffective when faced with multi-label videos - where two semantically distinct co-occurring action categories cannot be predicted with high confidence. To overcome these limitations, we propose a ZSAR framework which does not rely on nearest neighbor classification, but rather consists of a pairwise scoring function. Given a video and a set of action classes, our method predicts a set of confidence scores for each class independently. This allows for the prediction of several semantically distinct classes within one video input. Our evaluations show that our method not only achieves strong performance on three single-label action classification datasets (UCF-101, HMDB, and RareAct), but also outperforms previous ZSAR approaches on a challenging multi-label dataset (AVA) and a real-world surprise activity detection dataset (MEVA).",
    "authors": [
      "Kerrigan, Alec",
      "Duarte, Kevin",
      "Rawat, Yogesh",
      "Shah, Mubarak"
    ]
  },
  {
    "id": "d69c7ebb6a253532b266151eac6591af",
    "title": "Optimal Best-Arm Identification Methods for Tail-Risk Measures",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d69c7ebb6a253532b266151eac6591af-Paper.pdf",
    "abstract": "Conditional value-at-risk (CVaR) and value-at-risk (VaR) are popular tail-risk measures in finance and insurance industries as well as in highly reliable, safety-critical uncertain environments where often the underlying probability distributions are heavy-tailed. We use the multi-armed bandit best-arm identification framework and consider the problem of identifying the arm from amongst finitely many that has the smallest CVaR, VaR, or weighted sum of CVaR and mean. The latter captures the risk-return trade-off common in finance. Our main contribution is an optimal $\\delta$-correct algorithm that acts on general arms, including heavy-tailed distributions, and matches the lower bound on the expected number of samples needed, asymptotically (as $ \\delta$ approaches $0$). The algorithm requires solving a non-convex optimization problem in the space of probability measures, that requires delicate analysis. En-route, we develop new non-asymptotic, anytime-valid, empirical-likelihood-based concentration inequalities for tail-risk measures. ",
    "authors": [
      "Agrawal, Shubhada",
      "Koolen, Wouter M.",
      "Juneja, Sandeep"
    ]
  },
  {
    "id": "d6ef5f7fa914c19931a55bb262ec879c",
    "title": "SyMetric: Measuring the Quality of Learnt Hamiltonian Dynamics Inferred from Vision",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d6ef5f7fa914c19931a55bb262ec879c-Paper.pdf",
    "abstract": "A recently proposed class of models attempts to learn latent dynamics from high-dimensional observations, like images, using priors informed by Hamiltonian mechanics. While these models have important potential applications in areas like robotics or autonomous driving, there is currently no good way to evaluate their performance: existing methods primarily rely on image reconstruction quality, which does not always reflect the quality of the learnt latent dynamics. In this work, we empirically highlight the problems with the existing measures and develop a set of new measures, including a binary indicator of whether the underlying Hamiltonian dynamics have been faithfully captured, which we call Symplecticity Metric or SyMetric. Our measures take advantage of the known properties of Hamiltonian dynamics and are more discriminative of the model's ability to capture the underlying dynamics than reconstruction error. Using SyMetric, we identify a set of architectural choices that significantly improve the performance of a previously proposed model for inferring latent dynamics from pixels, the Hamiltonian Generative Network (HGN). Unlike the original HGN, the new SyMetric is able to discover an interpretable phase space with physically meaningful latents on some datasets. Furthermore, it is stable for significantly longer rollouts on a diverse range of 13 datasets,  producing rollouts of essentially infinite length both forward and backwards in time with no degradation in quality on a subset of the datasets.",
    "authors": [
      "Higgins, Irina",
      "Wirnsberger, Peter",
      "Jaegle, Andrew",
      "Botev, Aleksandar"
    ]
  },
  {
    "id": "d71dd235287466052f1630f31bde7932",
    "title": "Learning with Holographic Reduced Representations",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d71dd235287466052f1630f31bde7932-Paper.pdf",
    "abstract": "Holographic Reduced Representations (HRR) are a method for performing symbolic AI on top of real-valued vectors by associating each vector with an abstract concept, and providing mathematical operations to manipulate vectors as if they were classic symbolic objects. This method has seen little use outside of older symbolic AI work and cognitive science. Our goal is to revisit this approach to understand if it is viable for enabling a hybrid neural-symbolic  approach to learning as a differential component of a deep learning architecture. HRRs today are not effective in a differential solution due to numerical instability, a problem we solve by introducing a projection step that forces the vectors to exist in a well behaved point in space. In doing so we improve the concept retrieval efficacy of HRRs by over $100\\times$. Using multi-label classification we demonstrate how to leverage the symbolic HRR properties to develop a output layer and loss function that is able to learn effectively, and allows us to investigate some of the pros and cons of an HRR neuro-symbolic learning approach. ",
    "authors": [
      "Ganesan, Ashwinkumar",
      "Gao, Hang",
      "Gandhi, Sunil",
      "Raff, Edward",
      "Oates, Tim",
      "Holt, James",
      "McLean, Mark"
    ]
  },
  {
    "id": "d71fa38b648d86602d14ac610f2e6194",
    "title": "Learning Barrier Certificates: Towards Safe Reinforcement Learning with Zero Training-time Violations",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d71fa38b648d86602d14ac610f2e6194-Paper.pdf",
    "abstract": "Training-time safety violations have been a major concern when we deploy reinforcement learning algorithms in the real world.This paper explores the possibility of safe RL algorithms with zero training-time safety violations in the challenging setting where we are only given a safe but trivial-reward initial policy without any prior knowledge of the dynamics and additional offline data.We propose an algorithm, Co-trained Barrier Certificate for Safe RL (CRABS), which iteratively learns barrier certificates, dynamics models, and policies. The barrier certificates are learned via adversarial training and ensure the policy's safety assuming calibrated learned dynamics. We also add a regularization term to encourage larger certified regions to enable better exploration. Empirical simulations show that zero safety violations are already challenging for a suite of simple environments with only 2-4 dimensional state space, especially if high-reward policies have to visit regions near the safety boundary.  Prior methods require hundreds of violations to achieve decent rewards on these tasks,  whereas our proposed algorithms incur zero violations.",
    "authors": [
      "Luo, Yuping",
      "Ma, Tengyu"
    ]
  },
  {
    "id": "d757719ed7c2b66dd17dcee2a3cb29f4",
    "title": "On the Second-order Convergence Properties of Random Search Methods",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d757719ed7c2b66dd17dcee2a3cb29f4-Paper.pdf",
    "abstract": "We study the theoretical convergence properties of random-search methods when optimizing non-convex objective functions without having access to derivatives. We prove that standard random-search methods that do not rely on second-order information converge to a second-order stationary point. However, they suffer from an exponential complexity in terms of the input dimension of the problem. In order to address this issue, we propose a novel variant of random search that exploits negative curvature by only relying on function evaluations. We prove that this approach converges to a second-order stationary point at a much faster rate than vanilla methods: namely, the complexity in terms of the number of function evaluations is only linear in the problem dimension. We test our algorithm empirically and find good agreements with our theoretical results.",
    "authors": [
      "Lucchi, Aurelien",
      "Orvieto, Antonio",
      "Solomou, Adamos"
    ]
  },
  {
    "id": "d76d8deea9c19cc9aaf2237d2bf2f785",
    "title": "Noether\u2019s Learning Dynamics: Role of Symmetry Breaking in Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d76d8deea9c19cc9aaf2237d2bf2f785-Paper.pdf",
    "abstract": "In nature, symmetry governs regularities, while symmetry breaking brings texture. In artificial neural networks, symmetry has been a central design principle to efficiently capture regularities in the world, but the role of symmetry breaking is not well understood. Here, we develop a theoretical framework to study the \"geometry of learning dynamics\" in neural networks, and reveal a key mechanism of explicit symmetry breaking behind the efficiency and stability of modern neural networks. To build this understanding, we model the discrete learning dynamics of gradient descent using a continuous-time Lagrangian formulation, in which the learning rule corresponds to the kinetic energy and the loss function corresponds to the potential energy. Then, we identify \"kinetic symmetry breaking\" (KSB), the condition when the kinetic energy explicitly breaks the symmetry of the potential function. We generalize Noether\u2019s theorem known in physics to take into account KSB and derive the resulting motion of the Noether charge: \"Noether's Learning Dynamics\" (NLD). Finally, we apply NLD to neural networks with normalization layers and reveal how KSB introduces a mechanism of implicit adaptive optimization, establishing an analogy between learning dynamics induced by normalization layers and RMSProp. Overall, through the lens of Lagrangian mechanics, we have established a theoretical foundation to discover geometric design principles for the learning dynamics of neural networks.",
    "authors": [
      "Tanaka, Hidenori",
      "Kunin, Daniel"
    ]
  },
  {
    "id": "d77e68596c15c53c2a33ad143739902d",
    "title": "A Theory of the Distortion-Perception Tradeoff in Wasserstein Space",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d77e68596c15c53c2a33ad143739902d-Paper.pdf",
    "abstract": "The lower the distortion of an estimator, the more the distribution of its outputs generally deviates from the distribution of the signals it attempts to estimate. This phenomenon, known as the perception-distortion tradeoff, has captured significant attention in image restoration, where it implies that fidelity to ground truth images comes on the expense of perceptual quality (deviation from statistics of natural images). However, despite the increasing popularity of performing comparisons on the perception-distortion plane, there remains an important open question: what is the minimal distortion that can be achieved under a given perception constraint? In this paper, we derive a closed form expression for this distortion-perception (DP) function for the mean squared-error (MSE) distortion and Wasserstein-2 perception index. We prove that the DP function is always quadratic, regardless of the underlying distribution. This stems from the fact that estimators on the DP curve form a geodesic in Wasserstein space. In the Gaussian setting, we further provide a closed form expression for such estimators. For general distributions, we show how these estimators can be constructed from the estimators at the two extremes of the tradeoff: The global MSE minimizer, and a  minimizer of the MSE under a perfect perceptual quality constraint. The latter can be obtained as a stochastic transformation of the former.",
    "authors": [
      "Freirich, Dror",
      "Michaeli, Tomer",
      "Meir, Ron"
    ]
  },
  {
    "id": "d785bf9067f8af9e078b93cf26de2b54",
    "title": "Neural Production Systems",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d785bf9067f8af9e078b93cf26de2b54-Paper.pdf",
    "abstract": "Visual environments are structured, consisting of distinct  objects or entities. These entities have properties---visible or latent---that determine the manner in which they interact with one another. To partition images into entities, deep-learning researchers have proposed structural inductive biases such as slot-based architectures. To model interactions among entities, equivariant graph neural nets (GNNs) are used, but these are not particularly well suited to the task for two reasons. First, GNNs do not predispose interactions to be sparse, as relationships among independent entities are likely to be.  Second, GNNs do not factorize knowledge about  interactions in an entity-conditional manner. As an alternative, we take inspiration from cognitive science and resurrect a classic approach, production systems, which consist of a set of rule templates that are applied by binding placeholder  variables in the rules to specific entities. Rules are scored on their match to entities, and the best fitting rules are applied to update entity properties. In a series of experiments, we demonstrate that this architecture achieves a flexible, dynamic flow of control and serves to factorize entity-specific and rule-based information. This disentangling of knowledge achieves robust future-state prediction in rich visual environments, outperforming state-of-the-art methods using GNNs, and allows for the extrapolation from simple (few object) environments to more complex environments.",
    "authors": [
      "ALIAS PARTH GOYAL, Anirudh Goyal",
      "Didolkar, Aniket",
      "Ke, Nan Rosemary",
      "Blundell, Charles",
      "Beaudoin, Philippe",
      "Heess, Nicolas",
      "Mozer, Michael C.",
      "Bengio, Yoshua"
    ]
  },
  {
    "id": "d79c6256b9bdac53a55801a066b70da3",
    "title": "Smoothness Matrices Beat Smoothness Constants: Better  Communication Compression Techniques for Distributed Optimization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d79c6256b9bdac53a55801a066b70da3-Paper.pdf",
    "abstract": "Large scale distributed optimization has become the default tool for the training of supervised machine learning models with a large number of parameters and training data. Recent advancements in the field provide several mechanisms for speeding up the training, including {\\em compressed communication}, {\\em variance reduction} and {\\em acceleration}. However, none of these methods is capable of exploiting the inherently rich data-dependent smoothness structure of the local losses beyond standard smoothness constants. In this paper, we argue that when training supervised models,  {\\em smoothness matrices}---information-rich generalizations of the ubiquitous smoothness constants---can and should be exploited for further dramatic gains, both in theory and practice. In order to further alleviate the communication burden inherent in distributed optimization, we propose a novel communication sparsification strategy that can take full advantage of the smoothness matrices associated with local losses. To showcase the power of this tool, we describe how our sparsification technique can be adapted to three distributed optimization algorithms---DCGD, DIANA and ADIANA---yielding significant savings in terms of communication complexity.  The new methods always outperform the baselines, often dramatically so.",
    "authors": [
      "Safaryan, Mher",
      "Hanzely, Filip",
      "Richtarik, Peter"
    ]
  },
  {
    "id": "d79c8788088c2193f0244d8f1f36d2db",
    "title": "Increasing Liquid State Machine Performance with Edge-of-Chaos Dynamics Organized by Astrocyte-modulated Plasticity",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d79c8788088c2193f0244d8f1f36d2db-Paper.pdf",
    "abstract": "The liquid state machine (LSM) combines low training complexity and biological plausibility, which has made it an attractive machine learning framework for edge and neuromorphic computing paradigms. Originally proposed as a model of brain computation, the LSM tunes its internal weights without backpropagation of gradients, which results in lower performance compared to multi-layer neural networks. Recent findings in neuroscience suggest that astrocytes, a long-neglected non-neuronal brain cell, modulate synaptic plasticity and brain dynamics, tuning brain networks to the vicinity of the computationally optimal critical phase transition between order and chaos. Inspired by this disruptive understanding of how brain networks self-tune, we propose the neuron-astrocyte liquid state machine (NALSM) that addresses under-performance through self-organized near-critical dynamics. Similar to its biological counterpart, the astrocyte model integrates neuronal activity and provides global feedback to spike-timing-dependent plasticity (STDP), which self-organizes NALSM dynamics around a critical branching factor that is associated with the edge-of-chaos. We demonstrate that NALSM achieves state-of-the-art accuracy versus comparable LSM methods, without the need for data-specific hand-tuning. With a top accuracy of $97.61\\%$ on MNIST, $97.51\\%$ on N-MNIST, and $85.84\\%$ on Fashion-MNIST, NALSM achieved comparable performance to current fully-connected multi-layer spiking neural networks trained via backpropagation. Our findings suggest that the further development of brain-inspired machine learning methods has the potential to reach the performance of deep learning, with the added benefits of supporting robust and energy-efficient neuromorphic computing on the edge.",
    "authors": [
      "Ivanov, Vladimir",
      "Michmizos, Konstantinos"
    ]
  },
  {
    "id": "d7b431b1a0cc5f032399870ff4710743",
    "title": "Fair Sortition Made Transparent",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d7b431b1a0cc5f032399870ff4710743-Paper.pdf",
    "abstract": "Sortition is an age-old democratic paradigm, widely manifested today through the random selection of citizens' assemblies. Recently-deployed algorithms select assemblies \\textit{maximally fairly}, meaning that subject to demographic quotas, they give all potential participants as equal a chance as possible of being chosen.  While these fairness gains can bolster the legitimacy of citizens' assemblies and facilitate their uptake, existing algorithms remain limited by their lack of transparency. To overcome this hurdle, in this work we focus on panel selection by uniform lottery, which is easy to realize in an observable way. By this approach, the final assembly is selected by uniformly sampling some pre-selected set of $m$ possible assemblies.We provide theoretical guarantees on the fairness attainable via this type of uniform lottery, as compared to the existing maximally fair but opaque algorithms, for two different fairness objectives. We complement these results with experiments on real-world instances that demonstrate the viability of the uniform lottery approach as a method of selecting assemblies both fairly and transparently.",
    "authors": [
      "Flanigan, Bailey",
      "Kehne, Gregory",
      "Procaccia, Ariel D."
    ]
  },
  {
    "id": "d7b76edf790923bf7177f7ebba5978df",
    "title": "A Max-Min Entropy Framework for Reinforcement Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d7b76edf790923bf7177f7ebba5978df-Paper.pdf",
    "abstract": "In this paper, we propose a max-min entropy framework for reinforcement learning (RL) to overcome the limitation of the soft actor-critic (SAC) algorithm implementing the maximum entropy RL in model-free sample-based learning. Whereas the maximum entropy RL guides learning for policies to reach states with high entropy in the future, the proposed max-min entropy framework aims to learn to visit states with low entropy and maximize the entropy of these low-entropy states to promote better exploration. For general Markov decision processes (MDPs), an efficient algorithm is constructed under the proposed max-min entropy framework based on disentanglement of exploration and exploitation. Numerical results show that the proposed algorithm yields drastic performance improvement over the current state-of-the-art RL algorithms.",
    "authors": [
      "Han, Seungyul",
      "Sung, Youngchul"
    ]
  },
  {
    "id": "d7e4cdde82a894b8f633e6d61a01ef15",
    "title": "Reward is enough for convex MDPs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d7e4cdde82a894b8f633e6d61a01ef15-Paper.pdf",
    "abstract": "Maximising a cumulative reward function that is Markov and stationary, i.e., defined over state-action pairs and independent of time, is sufficient to capture many kinds of goals in a Markov decision process (MDP). However, not all goals can be captured in this manner. In this paper we study convex MDPs in which goals are expressed as convex functions of the stationary distribution and show that they cannot be formulated using stationary reward functions. Convex MDPs generalize the standard reinforcement learning (RL) problem formulation to a larger framework that includes many supervised and unsupervised RL problems, such as apprenticeship learning, constrained MDPs, and so-called pure exploration'. Our approach is to reformulate the convex MDP problem as a min-max game involving policy and cost (negative reward)players', using Fenchel duality. We propose a meta-algorithm for solving this problem and show that it unifies many existing algorithms in the literature.",
    "authors": [
      "Zahavy, Tom",
      "O'Donoghue, Brendan",
      "Desjardins, Guillaume",
      "Singh, Satinder"
    ]
  },
  {
    "id": "d7f14b4988c30cc40e5e7b7d157bc018",
    "title": "Fast Doubly-Adaptive MCMC to Estimate the Gibbs Partition Function with Weak Mixing Time Bounds",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d7f14b4988c30cc40e5e7b7d157bc018-Paper.pdf",
    "abstract": "We present a novel method for reducing the computational complexity of rigorously estimating the partition functions of Gibbs (or Boltzmann) distributions, which arise ubiquitously in probabilistic graphical models. A major obstacle to applying the Gibbs distribution in practice is the need to estimate their partition function (normalizing constant).  The state of the art in addressing this problem is multi-stage algorithms which consist of a cooling schedule and a mean estimator in each step of the schedule.  While the cooling schedule in these algorithms is adaptive, the mean estimate computations use MCMC as a black-box to draw approximately-independent samples. Here we develop a doubly adaptive approach, combining the adaptive cooling schedule with an adaptive MCMC mean estimator, whose number of Markov chain steps adapts dynamically to the underlying chain. Through rigorous theoretical analysis, we prove that our method outperforms the state of the art algorithms in several factors: (1) The computational complexity of our method is smaller; (2) Our method is less sensitive to loose bounds on mixing times, an inherent components in these algorithms; and (3) The improvement obtained by our method is particularly significant in the most challenging regime of high precision estimates. We demonstrate the advantage of our method in experiments run on classic factor graphs, such as voting models and Ising models. ",
    "authors": [
      "Haddadan, Shahrzad",
      "Zhuang, Yue",
      "Cousins, Cyrus",
      "Upfal, Eli"
    ]
  },
  {
    "id": "d800149d2f947ad4d64f34668f8b20f6",
    "title": "Does enforcing fairness mitigate biases caused by subpopulation shift?",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d800149d2f947ad4d64f34668f8b20f6-Paper.pdf",
    "abstract": "Many instances of algorithmic bias are caused by subpopulation shifts. For example, ML models often perform worse on demographic groups that are underrepresented in the training data. In this paper, we study whether enforcing algorithmic fairness during training improves the performance of the trained model in the \\emph{target domain}. On one hand, we conceive scenarios in which enforcing fairness does not improve performance in the target domain. In fact, it may even harm performance. On the other hand, we derive necessary and sufficient conditions under which enforcing algorithmic fairness leads to the Bayes model in the target domain. We also illustrate the practical implications of our theoretical results in simulations and on real data.",
    "authors": [
      "Maity, Subha",
      "Mukherjee, Debarghya",
      "Yurochkin, Mikhail",
      "Sun, Yuekai"
    ]
  },
  {
    "id": "d811406316b669ad3d370d78b51b1d2e",
    "title": "Implicit Deep Adaptive Design: Policy-Based Experimental Design without Likelihoods",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d811406316b669ad3d370d78b51b1d2e-Paper.pdf",
    "abstract": "We introduce implicit Deep Adaptive Design (iDAD), a new method for performing adaptive experiments in real-time with implicit models. iDAD amortizes the cost of Bayesian optimal experimental design (BOED) by learning a design policy network upfront, which can then be deployed quickly at the time of the experiment. The iDAD network can be trained on any model which simulates differentiable samples, unlike previous design policy work that requires a closed form likelihood and conditionally independent experiments. At deployment, iDAD allows design decisions to be made in milliseconds, in contrast to traditional BOED approaches that require heavy computation during the experiment itself. We illustrate the applicability of iDAD on a number of experiments, and show that it provides a fast and effective mechanism for performing adaptive design with implicit models.",
    "authors": [
      "Ivanova, Desi R",
      "Foster, Adam",
      "Kleinegesse, Steven",
      "Gutmann, Michael U.",
      "Rainforth, Thomas"
    ]
  },
  {
    "id": "d82118376df344b0010f53909b961db3",
    "title": "Sample-Efficient Learning of Stackelberg Equilibria in General-Sum Games",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d82118376df344b0010f53909b961db3-Paper.pdf",
    "abstract": "Real world applications such as economics and policy making often involve solving multi-agent games with two unique features: (1) The agents are inherently asymmetric and partitioned into leaders and followers; (2) The agents have different reward functions, thus the game is general-sum. The majority of existing results in this field focuses on either symmetric solution concepts (e.g. Nash equilibrium) or zero-sum games. It remains open how to learn the Stackelberg equilibrium---an asymmetric analog of the Nash equilibrium---in general-sum games efficiently from noisy samples.  This paper initiates the theoretical study of sample-efficient learning of the Stackelberg equilibrium, in the bandit feedback setting where we only observe noisy samples of the reward. We consider three representative two-player general-sum games: bandit games, bandit-reinforcement learning (bandit-RL) games, and linear bandit games. In all these games, we identify a fundamental gap between the exact value of the Stackelberg equilibrium and its estimated version using finitely many noisy samples, which can not be closed information-theoretically regardless of the algorithm. We then establish sharp positive results on sample-efficient learning of Stackelberg equilibrium with value optimal up to the gap identified above, with matching lower bounds in the dependency on the gap, error tolerance, and the size of the action spaces. Overall, our results unveil unique challenges in learning Stackelberg equilibria under noisy bandit feedback, which we hope could shed light on future research on this topic.",
    "authors": [
      "Bai, Yu",
      "Jin, Chi",
      "Wang, Huan",
      "Xiong, Caiming"
    ]
  },
  {
    "id": "d827f12e35eae370ba9c65b7f6026695",
    "title": "Non-approximate Inference for Collective Graphical Models on Path Graphs via Discrete Difference of Convex Algorithm",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d827f12e35eae370ba9c65b7f6026695-Paper.pdf",
    "abstract": "The importance of aggregated count data, which is calculated from the data of multiple individuals, continues to increase. Collective Graphical Model (CGM) is a probabilistic approach to the analysis of aggregated data. One of the most important operations in CGM is maximum a posteriori (MAP) inference of unobserved variables under given observations. Because the MAP inference problem for general CGMs has been shown to be NP-hard, an approach that solves an approximate problem has been proposed. However, this approach has two major drawbacks. First, the quality of the solution deteriorates when the values in the count tables are small, because the approximation becomes inaccurate. Second, since continuous relaxation is applied, the integrality constraints of the output are violated. To resolve these problems, this paper proposes a new method for MAP inference for CGMs on path graphs. Our method is based on the Difference of Convex Algorithm (DCA), which is a general methodology to minimize a function represented as the sum of a convex function and a concave function. In our algorithm, important subroutines in DCA can be efficiently calculated by minimum convex cost flow algorithms. Experiments show that the proposed method outputs higher quality solutions than the conventional approach. ",
    "authors": [
      "Akagi, Yasunori",
      "Marumo, Naoki",
      "Kim, Hideaki",
      "Kurashima, Takeshi",
      "Toda, Hiroyuki"
    ]
  },
  {
    "id": "d82f9436247aa0049767b776dceab4ed",
    "title": "Implicit Task-Driven Probability Discrepancy Measure for Unsupervised Domain Adaptation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d82f9436247aa0049767b776dceab4ed-Paper.pdf",
    "abstract": "Probability discrepancy measure is a fundamental construct for numerous machine learning models such as weakly supervised learning and generative modeling.  However, most measures overlook the fact that the distributions are not the end-product of learning, but are the basis of downstream predictor.  Therefore it is important to warp the probability discrepancy measure towards the end tasks, and we hence propose a new bi-level optimization based approach so that the two distributions are compared not uniformly against the entire hypothesis space, but only with respect to the optimal predictor for the downstream end task.  When applied to margin disparity discrepancy and contrastive domain discrepancy, our method significantly improves the performance in unsupervised domain adaptation, and enjoys a much more principled training process.",
    "authors": [
      "Li, Mao",
      "Jiang, Kaiqi",
      "Zhang, Xinhua"
    ]
  },
  {
    "id": "d87ca511e2a8593c8039ef732f5bffed",
    "title": "SBO-RNN: Reformulating Recurrent Neural Networks via Stochastic Bilevel Optimization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d87ca511e2a8593c8039ef732f5bffed-Paper.pdf",
    "abstract": "In this paper we consider the training stability of recurrent neural networks (RNNs) and propose a family of RNNs, namely SBO-RNN, that can be formulated using stochastic bilevel optimization (SBO). With the help of stochastic gradient descent (SGD), we manage to convert the SBO problem into an RNN where the feedforward and backpropagation solve the lower and upper-level optimization for learning hidden states and their hyperparameters, respectively. We prove that under mild conditions there is no vanishing or exploding gradient in training SBO-RNN. Empirically we demonstrate our approach with superior performance on several benchmark datasets, with fewer parameters, less training data, and much faster convergence. Code is available at https://zhang-vislab.github.io.",
    "authors": [
      "Zhang, Ziming",
      "Yue, Yun",
      "Wu, Guojun",
      "Li, Yanhua",
      "Zhang, Haichong"
    ]
  },
  {
    "id": "d9896106ca98d3d05b8cbdf4fd8b13a1",
    "title": "Navigating to the Best Policy in Markov Decision Processes",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d9896106ca98d3d05b8cbdf4fd8b13a1-Paper.pdf",
    "abstract": "We investigate the classical active pure exploration problem in Markov Decision Processes, where the agent sequentially selects actions and, from the resulting system trajectory, aims at identifying the best policy as fast as possible. We propose a problem-dependent lower bound on the average number of steps required before a correct answer can be given with probability at least $1-\\delta$. We further provide the first algorithm with an instance-specific sample complexity in this setting. This algorithm addresses the general case of communicating MDPs; we also propose a variant with a reduced exploration rate (and hence faster convergence) under an additional ergodicity assumption. This work extends previous results relative to the \\emph{generative setting}~\\cite{pmlr-v139-marjani21a}, where the agent could at each step query the random outcome of any (state, action) pair. In contrast, we show here how to deal with the \\emph{navigation constraints}, induced by the \\emph{online setting}. Our analysis relies on an ergodic theorem for non-homogeneous Markov chains which we consider of wide interest in the analysis of Markov Decision Processes.",
    "authors": [
      "Al Marjani, Aymen",
      "Garivier, Aur\u00e9lien",
      "Proutiere, Alexandre"
    ]
  },
  {
    "id": "d994e3728ba5e28defb88a3289cd7ee8",
    "title": "A Faster Decentralized Algorithm for Nonconvex Minimax Problems",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d994e3728ba5e28defb88a3289cd7ee8-Paper.pdf",
    "abstract": "In this paper, we study the nonconvex-strongly-concave minimax optimization problem on decentralized setting. The minimax problems are attracting increasing attentions because of their popular practical applications such as policy evaluation and adversarial training. As training data become larger, distributed training has been broadly adopted in machine learning tasks. Recent research works show that the decentralized distributed data-parallel training techniques are specially promising, because they can achieve the efficient communications and avoid the bottleneck problem on the central node or the latency of low bandwidth network. However, the decentralized minimax problems were seldom studied in literature and the existing methods suffer from very high gradient complexity. To address this challenge, we propose a new faster decentralized algorithm, named as DM-HSGD, for nonconvex minimax problems by using the variance reduced technique of hybrid stochastic gradient descent. We prove that our DM-HSGD algorithm achieves stochastic first-order oracle (SFO) complexity of $O(\\kappa^3 \\epsilon^{-3})$ for decentralized stochastic nonconvex-strongly-concave problem to search an $\\epsilon$-stationary point, which improves the exiting best theoretical results. Moreover, we also prove that our algorithm achieves linear speedup with respect to the number of workers. Our experiments on decentralized settings show the superior performance of our new algorithm.",
    "authors": [
      "Xian, Wenhan",
      "Huang, Feihu",
      "Zhang, Yanfu",
      "Huang, Heng"
    ]
  },
  {
    "id": "d9d347f57ae11f34235b4555710547d8",
    "title": "Generalization Bounds For Meta-Learning: An Information-Theoretic Analysis",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d9d347f57ae11f34235b4555710547d8-Paper.pdf",
    "abstract": "We derive a novel information-theoretic analysis of the generalization property of meta-learning algorithms. Concretely, our analysis proposes a generic understanding in both the conventional learning-to-learn framework \\citep{amit2018meta} and the modern model-agnostic meta-learning (MAML) algorithms \\citep{finn2017model}.Moreover, we provide a data-dependent generalization bound for the stochastic variant of MAML, which is \\emph{non-vacuous} for deep few-shot learning. As compared to previous bounds that depend on the square norms of gradients, empirical validations on both simulated data and a well-known few-shot benchmark show that our bound is orders of magnitude tighter in most conditions.",
    "authors": [
      "CHEN, Qi",
      "Shui, Changjian",
      "Marchand, Mario"
    ]
  },
  {
    "id": "d9d3837ee7981e8c064774da6cdd98bf",
    "title": "ReLU Regression with Massart Noise",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d9d3837ee7981e8c064774da6cdd98bf-Paper.pdf",
    "abstract": "We study the fundamental problem of ReLU regression, where the goal is to fit Rectified Linear Units (ReLUs) to data. This supervised learning task is efficiently solvable in the realizable setting, but is known to be computationally hard with adversarial label noise. In this work, we focus on ReLU regression in the Massart noise model,  a natural and well-studied semi-random noise model. In this model, the label of every point is generated according to a function in the class, but an adversary is allowed to change this value arbitrarily with some probability, which is {\\em at most} $\\eta < 1/2$. We develop an efficient algorithm that achieves exact parameter recovery in this model under mild anti-concentration assumptions on the underlying distribution. Such assumptions are necessary for exact recovery to be information-theoretically possible. We demonstrate that our algorithm significantly outperforms naive applications of $\\ell_1$ and $\\ell_2$ regression on both synthetic and real data.",
    "authors": [
      "Diakonikolas, Ilias",
      "Park, Jong Ho",
      "Tzamos, Christos"
    ]
  },
  {
    "id": "d9de6a144a3cc26cb4b3c47b206a121a",
    "title": "Identification of the Generalized Condorcet Winner in Multi-dueling Bandits",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d9de6a144a3cc26cb4b3c47b206a121a-Paper.pdf",
    "abstract": "The reliable identification of the \u201cbest\u201d arm while keeping the sample complexity as low as possible is a common task in the field of multi-armed bandits. In the multi-dueling variant of multi-armed bandits, where feedback is provided in the form of a winning arm among as set of k chosen ones, a reasonable notion of best arm is the generalized Condorcet winner (GCW). The latter is an the arm that has the greatest probability of being the winner in each subset containing it. In this paper, we derive lower bounds on the sample complexity for the task of identifying the GCW under various assumptions. As a by-product, our lower bound results provide new insights for the special case of dueling bandits (k = 2). We propose the Dvoretzky\u2013Kiefer\u2013Wolfowitz tournament (DKWT) algorithm, which we prove to be nearly optimal. In a numerical study, we show that DKWT empirically outperforms current state-of-the-art algorithms, even in the special case of dueling bandits or under a Plackett-Luce assumption on the feedback mechanism.",
    "authors": [
      "Haddenhorst, Bj\u00f6rn",
      "Bengs, Viktor",
      "H\u00fcllermeier, Eyke"
    ]
  },
  {
    "id": "d9e74f47610385b11e295eec4c58d473",
    "title": "Robust Inverse Reinforcement Learning under Transition Dynamics Mismatch",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d9e74f47610385b11e295eec4c58d473-Paper.pdf",
    "abstract": "We study the inverse reinforcement learning (IRL) problem under a transition dynamics mismatch between the expert and the learner. Specifically, we consider the Maximum Causal Entropy (MCE) IRL learner model and provide a tight upper bound on the learner's performance degradation based on the $\\ell_1$-distance between the transition dynamics of the expert and the learner. Leveraging insights from the Robust RL literature, we propose a robust MCE IRL algorithm, which is a principled approach to help with this mismatch. Finally, we empirically demonstrate the stable performance of our algorithm compared to the standard MCE IRL algorithm under transition dynamics mismatches in both finite and continuous MDP problems.",
    "authors": [
      "Viano, Luca",
      "Huang, Yu-Ting",
      "Kamalaruban, Parameswaran",
      "Weller, Adrian",
      "Cevher, Volkan"
    ]
  },
  {
    "id": "d9fc0cdb67638d50f411432d0d41d0ba",
    "title": "Re-ranking for image retrieval and transductive few-shot classification",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d9fc0cdb67638d50f411432d0d41d0ba-Paper.pdf",
    "abstract": "In the problems of image retrieval and few-shot classification, the mainstream approaches focus on learning a better feature representation. However, directly tackling the distance or similarity measure between images could also be efficient. To this end, we revisit the idea of re-ranking the top-k retrieved images in the context of image retrieval (e.g., the k-reciprocal nearest neighbors) and generalize this idea to transductive few-shot learning. We propose to meta-learn the re-ranking updates such that the similarity graph converges towards the target similarity graph induced by the image labels. Specifically, the re-ranking module takes as input an initial similarity graph between the query image and the contextual images using a pre-trained feature extractor, and predicts an improved similarity graph by leveraging the structure among the involved images. We show that our re-ranking approach can be applied to unseen images and can further boost existing approaches for both image retrieval and few-shot learning problems. Our approach operates either independently or in conjunction with classical re-ranking approaches, yielding clear and consistent improvements on image retrieval (CUB, Cars, SOP, rOxford5K and rParis6K) and transductive few-shot classification (Mini-ImageNet, tiered-ImageNet and CIFAR-FS) benchmarks. Our code is available at https://imagine.enpc.fr/~shenx/SSR/.",
    "authors": [
      "SHEN, Xi",
      "Xiao, Yang",
      "Hu, Shell Xu",
      "Sbai, Othman",
      "Aubry, Mathieu"
    ]
  },
  {
    "id": "d9fea4ca7e4a74c318ec27c1deb0796c",
    "title": "Post-processing for Individual Fairness",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/d9fea4ca7e4a74c318ec27c1deb0796c-Paper.pdf",
    "abstract": "Post-processing in algorithmic fairness is a versatile approach for correcting bias in ML systems that are already used in production. The main appeal of post-processing is that it avoids expensive retraining. In this work, we propose general post-processing algorithms for individual fairness (IF). We consider a setting where the learner only has access to the predictions of the original model and a similarity graph between individuals, guiding the desired fairness constraints. We cast the IF post-processing problem as a graph smoothing problem corresponding to graph Laplacian regularization that preserves the desired \"treat similar individuals similarly\" interpretation. Our theoretical results demonstrate the connection of the new objective function to a local relaxation of the original individual fairness. Empirically, our post-processing algorithms correct individual biases in large-scale NLP models such as BERT, while preserving accuracy.",
    "authors": [
      "Petersen, Felix",
      "Mukherjee, Debarghya",
      "Sun, Yuekai",
      "Yurochkin, Mikhail"
    ]
  },
  {
    "id": "da11e8cd1811acb79ccf0fd62cd58f86",
    "title": "OpenMatch: Open-Set Semi-supervised Learning with Open-set Consistency Regularization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/da11e8cd1811acb79ccf0fd62cd58f86-Paper.pdf",
    "abstract": "Semi-supervised learning (SSL) is an effective means to leverage unlabeled data to improve a model\u2019s performance. Typical SSL methods like FixMatch assume that labeled and unlabeled data share the same label space. However, in practice, unlabeled data can contain categories unseen in the labeled set, i.e., outliers, which can significantly harm the performance of SSL algorithms.  To address this problem, we propose a novel Open-set Semi-Supervised Learning (OSSL) approach called OpenMatch.Learning representations of inliers while rejecting outliers is essential for the success of OSSL. To this end, OpenMatch unifies FixMatch with novelty detection based on one-vs-all (OVA) classifiers. The OVA-classifier outputs the confidence score of a sample being an inlier, providing a threshold to detect outliers. Another key contribution is an open-set soft-consistency regularization loss, which enhances the smoothness of the OVA-classifier with respect to input transformations and greatly improves outlier detection. \\ours achieves state-of-the-art performance on three datasets, and even outperforms a fully supervised model in detecting outliers unseen in unlabeled data on CIFAR10. The code is available at \\url{https://github.com/VisionLearningGroup/OP_Match}.  ",
    "authors": [
      "Saito, Kuniaki",
      "Kim, Donghyun",
      "Saenko, Kate"
    ]
  },
  {
    "id": "da3fde159d754a2555eaa198d2d105b2",
    "title": "End-to-End Training of Multi-Document Reader and Retriever for Open-Domain Question Answering",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/da3fde159d754a2555eaa198d2d105b2-Paper.pdf",
    "abstract": "We present an end-to-end differentiable training method for retrieval-augmented open-domain question answering systems that combine information from multiple retrieved documents when generating answers. We model retrieval decisions as latent variables over sets of relevant documents. Since marginalizing over sets of retrieved documents is computationally hard, we approximate this using an expectation-maximization algorithm. We iteratively estimate the value of our latent variable (the set of relevant documents for a given question) and then use this estimate to update the retriever and reader parameters. We hypothesize that such end-to-end training allows training signals to flow to the reader and then to the retriever better than staged-wise training. This results in a retriever that is able to select more relevant documents for a question and a reader that is trained on more accurate documents to generate an answer. Experiments on three benchmark datasets demonstrate that our proposed method outperforms all existing approaches of comparable size by 2-3% absolute exact match points, achieving new state-of-the-art results. Our results also demonstrate the feasibility of learning to retrieve to improve answer generation without explicit supervision of retrieval decisions.",
    "authors": [
      "Singh, Devendra",
      "Reddy, Siva",
      "Hamilton, Will",
      "Dyer, Chris",
      "Yogatama, Dani"
    ]
  },
  {
    "id": "da4fb5c6e93e74d3df8527599fa62642",
    "title": "Fast Algorithms for $L_\\infty$-constrained S-rectangular Robust MDPs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/da4fb5c6e93e74d3df8527599fa62642-Paper.pdf",
    "abstract": "Robust Markov decision processes (RMDPs) are a useful building block of robust reinforcement learning algorithms but can be hard to solve. This paper proposes a fast, exact algorithm for computing the Bellman operator for S-rectangular robust Markov decision processes with $L_\\infty$-constrained rectangular ambiguity sets. The algorithm combines a novel homotopy continuation method with a bisection method to solve S-rectangular ambiguity in quasi-linear time in the number of states and actions. The algorithm improves on the cubic time required by leading general linear programming methods. Our experimental results confirm the practical viability of our method and show that it outperforms a leading commercial optimization package by several orders of magnitude.",
    "authors": [
      "Behzadian, Bahram",
      "Petrik, Marek",
      "Ho, Chin Pang"
    ]
  },
  {
    "id": "da54dd5a0398011cdfa50d559c2c0ef8",
    "title": "Instance-optimal Mean Estimation Under Differential Privacy",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/da54dd5a0398011cdfa50d559c2c0ef8-Paper.pdf",
    "abstract": "Mean estimation under differential privacy is a fundamental problem, but worst-case optimal mechanisms do not offer meaningful utility guarantees in practice when the global sensitivity is very large.  Instead, various heuristics have been proposed to reduce the error on real-world data that do not resemble the worst-case instance.  This paper takes a principled approach, yielding a mechanism that is instance-optimal in a strong sense.  In addition to its theoretical optimality, the mechanism is also simple and practical, and adapts to a variety of data characteristics without the need of parameter tuning.  It easily extends to the local and shuffle model as well.",
    "authors": [
      "Huang, Ziyue",
      "Liang, Yuting",
      "Yi, Ke"
    ]
  },
  {
    "id": "da94cbeff56cfda50785df477941308b",
    "title": "Look at the Variance! Efficient Black-box Explanations with Sobol-based Sensitivity Analysis",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/da94cbeff56cfda50785df477941308b-Paper.pdf",
    "abstract": "We describe a novel attribution method which is grounded in Sensitivity Analysis and uses  Sobol indices. Beyond modeling the individual contributions of image regions,  Sobol indices provide an efficient way to capture higher-order interactions between image regions and their contributions to a neural network's prediction through the lens of variance.We describe an approach that makes the computation of these indices efficient for high-dimensional problems by using perturbation masks coupled with efficient estimators to handle the high dimensionality of images.Importantly, we show that the proposed method leads to favorable scores on standard benchmarks for vision (and language models) while drastically reducing the computing time compared to other black-box methods -- even surpassing the accuracy of state-of-the-art white-box methods which require access to internal representations. Our code is freely available:github.com/fel-thomas/Sobol-Attribution-Method.",
    "authors": [
      "FEL, Thomas",
      "Cadene, Remi",
      "Chalvidal, Mathieu",
      "Cord, Matthieu",
      "Vigouroux, David",
      "Serre, Thomas"
    ]
  },
  {
    "id": "dac32839a9f0baae954b41abee610cc0",
    "title": "PatchGame: Learning to Signal Mid-level Patches in Referential Games",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/dac32839a9f0baae954b41abee610cc0-Paper.pdf",
    "abstract": "We study a referential game (a type of signaling game) where two agents communicate with each other via a discrete bottleneck to achieve a common goal. In our referential game, the goal of the speaker is to compose a message or a symbolic representation of \"important\" image patches, while the task for the listener is to match the speaker's message to a different view of the same image. We show that it is indeed possible for the two agents to develop a communication protocol without explicit or implicit supervision. We further investigate the developed protocol and show the applications in speeding up recent Vision Transformers by using only important patches, and as pre-training for downstream recognition tasks (e.g., classification).",
    "authors": [
      "Gupta, Kamal",
      "Somepalli, Gowthami",
      "Anubhav, Anubhav",
      "Magalle Hewa, Vinoj Yasanga Jayasundara",
      "Zwicker, Matthias",
      "Shrivastava, Abhinav"
    ]
  },
  {
    "id": "dac4a67bdc4a800113b0f1ad67ed696f",
    "title": "Implicit Generative Copulas",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/dac4a67bdc4a800113b0f1ad67ed696f-Paper.pdf",
    "abstract": "Copulas are a powerful tool for modeling multivariate distributions as they allow to separately estimate the univariate marginal distributions and the joint dependency structure. However, known parametric copulas offer limited flexibility especially in high dimensions, while commonly used non-parametric methods suffer from the curse of dimensionality. A popular remedy is to construct a tree-based hierarchy of conditional bivariate copulas.In this paper, we propose a flexible, yet conceptually simple alternative based on implicit generative neural networks.The key challenge is to ensure marginal uniformity of the estimated copula distribution.We achieve this by learning a multivariate latent distribution with unspecified marginals but the desired dependency structure.By applying the probability integral transform, we can then obtain samples from the high-dimensional copula distribution without relying on parametric assumptions or the need to find a suitable tree structure.Experiments on synthetic and real data from finance, physics, and image generation demonstrate the performance of this approach.",
    "authors": [
      "Janke, Tim",
      "Ghanmi, Mohamed",
      "Steinke, Florian"
    ]
  },
  {
    "id": "dae3312c4c6c7000a37ecfb7b0aeb0e4",
    "title": "Tensor Normal Training for Deep Learning Models",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/dae3312c4c6c7000a37ecfb7b0aeb0e4-Paper.pdf",
    "abstract": "Despite the predominant use of first-order methods for training deep learning models, second-order methods, and in particular, natural gradient methods, remain of interest because of their potential for accelerating training through the use of curvature information. Several methods with non-diagonal preconditioning matrices, including KFAC, Shampoo, and K-BFGS, have been proposed and shown to be effective. Based on the so-called tensor normal (TN) distribution, we propose and analyze a brand new approximate natural gradient method, Tensor Normal Training (TNT), which like Shampoo, only requires knowledge of the shape of the training parameters. By approximating the probabilistically based Fisher matrix, as opposed to the empirical Fisher matrix, our method uses the block-wise covariance of the sampling based gradient as the pre-conditioning matrix. Moreover, the assumption that the sampling-based (tensor) gradient follows a TN distribution, ensures that its covariance has a Kronecker separable structure, which leads to a tractable approximation to the Fisher matrix. Consequently, TNT's memory requirements and per-iteration computational costs are only slightly higher than those for first-order methods. In our experiments, TNT exhibited superior optimization performance to state-of-the-art first-order methods, and comparable optimization performance to the state-of-the-art second-order methods KFAC and Shampoo. Moreover, TNT demonstrated its ability to generalize as well as first-order methods, while using fewer epochs.",
    "authors": [
      "Ren, Yi",
      "Goldfarb, Donald"
    ]
  },
  {
    "id": "db00f1b7fdf48fd26b5fb5f309e9afaf",
    "title": "Unintended Selection: Persistent Qualification Rate Disparities and Interventions",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/db00f1b7fdf48fd26b5fb5f309e9afaf-Paper.pdf",
    "abstract": "Realistically---and equitably---modeling the dynamics of group-level disparities in machine learning remains an open problem. In particular, we desire models that do not suppose inherent differences between artificial groups of people---but rather endogenize disparities by appeal to unequal initial conditions of insular subpopulations. In this paper, agents each have a real-valued feature $X$ (e.g., credit score) informed by a ``true'' binary label $Y$ representing qualification (e.g., for a loan). Each agent alternately (1) receives a binary classification label $\\hat{Y}$ (e.g., loan approval) from a Bayes-optimal machine learning classifier observing $X$ and (2) may update their qualification $Y$ by imitating successful strategies (e.g., seek a raise) within an isolated group $G$ of agents to which they belong. We consider the disparity of qualification rates $\\Pr(Y=1)$ between different groups and how this disparity changes subject to a sequence of Bayes-optimal classifiers repeatedly retrained on the global population. We model the evolving qualification rates of each subpopulation (group) using the replicator equation, which derives from a class of imitation processes. We show that differences in qualification rates between subpopulations can persist indefinitely for a set of non-trivial equilibrium states due to uniformed classifier deployments, even when groups are identical in all aspects except initial qualification densities. We next simulate the effects of commonly proposed fairness interventions on this dynamical system along with a new feedback control mechanism capable of permanently eliminating group-level qualification rate disparities. We conclude by discussing the limitations of our model and findings and by outlining potential future work.",
    "authors": [
      "Raab, Reilly",
      "Liu, Yang"
    ]
  },
  {
    "id": "db182d2552835bec774847e06406bfa2",
    "title": "Revisiting 3D Object Detection From an Egocentric Perspective",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/db182d2552835bec774847e06406bfa2-Paper.pdf",
    "abstract": "3D object detection is a key module for safety-critical robotics applications such as autonomous driving. For these applications, we care most about how the detections affect the ego-agent\u2019s behavior and safety (the egocentric perspective). Intuitively, we seek more accurate descriptions of object geometry when it\u2019s more likely to interfere with the ego-agent\u2019s motion trajectory. However, current detection metrics, based on box Intersection-over-Union (IoU), are object-centric and aren\u2019t designed to capture the spatio-temporal relationship between objects and the ego-agent. To address this issue, we propose a new egocentric measure to evaluate 3D object detection,  namely Support Distance Error (SDE). Our analysis based on SDE reveals that the egocentric detection quality is bounded by the coarse geometry of the bounding boxes. Given the insight that SDE would benefit from more accurate geometry descriptions, we propose to represent objects as amodal contours, specifically amodal star-shaped polygons, and devise a simple model, StarPoly, to predict such contours. Our experiments on the large-scale Waymo Open Dataset show that SDE better reflects the impact of detection quality on the ego-agent\u2019s safety compared to IoU; and the estimated contours from StarPoly consistently improve the egocentric detection quality over recent 3D object detectors.",
    "authors": [
      "Deng, Boyang",
      "Qi, Charles R",
      "Najibi, Mahyar",
      "Funkhouser, Thomas",
      "Zhou, Yin",
      "Anguelov, Dragomir"
    ]
  },
  {
    "id": "db2b4182156b2f1f817860ac9f409ad7",
    "title": "Optimizing Information-theoretical Generalization Bound via Anisotropic Noise of SGLD",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/db2b4182156b2f1f817860ac9f409ad7-Paper.pdf",
    "abstract": "Recently, the information-theoretical framework has been proven to be able to obtain non-vacuous generalization bounds for large models trained by Stochastic Gradient Langevin Dynamics (SGLD) with isotropic noise.  In this paper, we optimize the information-theoretical generalization bound by manipulating the noise structure in SGLD. We prove that with constraint to guarantee low empirical risk, the optimal noise covariance is the square root of the expected gradient covariance if both the prior and the posterior are jointly optimized. This validates that the optimal noise is quite close to the empirical gradient covariance.  Technically, we develop a new information-theoretical bound that enables such an optimization analysis. We then apply matrix analysis to derive the form of optimal noise covariance. Presented constraint and results are validated by the empirical observations. ",
    "authors": [
      "Wang, Bohan",
      "Zhang, Huishuai",
      "Zhang, Jieyu",
      "Meng, Qi",
      "Chen, Wei",
      "Liu, Tie-Yan"
    ]
  },
  {
    "id": "db8e1af0cb3aca1ae2d0018624204529",
    "title": "Addressing Algorithmic Disparity and Performance Inconsistency in Federated Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/db8e1af0cb3aca1ae2d0018624204529-Paper.pdf",
    "abstract": "Federated learning (FL) has gain growing interests for its capability of learning from distributed data sources collectively without the need of accessing the raw data samples across different sources. So far FL research has mostly focused on improving the performance, how the algorithmic disparity will be impacted for the model learned from FL and the impact of algorithmic disparity on the utility inconsistency are largely unexplored. In this paper, we propose an FL framework to jointly consider performance consistency and algorithmic fairness across different local clients (data sources). We derive our framework from a constrained multi-objective optimization perspective, in which we learn a model satisfying fairness constraints on all clients with consistent performance. Specifically, we treat the algorithm prediction loss at each local client as an objective and maximize the worst-performing client with fairness constraints through optimizing a surrogate maximum function with all objectives involved. A gradient-based procedure is employed to achieve the Pareto optimality of this optimization problem. Theoretical analysis is provided to prove that our method can converge to a Pareto solution that achieves the min-max performance with fairness constraints on all clients. Comprehensive experiments on synthetic and real-world datasets demonstrate the superiority that our approach over baselines and its effectiveness in achieving both fairness and consistency across all local clients.",
    "authors": [
      "Cui, Sen",
      "Pan, Weishen",
      "Liang, Jian",
      "Zhang, Changshui",
      "Wang, Fei"
    ]
  },
  {
    "id": "db9ad56c71619aeed9723314d1456037",
    "title": "A Mathematical Framework for Quantifying Transferability in Multi-source Transfer Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/db9ad56c71619aeed9723314d1456037-Paper.pdf",
    "abstract": "Current transfer learning algorithm designs mainly focus on the similarities between source and target tasks, while the impacts of the sample sizes of these tasks are often not sufficiently addressed. This paper proposes a mathematical framework for quantifying the transferability in multi-source transfer learning problems, with both the task similarities and the sample complexity of learning models taken into account. In particular, we consider the setup where the models learned from different tasks are linearly combined for learning the target task, and use the optimal combining coefficients to measure the transferability. Then, we demonstrate the analytical expression of this transferability measure, characterized by the sample sizes, model complexity, and the similarities between source and target tasks, which provides fundamental insights of the knowledge transferring mechanism and the guidance for algorithm designs. Furthermore, we apply our analyses for practical learning tasks, and establish a quantifiable transferability measure by exploiting a parameterized model. In addition, we develop an alternating iterative algorithm to implement our theoretical results for training deep neural networks in multi-source transfer learning tasks. Finally, experiments on image classification tasks show that our approach outperforms existing transfer learning algorithms in multi-source and few-shot scenarios.",
    "authors": [
      "Tong, Xinyi",
      "Xu, Xiangxiang",
      "Huang, Shao-Lun",
      "Zheng, Lizhong"
    ]
  },
  {
    "id": "db9eeb7e678863649bce209842e0d164",
    "title": "Mori\u00e9 Attack (MA): A New Potential Risk of Screen Photos",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/db9eeb7e678863649bce209842e0d164-Paper.pdf",
    "abstract": "Images, captured by a camera, play a critical role in training Deep Neural Networks (DNNs). Usually, we assume the images acquired by cameras are consistent with the ones perceived by human eyes. However, due to the different physical mechanisms between human-vision and computer-vision systems, the final perceived images could be very different in some cases, for example shooting on digital monitors. In this paper, we find a special phenomenon in digital image processing, the moir\u00e9 effect, that could cause unnoticed security threats to DNNs. Based on it, we propose a Moir\u00e9 Attack (MA) that generates the physical-world moir\u00e9 pattern adding to the images by mimicking the shooting process of digital devices. Extensive experiments demonstrate that our proposed digital Moir\u00e9 Attack (MA) is a perfect camouflage for attackers to tamper with DNNs with a high success rate ($100.0\\%$ for untargeted and $97.0\\%$ for targeted attack with the noise budget $\\epsilon=4$), high transferability rate across different models, and high robustness under various defenses. Furthermore, MA owns great stealthiness because the moir\u00e9 effect is unavoidable due to the camera's inner physical structure, which therefore hardly attracts the awareness of humans. Our code is available at https://github.com/Dantong88/Moire_Attack.",
    "authors": [
      "Niu, Dantong",
      "Guo, Ruohao",
      "Wang, Yisen"
    ]
  },
  {
    "id": "dba31bb5c75992690f20c2d3b370ec7c",
    "title": "Fast Bayesian Inference for Gaussian Cox Processes via Path Integral Formulation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/dba31bb5c75992690f20c2d3b370ec7c-Paper.pdf",
    "abstract": "Gaussian Cox processes are widely-used point process models that use a Gaussian process to describe the Bayesian a priori uncertainty present in latent intensity functions. In this paper, we propose a novel Bayesian inference scheme for Gaussian Cox processes by exploiting a conceptually-intuitive {\u00a5it path integral} formulation. The proposed scheme does not rely on domain discretization, scales linearly with the number of observed events, has a lower complexity than the state-of-the-art variational Bayesian schemes with respect to the number of inducing points, and is applicable to a wide range of Gaussian Cox processes with various types of link functions. Our scheme is especially beneficial under the multi-dimensional input setting, where the number of inducing points tends to be large. We evaluate our scheme on synthetic and real-world data, and show that it achieves comparable predictive accuracy while being tens of times faster than reference methods.",
    "authors": [
      "Kim, Hideaki"
    ]
  },
  {
    "id": "dba4c1a117472f6aca95211285d0587e",
    "title": "Lattice partition recovery with dyadic CART",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/dba4c1a117472f6aca95211285d0587e-Paper.pdf",
    "abstract": "We study piece-wise constant signals corrupted by additive Gaussian noise over a $d$-dimensional lattice. Data of this form naturally arise in a host of applications, and the tasks of signal detection or testing, de-noising and  estimation have been studied extensively in the statistical and signal processing literature. In this paper we consider instead the problem of partition recovery, i.e.~of estimating the partition of the lattice induced by the constancy regions of the unknown signal, using the computationally-efficient dyadic classification and regression tree (DCART)  methodology proposed by \\citep{donoho1997cart}.   We prove that, under appropriate regularity conditions on the shape of the partition elements, a DCART-based procedure consistently estimates the underlying partition at a rate of order $\\sigma^2 k^* \\log (N)/\\kappa^2$, where $k^*$ is the minimal number of rectangular sub-graphs obtained using recursive dyadic partitions supporting the signal partition, $\\sigma^2$ is the noise variance, $\\kappa$ is the minimal magnitude of the signal difference among contiguous elements of the partition and $N$ is the size of the lattice. Furthermore,  under stronger assumptions, our method attains a sharper estimation error of order $\\sigma^2\\log(N)/\\kappa^2$, independent of $k^*$, which we show to be minimax rate optimal.  Our theoretical guarantees further extend to the partition estimator based on the optimal regression tree estimator (ORT) of \\cite{chatterjee2019adaptive} and to the one obtained through an NP-hard exhaustive search method.  We corroborate our theoretical findings and the effectiveness of  DCART for partition recovery in simulations.",
    "authors": [
      "MADRID PADILLA, OSCAR HERNAN",
      "Yu, Yi",
      "Rinaldo, Alessandro"
    ]
  },
  {
    "id": "dbb422937d7ff56e049d61da730b3e11",
    "title": "Robust Deep Reinforcement Learning through Adversarial Loss",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/dbb422937d7ff56e049d61da730b3e11-Paper.pdf",
    "abstract": "Recent studies have shown that deep reinforcement learning agents are vulnerable to small adversarial perturbations on the agent's inputs, which raises concerns about deploying such agents in the real world. To address this issue, we propose RADIAL-RL, a principled framework to train reinforcement learning agents with improved robustness against $l_p$-norm bounded adversarial attacks. Our framework is compatible with popular deep reinforcement learning algorithms and we demonstrate its performance with deep Q-learning, A3C and PPO. We experiment on three deep RL benchmarks (Atari, MuJoCo and ProcGen) to show the effectiveness of our robust training algorithm. Our RADIAL-RL agents consistently outperform prior methods when tested against attacks of varying strength and are more computationally efficient to train. In addition, we propose a new evaluation method called Greedy-Worst-Case Reward (GWC) to measure attack agnostic robustness of deep RL agents. We show that GWC can be evaluated efficiently and is a good estimate of the reward under the worst possible sequence of adversarial attacks. All code used for our experiments is available at https://github.com/tuomaso/radial_rl_v2.",
    "authors": [
      "Oikarinen, Tuomas",
      "Zhang, Wang",
      "Megretski, Alexandre",
      "Daniel, Luca",
      "Weng, Tsui-Wei"
    ]
  },
  {
    "id": "dc5d637ed5e62c36ecb73b654b05ba2a",
    "title": "Provable Model-based Nonlinear Bandit and Reinforcement Learning: Shelve Optimism, Embrace Virtual Curvature",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/dc5d637ed5e62c36ecb73b654b05ba2a-Paper.pdf",
    "abstract": "This paper studies model-based bandit and reinforcement learning (RL) with nonlinear function approximations. We propose to study convergence to approximate local maxima because we show that global convergence is statistically intractable even for one-layer neural net bandit with a deterministic reward. For both nonlinear bandit and RL, the paper presents a model-based algorithm, Virtual Ascent with Online Model Learner (ViOlin), which provably converges to a local maximum with sample complexity that only depends on the sequential Rademacher complexity of the model class. Our results imply novel global or local regret bounds on several concrete settings such as linear bandit with finite or sparse model class, and two-layer neural net bandit. A key algorithmic insight is that optimism may lead to over-exploration even for two-layer neural net model class. On the other hand, for convergence to local maxima, it suffices to maximize the virtual return if the model can also reasonably predict the gradient and Hessian of the real return.",
    "authors": [
      "Dong, Kefan",
      "Yang, Jiaqi",
      "Ma, Tengyu"
    ]
  },
  {
    "id": "dc912a253d1e9ba40e2c597ed2376640",
    "title": "You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/dc912a253d1e9ba40e2c597ed2376640-Paper.pdf",
    "abstract": "Can Transformer perform $2\\mathrm{D}$ object- and region-level recognition from a pure sequence-to-sequence perspective with minimal knowledge about the $2\\mathrm{D}$ spatial structure? To answer this question, we present You Only Look at One Sequence (YOLOS), a series of object detection models based on the vanilla Vision Transformer with the fewest possible modifications, region priors, as well as inductive biases of the target task. We find that YOLOS pre-trained on the mid-sized ImageNet-$1k$ dataset only can already achieve quite competitive performance on the challenging COCO object detection benchmark, e.g., YOLOS-Base directly adopted from BERT-Base architecture can obtain $42.0$ box AP on COCO val. We also discuss the impacts as well as limitations of current pre-train schemes and model scaling strategies for Transformer in vision through YOLOS. Code and pre-trained models are available at https://github.com/hustvl/YOLOS.",
    "authors": [
      "Fang, Yuxin",
      "Liao, Bencheng",
      "Wang, Xinggang",
      "Fang, Jiemin",
      "Qi, Jiyang",
      "Wu, Rui",
      "Niu, Jianwei",
      "Liu, Wenyu"
    ]
  },
  {
    "id": "dc9fa5f217a1e57b8a6adeb065560b38",
    "title": "Learning to delegate for large-scale vehicle routing",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/dc9fa5f217a1e57b8a6adeb065560b38-Paper.pdf",
    "abstract": "Vehicle routing problems (VRPs) form a class of combinatorial problems with wide practical applications. While previous heuristic or learning-based works achieve decent solutions on small problem instances, their performance deteriorates in large problems. This article presents a novel learning-augmented local search framework to solve large-scale VRP. The method iteratively improves the solution by identifying appropriate subproblems and $delegating$ their improvement to a black box subsolver. At each step, we leverage spatial locality to consider only a linear number of subproblems, rather than exponential. We frame subproblem selection as regression and train a Transformer on a generated training set of problem instances. Our method accelerates state-of-the-art VRP solvers by 10x to 100x while achieving competitive solution qualities for VRPs with sizes ranging from 500 to 3000. Learned subproblem selection offers a 1.5x to 2x speedup over heuristic or random selection. Our results generalize to a variety of VRP distributions, variants, and solvers.",
    "authors": [
      "Li, Sirui",
      "Yan, Zhongxia",
      "Wu, Cathy"
    ]
  },
  {
    "id": "dcc5c249e15c211f21e1da0f3ba66169",
    "title": "Effective Meta-Regularization by Kernelized Proximal Regularization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/dcc5c249e15c211f21e1da0f3ba66169-Paper.pdf",
    "abstract": "We study the problem of meta-learning, which has proved to be advantageous to accelerate learning new tasks with a few samples. The recent approaches based on deep kernels achieve the state-of-the-art performance. However, the regularizers in their base learners are not learnable. In this paper, we propose an algorithm called MetaProx to learn a proximal regularizer for the base learner. We theoretically establish the convergence of MetaProx. Experimental results confirm the advantage of the proposed algorithm.",
    "authors": [
      "Jiang, Weisen",
      "Kwok, James",
      "Zhang, Yu"
    ]
  },
  {
    "id": "dccb1c3a558c50d389c24d69a9856730",
    "title": "Towards Context-Agnostic Learning Using Synthetic Data",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/dccb1c3a558c50d389c24d69a9856730-Paper.pdf",
    "abstract": "We propose a novel setting for learning, where the input domain is the image of a map defined on the product of two sets, one of which completely determines the labels. We derive a new risk bound for this setting that decomposes into a bias and an error term, and exhibits a surprisingly weak dependence on the true labels. Inspired by these results, we present an algorithm aimed at minimizing the bias term by exploiting the ability to sample from each set independently. We apply our setting to visual classification tasks, where our approach enables us to train classifiers on datasets that consist entirely of a single synthetic example of each class. On several standard benchmarks for real-world image classification, we achieve robust performance in the context-agnostic setting, with good generalization to real world domains, whereas training directly on real world data without our techniques yields classifiers that are brittle to perturbations of the background.",
    "authors": [
      "Jin, Charles",
      "Rinard, Martin"
    ]
  },
  {
    "id": "dcd2f3f312b6705fb06f4f9f1b55b55c",
    "title": "Minimax Optimal Quantile and Semi-Adversarial Regret via Root-Logarithmic Regularizers",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/dcd2f3f312b6705fb06f4f9f1b55b55c-Paper.pdf",
    "abstract": "Quantile (and, more generally, KL) regret bounds, such as those achieved by NormalHedge (Chaudhuri, Freund, and Hsu 2009) and its variants, relax the goal of competing against the best individual expert to only competing against a majority of experts on adversarial data. More recently, the semi-adversarial paradigm (Bilodeau, Negrea, and Roy 2020) provides an alternative relaxation of adversarial online learning by considering data that may be neither fully adversarial nor stochastic (I.I.D.).  We achieve the minimax optimal regret in both paradigms using FTRL with separate, novel, root-logarithmic regularizers, both of which can be interpreted as yielding variants of NormalHedge. We extend existing KL regret upper bounds, which hold uniformly over target distributions, to possibly uncountable expert classes with arbitrary priors; provide the first full-information lower bounds for quantile regret on finite expert classes (which are tight); and provide an adaptively minimax optimal algorithm for the semi-adversarial paradigm that adapts to the true, unknown constraint faster, leading to uniformly improved regret bounds over existing methods.",
    "authors": [
      "Negrea, Jeffrey",
      "Bilodeau, Blair",
      "Campolongo, Nicol\u00f2",
      "Orabona, Francesco",
      "Roy, Dan"
    ]
  },
  {
    "id": "dce8af15f064d1accb98887a21029b08",
    "title": "Gradient-Free Adversarial Training Against Image Corruption for Learning-based Steering",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/dce8af15f064d1accb98887a21029b08-Paper.pdf",
    "abstract": "We introduce a simple yet effective framework for improving the robustness of learning algorithms against image corruptions for autonomous driving. These corruptions can occur due to both internal (e.g., sensor noises and hardware abnormalities) and external factors (e.g., lighting, weather, visibility, and other environmental effects). Using sensitivity analysis with FID-based parameterization, we propose a novel algorithm exploiting basis perturbations to improve the overall performance of autonomous steering and other image processing tasks, such as classification and detection, for self-driving cars. Our model not only improves the performance on the original dataset, but also achieves significant performance improvement on datasets with multiple and unseen perturbations, up to 87% and 77%, respectively. A comparison between our approach and other SOTA techniques confirms the effectiveness of our technique in improving the robustness of neural network training for learning-based steering and other image processing tasks.",
    "authors": [
      "Shen, Yu",
      "Zheng, Laura",
      "Shu, Manli",
      "Li, Weizi",
      "Goldstein, Tom",
      "Lin, Ming"
    ]
  },
  {
    "id": "dcf3219715a7c9cd9286f19db46f2384",
    "title": "Deep Proxy Causal Learning and its Application to Confounded Bandit Policy Evaluation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/dcf3219715a7c9cd9286f19db46f2384-Paper.pdf",
    "abstract": "Proxy causal learning (PCL) is a method for estimating the causal effect of treatments on outcomes in the presence of unobserved confounding, using proxies (structured side information) for the confounder. This is achieved via two-stage regression: in the first stage, we model relations among the treatment and proxies; in the second stage, we use this model to learn the effect of treatment on the outcome, given the context provided by the proxies. PCL  guarantees recovery of the true causal effect, subject to identifiability conditions. We propose a novel method for PCL, the deep feature proxy variable method (DFPV), to address the case where the proxies, treatments, and outcomes are high-dimensional and have nonlinear complex relationships, as represented by deep neural network features. We show that DFPV outperforms recent state-of-the-art PCL methods on challenging synthetic benchmarks, including settings involving high dimensional image data. Furthermore, we show that PCL can be applied to off-policy evaluation for the confounded bandit problem, in which DFPV also exhibits competitive performance.",
    "authors": [
      "Xu, Liyuan",
      "Kanagawa, Heishiro",
      "Gretton, Arthur"
    ]
  },
  {
    "id": "dcf531edc9b229acfe0f4b87e1e278dd",
    "title": "Certifying Robustness to Programmable Data Bias in Decision Trees",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/dcf531edc9b229acfe0f4b87e1e278dd-Paper.pdf",
    "abstract": "Datasets can be biased due to societal inequities, human biases, under-representation of minorities, etc. Our goal is to certify that models produced by a learning algorithm are pointwise-robust to dataset biases. This is a challenging problem: it entails learning models for a large, or even infinite, number of datasets, ensuring that they all produce the same prediction. We focus on decision-tree learning due to the interpretable nature of the models. Our approach allows programmatically specifying \\emph{bias models} across a variety of dimensions (e.g., label-flipping or missing data), composing types of bias, and targeting bias towards a specific group. To certify robustness, we use a novel symbolic technique to evaluate a decision-tree learner on a large, or infinite, number of datasets, certifying that each and every dataset produces the same prediction for a specific test point. We evaluate our approach on datasets that are commonly used in the fairness literature, and demonstrate our approach's viability on a range of bias models.",
    "authors": [
      "Meyer, Anna",
      "Albarghouthi, Aws",
      "D'Antoni, Loris"
    ]
  },
  {
    "id": "dd03de08bfdff4d8ab01117276564cc7",
    "title": "T\u00f6RF: Time-of-Flight Radiance Fields for Dynamic Scene View Synthesis",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/dd03de08bfdff4d8ab01117276564cc7-Paper.pdf",
    "abstract": "Neural networks can represent and accurately reconstruct radiance fields for static 3D scenes (e.g., NeRF). Several works extend these to dynamic scenes captured with monocular video, with promising performance. However, the monocular setting is known to be an under-constrained problem, and so methods rely on data-driven priors for reconstructing dynamic content. We replace these priors with measurements from a time-of-flight (ToF) camera, and introduce a neural representation based on an image formation model for continuous-wave ToF cameras. Instead of working with processed depth maps, we model the raw ToF sensor measurements to improve reconstruction quality and avoid issues with low reflectance regions, multi-path interference, and a sensor's limited unambiguous depth range. We show that this approach improves robustness of dynamic scene reconstruction to erroneous calibration and large motions, and discuss the benefits and limitations of integrating RGB+ToF sensors now available on modern smartphones.",
    "authors": [
      "Attal, Benjamin",
      "Laidlaw, Eliot",
      "Gokaslan, Aaron",
      "Kim, Changil",
      "Richardt, Christian",
      "Tompkin, James",
      "O'Toole, Matthew"
    ]
  },
  {
    "id": "dd17e652cd2a08fdb8bf7f68e2ad3814",
    "title": "Sequence-to-Sequence Learning with Latent Neural Grammars",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/dd17e652cd2a08fdb8bf7f68e2ad3814-Paper.pdf",
    "abstract": "Sequence-to-sequence learning with neural networks has become the de facto standard for sequence modeling. This approach typically models the local distribution over the next element with a powerful neural network that can condition on arbitrary context. While flexible and performant, these models often require large datasets for training and can fail spectacularly on benchmarks designed to test for compositional generalization. This work explores an alternative, hierarchical approach to sequence-to-sequence learning with synchronous grammars, where each node in the target tree is transduced by a subset of nodes in the source tree. The source and target trees are treated as fully latent and marginalized out during training. We develop a neural parameterization of the grammar which enables parameter sharing over combinatorial structures without the need for manual feature engineering. We apply this latent neural grammar to various domains---a diagnostic language navigation task designed to test for compositional generalization (SCAN), style transfer, and small-scale machine translation---and find that it performs respectably compared to standard baselines.",
    "authors": [
      "Kim, Yoon"
    ]
  },
  {
    "id": "dd1970fb03877a235d530476eb727dab",
    "title": "Exploration-Exploitation in Multi-Agent Competition: Convergence with Bounded Rationality",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/dd1970fb03877a235d530476eb727dab-Paper.pdf",
    "abstract": "The interplay between exploration and exploitation in competitive multi-agent learning is still far from being well understood. Motivated by this, we study smooth Q-learning, a prototypical learning model that explicitly captures the balance between game rewards and exploration costs. We show that Q-learning always converges to the unique quantal-response equilibrium (QRE), the standard solution concept for games under bounded rationality, in weighted zero-sum polymatrix games with heterogeneous learning agents using positive exploration rates. Complementing recent results about convergence in weighted potential games [16,34], we show that fast convergence of Q-learning in competitive settings obtains regardless of the number of agents and without any need for parameter fine-tuning. As showcased by our experiments in network zero-sum games, these theoretical results provide the necessary guarantees for an algorithmic approach to the currently open problem of equilibrium selection in competitive multi-agent settings.",
    "authors": [
      "Leonardos, Stefanos",
      "Piliouras, Georgios",
      "Spendlove, Kelly"
    ]
  },
  {
    "id": "dd32544610bf007f0def4abc9b7ff9ef",
    "title": "Low-Rank Extragradient Method for Nonsmooth and Low-Rank Matrix Optimization Problems",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/dd32544610bf007f0def4abc9b7ff9ef-Paper.pdf",
    "abstract": "Low-rank and nonsmooth matrix optimization problems capture many fundamental tasks in statistics and machine learning. While significant progress has been made in recent years in developing efficient methods for \\textit{smooth} low-rank optimization problems that avoid maintaining high-rank matrices and computing expensive high-rank SVDs, advances for nonsmooth problems have been slow paced. In this paper we consider standard convex relaxations for such problems. Mainly, we prove that under a natural \\textit{generalized strict complementarity} condition and under the relatively mild assumption that the nonsmooth objective can be written as a maximum of smooth functions, the \\textit{extragradient method}, when initialized with a \"warm-start'' point, converges to an optimal solution with rate $O(1/t)$ while requiring only two \\textit{low-rank} SVDs per iteration. We give a precise trade-off between the rank of the SVDs required and the radius of the ball in which we need to initialize the method. We support our theoretical results with empirical experiments on several nonsmooth low-rank matrix recovery tasks, demonstrating that using simple initializations, the extragradient method produces exactly the same iterates when full-rank SVDs are replaced with SVDs of rank that matches the rank of the (low-rank) ground-truth matrix to be recovered.",
    "authors": [
      "Kaplan, Atara",
      "Garber, Dan"
    ]
  },
  {
    "id": "dd45045f8c68db9f54e70c67048d32e8",
    "title": "Which Mutual-Information Representation Learning Objectives are Sufficient for Control?",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/dd45045f8c68db9f54e70c67048d32e8-Paper.pdf",
    "abstract": "Mutual information (MI) maximization provides an appealing formalism for learning representations of data. In the context of reinforcement learning (RL), such representations can accelerate learning by discarding irrelevant and redundant information, while retaining the information necessary for control. Much prior work on these methods has addressed the practical difficulties of estimating MI from samples of high-dimensional observations, while comparatively less is understood about which MI objectives yield representations that are sufficient for RL from a theoretical perspective. In this paper, we formalize the sufficiency of a state representation for learning and representing the optimal policy, and study several popular MI based objectives through this lens. Surprisingly, we find that two of these objectives can yield insufficient representations given mild and common assumptions on the structure of the MDP. We corroborate our theoretical results with empirical experiments on a simulated game environment with visual observations. ",
    "authors": [
      "Rakelly, Kate",
      "Gupta, Abhishek",
      "Florensa, Carlos",
      "Levine, Sergey"
    ]
  },
  {
    "id": "dda99de58ff020cfb57fec1404c97003",
    "title": "A Geometric Perspective towards Neural Calibration via Sensitivity Decomposition",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/dda99de58ff020cfb57fec1404c97003-Paper.pdf",
    "abstract": "It is well known that vision classification models suffer from poor calibration in the face of data distribution shifts. In this paper, we take a geometric approach to this problem. We propose Geometric Sensitivity Decomposition (GSD) which decomposes the norm of a sample feature embedding and the angular similarity to a target classifier into an instance-dependent and an instance-independent com-ponent. The instance-dependent component captures the sensitive information about changes in the input while the instance-independent component represents the insensitive information serving solely to minimize the loss on the training dataset. Inspired by the decomposition, we analytically derive a simple extension to current softmax-linear models, which learns to disentangle the two components during training. On several common vision models, the disentangled model out-performs other calibration methods on standard calibration metrics in the face of out-of-distribution (OOD) data and corruption with significantly less complexity. Specifically, we surpass the current state of the art by 30.8% relative improvement on corrupted CIFAR100 in Expected Calibration Error.",
    "authors": [
      "Tian, Junjiao",
      "Yung, Dylan",
      "Hsu, Yen-Chang",
      "Kira, Zsolt"
    ]
  },
  {
    "id": "ddbc86dc4b2fbfd8a62e12096227e068",
    "title": "Towards a Unified Information-Theoretic Framework for Generalization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ddbc86dc4b2fbfd8a62e12096227e068-Paper.pdf",
    "abstract": "In this work, we investigate the expressiveness of the \"conditional mutual information\" (CMI)  framework of Steinke and Zakynthinou (2020)  and the prospect of using it to provide a unified framework for proving generalization bounds in the realizable setting.  We first demonstrate that one can use this framework to express non-trivial (but sub-optimal) bounds for any learning algorithm that outputs hypotheses from a class of bounded VC dimension.  We then explore two directions of strengthening this bound: (i) Can the CMI framework express optimal bounds for VC classes? (ii) Can the CMI framework be used to analyze algorithms whose output hypothesis space is unrestricted (i.e. has an unbounded VC dimension)?    With respect to Item (i) we prove that the CMI framework yields the optimal bound on the expected risk  of Support Vector Machines (SVMs) for learning halfspaces. This result is an application of our general result showing that stable compression schemes Bousquet al. (2020) of size $k$ have uniformly bounded CMI of order $O(k)$. We further show that an inherent limitation of proper learning of VC classes contradicts the existence of a proper learner with constant CMI, and it implies a negative resolution to an open problem of Steinke and Zakynthinou (2020).  We further study the CMI of empirical risk minimizers (ERMs) of class $H$ and show that it is possible to output all  consistent classifiers (version space) with bounded CMI if and only if $H$ has a bounded star number (Hanneke and Yang (2015)). With respect to Item (ii) we prove a general reduction showing that \"leave-one-out\" analysis is expressible via the CMI framework. As a corollary we investigate the CMI of the one-inclusion-graph algorithm proposed by Haussler et al. (1994). More generally, we  show that the CMI framework is universal in the sense that for every consistent algorithm and data distribution, the expected risk vanishes as the number of  samples diverges if and only if its evaluated CMI has sublinear growth with the number of samples.",
    "authors": [
      "Haghifam, Mahdi",
      "Dziugaite, Gintare Karolina",
      "Moran, Shay",
      "Roy, Dan"
    ]
  },
  {
    "id": "ddcbe25988981920c872c1787382f04d",
    "title": "Bayesian decision-making under misspecified priors with applications to meta-learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ddcbe25988981920c872c1787382f04d-Paper.pdf",
    "abstract": "Thompson sampling and other Bayesian sequential decision-making algorithms are among the most popular approaches to tackle explore/exploit trade-offs in (contextual) bandits.  The choice of prior in these algorithms offers flexibility to encode domain knowledge but can also lead to poor performance when misspecified.  In this paper, we demonstrate that performance degrades gracefully with misspecification.  We prove that the expected reward accrued by Thompson sampling (TS) with a misspecified prior differs by at most $\\tilde{O}(H^2 \\epsilon)$ from TS with a well-specified prior, where $\\epsilon$ is the total-variation distance between priors and $H$ is the learning horizon.  Our bound does not require the prior to have any parametric form.  For priors with bounded support, our bound is independent of the cardinality or structure of the action space, and we show that it is tight up to universal constants in the worst case.Building on our sensitivity analysis, we establish generic PAC guarantees for algorithms in the recently studied Bayesian meta-learning setting and derive corollaries for various families of priors.  Our results generalize along two axes: (1) they apply to a broader family of Bayesian decision-making algorithms, including a Monte-Carlo implementation of the knowledge gradient algorithm (KG), and (2) they apply to Bayesian POMDPs, the most general Bayesian decision-making setting, encompassing contextual bandits as a special case. Through numerical simulations, we illustrate how prior misspecification and the deployment of one-step look-ahead (as in KG) can impact the convergence of meta-learning in multi-armed and contextual bandits with structured and correlated priors.",
    "authors": [
      "Simchowitz, Max",
      "Tosh, Christopher",
      "Krishnamurthy, Akshay",
      "Hsu, Daniel J.",
      "Lykouris, Thodoris",
      "Dudik, Miro",
      "Schapire, Robert E."
    ]
  },
  {
    "id": "ddf88ea64eaed0f3de5531ac964a0a1a",
    "title": "Neural Trees for Learning on Graphs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ddf88ea64eaed0f3de5531ac964a0a1a-Paper.pdf",
    "abstract": "Graph Neural Networks (GNNs) have emerged as a flexible and powerful approach for learning over graphs. Despite this success, existing GNNs are constrained by their local message-passing architecture and are provably limited in their expressive power. In this work, we propose a new GNN architecture \u2013 the Neural Tree. The neural tree architecture does not perform message passing on the input graph, but on a tree-structured graph, called the H-tree, that is constructed from the input graph. Nodes in the H-tree correspond to subgraphs in the input graph, and they are reorganized in a hierarchical manner such that the parent of a node in the H-tree always corresponds to a larger subgraph in the input graph. We show that the neural tree architecture can approximate any smooth probability distribution function over an undirected graph. We also prove that the number of parameters needed to achieve an $\\epsilon$-approximation of the distribution function is exponential in the treewidth of the input graph, but linear in its size. We prove that any continuous G-invariant/equivariant function can be approximated by a nonlinear combination of such probability distribution functions over G. We apply the neural tree to semi-supervised node classification in 3D scene graphs, and show that these theoretical properties translate into significant gains in prediction accuracy, over the more traditional GNN architectures. We also show the applicability of the neural tree architecture to citation networks with large treewidth, by using a graph sub-sampling technique.",
    "authors": [
      "Talak, Rajat",
      "Hu, Siyi",
      "Peng, Lisa",
      "Carlone, Luca"
    ]
  },
  {
    "id": "ddf9029977a61241841edeae15e9b53f",
    "title": "Enabling Fast Differentially Private SGD via Just-in-Time Compilation and Vectorization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ddf9029977a61241841edeae15e9b53f-Paper.pdf",
    "abstract": "A common pain point in differentially private machine learning is the significant runtime overhead incurred when executing Differentially Private Stochastic Gradient Descent (DPSGD), which may be as large as two orders of magnitude. We thoroughly demonstrate that by exploiting powerful language primitives, including vectorization, just-in-time compilation, and static graph optimization, one can dramatically reduce these overheads, in many cases nearly matching the best non-private running times. These gains are realized in two frameworks: one is JAX, which provides rich support for these primitives through the XLA compiler. We also rebuild core parts of TensorFlow Privacy, integrating more effective vectorization as well as XLA compilation, granting significant memory and runtime improvements over previous release versions. Our proposed approaches allow us to achieve up to 50x speedups compared to the best alternatives. Our code is available at https://github.com/TheSalon/fast-dpsgd.",
    "authors": [
      "Subramani, Pranav",
      "Vadivelu, Nicholas",
      "Kamath, Gautam"
    ]
  },
  {
    "id": "de043a5e421240eb846da8effe472ff1",
    "title": "The effectiveness of feature attribution methods and its correlation with automatic evaluation scores",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/de043a5e421240eb846da8effe472ff1-Paper.pdf",
    "abstract": "Explaining the decisions of an Artificial Intelligence (AI) model is increasingly critical in many real-world, high-stake applications.Hundreds of papers have either proposed new feature attribution methods, discussed or harnessed these tools in their work.However, despite humans being the target end-users, most attribution methods were only evaluated on proxy automatic-evaluation metrics (Zhang et al. 2018; Zhou et al. 2016; Petsiuk et al. 2018). In this paper, we conduct the first user study to measure attribution map effectiveness in assisting humans in ImageNet classification and Stanford Dogs fine-grained classification, and when an image is natural or adversarial (i.e., contains adversarial perturbations). Overall, feature attribution is surprisingly not more effective than showing humans nearest training-set examples. On a harder task of fine-grained dog categorization, presenting attribution maps to humans does not help, but instead hurts the performance of human-AI teams compared to AI alone. Importantly, we found automatic attribution-map evaluation measures to correlate poorly with the actual human-AI team performance. Our findings encourage the community to rigorously test their methods on the downstream human-in-the-loop applications and to rethink the existing evaluation metrics.",
    "authors": [
      "Nguyen, Giang",
      "Kim, Daeyoung",
      "Nguyen, Anh"
    ]
  },
  {
    "id": "de73998802680548b916f1947ffbad76",
    "title": "Coordinated Proximal Policy Optimization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/de73998802680548b916f1947ffbad76-Paper.pdf",
    "abstract": "We present Coordinated Proximal Policy Optimization (CoPPO), an algorithm that extends the original Proximal Policy Optimization (PPO) to the multi-agent setting. The key idea lies in the coordinated adaptation of step size during the policy update process among multiple agents. We prove the monotonicity of policy improvement when optimizing a theoretically-grounded joint objective, and derive a simplified optimization objective based on a set of approximations. We then interpret that such an objective in CoPPO can achieve dynamic credit assignment among agents, thereby alleviating the high variance issue during the concurrent update of agent policies. Finally, we demonstrate that CoPPO outperforms several strong baselines and is competitive with the latest multi-agent PPO method (i.e. MAPPO) under typical multi-agent settings, including cooperative matrix games and the StarCraft II micromanagement tasks. ",
    "authors": [
      "Wu, Zifan",
      "Yu, Chao",
      "Ye, Deheng",
      "Zhang, Junge",
      "piao, haiyin",
      "Zhuo, Hankz Hankui"
    ]
  },
  {
    "id": "de8aa43e5d5fa8536cf23e54244476fa",
    "title": "Unbiased Classification through Bias-Contrastive and Bias-Balanced Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/de8aa43e5d5fa8536cf23e54244476fa-Paper.pdf",
    "abstract": "Datasets for training machine learning models tend to be biased unless the data is collected with complete care. In such a biased dataset, models are susceptible to making predictions based on the biased features of the data. The biased model fails to generalize to the case where correlations between biases and targets are shifted. To mitigate this, we propose Bias-Contrastive (BiasCon) loss based on the contrastive learning framework, which effectively leverages the knowledge of bias labels. We further suggest Bias-Balanced (BiasBal) regression which trains the classification model toward the data distribution with balanced target-bias correlation. Furthermore, we propose Soft Bias-Contrastive (SoftCon) loss which handles the dataset without bias labels by softening the pair assignment of the BiasCon loss based on the distance in the feature space of the bias-capturing model. Our experiments show that our proposed methods significantly improve previous debiasing methods in various realistic datasets.",
    "authors": [
      "Hong, Youngkyu",
      "Yang, Eunho"
    ]
  },
  {
    "id": "dea184826614d3f4c608731389ed0c74",
    "title": "Learning from Inside: Self-driven Siamese Sampling and Reasoning for Video Question Answering",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/dea184826614d3f4c608731389ed0c74-Paper.pdf",
    "abstract": "Recent advances in the video question answering (i.e., VideoQA) task have achieved strong success by following the paradigm of fine-tuning each clip-text pair independently on the pretrained transformer-based model via supervised learning. Intuitively, multiple samples (i.e., clips) should be interdependent to capture similar visual and key semantic information in the same video. To consider the interdependent knowledge between contextual clips into the network inference, we propose a Siamese Sampling and Reasoning (SiaSamRea) approach, which consists of a siamese sampling mechanism to generate sparse and similar clips (i.e., siamese clips) from the same video, and a novel reasoning strategy for integrating the interdependent knowledge between contextual clips into the network. The reasoning strategy contains two modules: (1) siamese knowledge generation to learn the inter-relationship among clips; (2) siamese knowledge reasoning to produce the refined soft label by propagating the weights of inter-relationship to the predicted candidates of all clips. Finally, our SiaSamRea can endow the current multimodal reasoning paradigm with the ability of learning from inside via the guidance of soft labels. Extensive experiments demonstrate our SiaSamRea achieves state-of-the-art performance on five VideoQA benchmarks, e.g., a significant +2.1% gain on MSRVTT-QA, +2.9% on MSVD-QA, +1.0% on ActivityNet-QA, +1.8% on How2QA and +4.3% (action) on TGIF-QA.",
    "authors": [
      "Yu, Weijiang",
      "Zheng, Haoteng",
      "Li, Mengfei",
      "Ji, Lei",
      "Wu, Lijun",
      "Xiao, Nong",
      "Duan, Nan"
    ]
  },
  {
    "id": "dea9ddb25cbf2352cf4dec30222a02a5",
    "title": "Identification and Estimation of Joint Probabilities of Potential Outcomes in Observational Studies with Covariate Information",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/dea9ddb25cbf2352cf4dec30222a02a5-Paper.pdf",
    "abstract": "The joint probabilities of potential outcomes are fundamental components of causal inference in the sense that (i) if they are identifiable, then the causal risk is also identifiable, but not vise versa (Pearl, 2009; Tian and Pearl, 2000) and (ii) they enable us to evaluate the probabilistic aspects of necessity'',sufficiency'', and ``necessity and sufficiency'', which are important concepts of successful explanation (Watson, et al., 2020). However, because they are not identifiable without any assumptions, various assumptions have been utilized to evaluate the joint probabilities of potential outcomes, e.g., the assumption of monotonicity (Pearl, 2009; Tian and Pearl, 2000), the independence between potential outcomes (Robins and Richardson, 2011),  the condition of gain equality (Li and Pearl, 2019), and the specific functional relationships between cause and effect (Pearl, 2009). Unlike existing identification conditions, in order to evaluate the joint probabilities of potential outcomes without such assumptions, this paper proposes two types of novel identification conditions using covariate information.  In addition, when the joint probabilities of potential outcomes are identifiable through the proposed conditions, the estimation problem of the joint probabilities of potential outcomes reduces to that of singular models and thus they can not be evaluated by standard statistical estimation methods. To solve the problem, this paper proposes a new statistical estimation method based on the augmented Lagrangian method and shows the asymptotic normality of the proposed estimators. Given space constraints, the proofs, the details on the statistical estimation method, some numerical experiments, and the case study are provided in the supplementary material.",
    "authors": [
      "Shingaki, Ryusei",
      "kuroki, manabu"
    ]
  },
  {
    "id": "def130d0b67eb38b7a8f4e7121ed432c",
    "title": "Online false discovery rate control for anomaly detection in time series",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/def130d0b67eb38b7a8f4e7121ed432c-Paper.pdf",
    "abstract": "This article proposes novel rules for false discovery rate control (FDRC) geared towards online anomaly detection in time series. Online FDRC rules allow to control the properties of a sequence of statistical tests. In the context of anomaly detection, the null hypothesis is that an observation is normal and the alternative is that it is anomalous. FDRC rules allow users to target a lower bound on precision in unsupervised settings. The methods proposed in this article overcome short-comings of previous FDRC rules in the context of anomaly detection, in particular ensuring that power remains high even when the alternative is exceedingly rare (typical in anomaly detection) and the test statistics are serially dependent (typical in time series). We show the soundness of these rules in both theory and experiments.",
    "authors": [
      "Rebjock, Quentin",
      "Kurt, Baris",
      "Januschowski, Tim",
      "Callot, Laurent"
    ]
  },
  {
    "id": "df0aab058ce179e4f7ab135ed4e641a9",
    "title": "Pragmatic Image Compression for Human-in-the-Loop Decision-Making",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/df0aab058ce179e4f7ab135ed4e641a9-Paper.pdf",
    "abstract": "Standard lossy image compression algorithms aim to preserve an image's appearance, while minimizing the number of bits needed to transmit it. However, the amount of information actually needed by the user for downstream tasks -- e.g., deciding which product to click on in a shopping website -- is likely much lower. To achieve this lower bitrate, we would ideally only transmit the visual features that drive user behavior, while discarding details irrelevant to the user's decisions. We approach this problem by training a compression model through human-in-the-loop learning as the user performs tasks with the compressed images. The key insight is to train the model to produce a compressed image that induces the user to take the same action that they would have taken had they seen the original image. To approximate the loss function for this model, we train a discriminator that tries to distinguish whether a user's action was taken in response to the compressed image or the original. We evaluate our method through experiments with human participants on four tasks: reading handwritten digits, verifying photos of faces, browsing an online shopping catalogue, and playing a car racing video game. The results show that our method learns to match the user's actions with and without compression at lower bitrates than baseline methods, and adapts the compression model to the user's behavior: it preserves the digit number and randomizes handwriting style in the digit reading task, preserves hats and eyeglasses while randomizing faces in the photo verification task, preserves the perceived price of an item while randomizing its color and background in the online shopping task, and preserves upcoming bends in the road in the car racing game.",
    "authors": [
      "Reddy, Sid",
      "Dragan, Anca",
      "Levine, Sergey"
    ]
  },
  {
    "id": "df0e09d6f25a15a815563df9827f48fa",
    "title": "Generalized Linear Bandits with Local Differential Privacy ",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/df0e09d6f25a15a815563df9827f48fa-Paper.pdf",
    "abstract": "Contextual bandit algorithms are useful in personalized online decision-making. However, many applications such as personalized medicine and online advertising require the utilization of individual-specific information for effective learning, while user's data should remain private from the server due to privacy concerns. This motivates the introduction of local differential privacy (LDP), a stringent notion in privacy, to contextual bandits. In this paper, we design LDP algorithms for stochastic generalized linear bandits to achieve the same regret bound as in non-privacy settings. Our main idea is to develop a stochastic gradient-based estimator and update mechanism to ensure LDP. We then exploit the flexibility of stochastic gradient descent (SGD), whose theoretical guarantee for bandit problems is rarely explored, in dealing with generalized linear bandits. We also develop an estimator and update mechanism based on Ordinary Least Square (OLS) for linear bandits. Finally, we conduct experiments with both simulation and real-world datasets to demonstrate the consistently superb performance of our algorithms under LDP constraints with reasonably small parameters $(\\varepsilon, \\delta)$ to ensure strong privacy protection. ",
    "authors": [
      "Han, Yuxuan",
      "Liang, Zhipeng",
      "Wang, Yang",
      "Zhang, Jiheng"
    ]
  },
  {
    "id": "df1f1d20ee86704251795841e6a9405a",
    "title": "On the Algorithmic Stability of Adversarial Training",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/df1f1d20ee86704251795841e6a9405a-Paper.pdf",
    "abstract": "The adversarial training is a popular tool to remedy the vulnerability of deep learning models against adversarial attacks, and there is rich theoretical literature on the training loss of adversarial training algorithms. In contrast, this paper studies the algorithmic stability of a generic adversarial training algorithm, which can further help to establish an upper bound for generalization error. By figuring out the stability upper bound and lower bound, we argue that the non-differentiability issue of adversarial training causes worse algorithmic stability than their natural counterparts. To tackle this problem, we consider a noise injection method. While the non-differentiability problem seriously affects the stability of adversarial training, injecting noise enables the training trajectory to avoid the occurrence of non-differentiability with dominating probability, hence enhancing the stability performance of adversarial training. Our analysis also studies the relation between the algorithm stability and numerical approximation error of adversarial attacks.",
    "authors": [
      "Xing, Yue",
      "Song, Qifan",
      "Cheng, Guang"
    ]
  },
  {
    "id": "df42e2244c97a0d80d565ae8176d3351",
    "title": "Width-based Lookaheads with Learnt Base Policies and Heuristics Over the Atari-2600 Benchmark",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/df42e2244c97a0d80d565ae8176d3351-Paper.pdf",
    "abstract": "We propose new width-based planning and learning algorithms inspired from a careful analysis of the design decisions made by previous width-based planners. The algorithms are applied over the Atari-2600 games and our best performing algorithm, Novelty guided Critical Path Learning (N-CPL), outperforms the previously introduced width-based planning and learning algorithms $\\pi$-IW(1), $\\pi$-IW(1)+ and $\\pi$-HIW(n, 1). Furthermore, we present a taxonomy of the Atari-2600 games according to some of their defining characteristics. This analysis of the games provides further insight into the behaviour and performance of the algorithms introduced. Namely, for games with large branching factors, and games with sparse meaningful rewards, N-CPL outperforms $\\pi$-IW, $\\pi$-IW(1)+ and $\\pi$-HIW(n, 1).",
    "authors": [
      "O'Toole, Stefan",
      "Lipovetzky, Nir",
      "Ramirez, Miquel",
      "Pearce, Adrian"
    ]
  },
  {
    "id": "df438e5206f31600e6ae4af72f2725f1",
    "title": "Characterizing possible failure modes in physics-informed neural networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/df438e5206f31600e6ae4af72f2725f1-Paper.pdf",
    "abstract": "Recent work in scientific machine learning has developed so-called physics-informed neural network (PINN) models. The typical approach is to incorporate physical domain knowledge as soft constraints on an empirical loss function and use existing machine learning methodologies to train the model. We demonstrate that, while existing PINN methodologies can learn good models for relatively trivial problems, they can easily fail to learn relevant physical phenomena for even slightly more complex problems. In particular, we analyze several distinct situations of widespread physical interest, including learning differential equations with convection, reaction, and diffusion operators. We provide evidence that the soft regularization in PINNs, which involves PDE-based differential operators, can introduce a number of subtle problems, including making the problem more ill-conditioned. Importantly, we show that these possible failure modes are not due to the lack of expressivity in the NN architecture, but that the PINN's setup makes the loss landscape very hard to optimize. We then describe two promising solutions to address these failure modes. The first approach is to use curriculum regularization, where the PINN's loss term starts from a simple PDE regularization, and becomes progressively more complex as the NN gets trained. The second approach is to pose the problem as a sequence-to-sequence learning task, rather than learning to predict the entire space-time at once. Extensive testing shows that we can achieve up to 1-2 orders of magnitude lower error with these methods as compared to regular PINN training.",
    "authors": [
      "Krishnapriyan, Aditi",
      "Gholami, Amir",
      "Zhe, Shandian",
      "Kirby, Robert",
      "Mahoney, Michael W."
    ]
  },
  {
    "id": "df5354693177e83e8ba089e94b7b6b55",
    "title": "Artistic Style Transfer with Internal-external Learning and Contrastive Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/df5354693177e83e8ba089e94b7b6b55-Paper.pdf",
    "abstract": "Although existing artistic style transfer methods have achieved significant improvement with deep neural networks, they still suffer from artifacts such as disharmonious colors and repetitive patterns. Motivated by this, we propose an internal-external style transfer method with two contrastive losses. Specifically, we utilize internal statistics of a single style image to determine the colors and texture patterns of the stylized image, and in the meantime, we leverage the external information of the large-scale style dataset to learn the human-aware style information, which makes the color distributions and texture patterns in the stylized image more reasonable and harmonious. In addition, we argue that existing style transfer methods only consider the content-to-stylization and style-to-stylization relations, neglecting the stylization-to-stylization relations. To address this issue, we introduce two contrastive losses, which pull the multiple stylization embeddings closer to each other when they share the same content or style, but push far away otherwise. We conduct extensive experiments, showing that our proposed method can not only produce visually more harmonious and satisfying artistic images, but also promote the stability and consistency of rendered video clips.",
    "authors": [
      "Chen, Haibo",
      "zhao, lei",
      "Wang, Zhizhong",
      "Zhang, Huiming",
      "Zuo, Zhiwen",
      "Li, Ailin",
      "Xing, Wei",
      "Lu, Dongming"
    ]
  },
  {
    "id": "df7e148cabfd9b608090fa5ee3348bfe",
    "title": "Fast Abductive Learning by Similarity-based Consistency Optimization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/df7e148cabfd9b608090fa5ee3348bfe-Paper.pdf",
    "abstract": "To utilize the raw inputs and symbolic knowledge simultaneously, some recent neuro-symbolic learning methods use abduction, i.e., abductive reasoning, to integrate sub-symbolic perception and logical inference. While the perception model, e.g., a neural network, outputs some facts that are inconsistent with the symbolic background knowledge base, abduction can help revise the incorrect perceived facts by minimizing the inconsistency between them and the background knowledge. However, to enable effective abduction, previous approaches need an initialized perception model that discriminates the input raw instances. This limits the application of these methods, as the discrimination ability is usually acquired from a thorough pre-training when the raw inputs are difficult to classify. In this paper, we propose a novel abduction strategy, which leverages the similarity between samples, rather than the output information by the perceptual neural network, to guide the search in abduction. Based on this principle, we further present ABductive Learning with Similarity (ABLSim) and apply it to some difficult neuro-symbolic learning tasks. Experiments show that the efficiency of ABLSim is significantly higher than the state-of-the-art neuro-symbolic methods, allowing it to achieve better performance with less labeled data and weaker domain knowledge.",
    "authors": [
      "Huang, Yu-Xuan",
      "Dai, Wang-Zhou",
      "Cai, Le-Wen",
      "Muggleton, Stephen H",
      "Jiang, Yuan"
    ]
  },
  {
    "id": "df9028fcb6b065e000ffe8a4f03eeb38",
    "title": "To Beam Or Not To Beam: That is a Question of Cooperation for Language GANs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/df9028fcb6b065e000ffe8a4f03eeb38-Paper.pdf",
    "abstract": "Due to the discrete nature of words, language GANs require to be optimized from rewards provided by discriminator networks, via reinforcement learning methods. This is a much harder setting than for continuous tasks, which enjoy gradient flows from discriminators to generators, usually leading to dramatic learning instabilities.   However, we claim that this can be solved by making discriminator and generator networks cooperate to produce output sequences during training. These cooperative outputs, inherently built to obtain higher discrimination scores, not only provide denser rewards for training but also form a more compact artificial set for discriminator training, hence improving its accuracy and stability.In this paper, we show that our SelfGAN framework, built on this cooperative principle, outperforms Teacher Forcing and obtains state-of-the-art results on two challenging tasks, Summarization and Question Generation.",
    "authors": [
      "Scialom, Thomas",
      "Dray, Paul-Alexis",
      "Staiano, Jacopo",
      "Lamprier, Sylvain",
      "Piwowarski, Benjamin"
    ]
  },
  {
    "id": "dfc6aa246e88ab3e32caeaaecf433550",
    "title": "Shapley Residuals: Quantifying the limits of the Shapley value for explanations",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/dfc6aa246e88ab3e32caeaaecf433550-Paper.pdf",
    "abstract": "Popular feature importance techniques compute additive approximations to nonlinear models by first defining a cooperative game describing the value of different subsets of the model's features, then calculating the resulting game's Shapley values to attribute credit additively between the features. However, the specific modeling settings in which the Shapley values are a poor approximation for the true game have not been well-described. In this paper we utilize an interpretation of Shapley values as the result of an orthogonal projection between vector spaces to calculate a residual representing the kernel component of that projection. We provide an algorithm for computing these residuals, characterize different modeling settings based on the value of the residuals, and demonstrate that they capture information about model predictions that Shapley values cannot. Shapley residuals can thus act as a warning to practitioners against overestimating the degree to which Shapley-value-based explanations give them insight into a model.",
    "authors": [
      "Kumar, Indra",
      "Scheidegger, Carlos ",
      "Venkatasubramanian, Suresh",
      "Friedler, Sorelle"
    ]
  },
  {
    "id": "dfccdb8b1cc7e4dab6d33db0fef12b88",
    "title": "The Elastic Lottery Ticket Hypothesis",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/dfccdb8b1cc7e4dab6d33db0fef12b88-Paper.pdf",
    "abstract": "Lottery Ticket Hypothesis (LTH) raises keen attention to identifying sparse trainable subnetworks, or winning tickets, which can be trained in isolation to achieve similar or even better performance compared to the full models. Despite many efforts being made, the most effective method to identify such winning tickets is still Iterative Magnitude-based Pruning (IMP), which is computationally expensive and has to be run thoroughly for every different network. A natural question that comes in is: can we \u201ctransform\u201d the winning ticket found in one network to another with a different architecture, yielding a winning ticket for the latter at the beginning, without re-doing the expensive IMP? Answering this question is not only practically relevant for efficient \u201conce-for-all\u201d winning ticket \ufb01nding, but also theoretically appealing for uncovering inherently scalable sparse patterns in networks. We conduct extensive experiments on CIFAR-10 and ImageNet, and propose a variety of strategies to tweak the winning tickets found from different networks of the same model family (e.g., ResNets). Based on these results, we articulate the Elastic Lottery Ticket Hypothesis (E-LTH): by mindfully replicating (or dropping) and re-ordering layers for one network, its corresponding winning ticket could be stretched (or squeezed) into a subnetwork for another deeper (or shallower) network from the same family, whose performance is nearly the same competitive as the latter\u2019s winning ticket directly found by IMP. We have also extensively compared E-LTH with pruning-at-initialization and dynamic sparse training methods, as well as discussed the generalizability of E-LTH to different model families, layer types, and across datasets. Code is available at https://github.com/VITA-Group/ElasticLTH.",
    "authors": [
      "Chen, Xiaohan",
      "Cheng, Yu",
      "Wang, Shuohang",
      "Gan, Zhe",
      "Liu, Jingjing",
      "Wang, Zhangyang"
    ]
  },
  {
    "id": "dfce06801e1a85d6d06f1fdd4475dacd",
    "title": "Joint Inference for Neural Network Depth and Dropout Regularization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/dfce06801e1a85d6d06f1fdd4475dacd-Paper.pdf",
    "abstract": "Dropout regularization methods prune a neural network's pre-determined backbone structure to avoid overfitting. However, a deep model still tends to be poorly calibrated with high confidence on incorrect predictions. We propose a unified Bayesian model selection method to jointly infer the most plausible network depth warranted by data, and perform dropout regularization simultaneously. In particular, to infer network depth we define a beta process over the number of hidden layers which allows it to go to infinity. Layer-wise activation probabilities induced by the beta process modulate neuron activation via binary vectors of a conjugate Bernoulli process. Experiments across domains show that by adapting network depth and dropout regularization to data, our method achieves superior performance comparing to state-of-the-art methods with well-calibrated uncertainty estimates. In continual learning, our method enables neural networks to dynamically evolve their depths to accommodate incrementally available data beyond their initial structures, and alleviate catastrophic forgetting.",
    "authors": [
      "K C, Kishan",
      "Li, Rui",
      "Gilany, MohammadMahdi"
    ]
  },
  {
    "id": "dfd786998e082758be12670d856df755",
    "title": "Tractable Density Estimation on Learned Manifolds with Conformal Embedding Flows",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/dfd786998e082758be12670d856df755-Paper.pdf",
    "abstract": "Normalizing flows are generative models that provide tractable density estimation via an invertible transformation from a simple base distribution to a complex target distribution. However, this technique cannot directly model data supported on an unknown low-dimensional manifold, a common occurrence in real-world domains such as image data. Recent attempts to remedy this limitation have introduced geometric complications that defeat a central benefit of normalizing flows: exact density estimation. We recover this benefit with Conformal Embedding Flows, a framework for designing flows that learn manifolds with tractable densities. We argue that composing a standard flow with a trainable conformal embedding is the most natural way to model manifold-supported data. To this end, we present a series of conformal building blocks and apply them in experiments with synthetic and real-world data to demonstrate that flows can model manifold-supported distributions without sacrificing tractable likelihoods.",
    "authors": [
      "Ross, Brendan",
      "Cresswell, Jesse"
    ]
  },
  {
    "id": "e0126439e08ddfbdf4faa952dc910590",
    "title": "The Limits of Optimal Pricing in the Dark",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e0126439e08ddfbdf4faa952dc910590-Paper.pdf",
    "abstract": "A ubiquitous learning problem in today\u2019s digital market is, during repeated interactions between a seller and a buyer, how a seller can gradually learn optimal pricing decisions based on the buyer\u2019s past purchase responses. A fundamental challenge of learning in such a strategic setup is that the buyer will naturally have incentives to manipulate his responses in order to induce more favorable learning outcomes for him. To understand the limits of the seller\u2019s learning when facing such a strategic and possibly manipulative buyer, we study a natural yet powerful buyer manipulation strategy. That is, before the pricing game starts, the buyer simply commits to \u201cimitate\u201d a different value function by pretending to always react optimally according to this imitative value function. We fully characterize the optimal imitative value function that the buyer should imitate as well as the resultant seller revenue and buyer surplus under this optimal buyer manipulation. Our characterizations reveal many useful insights about what happens at equilibrium. For example, a seller with concave production cost will obtain essentially 0 revenue at equilibrium whereas the revenue for a seller with convex production cost is the Bregman divergence of her cost function between no production and certain production. Finally, and importantly, we show that a more powerful class of pricing schemes does not necessarily increase, in fact, may be harmful to, the seller\u2019s revenue. Our results not only lead to an effective prescriptive way for buyers to manipulate learning algorithms but also shed lights on the limits of what a seller can really achieve when pricing in the dark.",
    "authors": [
      "Dawkins, Quinlan",
      "Han, Minbiao",
      "Xu, Haifeng"
    ]
  },
  {
    "id": "e02a35b1563d0db53486ec068ebab80f",
    "title": "No RL, No Simulation: Learning to Navigate without Navigating",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e02a35b1563d0db53486ec068ebab80f-Paper.pdf",
    "abstract": "Most prior methods for learning navigation policies require access to simulation environments, as they need online policy interaction and rely on ground-truth maps for rewards. However, building simulators is expensive (requires manual effort for each and every scene) and creates challenges in transferring learned policies to robotic platforms in the real-world, due to the sim-to-real domain gap. In this paper, we pose a simple question: Do we really need active interaction, ground-truth maps or even reinforcement-learning (RL) in order to solve the image-goal navigation task? We propose a self-supervised approach to learn to navigate from only passive videos of roaming. Our approach, No RL, No Simulator (NRNS), is simple and scalable, yet highly effective. NRNS outperforms RL-based formulations by a significant margin. We present NRNS as a strong baseline for any future image-based navigation tasks that use RL or Simulation.",
    "authors": [
      "Hahn, Meera",
      "Chaplot, Devendra Singh",
      "Tulsiani, Shubham",
      "Mukadam, Mustafa",
      "Rehg, James M.",
      "Gupta, Abhinav"
    ]
  },
  {
    "id": "e02e27e04fdff967ba7d76fb24b8069d",
    "title": "Analogous to Evolutionary Algorithm: Designing a Unified Sequence Model",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e02e27e04fdff967ba7d76fb24b8069d-Paper.pdf",
    "abstract": "Inspired by biological evolution, we explain the rationality of Vision Transformer by analogy with the proven practical Evolutionary Algorithm (EA) and derive that both of them have consistent mathematical representation. Analogous to the dynamic local population in EA, we improve the existing transformer structure and propose a more efficient EAT model, and design task-related heads to deal with different tasks more flexibly. Moreover, we introduce the spatial-filling curve into the current vision transformer to sequence image data into a uniform sequential format. Thus we can design a unified EAT framework to address multi-modal tasks, separating the network architecture from the data format adaptation. Our approach achieves state-of-the-art results on the ImageNet classification task compared with recent vision transformer works while having smaller parameters and greater throughput. We further conduct multi-modal tasks to demonstrate the superiority of the unified EAT, \\eg, Text-Based Image Retrieval, and our approach improves the rank-1 by +3.7 points over the baseline on the CSS dataset.",
    "authors": [
      "Zhang, Jiangning",
      "Xu, Chao",
      "Li, Jian",
      "Chen, Wenzhou",
      "Wang, Yabiao",
      "Tai, Ying",
      "Chen, Shuo",
      "Wang, Chengjie",
      "Huang, Feiyue",
      "Liu, Yong"
    ]
  },
  {
    "id": "e0308d73972d8dd5e2dd27853106386e",
    "title": "Improving Compositionality of Neural Networks by Decoding Representations to Inputs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e0308d73972d8dd5e2dd27853106386e-Paper.pdf",
    "abstract": "In traditional software programs, it is easy to trace program logic from variables back to input, apply assertion statements to block erroneous behavior, and compose programs together. Although deep learning programs have demonstrated strong performance on novel applications, they sacrifice many of the functionalities of traditional software programs. With this as motivation, we take a modest first step towards improving deep learning programs by jointly training a generative model to constrain neural network activations to \"decode\" back to inputs. We call this design a Decodable Neural Network, or DecNN. Doing so enables a form of compositionality in neural networks, where one can recursively compose DecNN with itself to create an ensemble-like model with uncertainty. In our experiments, we demonstrate applications of this uncertainty to out-of-distribution detection, adversarial example detection, and calibration --- while matching standard neural networks in accuracy. We further explore this compositionality by combining DecNN with pretrained models, where we show promising results that neural networks can be regularized from using protected features.",
    "authors": [
      "Wu, Mike",
      "Goodman, Noah",
      "Ermon, Stefano"
    ]
  },
  {
    "id": "e0688d13958a19e087e123148555e4b4",
    "title": "The Hardness Analysis of Thompson Sampling for Combinatorial Semi-bandits with Greedy Oracle",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e0688d13958a19e087e123148555e4b4-Paper.pdf",
    "abstract": "Thompson sampling (TS) has attracted a lot of interest in the bandit area. It was introduced in the 1930s but has not been theoretically proven until recent years. All of its analysis in the combinatorial multi-armed bandit (CMAB) setting requires an exact oracle to provide optimal solutions with any input. However, such an oracle is usually not feasible since many combinatorial optimization problems are NP-hard and only approximation oracles are available. An example \\cite{WangC18} has shown the failure of TS to learn with an approximation oracle. However, this oracle is uncommon and is designed only for a specific problem instance. It is still an open question whether the convergence analysis of TS can be extended beyond the exact oracle in CMAB. In this paper, we study this question under the greedy oracle, which is a common (approximation) oracle with theoretical guarantees to solve many (offline) combinatorial optimization problems. We provide a problem-dependent regret lower bound of order $\\Omega(\\log T/\\Delta^2)$ to quantify the hardness of TS to solve CMAB problems with greedy oracle, where $T$ is the time horizon and $\\Delta$ is some reward gap. We also provide an almost matching regret upper bound. These are the first theoretical results for TS to solve CMAB with a common approximation oracle and break the misconception that TS cannot work with approximation oracles.",
    "authors": [
      "Kong, Fang",
      "Yang, Yueran",
      "Chen, Wei",
      "Li, Shuai"
    ]
  },
  {
    "id": "e06f967fb0d355592be4e7674fa31d26",
    "title": "Universal Semi-Supervised Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e06f967fb0d355592be4e7674fa31d26-Paper.pdf",
    "abstract": "Universal Semi-Supervised Learning (UniSSL) aims to solve the open-set problem where both the class distribution (i.e., class set) and feature distribution (i.e., feature domain) are different between labeled dataset and unlabeled dataset. Such a problem seriously hinders the realistic landing of classical SSL. Different from the existing SSL methods targeting at the open-set problem that only study one certain scenario of class distribution mismatch and ignore the feature distribution mismatch, we consider a more general case where a mismatch exists in both class and feature distribution. In this case, we propose a ''Class-shAring data detection and Feature Adaptation'' (CAFA) framework which requires no prior knowledge of the class relationship between the labeled dataset and unlabeled dataset. Particularly, CAFA utilizes a novel scoring strategy to detect the data in the shared class set. Then, it conducts domain adaptation to fully exploit the value of the detected class-sharing data for better semi-supervised consistency training. Exhaustive experiments on several benchmark datasets show the effectiveness of our method in tackling open-set problems.",
    "authors": [
      "Huang, Zhuo",
      "Xue, Chao",
      "Han, Bo",
      "Yang, Jian",
      "Gong, Chen"
    ]
  },
  {
    "id": "e0cd3f16f9e883ca91c2a4c24f47b3d9",
    "title": "Improving Deep Learning Interpretability by Saliency Guided Training",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e0cd3f16f9e883ca91c2a4c24f47b3d9-Paper.pdf",
    "abstract": "Saliency methods have been widely used to highlight important input features in model predictions. Most existing methods use backpropagation on a modified gradient function to generate saliency maps. Thus, noisy gradients can result in unfaithful feature attributions. In this paper, we tackle this issue and introduce a {\\it saliency guided training} procedure for neural networks to reduce noisy gradients used in predictions while retaining the predictive performance of the model. Our saliency guided training procedure iteratively masks features with small and potentially noisy gradients while maximizing the similarity of model outputs for both masked and unmasked inputs. We apply the saliency guided training procedure to various synthetic and real data sets from computer vision, natural language processing, and time series across diverse neural architectures, including Recurrent Neural Networks, Convolutional Networks, and Transformers. Through qualitative and quantitative evaluations, we show that saliency guided training procedure significantly improves model interpretability across various domains while preserving its predictive performance.",
    "authors": [
      "Ismail, Aya Abdelsalam",
      "Corrada Bravo, Hector",
      "Feizi, Soheil"
    ]
  },
  {
    "id": "e0eacd983971634327ae1819ea8b6214",
    "title": "SurvITE: Learning Heterogeneous Treatment Effects from Time-to-Event Data",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e0eacd983971634327ae1819ea8b6214-Paper.pdf",
    "abstract": "We study the problem of inferring heterogeneous treatment effects from time-to-event data. While both the related problems of (i) estimating treatment effects for binary or continuous outcomes and (ii) predicting survival outcomes have been well studied in the recent machine learning literature, their combination -- albeit of high practical relevance -- has received considerably less attention. With the ultimate goal of reliably estimating the effects of treatments on instantaneous risk and survival probabilities, we focus on the problem of learning (discrete-time) treatment-specific conditional hazard functions. We find that unique challenges arise in this context due to a variety of covariate shift issues that go beyond a mere combination of well-studied confounding and censoring biases. We theoretically analyse their effects by adapting recent generalization bounds from domain adaptation and treatment effect estimation to our setting and discuss implications for model design. We use the resulting insights to propose a novel deep learning method for treatment-specific hazard estimation based on balancing representations. We investigate performance across a range of experimental settings and empirically confirm that our method outperforms baselines by addressing covariate shifts from various sources.",
    "authors": [
      "Curth, Alicia",
      "Lee, Changhee",
      "van der Schaar, Mihaela"
    ]
  },
  {
    "id": "e1021d43911ca2c1845910d84f40aeae",
    "title": "Optimal Rates for Nonparametric Density Estimation under Communication Constraints",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e1021d43911ca2c1845910d84f40aeae-Paper.pdf",
    "abstract": "We consider density estimation for Besov spaces when the estimator is restricted to use only a limited number of bits about each sample. We provide a noninteractive adaptive estimator which exploits the sparsity of wavelet bases, along with a simulate-and-infer technique from parametric estimation under communication constraints. We show that our estimator is nearly rate-optimal by deriving minmax lower bounds that hold even when interactive protocols are allowed. Interestingly, while our wavelet-based estimator is almost rate-optimal for Sobolev spaces as well, it is unclear whether the standard Fourier basis, which arise naturally for those spaces, can be used to achieve the same performance.",
    "authors": [
      "Acharya, Jayadev",
      "Canonne, Clement",
      "Singh, Aditya Vikram",
      "Tyagi, Himanshu"
    ]
  },
  {
    "id": "e13748298cfb23c19fdfd134a2221e7b",
    "title": "Rank Overspecified Robust Matrix Recovery: Subgradient Method and Exact Recovery",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e13748298cfb23c19fdfd134a2221e7b-Paper.pdf",
    "abstract": "We study the robust recovery of a low-rank matrix from sparsely and grossly corrupted Gaussian measurements, with no prior knowledge on the intrinsic rank. We consider the robust matrix factorization approach. We employ a robust $\\ell_1$ loss function and deal with the challenge of the unknown rank by using an overspecified factored representation of the matrix variable. We then solve the associated nonconvex nonsmooth problem using a subgradient method with diminishing stepsizes. We show that under a regularity condition on the sensing matrices and corruption, which we call restricted direction preserving property (RDPP), even with rank overspecified, the subgradient method converges to the exact low-rank solution at a sublinear rate. Moreover, our result is more general in the sense that it automatically speeds up to a linear rate once the factor rank matches the unknown rank. On the other hand, we show that the RDPP condition holds under generic settings, such as Gaussian measurements under independent or adversarial sparse corruptions, where the result could be of independent interest. Both the exact recovery and the convergence rate of the proposed subgradient method are numerically verified in the overspecified regime. Moreover, our experiment further shows that our particular design of diminishing stepsize effectively prevents overfitting for robust recovery under overparameterized models, such as robust matrix sensing and learning robust deep image prior. This regularization effect is worth further investigation.  ",
    "authors": [
      "Ding, Lijun",
      "Jiang, Liwei",
      "Chen, Yudong",
      "Qu, Qing",
      "Zhu, Zhihui"
    ]
  },
  {
    "id": "e140dbab44e01e699491a59c9978b924",
    "title": "Improving Computational Efficiency in Visual Reinforcement Learning via Stored Embeddings",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e140dbab44e01e699491a59c9978b924-Paper.pdf",
    "abstract": "Recent advances in off-policy deep reinforcement learning (RL) have led to impressive success in complex tasks from visual observations. Experience replay improves sample-efficiency by reusing experiences from the past, and convolutional neural networks (CNNs) process high-dimensional inputs effectively. However, such techniques demand high memory and computational bandwidth. In this paper, we present Stored Embeddings for Efficient Reinforcement Learning (SEER), a simple modification of existing off-policy RL methods, to address these computational and memory requirements. To reduce the computational overhead of gradient updates in CNNs, we freeze the lower layers of CNN encoders early in training due to early convergence of their parameters. Additionally, we reduce memory requirements by storing the low-dimensional latent vectors for experience replay instead of high-dimensional images, enabling an adaptive increase in the replay buffer capacity, a useful technique in constrained-memory settings. In our experiments, we show that SEER does not degrade the performance of RL agents while significantly saving computation and memory across a diverse set of DeepMind Control environments and Atari games.",
    "authors": [
      "Chen, Lili",
      "Lee, Kimin",
      "Srinivas, Aravind",
      "Abbeel, Pieter"
    ]
  },
  {
    "id": "e143c01e314f7b950daca31188cb5d0f",
    "title": "Learning Generalized Gumbel-max Causal Mechanisms",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e143c01e314f7b950daca31188cb5d0f-Paper.pdf",
    "abstract": "To perform counterfactual reasoning in Structural Causal Models (SCMs), one needs to know the causal mechanisms, which provide factorizations of conditional distributions into noise sources and deterministic functions mapping realizations of noise to samples. Unfortunately, the causal mechanism is not uniquely identified by data that can be gathered by observing and interacting with the world, so there remains the question of how to choose causal mechanisms. In recent work, Oberst & Sontag (2019) propose Gumbel-max SCMs, which use Gumbel-max reparameterizations as the causal mechanism due to an appealing  counterfactual stability property. However, the justification requires appealing to intuition. In this work, we instead argue for choosing a causal mechanism that is best under a quantitative criteria such as minimizing variance when estimating counterfactual treatment effects. We propose a parameterized family of causal mechanisms that generalize Gumbel-max. We show that they can be trained to minimize counterfactual effect variance and other losses on a distribution of queries of interest, yielding lower variance estimates of counterfactual treatment effect than fixed alternatives, also generalizing to queries not seen at training time.",
    "authors": [
      "Lorberbom, Guy",
      "Johnson, Daniel D.",
      "Maddison, Chris J.",
      "Tarlow, Daniel",
      "Hazan, Tamir"
    ]
  },
  {
    "id": "e17184bcb70dcf3942c54e0b537ffc6d",
    "title": "Bandit Learning with Delayed Impact of Actions",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e17184bcb70dcf3942c54e0b537ffc6d-Paper.pdf",
    "abstract": "We consider a stochastic multi-armed bandit (MAB) problem with delayed impact of actions. In our setting, actions taken in the pastimpact the arm rewards in the subsequent future. This delayed impact of actions is prevalent in the real world. For example, the capability to pay back a loan for people in a certain social group might depend on historically how frequently that group has been approved loan applications. If banks keep rejecting loan applications to people in a disadvantaged group, it could create a feedback loop and further damage the chance of getting loans for people in that group. In this paper, we formulate this delayed and long-term impact of actions within the context of multi-armed bandits. We generalize the bandit setting to encode the dependency of this ``bias\" due to the action history during learning. The goal is to maximize the collected utilities over time while taking into account the dynamics created by the delayed impacts of historical actions. We propose an algorithm that achieves a regret of $\\tilde{O}(KT^{2/3})$ and show a matching regret lower bound of $\\Omega(KT^{2/3})$, where $K$ is the number of arms and $T$ is the learning horizon. Our results complement the bandit literature by adding techniques to deal with actions with long-term impacts and have implications in designing fair algorithms.",
    "authors": [
      "Tang, Wei",
      "Ho, Chien-Ju",
      "Liu, Yang"
    ]
  },
  {
    "id": "e17a5a399de92e1d01a56c50afb2a68e",
    "title": "A Stochastic Newton Algorithm for Distributed Convex Optimization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e17a5a399de92e1d01a56c50afb2a68e-Paper.pdf",
    "abstract": "We propose and analyze a stochastic Newton algorithm for homogeneous distributed stochastic convex optimization, where each machine can calculate stochastic gradients of the same population objective, as well as stochastic Hessian-vector products (products of an independent unbiased estimator of the Hessian of the population objective with arbitrary vectors), with many such stochastic computations performed between rounds of communication.  We show that our method can reduce the number, and frequency, of required communication rounds, compared to existing methods without hurting performance, by proving convergence guarantees for quasi-self-concordant objectives (e.g., logistic regression), alongside empirical evidence.",
    "authors": [
      "Bullins, Brian",
      "Patel, Kshitij",
      "Shamir, Ohad",
      "Srebro, Nathan",
      "Woodworth, Blake E."
    ]
  },
  {
    "id": "e19347e1c3ca0c0b97de5fb3b690855a",
    "title": "Are Transformers more robust than CNNs? ",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e19347e1c3ca0c0b97de5fb3b690855a-Paper.pdf",
    "abstract": "Transformer emerges as a powerful tool for visual recognition. In addition to demonstrating competitive performance on a broad range of visual benchmarks,  recent works also argue that Transformers are much more robust than Convolutions Neural Networks (CNNs). Nonetheless, surprisingly, we find these conclusions are drawn from unfair experimental settings, where Transformers and CNNs are compared at different scales and are applied with distinct training frameworks. In this paper, we aim to provide the first fair & in-depth comparisons between Transformers and CNNs, focusing on robustness evaluations. With our unified training setup, we first challenge the previous belief that Transformers outshine CNNs when measuring adversarial robustness. More surprisingly, we find CNNs can easily be as robust as Transformers on defending against adversarial attacks, if they properly adopt Transformers' training recipes. While regarding generalization on out-of-distribution samples, we show pre-training on (external) large-scale datasets is not a fundamental request for enabling Transformers to achieve better performance than CNNs. Moreover, our ablations suggest such stronger generalization is largely benefited by the Transformer's self-attention-like architectures per se, rather than by other training setups. We hope this work can help the community better understand and benchmark the robustness of Transformers and CNNs. The code and models are publicly available at: https://github.com/ytongbai/ViTs-vs-CNNs. ",
    "authors": [
      "Bai, Yutong",
      "Mei, Jieru",
      "Yuille, Alan L.",
      "Xie, Cihang"
    ]
  },
  {
    "id": "e1b90346c92331860b1391257a106bb1",
    "title": "Towards Sharper Generalization Bounds for Structured Prediction",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e1b90346c92331860b1391257a106bb1-Paper.pdf",
    "abstract": "In this paper, we investigate the generalization performance of structured prediction learning and obtain state-of-the-art generalization bounds. Our analysis is based on factor graph decomposition of structured prediction algorithms, and we present novel margin guarantees from three different perspectives: Lipschitz continuity, smoothness, and space capacity condition. In the Lipschitz continuity scenario, we improve the square-root dependency on the label set cardinality of existing bounds to a logarithmic dependence. In the smoothness scenario, we provide generalization bounds that are not only a logarithmic dependency on the label set cardinality but a faster convergence rate of order $\\mathcal{O}(\\frac{1}{n})$ on the sample size $n$. In the space capacity scenario, we obtain bounds that do not depend on the label set cardinality and have faster convergence rates than $\\mathcal{O}(\\frac{1}{\\sqrt{n}})$. In each scenario, applications are provided to suggest that these conditions are easy to be satisfied. ",
    "authors": [
      "Li, Shaojie",
      "Liu, Yong"
    ]
  },
  {
    "id": "e1c13a13fc6b87616b787b986f98a111",
    "title": "Automated Discovery of Adaptive Attacks on Adversarial Defenses",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e1c13a13fc6b87616b787b986f98a111-Paper.pdf",
    "abstract": "Reliable evaluation of adversarial defenses is a challenging task, currently limited to an expert who manually crafts attacks that exploit the defense\u2019s inner workings, or to approaches based on ensemble of fixed attacks, none of which may be effective for the specific defense at hand. Our key observation is that adaptive attacks are composed from a set of reusable building blocks that can be formalized in a search space and used to automatically discover attacks for unknown defenses. We evaluated our approach on 24 adversarial defenses and show that it outperforms AutoAttack, the current state-of-the-art tool for reliable evaluation of adversarial defenses: our tool discovered significantly stronger attacks by producing 3.0%-50.8% additional adversarial examples for 10 models, while obtaining attacks with slightly stronger or similar strength for the remaining models.",
    "authors": [
      "Yao, Chengyuan",
      "Bielik, Pavol",
      "Tsankov, Petar",
      "Vechev, Martin"
    ]
  },
  {
    "id": "e1e32e235eee1f970470a3a6658dfdd5",
    "title": "PolarStream: Streaming Object Detection and Segmentation with Polar Pillars",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e1e32e235eee1f970470a3a6658dfdd5-Paper.pdf",
    "abstract": "Recent works recognized lidars as an inherently streaming data source and showed that the end-to-end latency of lidar perception models can be reduced significantly by operating on wedge-shaped point cloud sectors rather then the full point cloud. However, due to use of cartesian coordinate systems these methods  represent the sectors as rectangular regions, wasting memory and compute. In this work we propose using a polar coordinate system and make two key improvements on this design. First, we increase the spatial context by using multi-scale padding from neighboring sectors: preceding sector from the current scan and/or the following sector from the past scan. Second, we improve the core polar convolutional architecture by introducing feature undistortion and range stratified convolutions. Experimental results on the nuScenes dataset show significant improvements over other streaming based methods. We also achieve comparable results to existing non-streaming methods but with lower latencies.",
    "authors": [
      "Chen, Qi",
      "Vora, Sourabh",
      "Beijbom, Oscar"
    ]
  },
  {
    "id": "e22cb9d6bbb4c290a94e4fff4d68a831",
    "title": "Representation Costs of Linear Neural Networks: Analysis and Design",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e22cb9d6bbb4c290a94e4fff4d68a831-Paper.pdf",
    "abstract": "For different parameterizations (mappings from parameters to predictors), we study the regularization cost in predictor space induced by $l_2$ regularization on the parameters (weights).  We focus on linear neural networks as parameterizations of linear predictors.  We identify the representation cost of certain sparse linear ConvNets and residual networks.  In order to get a better understanding of how the architecture and parameterization affect the representation cost, we also study the reverse problem, identifying which regularizers on linear predictors (e.g., $l_p$ norms, group norms, the $k$-support-norm, elastic net) can be the representation cost induced by simple $l_2$ regularization, and designing the parameterizations that do so.",
    "authors": [
      "Dai, Zhen",
      "Karzand, Mina",
      "Srebro, Nathan"
    ]
  },
  {
    "id": "e22dd5dabde45eda5a1a67772c8e25dd",
    "title": "Teaching via Best-Case Counterexamples in the Learning-with-Equivalence-Queries Paradigm",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e22dd5dabde45eda5a1a67772c8e25dd-Paper.pdf",
    "abstract": "We study the sample complexity of teaching, termed as \"teaching dimension\" (TD) in the literature, for the learning-with-equivalence-queries (LwEQ) paradigm. More concretely, we consider a learner who asks equivalence queries (i.e., \"is the queried hypothesis the target hypothesis?\"), and a teacher responds either \"yes\" or \"no\" along with a counterexample to the queried hypothesis. This learning paradigm has been extensively studied when the learner receives worst-case or random counterexamples; in this paper, we consider the optimal teacher who picks best-case counterexamples to teach the target hypothesis within a hypothesis class. For this optimal teacher, we introduce LwEQ-TD, a notion of TD capturing the teaching complexity (i.e., the number of queries made) in this paradigm. We show that a significant reduction in queries can be achieved with best-case counterexamples, in contrast to worst-case or random counterexamples, for different hypothesis classes. Furthermore, we establish new connections of LwEQ-TD to the well-studied notions of TD in the learning-from-samples paradigm.",
    "authors": [
      "Kumar, Akash",
      "Chen, Yuxin",
      "Singla, Adish"
    ]
  },
  {
    "id": "e234e195f3789f05483378c397db1cb5",
    "title": "Distilling Meta Knowledge on Heterogeneous Graph for Illicit Drug Trafficker Detection on Social Media",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e234e195f3789f05483378c397db1cb5-Paper.pdf",
    "abstract": "Driven by the considerable profits, the crime of drug trafficking (a.k.a. illicit drug trading) has co-evolved with modern technologies, e.g., social media such as Instagram has become a popular platform for marketing and selling illicit drugs. The activities of online drug trafficking are nimble and resilient, which call for novel techniques to effectively detect, disrupt, and dismantle illicit drug trades. In this paper, we propose a holistic framework named MetaHG to automatically detect illicit drug traffickers on social media (i.e., Instagram), by tackling the following two new challenges: (1) different from existing works which merely focus on analyzing post content, MetaHG is capable of jointly modeling multi-modal content and relational structured information on social media for illicit drug trafficker detection; (2) in addition, through the proposed meta-learning technique, MetaHG addresses the issue of requiring sufficient data for model training. More specifically, in our proposed MetaHG, we first build a heterogeneous graph (HG) to comprehensively characterize the complex ecosystem of drug trafficking on social media.  Then, we employ a relation-based graph convolutional neural network to learn node (i.e., user) representations over the built HG, in which we introduce graph structure refinement to compensate the sparse connection among entities in the HG for more robust node representation learning. Afterwards, we propose a meta-learning algorithm for model optimization. A self-supervised module and a knowledge distillation module are further designed to exploit unlabeled data for improving the model. Extensive experiments based on the real-world data collected from Instagram demonstrate that the proposed MetaHG outperforms state-of-the-art methods.",
    "authors": [
      "Qian, Yiyue",
      "Zhang, Yiming",
      "Ye, Yanfang (Fa",
      "Zhang, Chuxu"
    ]
  },
  {
    "id": "e242660df1b69b74dcc7fde711f924ff",
    "title": "Curriculum Disentangled Recommendation with Noisy Multi-feedback",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e242660df1b69b74dcc7fde711f924ff-Paper.pdf",
    "abstract": "Learning disentangled representations for user intentions from multi-feedback (i.e., positive and negative feedback) can enhance the accuracy and explainability of recommendation algorithms. However, learning such disentangled representations from multi-feedback data is challenging because  i) multi-feedback is complex: there exist complex relations among different types of feedback (e.g., click, unclick, and dislike, etc) as well as various user intentions, and ii) multi-feedback is noisy: there exists noisy (useless) information both in features and labels, which may deteriorate the recommendation performance.  Existing works on disentangled representation learning only focus on positive feedback, failing to handle the complex relations and noise hidden in multi-feedback data. To solve this problem, in this work we propose a Curriculum Disentangled Recommendation (CDR) model that is capable of efficiently learning disentangled representations from complex and noisy multi-feedback for better recommendation. Concretely, we design a co-filtering dynamic routing mechanism that simultaneously captures the complex relations among different behavioral feedback and user intentions as well as denoise the representations in the feature level. We then present an adjustable self-evaluating curriculum that is able to evaluate sample difficulties for better model training and conduct denoising in the label level via disregarding useless information. Our extensive experiments on several real-world datasets demonstrate that the proposed CDR model can significantly outperform several state-of-the-art methods in terms of recommendation accuracy.",
    "authors": [
      "Chen, Hong",
      "Chen, Yudong",
      "Wang, Xin",
      "Xie, Ruobing",
      "Wang, Rui",
      "Xia, Feng",
      "Zhu, Wenwu"
    ]
  },
  {
    "id": "e250c59336b505ed411d455abaa30b4d",
    "title": "Interpretable agent communication from scratch (with a generic visual processor emerging on the side)",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e250c59336b505ed411d455abaa30b4d-Paper.pdf",
    "abstract": "As deep networks begin to be deployed as autonomous agents, the issue of how they can communicate with each other becomes important. Here, we train two deep nets from scratch to perform realistic referent identification through unsupervised emergent communication. We show that the largely interpretable emergent protocol allows the nets to successfully communicate even about object types they did not see at training time. The visual representations induced as a by-product of our training regime, moreover, show comparable quality, when re-used as generic visual features, to a recent self-supervised learning model. Our results provide concrete evidence of the viability of (interpretable) emergent deep net communication in a more realistic scenario than previously considered, as well as establishing an intriguing link between this field and self-supervised visual learning.",
    "authors": [
      "Dessi, Roberto",
      "Kharitonov, Eugene",
      "Marco, Baroni"
    ]
  },
  {
    "id": "e25cfa90f04351958216f97e3efdabe9",
    "title": "MAU: A Motion-Aware Unit for Video Prediction and Beyond",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e25cfa90f04351958216f97e3efdabe9-Paper.pdf",
    "abstract": "Accurately predicting inter-frame motion information plays a key role in video prediction tasks. In this paper, we propose a Motion-Aware Unit (MAU) to capture reliable inter-frame motion information by broadening the temporal receptive field of the predictive units. The MAU consists of two modules, the attention module and the fusion module. The attention module aims to learn an attention map based on the correlations between the current spatial state and the historical spatial states. Based on the learned attention map, the historical temporal states are aggregated to an augmented motion information (AMI). In this way, the predictive unit can perceive more temporal dynamics from a wider receptive field. Then, the fusion module is utilized to further aggregate the augmented motion information (AMI) and current appearance information (current spatial state) to the final predicted frame. The computation load of MAU is relatively low and the proposed unit can be easily applied to other predictive models. Moreover, an information recalling scheme is employed into the encoders and decoders to help preserve the visual details of the predictions. We evaluate the MAU on both video prediction and early action recognition tasks. Experimental results show that the MAU outperforms the state-of-the-art methods on both tasks.",
    "authors": [
      "Chang, Zheng",
      "Zhang, Xinfeng",
      "Wang, Shanshe",
      "Ma, Siwei",
      "Ye, Yan",
      "Xinguang, Xiang",
      "Gao, Wen"
    ]
  },
  {
    "id": "e27c71957d1e6c223e0d48a165da2ee1",
    "title": "Successor Feature Landmarks for Long-Horizon Goal-Conditioned Reinforcement Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e27c71957d1e6c223e0d48a165da2ee1-Paper.pdf",
    "abstract": "Operating in the real-world often requires agents to learn about a complex environment and apply this understanding to achieve a breadth of goals. This problem, known as goal-conditioned reinforcement learning (GCRL), becomes especially challenging for long-horizon goals. Current methods have tackled this problem by augmenting goal-conditioned policies with graph-based planning algorithms. However, they struggle to scale to large, high-dimensional state spaces and assume access to exploration mechanisms for efficiently collecting training data. In this work, we introduce Successor Feature Landmarks (SFL), a framework for exploring large, high-dimensional environments so as to obtain a policy that is proficient for any goal. SFL leverages the ability of successor features (SF) to capture transition dynamics, using it to drive exploration by estimating state-novelty and to enable high-level planning by abstracting the state-space as a non-parametric landmark-based graph. We further exploit SF to directly compute a goal-conditioned policy for inter-landmark traversal, which we use to execute plans to \"frontier\" landmarks at the edge of the explored state space. We show in our experiments on MiniGrid and ViZDoom that SFL enables efficient exploration of large, high-dimensional state spaces and outperforms state-of-the-art baselines on long-horizon GCRL tasks.",
    "authors": [
      "Hoang, Christopher",
      "Sohn, Sungryull",
      "Choi, Jongwook",
      "Carvalho, Wilka",
      "Lee, Honglak"
    ]
  },
  {
    "id": "e2a2dcc36a08a345332c751b2f2e476c",
    "title": "Streaming Belief Propagation for Community Detection",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e2a2dcc36a08a345332c751b2f2e476c-Paper.pdf",
    "abstract": "The community detection problem requires to cluster the nodes of a network into a small number of well-connected \u2018communities\u2019. There has been substantial recent progress in characterizing the fundamental statistical limits of community detection under simple stochastic block models.  However, in real-world applications, the network structure is typically dynamic, with nodes that join over time. In this setting, we would like a detection algorithm to perform only a limited number of updates at each node arrival. While standard voting approaches satisfy this constraint, it is unclear whether they exploit the network information optimally. We introduce a simple model for networks growing over time which we refer to as streaming stochastic block model (StSBM). Within this model, we prove that voting algorithms have fundamental limitations.  We also develop a streaming belief-propagation (STREAMBP)  approach, for which we prove optimality in certain regimes. We validate our theoretical findings on synthetic and real data",
    "authors": [
      "Wu, Yuchen",
      "Tardos, Jakab",
      "Bateni, Mohammadhossein",
      "Linhares, Andr\u00e9",
      "Goncalves de Almeida, Filipe Miguel",
      "Montanari, Andrea",
      "Norouzi-Fard, Ashkan"
    ]
  },
  {
    "id": "e2db7186375992e729165726762cb4c1",
    "title": "The staircase property: How hierarchical structure can guide deep learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e2db7186375992e729165726762cb4c1-Paper.pdf",
    "abstract": "This paper identifies a structural property of data distributions that enables deep neural networks to learn hierarchically. We define the ``staircase'' property for functions over the Boolean hypercube, which posits that high-order Fourier coefficients are reachable from lower-order Fourier coefficients along increasing chains. We prove that functions satisfying this  property can be learned in polynomial time using layerwise  stochastic coordinate descent on regular neural networks -- a class of network architectures and initializations that have homogeneity properties. Our analysis shows that for such staircase functions and neural networks, the gradient-based algorithm learns high-level features by greedily combining lower-level features along the depth of the network. We further back our theoretical results with experiments showing that staircase functions are learnable by more standard ResNet architectures with stochastic gradient descent. Both the theoretical and experimental results support the fact that the staircase property has a role to play in understanding the capabilities of gradient-based learning on regular networks, in contrast to general polynomial-size networks that can emulate any Statistical Query or PAC algorithm, as recently shown.",
    "authors": [
      "Abbe, Emmanuel",
      "Boix-Adsera, Enric",
      "Brennan, Matthew S",
      "Bresler, Guy",
      "Nagaraj, Dheeraj"
    ]
  },
  {
    "id": "e32084632d369461572832e6582aac36",
    "title": "MagNet: A Neural Network for Directed Graphs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e32084632d369461572832e6582aac36-Paper.pdf",
    "abstract": "The prevalence of graph-based data has spurred the rapid development of graph neural networks (GNNs) and related machine learning algorithms. Yet, despite the many datasets naturally modeled as directed graphs, including citation, website, and traffic networks, the vast majority of this research focuses on undirected graphs. In this paper, we propose MagNet, a GNN for directed graphs based on a complex Hermitian matrix known as the magnetic Laplacian. This matrix encodes undirected geometric structure in the magnitude of its entries and directional information in their phase. A charge parameter attunes spectral information to variation among directed cycles. We apply our network to a variety of directed graph node classification and link prediction tasks showing that MagNet performs well on all tasks and that its performance exceeds all other methods on a  majority of such tasks. The underlying principles of MagNet are such that it can be adapted to other GNN architectures.",
    "authors": [
      "Zhang, Xitong",
      "He, Yixuan",
      "Brugnone, Nathan",
      "Perlmutter, Michael",
      "Hirn, Matthew"
    ]
  },
  {
    "id": "e3251075554389fe91d17a794861d47b",
    "title": "Hardware-adaptive Efficient Latency Prediction for NAS via Meta-Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e3251075554389fe91d17a794861d47b-Paper.pdf",
    "abstract": "For deployment, neural architecture search should be hardware-aware, in order to satisfy the device-specific constraints (e.g., memory usage, latency and energy consumption) and enhance the model efficiency. Existing methods on hardware-aware NAS collect a large number of samples (e.g., accuracy and latency) from a target device, either builds a lookup table or a latency estimator. However, such approach is impractical in real-world scenarios as there exist numerous devices with different hardware specifications, and collecting samples from such a large number of devices will require prohibitive computational and monetary cost. To overcome such limitations, we propose Hardware-adaptive Efficient Latency Predictor (HELP), which formulates the device-specific latency estimation problem as a meta-learning problem, such that we can estimate the latency of a model's performance for a given task on an unseen device with a few samples. To this end, we introduce novel hardware embeddings to embed any devices considering them as black-box functions that output latencies, and meta-learn the hardware-adaptive latency predictor in a device-dependent manner, using the hardware embeddings. We validate the proposed HELP for its latency estimation performance on unseen platforms, on which it achieves high estimation performance with as few as 10 measurement samples, outperforming all relevant baselines. We also validate end-to-end NAS frameworks using HELP against ones without it, and show that it largely reduces the total time cost of the base NAS method, in latency-constrained settings.",
    "authors": [
      "Lee, Hayeon",
      "Lee, Sewoong",
      "Chong, Song",
      "Hwang, Sung Ju"
    ]
  },
  {
    "id": "e334fd9dac68f13fa1a57796148cf812",
    "title": "Topological Relational Learning on Graphs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e334fd9dac68f13fa1a57796148cf812-Paper.pdf",
    "abstract": "Graph neural networks (GNNs) have emerged as a powerful tool for graph classification and representation learning. However, GNNs tend to suffer from over-smoothing problems and are vulnerable to graph perturbations. To address these challenges, we propose a novel topological neural framework of topological relational inference (TRI) which allows for integrating higher-order graph information to GNNs and for systematically learning a local graph structure. The key idea is to rewire the original graph by using the persistent homology of the small neighborhoods of the nodes and then to incorporate the extracted topological summaries as the side information into the local algorithm. As a result, the new framework enables us to harness both the conventional information on the graph structure and information on higher order topological properties of the graph. We derive theoretical properties on stability of the new local topological representation of the graph and discuss its implications on the graph algebraic connectivity. The experimental results on node classification tasks demonstrate that the new TRI-GNN outperforms all 14 state-of-the-art baselines on 6 out 7 graphs and exhibit higher robustness to perturbations, yielding up to 10\\% better performance under noisy scenarios.",
    "authors": [
      "Chen, Yuzhou",
      "Coskunuzer, Baris",
      "Gel, Yulia"
    ]
  },
  {
    "id": "e34376937c784505d9b4fcd980c2f1ce",
    "title": "Learning Theory Can (Sometimes) Explain Generalisation in Graph Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e34376937c784505d9b4fcd980c2f1ce-Paper.pdf",
    "abstract": "In recent years, several results in the supervised learning setting suggested that classical statistical learning-theoretic measures, such as VC dimension, do not adequately explain the performance of deep learning models which prompted a slew of work in the infinite-width and iteration regimes. However, there is little theoretical explanation for the success of neural networks beyond the supervised setting. In this paper we argue that, under some distributional assumptions, classical learning-theoretic measures can sufficiently explain generalization for graph neural networks in the transductive setting. In particular, we provide a rigorous analysis of the performance of neural networks in the context of transductive inference, specifically by analysing the generalisation properties of graph convolutional networks for the problem of node classification. While VC-dimension does result in trivial generalisation error bounds in this setting as well, we show that transductive Rademacher complexity can explain the generalisation properties of graph convolutional networks for stochastic block models. We further use the generalisation error bounds based on transductive Rademacher complexity to demonstrate the role of graph convolutions and network architectures in achieving smaller generalisation error and provide insights into when the graph structure can help in learning. The findings of this paper could re-new the interest in studying generalisation in neural networks in terms of learning-theoretic measures, albeit in specific problems.",
    "authors": [
      "Esser, Pascal",
      "Chennuru Vankadara, Leena",
      "Ghoshdastidar, Debarghya"
    ]
  },
  {
    "id": "e347c51419ffb23ca3fd5050202f9c3d",
    "title": "Federated Linear Contextual Bandits",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e347c51419ffb23ca3fd5050202f9c3d-Paper.pdf",
    "abstract": "This paper presents a novel federated linear contextual bandits model, where individual clients face different $K$-armed stochastic bandits coupled through common global parameters. By leveraging the geometric structure of the linear rewards, a collaborative algorithm called Fed-PE is proposed to cope with the heterogeneity across clients without exchanging local feature vectors or raw data. Fed-PE relies on a novel multi-client G-optimal design, and achieves near-optimal regrets for both disjoint and shared parameter cases with logarithmic communication costs. In addition, a new concept called collinearly-dependent policies is introduced, based on which a tight minimax regret lower bound for the disjoint parameter case is derived. Experiments demonstrate the effectiveness of the proposed algorithms on both synthetic and real-world datasets. ",
    "authors": [
      "Huang, Ruiquan",
      "Wu, Weiqiang",
      "Yang, Jing",
      "Shen, Cong"
    ]
  },
  {
    "id": "e354fd90b2d5c777bfec87a352a18976",
    "title": "Least Square Calibration for Peer Reviews",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e354fd90b2d5c777bfec87a352a18976-Paper.pdf",
    "abstract": "Peer review systems such as conference paper review often suffer from the issue of miscalibration. Previous works on peer review calibration usually only use the ordinal information or assume simplistic reviewer scoring functions such as linear functions. In practice, applications like academic conferences often rely on manual methods, such as open discussions, to mitigate miscalibration. It remains an important question to develop algorithms that can   handle different types of miscalibrations based on available prior knowledge. In this paper, we propose a flexible framework, namely \\emph{least square calibration} (LSC), for selecting top candidates from peer ratings. Our framework provably performs perfect calibration from noiseless linear scoring functions under mild assumptions, yet also provides competitive calibration results when the scoring function is from broader classes beyond linear functions and with arbitrary noise. On our synthetic dataset, we empirically demonstrate that our algorithm consistently outperforms the baseline which select top papers based on the highest average ratings.",
    "authors": [
      "Tan, Sijun",
      "Wu, Jibang",
      "Bei, Xiaohui",
      "Xu, Haifeng"
    ]
  },
  {
    "id": "e35d7a5768c4b85b4780384d55dc3620",
    "title": "Scaling Up Exact Neural Network Compression by ReLU Stability",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e35d7a5768c4b85b4780384d55dc3620-Paper.pdf",
    "abstract": "We can compress a rectifier network while exactly preserving its underlying functionality with respect to a given input domain if some of its neurons are stable. However, current approaches to determine the stability of neurons with Rectified Linear Unit (ReLU) activations require solving or finding a good approximation to multiple discrete optimization problems. In this work, we introduce an algorithm based on solving a single optimization problem to identify all stable neurons. Our approach is on median 183 times faster than the state-of-art method on CIFAR-10, which allows us to explore exact compression on deeper (5 x 100) and wider (2 x 800) networks within minutes. For classifiers trained under an amount of L1 regularization that does not worsen accuracy, we can remove up to 56% of the connections on the CIFAR-10 dataset. The code is available at the following link, https://github.com/yuxwind/ExactCompression .",
    "authors": [
      "Serra, Thiago",
      "Yu, Xin",
      "Kumar, Abhinav",
      "Ramalingam, Srikumar"
    ]
  },
  {
    "id": "e360367584297ee8d2d5afa709cd440e",
    "title": "Passive attention in artificial neural networks predicts human visual selectivity",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e360367584297ee8d2d5afa709cd440e-Paper.pdf",
    "abstract": "Developments in machine learning interpretability techniques over the past decade have provided new tools to observe the image regions that are most informative for classification and localization in artificial neural networks (ANNs). Are the same regions similarly informative to human observers? Using data from 79 new experiments and 7,810 participants, we show that passive attention techniques reveal a significant overlap with human visual selectivity estimates derived from 6 distinct behavioral tasks including visual discrimination, spatial localization, recognizability, free-viewing, cued-object search, and saliency search fixations. We find that input visualizations derived from relatively simple ANN architectures probed using guided backpropagation methods are the best predictors of a shared component in the joint variability of the human measures. We validate these correlational results with causal manipulations using recognition experiments. We show that images masked with ANN attention maps were easier for humans to classify than control masks in a speeded recognition experiment. Similarly, we find that recognition performance in the same ANN models was likewise influenced by masking input images using human visual selectivity maps. This work contributes a new approach to evaluating the biological and psychological validity of leading ANNs as models of human vision: by examining their similarities and differences in terms of their visual selectivity to the information contained in images.",
    "authors": [
      "Langlois, Thomas",
      "Zhao, Haicheng",
      "Grant, Erin",
      "Dasgupta, Ishita",
      "Griffiths, Tom",
      "Jacoby, Nori"
    ]
  },
  {
    "id": "e3670ce0c315396e4836d7024abcf3dd",
    "title": "GRIN: Generative Relation and Intention Network for Multi-agent Trajectory Prediction",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e3670ce0c315396e4836d7024abcf3dd-Paper.pdf",
    "abstract": "Learning the distribution of future trajectories conditioned on the past is a crucial problem for understanding multi-agent systems. This is challenging because humans make decisions based on complex social relations and personal intents, resulting in highly complex uncertainties over trajectories. To address this problem, we propose a conditional deep generative model that combines advances in graph neural networks. The prior and recognition model encodes two types of latent codes for each agent: an inter-agent latent code to represent social relations and an intra-agent latent code to represent agent intentions. The decoder is carefully devised to leverage the codes in a disentangled way to predict multi-modal future trajectory distribution. Specifically, a graph attention network built upon inter-agent latent code is used to learn continuous pair-wise relations, and an agent's motion is controlled by its latent intents and its observations of all other agents. Through experiments on both synthetic and real-world datasets, we show that our model outperforms previous work in multiple performance metrics. We also show that our model generates realistic multi-modal trajectories.",
    "authors": [
      "Li, Longyuan",
      "Yao, Jian",
      "Wenliang, Li",
      "He, Tong",
      "Xiao, Tianjun",
      "Yan, Junchi",
      "Wipf, David",
      "Zhang, Zheng"
    ]
  },
  {
    "id": "e38e37a99f7de1f45d169efcdb288dd1",
    "title": "Instance-Dependent Partial Label Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e38e37a99f7de1f45d169efcdb288dd1-Paper.pdf",
    "abstract": "Partial label learning (PLL) is a typical weakly supervised learning problem, where each training example is associated with a set of candidate labels among which only one is true. Most existing PLL approaches assume that the incorrect labels in each training example are randomly picked as the candidate labels. However, this assumption is not realistic since the candidate labels are always instance-dependent. In this paper, we consider instance-dependent PLL and assume that each example is associated with a latent label distribution constituted by the real number of each label, representing the degree to each label describing the feature. The incorrect label with a high degree is more likely to be annotated as the candidate label. Therefore, the latent label distribution is the essential labeling information in partially labeled examples and worth being leveraged for predictive model training. Motivated by this consideration, we propose a novel PLL method that recovers the label distribution as a label enhancement (LE) process and trains the predictive model iteratively in every epoch. Specifically, we assume the true posterior density of the latent label distribution takes on the variational approximate Dirichlet density parameterized by an inference model. Then the evidence lower bound is deduced for optimizing the inference model and the label distributions generated from the variational posterior are utilized for training the predictive model. Experiments on benchmark and real-world datasets validate the effectiveness of the proposed method. Source code is available at https://github.com/palm-ml/valen.",
    "authors": [
      "Xu, Ning",
      "Qiao, Congyu",
      "Geng, Xin",
      "Zhang, Min-Ling"
    ]
  },
  {
    "id": "e3a54649aeec04cf1c13907bc6c5c8aa",
    "title": "Deep Learning with Label Differential Privacy",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e3a54649aeec04cf1c13907bc6c5c8aa-Paper.pdf",
    "abstract": "The Randomized Response (RR) algorithm is a classical technique to improve robustness in survey aggregation, and has been widely adopted in applications with differential privacy guarantees. We propose a novel algorithm, Randomized Response with Prior (RRWithPrior), which can provide more accurate results while maintaining the same level of privacy guaranteed by RR. We then apply RRWithPrior to learn neural networks with label differential privacy (LabelDP), and show that when only the label needs to be protected, the model performance can be significantly improved over the previous state-of-the-art private baselines. Moreover, we study different ways to obtain priors, which when used with RRWithPrior can additionally improve the model performance, further reducing the accuracy gap between private and non-private models. We complement the empirical results with theoretical analysis showing that LabelDP is provably easier than protecting both the inputs and labels.",
    "authors": [
      "Ghazi, Badih",
      "Golowich, Noah",
      "Kumar, Ravi",
      "Manurangsi, Pasin",
      "Zhang, Chiyuan"
    ]
  },
  {
    "id": "e3b21256183cf7c2c7a66be163579d37",
    "title": "Semialgebraic Representation of Monotone Deep Equilibrium Models and Applications to Certification",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e3b21256183cf7c2c7a66be163579d37-Paper.pdf",
    "abstract": "Deep equilibrium models are based on implicitly defined functional relations and have shown competitive performance compared with the traditional deep networks. Monotone operator equilibrium networks (monDEQ) retain interesting performance with additional theoretical guaranties. Existing certification tools for classical deep networks cannot directly be applied to monDEQs for which much fewer tools exist. We introduce a semialgebraic representation for ReLU based monDEQs which allow to approximate the corresponding input output relation by semidefinite programs (SDP). We present several applications to network certification and obtain SDP models for the following problems : robustness certification, Lipschitz constant estimation, ellipsoidal uncertainty propagation. We use these models to certify robustness of monDEQs with respect to a general $L_p$ norm. Experimental results show that the proposed models outperform existing approaches for monDEQ certification. Furthermore, our investigations suggest that monDEQs are much more robust to $L_2$ perturbations than $L_{\\infty}$ perturbations.",
    "authors": [
      "Chen, Tong",
      "Lasserre, Jean B.",
      "Magron, Victor",
      "Pauwels, Edouard"
    ]
  },
  {
    "id": "e3b6fb0fd4df098162eede3313c54a8d",
    "title": "The Role of Global Labels in Few-Shot Classification and How to Infer Them",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e3b6fb0fd4df098162eede3313c54a8d-Paper.pdf",
    "abstract": "Few-shot learning is a central problem in meta-learning, where learners must quickly adapt to new tasks given limited training data. Recently, feature pre-training has become a ubiquitous component in state-of-the-art meta-learning methods and is shown to provide significant performance improvement. However, there is limited theoretical understanding of the connection between pre-training and meta-learning. Further, pre-training requires global labels shared across tasks, which may be unavailable in practice. In this paper, we show why exploiting pre-training is theoretically advantageous for meta-learning, and in particular the critical role of global labels. This motivates us to propose Meta Label Learning (MeLa), a novel meta-learning framework that automatically infers global labels to obtains robust few-shot models. Empirically, we demonstrate that MeLa is competitive with existing methods and provide extensive ablation experiments to highlight its key properties.",
    "authors": [
      "Wang, Ruohan",
      "Pontil, Massimiliano",
      "Ciliberto, Carlo"
    ]
  },
  {
    "id": "e41e164f7485ec4a28741a2d0ea41c74",
    "title": "NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e41e164f7485ec4a28741a2d0ea41c74-Paper.pdf",
    "abstract": "We present a novel neural surface reconstruction method, called NeuS, for reconstructing objects and scenes with high fidelity from 2D image inputs. Existing neural surface reconstruction approaches, such as DVR [Niemeyer et al., 2020] and IDR [Yariv et al., 2020], require foreground mask as supervision, easily get trapped in local minima, and therefore struggle with the reconstruction of objects with severe self-occlusion or thin structures. Meanwhile, recent neural methods for novel view synthesis, such as NeRF [Mildenhall et al., 2020] and its variants, use volume rendering to produce a neural scene representation with robustness of optimization, even for highly complex objects. However, extracting high-quality surfaces from this learned implicit representation is difficult because there are not sufficient surface constraints in the representation. In NeuS, we propose to represent a surface as the zero-level set of a signed distance function (SDF) and develop a new volume rendering method to train a neural SDF representation. We observe that the conventional volume rendering method causes inherent geometric errors (i.e. bias) for surface reconstruction, and therefore propose a new formulation that is free of bias in the first order of approximation, thus leading to more accurate surface reconstruction even without the mask supervision. Experiments on the DTU dataset and the BlendedMVS dataset show that NeuS outperforms the state-of-the-arts in high-quality surface reconstruction, especially for objects and scenes with complex structures and self-occlusion. ",
    "authors": [
      "Wang, Peng",
      "Liu, Lingjie",
      "Liu, Yuan",
      "Theobalt, Christian",
      "Komura, Taku",
      "Wang, Wenping"
    ]
  },
  {
    "id": "e43739bba7cdb577e9e3e4e42447f5a5",
    "title": "Improved Guarantees for Offline Stochastic Matching via new Ordered Contention Resolution Schemes",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e43739bba7cdb577e9e3e4e42447f5a5-Paper.pdf",
    "abstract": "Matching is one of the most fundamental and broadly applicable problems across many domains. In these diverse real-world applications, there is often a degree of uncertainty in the input which has led to the study of stochastic matching models. Here, each edge in the graph has a known, independent probability of existing derived from some prediction. Algorithms must probe edges to determine existence and match them irrevocably if they exist. Further, each vertex may have a patience constraint denoting how many of its neighboring edges can be probed. We present new ordered contention resolution schemes yielding improved approximation guarantees for some of the foundational problems studied in this area. For stochastic matching with patience constraints in general graphs, we provide a $0.382$-approximate algorithm, significantly improving over the previous best $0.31$-approximation of Baveja et al. (2018). When the vertices do not have patience constraints, we describe a $0.432$-approximate random order probing algorithm with several corollaries such as an improved guarantee for the Prophet Secretary problem under Edge Arrivals. Finally, for the special case of bipartite graphs with unit patience constraints on one of the partitions, we show a $0.632$-approximate algorithm that improves on the recent $1/3$-guarantee of Hikima et al. (2021).",
    "authors": [
      "Brubach, Brian",
      "Grammel, Nathaniel",
      "Ma, Will",
      "Srinivasan, Aravind"
    ]
  },
  {
    "id": "e46bc064f8e92ac2c404b9871b2a4ef2",
    "title": "UFC-BERT: Unifying Multi-Modal Controls for Conditional Image Synthesis",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e46bc064f8e92ac2c404b9871b2a4ef2-Paper.pdf",
    "abstract": "Conditional image synthesis aims to create an image according to some multi-modal guidance in the forms of textual descriptions, reference images, and image blocks to preserve, as well as their combinations. In this paper, instead of investigating these control signals separately, we propose a new two-stage architecture, UFC-BERT, to unify any number of multi-modal controls. In UFC-BERT, both the diverse control signals and the synthesized image are uniformly represented as a sequence of discrete tokens to be processed by Transformer. Different from existing two-stage autoregressive approaches such as DALL-E and VQGAN, UFC-BERT adopts non-autoregressive generation (NAR) at the second stage to enhance the holistic consistency of the synthesized image, to support preserving specified image blocks, and to improve the synthesis speed. Further, we design a progressive algorithm that iteratively improves the non-autoregressively generated image, with the help of two estimators developed for evaluating the compliance with the controls and evaluating the fidelity of the synthesized image, respectively. Extensive experiments on a newly collected large-scale clothing dataset M2C-Fashion and a facial dataset Multi-Modal CelebA-HQ verify that UFC-BERT can synthesize high-fidelity images that comply with flexible multi-modal controls.",
    "authors": [
      "Zhang, Zhu",
      "Ma, Jianxin",
      "Zhou, Chang",
      "Men, Rui",
      "Li, Zhikang",
      "Ding, Ming",
      "Tang, Jie",
      "Zhou, Jingren",
      "Yang, Hongxia"
    ]
  },
  {
    "id": "e46be61f0050f9cc3a98d5d2192cb0eb",
    "title": "Is Bang-Bang Control All You Need? Solving Continuous Control with Bernoulli Policies",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e46be61f0050f9cc3a98d5d2192cb0eb-Paper.pdf",
    "abstract": "Reinforcement learning (RL) for continuous control typically employs distributions whose support covers the entire action space. In this work, we investigate the colloquially known phenomenon that trained agents often prefer actions at the boundaries of that space. We draw theoretical connections to the emergence of bang-bang behavior in optimal control, and provide extensive empirical evaluation across a variety of recent RL algorithms. We replace the normal Gaussian by a Bernoulli distribution that solely considers the extremes along each action dimension - a bang-bang controller. Surprisingly, this achieves state-of-the-art performance on several continuous control benchmarks - in contrast to robotic hardware, where energy and maintenance cost affect controller choices. Since exploration, learning, and the final solution are entangled in RL, we provide additional imitation learning experiments to reduce the impact of exploration on our analysis. Finally, we show that our observations generalize to environments that aim to model real-world challenges and evaluate factors to mitigate the emergence of bang-bang solutions. Our findings emphasise challenges for benchmarking continuous control algorithms, particularly in light of potential real-world applications.",
    "authors": [
      "Seyde, Tim",
      "Gilitschenski, Igor",
      "Schwarting, Wilko",
      "Stellato, Bartolomeo",
      "Riedmiller, Martin",
      "Wulfmeier, Markus",
      "Rus, Daniela"
    ]
  },
  {
    "id": "e48e13207341b6bffb7fb1622282247b",
    "title": "Improving Generalization in Meta-RL with Imaginary Tasks from Latent Dynamics Mixture",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e48e13207341b6bffb7fb1622282247b-Paper.pdf",
    "abstract": "The generalization ability of most meta-reinforcement learning (meta-RL) methods is largely limited to test tasks that are sampled from the same distribution used to sample training tasks. To overcome the limitation, we propose Latent Dynamics Mixture (LDM) that trains a reinforcement learning agent with imaginary tasks generated from mixtures of learned latent dynamics. By training a policy on mixture tasks along with original training tasks, LDM allows the agent to prepare for unseen test tasks during training and prevents the agent from overfitting the training tasks. LDM significantly outperforms standard meta-RL methods in test returns on the gridworld navigation and MuJoCo tasks where we strictly separate the training task distribution and the test task distribution.",
    "authors": [
      "Lee, Suyoung",
      "Chung, Sae-Young"
    ]
  },
  {
    "id": "e4a6222cdb5b34375400904f03d8e6a5",
    "title": "Localization with Sampling-Argmax",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e4a6222cdb5b34375400904f03d8e6a5-Paper.pdf",
    "abstract": "Soft-argmax operation is commonly adopted in detection-based methods to localize the target position in a differentiable manner. However, training the neural network with soft-argmax makes the shape of the probability map unconstrained. Consequently, the model lacks pixel-wise supervision through the map during training, leading to performance degradation. In this work, we propose sampling-argmax, a differentiable training method that imposes implicit constraints to the shape of the probability map by minimizing the expectation of the localization error. To approximate the expectation, we introduce a continuous formulation of the output distribution and develop a differentiable sampling process. The expectation can be approximated by calculating the average error of all samples drawn from the output distribution. We show that sampling-argmax can seamlessly replace the conventional soft-argmax operation on various localization tasks. Comprehensive experiments demonstrate the effectiveness and flexibility of the proposed method. Code is available at https://github.com/Jeff-sjtu/sampling-argmax",
    "authors": [
      "Li, Jiefeng",
      "Chen, Tong",
      "Shi, Ruiqi",
      "Lou, Yujing",
      "Li, Yong-Lu",
      "Lu, Cewu"
    ]
  },
  {
    "id": "e4a93f0332b2519177ed55741ea4e5e7",
    "title": "Improved Regularization and Robustness for Fine-tuning in Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e4a93f0332b2519177ed55741ea4e5e7-Paper.pdf",
    "abstract": "A widely used algorithm for transfer learning is fine-tuning, where a pre-trained model is fine-tuned on a target task with a small amount of labeled data. When the capacity of the pre-trained model is much larger than the size of the target data set, fine-tuning is prone to overfitting and \"memorizing\" the training labels. Hence, an important question is to regularize fine-tuning and ensure its robustness to noise. To address this question, we begin by analyzing the generalization properties of fine-tuning. We present a PAC-Bayes generalization bound that depends on the distance traveled in each layer during fine-tuning and the noise stability of the fine-tuned model. We empirically measure these quantities. Based on the analysis, we propose regularized self-labeling---the interpolation between regularization and self-labeling methods, including (i) layer-wise regularization to constrain the distance traveled in each layer; (ii) self label-correction and label-reweighting to correct mislabeled data points (that the model is confident) and reweight less confident data points. We validate our approach on an extensive collection of image and text data sets using multiple pre-trained model architectures. Our approach improves baseline methods by 1.76% (on average) for seven image classification tasks and 0.75% for a few-shot classification task. When the target data set includes noisy labels, our approach outperforms baseline methods by 3.56% on average in two noisy settings.",
    "authors": [
      "Li, Dongyue",
      "Zhang, Hongyang"
    ]
  },
  {
    "id": "e4d2b6e6fdeca3e60e0f1a62fee3d9dd",
    "title": "BARTScore: Evaluating Generated Text as Text Generation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e4d2b6e6fdeca3e60e0f1a62fee3d9dd-Paper.pdf",
    "abstract": "A wide variety of NLP applications, such as machine translation, summarization, and dialog, involve text generation. One major challenge for these applications is how to evaluate whether such generated texts are actually fluent, accurate, or effective. In this work, we conceptualize the evaluation of generated text as a text generation problem, modeled using pre-trained sequence-to-sequence models. The general idea is that models trained to convert the generated text to/from a reference output or the source text will achieve higher scores when the generated text is better. We operationalize this idea using BART, an encoder-decoder based pre-trained model, and propose a metric BARTScore with a number of variants that can be flexibly applied in an unsupervised fashion to evaluation of text from different perspectives (e.g. informativeness, fluency, or factuality). BARTScore is conceptually simple and empirically effective. It can outperform existing top-scoring metrics in 16 of 22 test settings, covering evaluation of 16 datasets (e.g., machine translation, text summarization) and 7 different perspectives (e.g., informativeness, factuality). Code to calculate BARTScore is available at https://github.com/neulab/BARTScore, and we have released an interactive leaderboard for meta-evaluation at http://explainaboard.nlpedia.ai/leaderboard/task-meval/ on the ExplainaBoard platform, which allows us to interactively understand the strengths, weaknesses, and complementarity of each metric.",
    "authors": [
      "Yuan, Weizhe",
      "Neubig, Graham",
      "Liu, Pengfei"
    ]
  },
  {
    "id": "e531e258fe3098c3bdd707c30a687d73",
    "title": "An analysis of Ermakov-Zolotukhin quadrature using kernels",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e531e258fe3098c3bdd707c30a687d73-Paper.pdf",
    "abstract": "We study a quadrature, proposed by Ermakov and Zolotukhin in the sixties, through the lens of kernel methods. The nodes of this quadrature rule follow the distribution of a determinantal point process, while the weights are defined through a linear system, similarly to the optimal kernel quadrature. In this work, we show how these two classes of quadrature are related, and we prove a tractable formula of the expected value of the squared worst-case integration error on the unit ball of an RKHS of the former quadrature. In particular, this formula involves the eigenvalues of the corresponding kernel and leads to improving on the existing theoretical guarantees of the optimal kernel quadrature with determinantal point processes. ",
    "authors": [
      "Belhadji, Ayoub"
    ]
  },
  {
    "id": "e53a0a2978c28872a4505bdb51db06dc",
    "title": "Towards Understanding Why Lookahead Generalizes Better Than SGD and Beyond",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e53a0a2978c28872a4505bdb51db06dc-Paper.pdf",
    "abstract": "To train networks, lookahead algorithm~\\cite{zhang2019lookahead} updates its fast weights $k$ times via  an  inner-loop   optimizer before updating its slow weights once by using the latest  fast weights. Any optimizer, e.g. SGD,  can serve as the inner-loop optimizer, and the derived lookahead  generally enjoys remarkable test performance improvement over the vanilla optimizer.  But theoretical understandings on the test performance improvement   of lookahead remain absent yet. To solve this issue, we theoretically justify  the advantages of lookahead  in terms of the excess risk error which measures the test performance. Specifically, we prove that lookahead using  SGD as its inner-loop optimizer can better balance the optimization error and generalization error to achieve smaller excess risk error than vanilla SGD  on (strongly) convex problems and nonconvex problems with Polyak-{\\L}ojasiewicz condition which has been observed/proved in neural networks.   Moreover,  we show the stagewise optimization strategy~\\cite{barshan2015stage} which decays learning rate several times during training can also benefit lookahead in  improving  its optimization and generalization errors on strongly convex problems. Finally, we propose a  stagewise locally-regularized lookahead (SLRLA) algorithm which sums up the vanilla objective and a local regularizer to minimize at each stage and  provably enjoys optimization and generalization improvement  over the conventional (stagewise) lookahead.    Experimental results on   CIFAR10/100 and ImageNet  testify its  advantages. Codes is available at  \\url{https://github.com/sail-sg/SLRLA-optimizer}. ",
    "authors": [
      "Zhou, Pan",
      "Yan, Hanshu",
      "Yuan, Xiaotong",
      "Feng, Jiashi",
      "Yan, Shuicheng"
    ]
  },
  {
    "id": "e562cd9c0768d5464b64cf61da7fc6bb",
    "title": "Online Market Equilibrium with Application to Fair Division",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e562cd9c0768d5464b64cf61da7fc6bb-Paper.pdf",
    "abstract": "Computing market equilibria is a problem of both theoretical and applied interest. Much research to date focuses on the case of static Fisher markets with full information on buyers' utility functions and item supplies. Motivated by real-world markets, we consider an online setting: individuals have linear, additive utility functions; items arrive sequentially and must be allocated and priced irrevocably. We define the notion of an online market equilibrium in such a market as time-indexed allocations and prices which guarantee buyer optimality and market clearance in hindsight. We propose a simple, scalable and interpretable allocation and pricing dynamics termed as PACE. When items are drawn i.i.d. from an unknown distribution (with a possibly continuous support), we show that PACE leads to an online market equilibrium asymptotically. In particular, PACE ensures that buyers' time-averaged utilities converge to the equilibrium utilities w.r.t. a static market with item supplies being the unknown distribution and that buyers' time-averaged expenditures converge to their per-period budget. Hence, many desirable properties of market equilibrium-based fair division such as envy-freeness, Pareto optimality, and the proportional-share guarantee are also attained asymptotically in the online setting. Next, we extend the dynamics to handle quasilinear buyer utilities, which gives the first online algorithm for computing first-price pacing equilibria. Finally, numerical experiments on real and synthetic datasets show that the dynamics converges quickly under various metrics.",
    "authors": [
      "Gao, Yuan",
      "Peysakhovich, Alex",
      "Kroer, Christian"
    ]
  },
  {
    "id": "e56954b4f6347e897f954495eab16a88",
    "title": "Dynamic Resolution Network ",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e56954b4f6347e897f954495eab16a88-Paper.pdf",
    "abstract": "Deep convolutional neural networks (CNNs) are often of sophisticated design with numerous learnable parameters for the accuracy reason. To alleviate the expensive costs of deploying them on mobile devices, recent works have made huge efforts for excavating redundancy in pre-defined architectures. Nevertheless, the redundancy on the input resolution of modern CNNs has not been fully investigated, i.e., the resolution of input image is fixed. In this paper, we observe that the smallest resolution for accurately predicting the given image is different using the same neural network. To this end, we propose a novel dynamic-resolution network (DRNet) in which the input resolution is determined dynamically based on each input sample. Wherein, a resolution predictor with negligible computational costs is explored and optimized jointly with the desired network. Specifically, the predictor learns the smallest resolution that can retain and even exceed the original recognition accuracy for each image. During the inference, each input image will be resized to its predicted resolution for minimizing the overall computation burden. We then conduct extensive experiments on several benchmark networks and datasets. The results show that our DRNet can be embedded in any off-the-shelf network architecture to obtain a considerable reduction in computational complexity. For instance, DR-ResNet-50 achieves similar performance with an about 34% computation reduction, while gaining 1.4% accuracy increase with 10% computation reduction compared to the original ResNet-50 on ImageNet. Code will be available at https://gitee.com/mindspore/models/tree/master/research/cv/DRNet.",
    "authors": [
      "Zhu, Mingjian",
      "Han, Kai",
      "Wu, Enhua",
      "Zhang, Qiulin",
      "Nie, Ying",
      "Lan, Zhenzhong",
      "Wang, Yunhe"
    ]
  },
  {
    "id": "e57c6b956a6521b28495f2886ca0977a",
    "title": "Gauge Equivariant Transformer",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e57c6b956a6521b28495f2886ca0977a-Paper.pdf",
    "abstract": "Attention mechanism has shown great performance and efficiency in a lot of deep learning models, in which relative position encoding plays a crucial role. However, when introducing attention to manifolds, there is no canonical local coordinate system to parameterize neighborhoods. To address this issue, we propose an equivariant transformer to make our model agnostic to the orientation of local coordinate systems (\\textit{i.e.}, gauge equivariant), which employs multi-head self-attention to jointly incorporate both position-based and content-based information. To enhance expressive ability, we adopt regular field of cyclic groups as feature fields in intermediate layers, and propose a novel method to parallel transport the feature vectors in these fields. In addition, we project the position vector of each point onto its local coordinate system to disentangle the orientation of the coordinate system in ambient space (\\textit{i.e.}, global coordinate system), achieving rotation invariance. To the best of our knowledge, we are the first to introduce gauge equivariance to self-attention, thus name our model Gauge Equivariant Transformer (GET), which can be efficiently implemented on triangle meshes. Extensive experiments show that GET achieves state-of-the-art performance on two common recognition tasks.",
    "authors": [
      "He, Lingshen",
      "Dong, Yiming",
      "Wang, Yisen",
      "Tao, Dacheng",
      "Lin, Zhouchen"
    ]
  },
  {
    "id": "e5841df2166dd424a57127423d276bbe",
    "title": "Unsupervised Object-Based Transition Models For 3D Partially Observable Environments",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e5841df2166dd424a57127423d276bbe-Paper.pdf",
    "abstract": "We present a slot-wise, object-based transition model that decomposes a scene into objects, aligns them (with respect to a slot-wise object memory) to maintain a consistent order across time, and predicts how those objects evolve over successive frames. The model is trained end-to-end without supervision using transition losses at the level of the object-structured representation rather than pixels. Thanks to the introduction of our novel alignment module, the model deals properly with two issues that are not handled satisfactorily by other transition models, namely object persistence and object identity. We show that the combination of an object-level loss and correct object alignment over time enables the model to outperform a state-of-the-art baseline, and allows it to deal well with object occlusion and re-appearance in partially observable environments.",
    "authors": [
      "Creswell, Antonia",
      "Kabra, Rishabh",
      "Burgess, Chris",
      "Shanahan, Murray"
    ]
  },
  {
    "id": "e5afb0f2dbc6d39b312d7406054cb4c6",
    "title": "Robust Contrastive Learning Using Negative Samples with Diminished Semantics",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e5afb0f2dbc6d39b312d7406054cb4c6-Paper.pdf",
    "abstract": "Unsupervised learning has recently made exceptional progress because of the development of more effective contrastive learning methods. However, CNNs are prone to depend on low-level features that humans deem non-semantic. This dependency has been conjectured to induce a lack of robustness to image perturbations or domain shift. In this paper, we show that by generating carefully designed negative samples, contrastive learning can learn more robust representations with less dependence on such features. Contrastive learning utilizes positive pairs which preserve semantic information while perturbing superficial features in the training images. Similarly, we propose to generate negative samples in a reversed way, where only the superfluous instead of the semantic features are preserved. We develop two methods, texture-based and patch-based augmentations, to generate negative samples.  These samples achieve better generalization, especially under out-of-domain settings. We also analyze our method and the generated texture-based samples, showing that texture features are indispensable in classifying particular ImageNet classes and especially finer classes. We also show that the model bias between texture and shape features favors them differently under different test settings. ",
    "authors": [
      "Ge, Songwei",
      "Mishra, Shlok",
      "Li, Chun-Liang",
      "Wang, Haohan",
      "Jacobs, David"
    ]
  },
  {
    "id": "e60e81c4cbe5171cd654662d9887aec2",
    "title": "General Low-rank Matrix Optimization: Geometric Analysis and Sharper Bounds",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e60e81c4cbe5171cd654662d9887aec2-Paper.pdf",
    "abstract": "This paper considers the global geometry of general low-rank minimization problems via the Burer-Monterio factorization approach. For the rank-$1$ case, we prove that there is no spurious second-order critical point for both symmetric and asymmetric problems if the rank-$2$ RIP constant $\\delta$ is less than $1/2$. Combining with a counterexample with $\\delta=1/2$, we show that the derived bound is the sharpest possible. For the arbitrary rank-$r$ case, the same property is established when the rank-$2r$ RIP constant $\\delta$ is at most $1/3$. We design a counterexample to show that the non-existence of spurious second-order critical points may not hold if $\\delta$ is at least $1/2$. In addition, for any problem with $\\delta$ between $1/3$ and $1/2$, we prove that all second-order critical points have a positive correlation to the ground truth. Finally, the strict saddle property, which can lead to the polynomial-time global convergence of various algorithms, is established for both the symmetric and asymmetric problems when the rank-$2r$ RIP constant $\\delta$ is less than $1/3$. The results of this paper significantly extend several existing bounds in the literature. ",
    "authors": [
      "Zhang, Haixiang",
      "Bi, Yingjie",
      "Lavaei, Javad"
    ]
  },
  {
    "id": "e614f646836aaed9f89ce58e837e2310",
    "title": "Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e614f646836aaed9f89ce58e837e2310-Paper.pdf",
    "abstract": "This paper is about the problem of learning a stochastic policy for generating an object (like a molecular graph) from a sequence of actions, such that the probability of generating an object is proportional to a given positive reward for that object. Whereas standard return maximization tends to converge to a single return-maximizing sequence, there are cases where we would like to sample a diverse set of high-return solutions. These arise, for example, in black-box function optimization when few rounds are possible, each with large batches of queries, where the batches should be diverse, e.g., in the design of new molecules. One can also see this as a problem of approximately converting an energy function to a generative distribution. While MCMC methods can achieve that, they are expensive and generally only perform local exploration. Instead, training a generative policy amortizes the cost of search during training and yields to fast generation.  Using insights from Temporal Difference learning, we propose GFlowNet, based on a view of the generative process as a flow network, making it possible to handle the tricky case where different trajectories can yield the same final state, e.g., there are many ways to sequentially add atoms to generate some molecular graph. We cast the set of trajectories as a flow and convert the flow consistency equations into a learning objective, akin to the casting of the Bellman equations into Temporal Difference methods. We prove that any global minimum of the proposed objectives yields a policy which samples from the desired distribution, and demonstrate the improved performance and diversity of GFlowNet on a simple domain where there are many modes to the reward function, and on a molecule synthesis task.",
    "authors": [
      "Bengio, Emmanuel",
      "Jain, Moksh",
      "Korablyov, Maksym",
      "Precup, Doina",
      "Bengio, Yoshua"
    ]
  },
  {
    "id": "e61eaa38aed621dd776d0e67cfeee366",
    "title": "Policy Finetuning: Bridging Sample-Efficient Offline and Online Reinforcement Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e61eaa38aed621dd776d0e67cfeee366-Paper.pdf",
    "abstract": "Recent theoretical work studies sample-efficient reinforcement learning (RL) extensively in two settings: learning interactively in the environment (online RL), or learning from an offline dataset (offline RL). However, existing algorithms and theories for learning near-optimal policies in these two settings are rather different and disconnected. Towards bridging this gap, this paper initiates the theoretical study of *policy finetuning*, that is, online RL where the learner has additional access to a \"reference policy\" $\\mu$ close to the optimal policy $\\pi_\\star$ in a certain sense. We consider the policy finetuning problem in episodic Markov Decision Processes (MDPs) with $S$ states, $A$ actions, and horizon length $H$. We first design a sharp *offline reduction* algorithm---which simply executes $\\mu$ and runs offline policy optimization on the collected dataset---that finds an $\\varepsilon$ near-optimal policy within $\\widetilde{O}(H^3SC^\\star/\\varepsilon^2)$ episodes, where $C^\\star$ is the single-policy concentrability coefficient between $\\mu$ and $\\pi_\\star$. This offline result is the first that matches the sample complexity lower bound in this setting, and resolves a recent open question in offline RL. We then establish an $\\Omega(H^3S\\min\\{C^\\star, A\\}/\\varepsilon^2)$ sample complexity lower bound for *any* policy finetuning algorithm, including those that can adaptively explore the environment. This implies that---perhaps surprisingly---the optimal policy finetuning algorithm is either offline reduction or a purely online RL algorithm that does not use $\\mu$. Finally, we design a new hybrid offline/online algorithm for policy finetuning that achieves better sample complexity than both vanilla offline reduction and purely online RL algorithms, in a relaxed setting where $\\mu$ only satisfies concentrability partially up to a certain time step. Overall, our results offer a quantitative understanding on the benefit of a good reference policy, and make a step towards bridging offline and online RL. ",
    "authors": [
      "Xie, Tengyang",
      "Jiang, Nan",
      "Wang, Huan",
      "Xiong, Caiming",
      "Bai, Yu"
    ]
  },
  {
    "id": "e6384711491713d29bc63fc5eeb5ba4f",
    "title": "Reducing Information Bottleneck for Weakly Supervised Semantic Segmentation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e6384711491713d29bc63fc5eeb5ba4f-Paper.pdf",
    "abstract": "Weakly supervised semantic segmentation produces pixel-level localization from class labels; however, a classifier trained on such labels is likely to focus on a small discriminative region of the target object. We interpret this phenomenon using the information bottleneck principle: the final layer of a deep neural network, activated by the sigmoid or softmax activation functions, causes an information bottleneck, and as a result, only a subset of the task-relevant information is passed on to the output. We first support this argument through a simulated toy experiment and then propose a method to reduce the information bottleneck by removing the last activation function. In addition, we introduce a new pooling method that further encourages the transmission of information from non-discriminative regions to the classification. Our experimental evaluations demonstrate that this simple modification significantly improves the quality of localization maps on both the PASCAL VOC 2012 and MS COCO 2014 datasets, exhibiting a new state-of-the-art performance for weakly supervised semantic segmentation.",
    "authors": [
      "Lee, Jungbeom",
      "Choi, Jooyoung",
      "Mok, Jisoo",
      "Yoon, Sungroh"
    ]
  },
  {
    "id": "e64c9ec33f19c7de745bd6b6d1a7a86e",
    "title": "SGD: The Role of Implicit Regularization, Batch-size and Multiple-epochs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e64c9ec33f19c7de745bd6b6d1a7a86e-Paper.pdf",
    "abstract": "Multi-epoch, small-batch, Stochastic Gradient Descent (SGD) has been the method of choice for learning with large over-parameterized models. A popular theory for explaining why SGD works well in practice is that the algorithm has an implicit regularization that biases its output towards a good solution. Perhaps the theoretically most well understood learning setting for SGD is that of Stochastic Convex Optimization (SCO), where it is well known that SGD learns at a rate of $O(1/\\sqrt{n})$, where $n$ is the number of samples. In this paper, we consider the problem of SCO and explore the role of implicit regularization, batch size and multiple epochs for SGD. Our main contributions are threefold: * We show that for any regularizer, there is an SCO problem for which Regularized Empirical Risk Minimzation fails to learn. This automatically rules out any implicit regularization based explanation for the success of SGD.* We provide a separation between SGD and learning via Gradient Descent on empirical loss (GD) in terms of sample complexity. We show that there is an SCO problem such that GD with any step size and number of iterations can only learn at a suboptimal rate: at least $\\widetilde{\\Omega}(1/n^{5/12})$.*  We present a multi-epoch variant of SGD commonly used in practice. We prove that this algorithm is at least as good as single pass SGD in the worst case. However, for certain SCO problems, taking multiple passes over the dataset can significantly outperform single pass SGD. We extend our results to the general learning setting by showing a problem which is learnable for any data distribution, and for this problem, SGD is strictly better than RERM for any regularization function. We conclude by discussing the implications of our results for deep learning, and show a separation between SGD and ERM for two layer diagonal neural networks.",
    "authors": [
      "Sekhari, Ayush",
      "Sridharan, Karthik",
      "Kale, Satyen"
    ]
  },
  {
    "id": "e655c7716a4b3ea67f48c6322fc42ed6",
    "title": "AC-GC: Lossy Activation Compression with Guaranteed Convergence",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e655c7716a4b3ea67f48c6322fc42ed6-Paper.pdf",
    "abstract": "Parallel hardware devices (e.g., graphics processor units) have limited high-bandwidth memory capacity.This negatively impacts the training of deep neural networks (DNNs) by increasing runtime and/or decreasing accuracy when reducing model and/or batch size to fit this capacity. Lossy compression is a promising approach to tackling memory capacity constraints, but prior approaches rely on hyperparameter search to achieve a suitable trade-off between convergence and compression, negating runtime benefits. In this paper we build upon recent developments on Stochastic Gradient Descent convergence to prove an upper bound on the expected loss increase when training with compressed activation storage. We then express activation compression error in terms of this bound, allowing the compression rate to adapt to training conditions automatically. The advantage of our approach, called AC-GC, over existing lossy compression frameworks is that, given a preset allowable increase in loss, significant compression without significant increase in error can be achieved with a single training run. When combined with error-bounded methods, AC-GC achieves 15.1x compression with an average accuracy change of 0.1% on text and image datasets. AC-GC functions on any model composed of the layers analyzed and, by avoiding compression rate search, reduces overall training time by 4.6x over SuccessiveHalving. ",
    "authors": [
      "Evans, R David",
      "Aamodt, Tor"
    ]
  },
  {
    "id": "e6af401c28c1790eaef7d55c92ab6ab6",
    "title": "Label Noise SGD Provably Prefers Flat Global Minimizers",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e6af401c28c1790eaef7d55c92ab6ab6-Paper.pdf",
    "abstract": "In overparametrized models, the noise in stochastic gradient descent (SGD) implicitly regularizes the optimization trajectory and determines which local minimum SGD converges to. Motivated by empirical studies that demonstrate that training with noisy labels improves generalization, we study the implicit regularization effect of SGD with label noise. We show that SGD with label noise converges to a stationary point of a regularized loss $L(\\theta) +\\lambda R(\\theta)$, where $L(\\theta)$ is the training loss, $\\lambda$ is an effective regularization parameter depending on the step size, strength of the label noise, and the batch size, and $R(\\theta)$ is an explicit regularizer that penalizes sharp minimizers. Our analysis uncovers an additional regularization effect of large learning rates beyond the linear scaling rule that penalizes large eigenvalues of the Hessian more than small ones. We also prove extensions to classification with general loss functions, significantly strengthening the prior work of Blanc et al. to global convergence and large learning rates and of HaoChen et al. to general models.",
    "authors": [
      "Damian, Alex",
      "Ma, Tengyu",
      "Lee, Jason D."
    ]
  },
  {
    "id": "e6ff107459d435e38b54ad4c06202c33",
    "title": "Can we have it all? On the Trade-off between Spatial and Adversarial Robustness of Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e6ff107459d435e38b54ad4c06202c33-Paper.pdf",
    "abstract": "(Non-)robustness of neural networks to small, adversarial pixel-wise perturbations, and as more recently shown, to even random spatial transformations (e.g., translations, rotations) entreats both theoretical and empirical understanding. Spatial robustness to random translations and rotations is commonly attained via equivariant models (e.g., StdCNNs, GCNNs) and training augmentation, whereas adversarial robustness is typically achieved by adversarial training. In this paper, we prove a quantitative trade-off between spatial and adversarial robustness in a simple statistical setting. We complement this empirically by showing that: (a) as the spatial robustness of equivariant models improves by training augmentation with progressively larger transformations, their adversarial robustness worsens progressively, and (b) as the state-of-the-art robust models are adversarially trained with progressively larger pixel-wise perturbations, their spatial robustness drops progressively. Towards achieving Pareto-optimality in this trade-off, we propose a method based on curriculum learning that trains gradually on more difficult perturbations (both spatial and adversarial) to\u00a0improve spatial and adversarial robustness simultaneously.",
    "authors": [
      "Kamath, Sandesh",
      "Deshpande, Amit",
      "Kambhampati Venkata, Subrahmanyam",
      "N Balasubramanian, Vineeth"
    ]
  },
  {
    "id": "e71e5cd119bbc5797164fb0cd7fd94a4",
    "title": "Universal Off-Policy Evaluation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e71e5cd119bbc5797164fb0cd7fd94a4-Paper.pdf",
    "abstract": "When faced with sequential decision-making problems, it is often useful to be able to predict what would happen if decisions were made using a new policy. Those predictions must often be based on data collected under some previously used decision-making rule.  Many previous methods enable such off-policy (or counterfactual) estimation of the expected value of a performance measure called the return.  In this paper, we take the first steps towards a 'universal off-policy estimator' (UnO)---one that provides off-policy estimates and high-confidence bounds for any parameter of the return distribution. We use UnO for estimating and simultaneously bounding the mean, variance, quantiles/median, inter-quantile range, CVaR, and the entire cumulative distribution of returns. Finally, we also discuss UnO's applicability in various settings, including fully observable, partially observable (i.e., with unobserved confounders), Markovian, non-Markovian, stationary, smoothly non-stationary, and discrete distribution shifts. ",
    "authors": [
      "Chandak, Yash",
      "Niekum, Scott",
      "da Silva, Bruno",
      "Learned-Miller, Erik",
      "Brunskill, Emma",
      "Thomas, Philip S."
    ]
  },
  {
    "id": "e727fa59ddefcefb5d39501167623132",
    "title": "A Non-commutative Extension of  Lee-Seung's Algorithm for Positive Semidefinite Factorizations",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e727fa59ddefcefb5d39501167623132-Paper.pdf",
    "abstract": "Given a data matrix $X\\in \\mathbb{R}_+^{m\\times n}$ with non-negative entries, a Positive Semidefinite (PSD) factorization of $X$ is a collection of $r \\times r$-dimensional PSD matrices $\\{A_i\\}$ and $\\{B_j\\}$ satisfying the condition $X_{ij}= \\mathrm{tr}(A_i B_j)$ for all $\\ i\\in [m],\\ j\\in [n]$.  PSD factorizations are fundamentally linked to understanding the expressiveness of semidefinite programs as well as the power and limitations of quantum resources in information theory.  The PSD factorization task generalizes the Non-negative Matrix Factorization (NMF) problem in which we seek a collection of $r$-dimensional non-negative vectors $\\{a_i\\}$ and $\\{b_j\\}$ satisfying $X_{ij}= a_i^T b_j$,  for all $i\\in [m],\\ j\\in [n]$ -- one can recover the latter problem by choosing matrices in the PSD factorization to be diagonal.  The most widely used algorithm for computing NMFs of a matrix is the Multiplicative Update algorithm developed by Lee and Seung, in which non-negativity of the updates is preserved by scaling with positive diagonal matrices.  In this paper, we describe a non-commutative extension of Lee-Seung's algorithm, which we call the Matrix Multiplicative Update (MMU) algorithm, for computing PSD factorizations.  The MMU algorithm ensures that updates remain PSD by congruence scaling with the matrix geometric mean of appropriate PSD matrices, and it retains the simplicity of implementation that the multiplicative update algorithm for NMF enjoys.  Building on the Majorization-Minimization framework, we show that under our update scheme the squared loss objective is non-increasing and fixed points correspond to critical points.  The analysis relies on a Lieb's Concavity Theorem.  Beyond PSD factorizations, we show that the MMU algorithm can be also used as a primitive to calculate block-diagonal PSD factorizations and tensor PSD factorizations.  We demonstrate the utility of our method with experiments on real and synthetic data. ",
    "authors": [
      "Soh, Yong Sheng",
      "Varvitsiotis, Antonios"
    ]
  },
  {
    "id": "e77910ebb93b511588557806310f78f1",
    "title": "Efficiently Identifying Task Groupings for Multi-Task Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e77910ebb93b511588557806310f78f1-Paper.pdf",
    "abstract": "Multi-task learning can leverage information learned by one task to benefit the training of other tasks. Despite this capacity, naively training all tasks together in one model often degrades performance, and exhaustively searching through combinations of task groupings can be prohibitively expensive. As a result, efficiently identifying the tasks that would benefit from training together remains a challenging design question without a clear solution. In this paper, we suggest an approach to select which tasks should train together in multi-task learning models. Our method determines task groupings in a single run by training all tasks together and quantifying the effect to which one task's gradient would affect another task's loss. On the large-scale Taskonomy computer vision dataset, we find this method can decrease test loss by 10.0% compared to simply training all tasks together while operating 11.6 times faster than a state-of-the-art task grouping method. ",
    "authors": [
      "Fifty, Chris",
      "Amid, Ehsan",
      "Zhao, Zhe",
      "Yu, Tianhe",
      "Anil, Rohan",
      "Finn, Chelsea"
    ]
  },
  {
    "id": "e7ac288b0f2d41445904d071ba37aaff",
    "title": "Instance-Conditioned GAN",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e7ac288b0f2d41445904d071ba37aaff-Paper.pdf",
    "abstract": "Generative Adversarial Networks (GANs) can generate near photo realistic images in narrow domains such as human faces. Yet, modeling complex distributions of datasets such as ImageNet and COCO-Stuff remains challenging in unconditional settings. In this paper, we take inspiration from kernel density estimation techniques and introduce a non-parametric approach to modeling distributions of complex datasets. We partition the data manifold into a mixture of overlapping neighborhoods described by a datapoint and its nearest neighbors, and introduce a model, called instance-conditioned GAN (IC-GAN), which learns the distribution around each datapoint. Experimental results on ImageNet and COCO-Stuff show that IC-GAN significantly improves over unconditional models and unsupervised data partitioning baselines. Moreover, we show that IC-GAN can effortlessly transfer to datasets not seen during training by simply changing the conditioning instances, and still generate realistic images. Finally, we extend IC-GAN to the class-conditional case and show semantically controllable generation and competitive quantitative results on ImageNet; while improving over BigGAN on ImageNet-LT. Code and trained models to reproduce the reported results are available at https://github.com/facebookresearch/ic_gan.",
    "authors": [
      "Casanova, Arantxa",
      "Careil, Marlene",
      "Verbeek, Jakob",
      "Drozdzal, Michal",
      "Romero Soriano, Adriana"
    ]
  },
  {
    "id": "e7dfca01f394755c11f853602cb2608a",
    "title": "DeepSITH: Efficient Learning via Decomposition of What and When Across Time Scales",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e7dfca01f394755c11f853602cb2608a-Paper.pdf",
    "abstract": "Extracting temporal relationships over a range of scales is a hallmark ofhuman perception and cognition---and thus it is a critical feature of machinelearning applied to real-world problems.  Neural networks are either plaguedby the exploding/vanishing gradient problem in recurrent neural networks(RNNs) or must adjust their parameters to learn the relevant time scales(e.g., in LSTMs). This paper introduces DeepSITH, a deep network comprisingbiologically-inspired Scale-Invariant Temporal History (SITH) modules inseries with dense connections between layers. Each SITH module is simply aset of time cells coding what happened when with a geometrically-spaced set oftime lags.  The dense connections between layers change the definition of whatfrom one layer to the next.  The geometric series of time lags implies thatthe network codes time on a logarithmic scale, enabling DeepSITH network tolearn problems requiring memory over a wide range of time scales. We compareDeepSITH to LSTMs and other recent RNNs on several time series prediction anddecoding tasks. DeepSITH achieves results comparable to state-of-the-artperformance on these problems and continues to perform well even as the delaysare increased.",
    "authors": [
      "Jacques, Brandon",
      "Tiganj, Zoran",
      "Howard, Marc",
      "Sederberg, Per B"
    ]
  },
  {
    "id": "e7e69cdf28f8ce6b69b4e1853ee21bab",
    "title": "A Gaussian Process-Bayesian Bernoulli Mixture Model for Multi-Label Active Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e7e69cdf28f8ce6b69b4e1853ee21bab-Paper.pdf",
    "abstract": "Multi-label classification (MLC) allows complex dependencies among labels, making it more suitable to model many real-world problems. However, data annotation for training MLC models becomes much more labor-intensive due to the correlated (hence non-exclusive) labels and a potential large and sparse label space.  We propose to conduct multi-label active learning (ML-AL) through a novel integrated Gaussian Process-Bayesian Bernoulli Mixture model (GP-B$^2$M) to accurately quantify a data sample's overall contribution to a correlated label space and choose the most informative samples for cost-effective annotation. In particular, the B$^2$M encodes label correlations using a Bayesian Bernoulli mixture of label clusters, where each mixture component corresponds to a global pattern of label correlations. To tackle highly sparse labels under AL, the B$^2$M is further integrated with a predictive GP to connect data features as an effective inductive bias and achieve a feature-component-label mapping. The GP predicts coefficients of mixture components that help to recover the final set of labels of a data sample. A novel auxiliary variable based variational inference algorithm is developed to tackle the non-conjugacy introduced along with the mapping process for efficient end-to-end posterior inference.  The model also outputs a predictive  distribution that provides both the label prediction and their correlations in the form of a label covariance matrix. A principled sampling function is designed accordingly to naturally capture both the feature uncertainty (through GP) and label covariance (through B$^2$M) for effective data sampling. Experiments on real-world multi-label datasets demonstrate the state-of-the-art AL performance of the proposed GP-B$^2$M model. ",
    "authors": [
      "Shi, Weishi",
      "Yu, Dayou",
      "Yu, Qi"
    ]
  },
  {
    "id": "e7e8f8e5982b3298c8addedf6811d500",
    "title": "Differentially Private Empirical Risk Minimization under the Fairness Lens",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e7e8f8e5982b3298c8addedf6811d500-Paper.pdf",
    "abstract": "Differential Privacy (DP) is an important privacy-enhancing technology for private machine learning systems. It allows to measure and bound the risk associated with an individual participation in a computation. However, it was recently observed that DP learning systems may exacerbate bias and unfairness for different groups of individuals. This paper builds on these important observations and sheds light on the causes of the disparate impacts arising in the problem of differentially private empirical risk minimization. It focuses on the accuracy disparity arising among groups of individuals in two well-studied DP learning methods: output perturbation and differentially private stochastic gradient descent. The paper analyzes which data and model properties are responsible for the disproportionate impacts, why these aspects are affecting different groups disproportionately, and proposes guidelines to mitigate these effects. The proposed approach is evaluated on several datasets and settings.",
    "authors": [
      "Tran, Cuong",
      "Dinh, My",
      "Fioretto, Ferdinando"
    ]
  },
  {
    "id": "e8219d4c93f6c55c6b10fe6bfe997c6c",
    "title": "A Unified View of cGANs with and without Classifiers",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e8219d4c93f6c55c6b10fe6bfe997c6c-Paper.pdf",
    "abstract": "Conditional Generative Adversarial Networks (cGANs) are implicit generative models which allow to sample from class-conditional distributions. Existing cGANs are based on a wide range of different discriminator designs and training objectives. One popular design in earlier works is to include a classifier during training with the assumption that good classifiers can help eliminate samples generated with wrong classes. Nevertheless, including classifiers in cGANs often comes with a side effect of only generating easy-to-classify samples. Recently, some representative cGANs avoid the shortcoming and reach state-of-the-art performance without having classifiers. Somehow it remains unanswered whether the classifiers can be resurrected to design better cGANs. In this work, we demonstrate that classifiers can be properly leveraged to improve cGANs. We start by using the decomposition of the joint probability distribution to connect the goals of cGANs and classification as a unified framework. The framework, along with a classic energy model to parameterize distributions, justifies the use of classifiers for cGANs in a principled manner. It explains several popular cGAN variants, such as ACGAN, ProjGAN, and ContraGAN, as special cases with different levels of approximations, which provides a unified view and brings new insights to understanding cGANs. Experimental results demonstrate that the design inspired by the proposed framework outperforms state-of-the-art cGANs on multiple benchmark datasets, especially on the most challenging ImageNet. The code is available at https://github.com/sian-chen/PyTorch-ECGAN.",
    "authors": [
      "Chen, Si-An",
      "Li, Chun-Liang",
      "Lin, Hsuan-Tien"
    ]
  },
  {
    "id": "e8258e5140317ff36c7f8225a3bf9590",
    "title": "Online and Offline Reinforcement Learning by Planning with a Learned Model",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e8258e5140317ff36c7f8225a3bf9590-Paper.pdf",
    "abstract": "Learning efficiently from small amounts of data has long been the focus of model-based reinforcement learning, both for the online case when interacting with the environment, and the offline case when learning from a fixed dataset. However, to date no single unified algorithm could demonstrate state-of-the-art results for both settings.In this work, we describe the Reanalyse algorithm, which uses model-based policy and value improvement operators to compute improved training targets for existing data points, allowing for efficient learning at data budgets varying by several orders of magnitude. We further show that Reanalyse can also be used to learn completely without environment interactions, as in the case of Offline Reinforcement Learning (Offline RL). Combining Reanalyse with the MuZero algorithm, we introduce MuZero Unplugged, a single unified algorithm for any data budget, including Offline RL. In contrast to previous work, our algorithm requires no special adaptations for the off-policy or Offline RL settings. MuZero Unplugged sets new state-of-the-art results for Atari in the standard 200 million frame online setting as well as in the RL Unplugged Offline RL benchmark.",
    "authors": [
      "Schrittwieser, Julian",
      "Hubert, Thomas",
      "Mandhane, Amol",
      "Barekatain, Mohammadamin",
      "Antonoglou, Ioannis",
      "Silver, David"
    ]
  },
  {
    "id": "e8542a04d734d0cae36d648b3f519e5c",
    "title": "Stochastic Multi-Armed Bandits with Control Variates",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e8542a04d734d0cae36d648b3f519e5c-Paper.pdf",
    "abstract": "This paper studies a new variant of the stochastic multi-armed bandits problem where auxiliary information about the arm rewards is available in the form of control variates. In many applications like queuing and wireless networks, the arm rewards are functions of some exogenous variables. The mean values of these variables are known a priori from historical data and can be used as control variates.  Leveraging the theory of control variates, we obtain mean estimates with smaller variance and tighter confidence bounds. We develop an upper confidence bound based algorithm named UCB-CV and characterize the regret bounds in terms of the correlation between rewards and control variates when they follow a multivariate normal distribution. We also extend UCB-CV to other distributions using resampling methods like Jackknifing and Splitting. Experiments on synthetic problem instances validate performance guarantees of the proposed algorithms.",
    "authors": [
      "Verma, Arun",
      "Hanawal, Manjesh Kumar"
    ]
  },
  {
    "id": "e85cc63b4f0f312f11e073fc68ccffd5",
    "title": "Near-Optimal No-Regret Learning in General Games",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e85cc63b4f0f312f11e073fc68ccffd5-Paper.pdf",
    "abstract": "We show that Optimistic Hedge -- a common variant of multiplicative-weights-updates with recency bias -- attains ${\\rm poly}(\\log T)$ regret in multi-player general-sum games. In particular, when every player of the game uses Optimistic Hedge to iteratively update her action in response to the history of play so far, then after $T$ rounds of interaction, each player experiences total regret that is ${\\rm poly}(\\log T)$. Our bound improves, exponentially, the $O(T^{1/2})$ regret attainable  by standard no-regret learners in games, the $O(T^{1/4})$ regret attainable by no-regret learners with recency bias (Syrgkanis et al., NeurIPS 2015), and the $O(T^{1/6})$ bound that was recently shown for Optimistic Hedge in the special case of two-player games (Chen & Peng, NeurIPS 2020). A direct corollary of our bound is that Optimistic Hedge converges to coarse correlated equilibrium in general games at a rate of $\\tilde{O}(1/T)$.",
    "authors": [
      "Daskalakis, Constantinos",
      "Fishelson, Maxwell",
      "Golowich, Noah"
    ]
  },
  {
    "id": "e8855b3528cb03d1def9803220bd3cb9",
    "title": "Improving Self-supervised Learning with Automated Unsupervised Outlier Arbitration",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e8855b3528cb03d1def9803220bd3cb9-Paper.pdf",
    "abstract": "Our work reveals a structured shortcoming of the existing mainstream self-supervised learning methods. Whereas self-supervised learning frameworks usually take the prevailing perfect instance level invariance hypothesis for granted, we carefully investigate the pitfalls behind. Particularly, we argue that the existing augmentation pipeline for generating multiple positive views naturally introduces out-of-distribution (OOD) samples that undermine the learning of the downstream tasks. Generating diverse positive augmentations on the input does not always pay off in benefiting downstream tasks. To overcome this inherent deficiency, we introduce a lightweight latent variable model UOTA, targeting the view sampling issue for self-supervised learning. UOTA adaptively searches for the most important sampling region to produce views, and provides viable choice for outlier-robust self-supervised learning approaches. Our method directly generalizes to many mainstream self-supervised learning approaches, regardless of the loss's nature contrastive or not. We empirically show UOTA's advantage over the state-of-the-art self-supervised paradigms with evident margin, which well justifies the existence of the OOD sample issue embedded in the existing approaches. Especially, we theoretically prove that the merits of the proposal boil down to guaranteed estimator variance and bias reduction. Code is available: https://github.com/ssl-codelab/uota.",
    "authors": [
      "Wang, Yu",
      "Lin, Jingyang",
      "Zou, Jingjing",
      "Pan, Yingwei",
      "Yao, Ting",
      "Mei, Tao"
    ]
  },
  {
    "id": "e894d787e2fd6c133af47140aa156f00",
    "title": "Improving Anytime Prediction with Parallel Cascaded Networks and a Temporal-Difference Loss",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e894d787e2fd6c133af47140aa156f00-Paper.pdf",
    "abstract": "Although deep feedforward neural networks share some characteristics with the primate visual system, a key distinction is their dynamics.  Deep nets typically operate in serial stages wherein each layer completes its computation before processing begins in subsequent layers.   In contrast, biological systems have cascaded dynamics: information propagates from neurons at all layers in parallel but transmission occurs gradually over time, leading to speed-accuracy trade offs even in feedforward architectures. We explore the consequences of biologically inspired parallel hardware by constructing cascaded ResNets in which each residual block has propagation delays but all blocks update in parallel in a stateful manner. Because information transmitted through skip connections avoids delays, the functional depth of the architecture increases over time, yielding  anytime predictions that improve with internal-processing time. We introduce a temporal-difference training loss that achieves a strictly superior speed-accuracy profile over standard losses and enables the cascaded architecture to outperform state-of-the-art anytime-prediction methods. The cascaded architecture has intriguing properties, including: it classifies typical instances more rapidly than atypical instances; it is more robust to both persistent and transient noise than is a conventional ResNet; and its time-varying output trace provides a signal that can be exploited to improve information processing and inference.",
    "authors": [
      "Iuzzolino, Michael",
      "Mozer, Michael C.",
      "Bengio, Samy"
    ]
  },
  {
    "id": "e8a642ed6a9ad20fb159472950db3d65",
    "title": "Identifiable Generative models for Missing Not at Random Data Imputation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e8a642ed6a9ad20fb159472950db3d65-Paper.pdf",
    "abstract": "Real-world datasets often have missing values associated with complex generative processes, where the cause of the missingness may not be fully observed. This is known as missing not at random (MNAR) data. However, many imputation methods do not take into account the missingness mechanism, resulting in biased imputation values when MNAR data is present. Although there are a few methods that have considered the MNAR scenario, their model's identifiability under MNAR is generally not guaranteed. That is, model parameters can not be uniquely determined even with infinite data samples, hence the imputation results given by such models can still be biased. This issue is especially overlooked by many modern deep generative models. In this work, we fill in this gap by systematically analyzing the identifiability of generative models under MNAR. Furthermore, we propose a practical deep generative model which can provide identifiability guarantees under mild assumptions, for a wide range of MNAR mechanisms. Our method demonstrates a clear advantage for tasks on both synthetic data and multiple real-world scenarios with MNAR data. ",
    "authors": [
      "Ma, Chao",
      "Zhang, Cheng"
    ]
  },
  {
    "id": "e8aac01231200e7ef318b9db75c72695",
    "title": "DNN-based Topology Optimisation:  Spatial Invariance and Neural Tangent Kernel",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e8aac01231200e7ef318b9db75c72695-Paper.pdf",
    "abstract": "We study the Solid Isotropic Material Penalization (SIMP) method with a density field generated by a fully-connected neural network, taking the coordinates as inputs. In the large width limit, we show that the use of DNNs leads to a filtering effect similar to traditional filtering techniques for SIMP, with a filter described by the Neural Tangent Kernel (NTK). This filter is however not invariant under translation, leading to visual artifacts and non-optimal shapes. We propose two embeddings of the input coordinates, which lead  to (approximate) spatial invariance of the NTK and of the filter. We empirically confirm our theoretical observations and study how the filter size is affected by the architecture of the network. Our solution can easily be applied to any other coordinates-based generation method. ",
    "authors": [
      "Dupuis, Benjamin",
      "Jacot, Arthur"
    ]
  },
  {
    "id": "e8b1cbd05f6e6a358a81dee52493dd06",
    "title": "Baleen: Robust Multi-Hop Reasoning at Scale via Condensed Retrieval",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e8b1cbd05f6e6a358a81dee52493dd06-Paper.pdf",
    "abstract": "Multi-hop reasoning (i.e., reasoning across two or more documents) is a key ingredient for NLP models that leverage large corpora to exhibit broad knowledge. To retrieve evidence passages, multi-hop models must contend with a fast-growing search space across the hops, represent complex queries that combine multiple information needs, and resolve ambiguity about the best order in which to hop between training passages. We tackle these problems via Baleen, a system that improves the accuracy of multi-hop retrieval while learning robustly from weak training signals in the many-hop setting. To tame the search space, we propose condensed retrieval, a pipeline that summarizes the retrieved passages after each hop into a single compact context. To model complex queries, we introduce a focused late interaction retriever that allows different parts of the same query representation to match disparate relevant passages. Lastly, to infer the hopping dependencies among unordered training passages, we devise latent hop ordering, a weak-supervision strategy in which the trained retriever itself selects the sequence of hops. We evaluate Baleen on retrieval for two-hop question answering and many-hop claim verification, establishing state-of-the-art performance.",
    "authors": [
      "Khattab, Omar",
      "Potts, Christopher",
      "Zaharia, Matei"
    ]
  },
  {
    "id": "e924517087669cf201ea91bd737a4ff4",
    "title": "Local Hyper-Flow Diffusion",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e924517087669cf201ea91bd737a4ff4-Paper.pdf",
    "abstract": "Recently, hypergraphs have attracted a lot of attention due to their ability to capture complex relations among entities. The insurgence of hypergraphs has resulted in data of increasing size and complexity that exhibit interesting small-scale and local structure, e.g., small-scale communities and localized node-ranking around a given set of seed nodes. Popular and principled ways to capture the local structure are the local hypergraph clustering problem and the related seed set expansion problem. In this work, we propose the first local diffusion method that achieves edge-size-independent Cheeger-type guarantee for the problem of local hypergraph clustering while applying to a rich class of higher-order relations that covers a number of previously studied special cases. Our method is based on a primal-dual optimization formulation where the primal problem has a natural network flow interpretation, and the dual problem has a cut-based interpretation using the $\\ell_2$-norm penalty on associated cut-costs. We demonstrate the new technique is significantly better than state-of-the-art methods on both synthetic and real-world data.",
    "authors": [
      "Fountoulakis, Kimon",
      "Li, Pan",
      "Yang, Shenghao"
    ]
  },
  {
    "id": "e9287a53b94620249766921107fe70a3",
    "title": "Permuton-induced Chinese Restaurant Process",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e9287a53b94620249766921107fe70a3-Paper.pdf",
    "abstract": "This paper proposes the permuton-induced Chinese restaurant process (PCRP), a stochastic process on rectangular partitioning of a matrix. This distribution is suitable for use as a prior distribution in Bayesian nonparametric relational model to find hidden clusters in matrices and network data. Our main contribution is to introduce the notion of permutons into the well-known Chinese restaurant process (CRP) for sequence partitioning: a permuton is a probability measure on $[0,1]\\times [0,1]$ and can be regarded as a geometric interpretation of the scaling limit of permutations. Specifically, we extend the model that the table order of CRPs has a random geometric arrangement on $[0,1]\\times [0,1]$ drawn from the permuton. By analogy with the relationship between the stick-breaking process (SBP) and CRP for the infinite mixture model of a sequence, this model can be regarded as a multi-dimensional extension of CRP paired with the block-breaking process (BBP), which has been recently proposed as a multi-dimensional extension of SBP. While BBP always has an infinite number of redundant intermediate variables, PCRP can be composed of varying size intermediate variables in a data-driven manner depending on the size and quality of the observation data. Experiments show that PCRP can improve the prediction performance in relational data analysis by reducing the local optima and slow mixing problems compared with the conventional BNP models because the local transitions of PCRP in Markov chain Monte Carlo inference are more flexible than the previous models.",
    "authors": [
      "Nakano, Masahiro",
      "Fujiwara, Yasuhiro",
      "Kimura, Akisato",
      "Yamada, Takeshi",
      "ueda, naonori"
    ]
  },
  {
    "id": "e92b755eb0d8800175a02a35c2bf44fe",
    "title": "Faster Algorithms and Constant Lower Bounds for the Worst-Case Expected Error",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e92b755eb0d8800175a02a35c2bf44fe-Paper.pdf",
    "abstract": "The study of statistical estimation without distributional assumptions on data values, but with knowledge of data collection methods was recently introduced by Chen, Valiant and Valiant (NeurIPS 2020). In this framework, the goal is to design estimators that minimize the worst-case expected error. Here the expectation is over a known, randomized data collection process from some population, and the data values corresponding to each element of the population are assumed to be worst-case. Chen, Valiant and Valiant show that, when data values are $\\ell_{\\infty}$-normalized, there is a polynomial time algorithm to compute an estimator for the mean with worst-case expected error that is within a factor $\\frac{\\pi}{2}$ of the optimum within the natural class of semilinear estimators. However, this algorithm is based on optimizing a somewhat complex concave objective function over a constrained set of positive semidefinite matrices, and thus does not come with explicit runtime guarantees beyond being polynomial time in the input.In this paper we design provably efficient algorithms for approximating the optimal semilinear estimator based on online convex optimization. In the setting where data values are $\\ell_{\\infty}$-normalized, our algorithm achieves a $\\frac{\\pi}{2}$-approximation by iteratively solving a sequence of standard SDPs. When data values are $\\ell_2$-normalized, our algorithm iteratively computes the top eigenvector of a sequence of matrices, and does not lose any multiplicative approximation factor. Further, using experiments in settings where sample membership is correlated with data values (e.g. \"importance sampling\" and \"snowball sampling\"), we show that our $\\ell_2$-normalized algorithm gives a similar advantage over standard estimators as the original $\\ell_{\\infty}$-normalized algorithm of Chen, Valiant and Valiant, but with much lower computational complexity. We complement these positive results by stating a simple combinatorial condition which, if satisfied by a data collection process, implies that any (not necessarily semilinear) estimator for the mean has constant worst-case expected error.",
    "authors": [
      "Brown-Cohen, Jonah"
    ]
  },
  {
    "id": "e9507053dd36cb9217816ffb566c8720",
    "title": "On Learning Domain-Invariant Representations for Transfer Learning with Multiple Sources",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e9507053dd36cb9217816ffb566c8720-Paper.pdf",
    "abstract": "Domain adaptation (DA) benefits from the rigorous theoretical works that study its insightful characteristics and various aspects, e.g., learning domain-invariant representations and its trade-off. However, it seems not the case for the multiple source DA and domain generalization (DG) settings which are remarkably more complicated and sophisticated due to the involvement of multiple source domains and potential unavailability of target domain during training. In this paper, we develop novel upper-bounds for the target general loss which appeal us to define two kinds of domain-invariant representations. We further study the pros and cons as well as the trade-offs of enforcing learning each domain-invariant representation. Finally, we conduct experiments to inspect the trade-off of these representations for offering practical hints regarding how to use them in practice and explore other interesting properties of our developed theory.",
    "authors": [
      "Phung, Trung",
      "Le, Trung",
      "Vuong, Tung-Long",
      "Tran, Toan",
      "Tran, Anh",
      "Bui, Hung",
      "Phung, Dinh"
    ]
  },
  {
    "id": "e96ed478dab8595a7dbda4cbcbee168f",
    "title": "You Never Cluster Alone",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e96ed478dab8595a7dbda4cbcbee168f-Paper.pdf",
    "abstract": "Recent advances in self-supervised learning with instance-level contrastive objectives facilitate unsupervised clustering. However, a standalone datum is not perceiving the context of the holistic cluster, and may undergo sub-optimal assignment. In this paper, we extend the mainstream contrastive learning paradigm to a cluster-level scheme, where all the data subjected to the same cluster contribute to a unified representation that encodes the context of each data group. Contrastive learning with this representation then rewards the assignment of each datum. To implement this vision, we propose twin-contrast clustering (TCC). We define a set of categorical variables as clustering assignment confidence, which links the instance-level learning track with the cluster-level one. On one hand, with the corresponding assignment variables being the weight, a weighted aggregation along the data points implements the set representation of a cluster. We further propose heuristic cluster augmentation equivalents to enable cluster-level contrastive learning. On the other hand, we derive the evidence lower-bound of the instance-level contrastive objective with the assignments. By reparametrizing the assignment variables, TCC is trained end-to-end, requiring no alternating steps. Extensive experiments show that TCC outperforms the state-of-the-art on benchmarked datasets.",
    "authors": [
      "Shen, Yuming",
      "Shen, Ziyi",
      "Wang, Menghan",
      "Qin, Jie",
      "Torr, Philip",
      "Shao, Ling"
    ]
  },
  {
    "id": "e97a4f04ef1b914f6a1698caa364f693",
    "title": "Dynamic COVID risk assessment accounting for community virus exposure from a spatial-temporal transmission model",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e97a4f04ef1b914f6a1698caa364f693-Paper.pdf",
    "abstract": "COVID-19 pandemic has caused unprecedented negative impacts on our society, including further exposing inequity and disparity in public health. To study the impact of socioeconomic factors on COVID transmission, we first propose a spatial-temporal model to examine the socioeconomic heterogeneity and spatial correlation of COVID-19 transmission at the community level. Second, to assess the individual risk of severe COVID-19 outcomes after a positive diagnosis, we propose a dynamic, varying-coefficient model that integrates individual-level risk factors from electronic health records (EHRs) with community-level risk factors. The underlying neighborhood prevalence of infections (both symptomatic and pre-symptomatic) predicted from the previous spatial-temporal model is included in the individual risk assessment so as to better capture the background risk of virus exposure for each individual. We design a weighting scheme to mitigate multiple selection biases inherited in EHRs of COVID patients. We analyze COVID transmission data in New York City (NYC, the epicenter of the first surge in the United States) and EHRs from NYC hospitals, where time-varying effects of community risk factors and significant interactions between individual- and community-level risk factors are detected. By examining the socioeconomic disparity of infection risks and interaction among the risk factors, our methods can assist public health decision-making and facilitate better clinical management of COVID patients.",
    "authors": [
      "Chen, Yuan",
      "Fei, Wenbo",
      "Wang, Qinxia",
      "Zeng, Donglin",
      "Wang, Yuanjia"
    ]
  },
  {
    "id": "e97ee2054defb209c35fe4dc94599061",
    "title": "Dueling Bandits with Adversarial Sleeping",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e97ee2054defb209c35fe4dc94599061-Paper.pdf",
    "abstract": "We introduce the problem of sleeping dueling bandits with stochastic preferences and adversarial availabilities (DB-SPAA). In almost all dueling bandit applications, the decision space often changes over time; eg, retail store management, online shopping, restaurant recommendation, search engine optimization, etc. Surprisingly, this `sleeping aspect' of dueling bandits has never been studied in the literature. Like dueling bandits, the goal is to compete with the best arm by sequentially querying the preference feedback of item pairs. The non-triviality however results due to the non-stationary item spaces that allow any arbitrary subsets items to go unavailable every round. The goal is to find an optimal `no-regret policy that can identify the best available item at each round, as opposed to the standard `fixed best-arm regret objective' of dueling bandits. We first derive an instance-specific lower bound for DB-SPAA $\\Omega( \\sum_{i =1}^{K-1}\\sum_{j=i+1}^K \\frac{\\log T}{\\Delta(i,j)})$, where $K$ is the number of items and $\\Delta(i,j)$ is the gap between items $i$ and $j$. This indicates that the sleeping problem with preference feedback is inherently more difficult than that for classical multi-armed bandits (MAB).  We then propose two algorithms, with near optimal regret guarantees. Our results are corroborated empirically.",
    "authors": [
      "Saha, Aadirupa",
      "Gaillard, Pierre"
    ]
  },
  {
    "id": "e987eff4a7c7b7e580d659feb6f60c1a",
    "title": "Beware of the Simulated DAG! Causal Discovery Benchmarks May Be Easy to Game",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e987eff4a7c7b7e580d659feb6f60c1a-Paper.pdf",
    "abstract": "Simulated DAG models may exhibit properties that, perhaps inadvertently, render their structure identifiable and unexpectedly affect structure learning algorithms. Here, we show that marginal variance tends to increase along the causal order for generically sampled additive noise models. We introduce varsortability as a measure of the agreement between the order of increasing marginal variance and the causal order. For commonly sampled graphs and model parameters, we show that the remarkable performance of some continuous structure learning algorithms can be explained by high varsortability and matched by a simple baseline method. Yet, this performance may not transfer to real-world data where varsortability may be moderate or dependent on the choice of measurement scales. On standardized data, the same algorithms fail to identify the ground-truth DAG or its Markov equivalence class. While standardization removes the pattern in marginal variance, we show that data generating processes that incur high varsortability also leave a distinct covariance pattern that may be exploited even after standardization. Our findings challenge the significance of generic benchmarks with independently drawn parameters. The code is available at https://github.com/Scriddie/Varsortability.",
    "authors": [
      "Reisach, Alexander",
      "Seiler, Christof",
      "Weichwald, Sebastian"
    ]
  },
  {
    "id": "e995f98d56967d946471af29d7bf99f1",
    "title": "Automated Dynamic Mechanism Design",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e995f98d56967d946471af29d7bf99f1-Paper.pdf",
    "abstract": "We study Bayesian automated mechanism design in unstructured dynamic environments, where a principal repeatedly interacts with an agent, and takes actions based on the strategic agent's report of the current state of the world.  Both the principal and the agent can have arbitrary and potentially different valuations for the actions taken, possibly also depending on the actual state of the world.  Moreover, at any time, the state of the world may evolve arbitrarily depending on the action taken by the principal.  The goal is to compute an optimal mechanism which maximizes the principal's utility in the face of the self-interested strategic agent.We give an efficient algorithm for computing optimal mechanisms, with or without payments, under different individual-rationality constraints, when the time horizon is constant.  Our algorithm is based on a sophisticated linear program formulation, which can be customized in various ways to accommodate richer constraints.  For environments with large time horizons, we show that the principal's optimal utility is hard to approximate within a certain constant factor, complementing our algorithmic result.  These results paint a relatively complete picture for automated dynamic mechanism design in unstructured environments.  We further consider a special case of the problem where the agent is myopic, and give a refined efficient algorithm whose time complexity scales linearly in the time horizon.    In the full version of the paper, we show that memoryless mechanisms, which are without loss of generality optimal in Markov decision processes without strategic behavior, do not provide a good solution for our problem, in terms of both optimality and computational tractability.  Moreover, we present experimental results where our algorithms are applied to synthetic dynamic environments with different characteristics, which not only serve as a proof of concept for our algorithms, but also exhibit intriguing phenomena in dynamic mechanism design.",
    "authors": [
      "Zhang, Hanrui",
      "Conitzer, Vincent"
    ]
  },
  {
    "id": "e9dcb63ca828d0e00cd05b445099ed2e",
    "title": "A generative nonparametric Bayesian model for whole genomes",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e9dcb63ca828d0e00cd05b445099ed2e-Paper.pdf",
    "abstract": "Generative probabilistic modeling of biological sequences has widespread existing and potential use across biology and biomedicine, particularly given advances in high-throughput sequencing, synthesis and editing. However, we still lack methods with nucleotide resolution that are tractable at the scale of whole genomes and that can achieve high predictive accuracy in theory and practice. In this article we propose a new generative sequence model, the Bayesian embedded autoregressive (BEAR) model, which uses a parametric autoregressive model to specify a conjugate prior over a nonparametric Bayesian Markov model. We explore, theoretically and empirically, applications of BEAR models to a variety of statistical problems including density estimation, robust parameter estimation, goodness-of-fit tests, and two-sample tests. We prove rigorous asymptotic consistency results including nonparametric posterior concentration rates. We scale inference in BEAR models to datasets containing tens of billions of nucleotides. On genomic, transcriptomic, and metagenomic sequence data we show that BEAR models provide large increases in predictive performance as compared to parametric autoregressive models, among other results. BEAR models offer a flexible and scalable framework, with theoretical guarantees, for building and critiquing generative models at the whole genome scale.",
    "authors": [
      "Amin, Alan",
      "Weinstein, Eli N",
      "Marks, Debora"
    ]
  },
  {
    "id": "e9f85782949743dcc42079e629332b5f",
    "title": "Robust Predictable Control",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e9f85782949743dcc42079e629332b5f-Paper.pdf",
    "abstract": "Many of the challenges facing today's reinforcement learning (RL) algorithms, such as robustness, generalization, transfer, and computational efficiency are closely related to compression.  Prior work has convincingly argued why minimizing information is useful in the supervised learning setting, but standard RL algorithms lack an explicit mechanism for compression. The RL setting is unique because (1) its sequential nature allows an agent to use past information to avoid looking at future observations and (2) the agent can optimize its behavior to prefer states where decision making requires few bits. We take advantage of these properties to propose a method (RPC) for learning simple policies. This method brings together ideas from information bottlenecks, model-based RL, and bits-back coding into a simple and theoretically-justified algorithm. Our method jointly optimizes a latent-space model and policy to be self-consistent, such that the policy avoids states where the model is inaccurate. We demonstrate that our method achieves much tighter compression than prior methods, achieving up to 5$\\times$ higher reward than a standard information bottleneck when constrained to use just 0.3 bits per observation. We also demonstrate that our method learns policies that are more robust and generalize better to new tasks.",
    "authors": [
      "Eysenbach, Ben",
      "Salakhutdinov, Russ R.",
      "Levine, Sergey"
    ]
  },
  {
    "id": "ea159dc9788ffac311592613b7f71fbb",
    "title": "Unsupervised Speech Recognition",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ea159dc9788ffac311592613b7f71fbb-Paper.pdf",
    "abstract": "Despite rapid progress in the recent past, current speech recognition systems still require labeled training data which limits this technology to a small fraction of the languages spoken around the globe. This paper describes wav2vec-U, short for wav2vec Unsupervised, a method to train speech recognition models without any labeled data. We leverage self-supervised speech representations to segment unlabeled audio and learn a mapping from these representations to phonemes via adversarial training. The right representations are key to the success of our method. Compared to the best previous unsupervised work, wav2vec-U reduces the phone error rate on the TIMIT benchmark from 26.1 to 11.3. On the larger English Librispeech benchmark, wav2vec-U achieves a word error rate of 5.9 on test-other, rivaling some of the best published systems trained on 960 hours of labeled data from only two years ago. We also experiment on nine other languages, including low-resource languages such as Kyrgyz, Swahili and Tatar.",
    "authors": [
      "Baevski, Alexei",
      "Hsu, Wei-Ning",
      "CONNEAU, Alexis",
      "Auli, Michael"
    ]
  },
  {
    "id": "ea4c796cccfc3899b5f9ae2874237c20",
    "title": "Robustness between the worst and average case",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ea4c796cccfc3899b5f9ae2874237c20-Paper.pdf",
    "abstract": "Several recent works in machine learning have focused on evaluating the test-time robustness of a classifier: how well the classifier performs not just on the target domain it was trained upon, but upon perturbed examples.  In these settings, the focus has largely been on two extremes of robustness: the robustness to perturbations drawn at random from within some distribution (i.e., robustness to random perturbations), and the robustness to the worst case perturbation in some set (i.e., adversarial robustness).  In this paper, we argue that a sliding scale between these two extremes provides a valuable additional metric by which to gauge robustness. Specifically, we illustrate that each of these two extremes is naturally characterized by a (functional) q-norm over perturbation space, with q=1 corresponding to robustness to random perturbations and q=\\infty corresponding to adversarial perturbations.  We then present the main technical contribution of our paper: a method for efficiently estimating the value of these norms by interpreting them as the partition function of a particular distribution, then using path sampling with MCMC methods to estimate this partition function (either traditional Metropolis-Hastings for non-differentiable perturbations, or Hamiltonian Monte Carlo for differentiable perturbations).  We show that our approach provides substantially better estimates than simple random sampling of the actual \u201cintermediate-q\u201d robustness of both standard, data-augmented, and adversarially-trained classifiers, illustrating a clear tradeoff between classifiers that optimize different metrics. Code for reproducing experiments can be found at https://github.com/locuslab/intermediate_robustness.",
    "authors": [
      "Rice, Leslie",
      "Bair, Anna",
      "Zhang, Huan",
      "Kolter, J. Zico"
    ]
  },
  {
    "id": "ea6979872125d5acbac6068f186a0359",
    "title": "Online Learning and Control of Complex Dynamical Systems from Sensory Input",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ea6979872125d5acbac6068f186a0359-Paper.pdf",
    "abstract": "Identifying an effective model of a dynamical system from sensory data and using it for future state prediction and control is challenging. Recent data-driven algorithms based on Koopman theory are a promising approach to this problem, but they typically never update the model once it has been identified from a relatively small set of observation, thus making long-term prediction and control difficult for realistic systems, in robotics or fluid mechanics for example. This paper introduces a novel method for learning an embedding of the state space with linear dynamics from sensory data. Unlike previous approaches, the dynamics model can be updated online and thus easily applied to systems with non-linear dynamics in the original configuration space.  The proposed approach is evaluated empirically on several classical dynamical systems and sensory modalities, with good performance on long-term prediction and control.",
    "authors": [
      "Bounou, Oumayma",
      "Ponce, Jean",
      "Carpentier, Justin"
    ]
  },
  {
    "id": "ea96efc03b9a050d895110db8c4af057",
    "title": "Self-Supervised Bug Detection and Repair",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ea96efc03b9a050d895110db8c4af057-Paper.pdf",
    "abstract": "Machine learning-based program analyses have recently shown the promise of integrating formal and probabilistic reasoning towards aiding software development. However, in the absence of large annotated corpora, training these analyses is challenging. Towards addressing this, we present BugLab, an approach for self-supervised learning of bug detection and repair.  BugLab co-trains two models: (1) a detector model that learns to detect and repair bugs in code, (2) a selector model that learns to create buggy code for the detector to use as training data. A Python implementation of BugLab improves by 30% upon baseline methods on a test dataset of 2374 real-life bugs and finds 19 previously unknown bugs in open-source software.",
    "authors": [
      "Allamanis, Miltiadis",
      "Jackson-Flux, Henry",
      "Brockschmidt, Marc"
    ]
  },
  {
    "id": "eaa1da31f7991743d18dadcf5fd1336f",
    "title": "Faster Neural Network Training with Approximate Tensor Operations",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/eaa1da31f7991743d18dadcf5fd1336f-Paper.pdf",
    "abstract": "We propose a novel technique for faster deep neural network training which systematically applies sample-based approximation to the constituent tensor operations, i.e., matrix multiplications and convolutions. We introduce new sampling techniques, study their theoretical properties, and prove that they provide the same convergence guarantees when applied to SGD training. We apply approximate tensor operations to single and multi-node training of MLP and CNN networks on MNIST, CIFAR-10 and ImageNet datasets. We demonstrate up to 66% reduction in the amount of computations and communication, and up to 1.37x faster training time while maintaining negligible or no impact on the final test accuracy.",
    "authors": [
      "Adelman, Menachem",
      "Levy, Kfir",
      "Hakimi, Ido",
      "Silberstein, Mark"
    ]
  },
  {
    "id": "eaa32c96f620053cf442ad32258076b9",
    "title": "Learning Interpretable Decision Rule Sets: A Submodular Optimization Approach",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/eaa32c96f620053cf442ad32258076b9-Paper.pdf",
    "abstract": "Rule sets are highly interpretable logical models in which the predicates for decision are expressed in disjunctive normal form (DNF, OR-of-ANDs), or, equivalently, the overall model comprises an unordered collection of if-then decision rules. In this paper, we consider a submodular optimization based approach for learning rule sets. The learning problem is framed as a subset selection task in which a subset of all possible rules needs to be selected to form an accurate and interpretable rule set. We employ an objective function that exhibits submodularity and thus is amenable to submodular optimization techniques. To overcome the difficulty arose from dealing with the exponential-sized ground set of rules, the subproblem of searching a rule is casted as another subset selection task that asks for a subset of features. We show it is possible to write the induced objective function for the subproblem as a difference of two submodular (DS) functions to make it approximately solvable by DS optimization algorithms. Overall, the proposed approach is simple, scalable, and likely to be benefited from further research on submodular optimization. Experiments on real datasets demonstrate the effectiveness of our method.",
    "authors": [
      "Yang, Fan",
      "He, Kai",
      "Yang, Linxiao",
      "Du, Hongxia",
      "Yang, Jingbang",
      "Yang, Bo",
      "Sun, Liang"
    ]
  },
  {
    "id": "ead81fe8cfe9fda9e4c2093e17e4d024",
    "title": "Spatial-Temporal Super-Resolution of Satellite Imagery via Conditional Pixel Synthesis",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ead81fe8cfe9fda9e4c2093e17e4d024-Paper.pdf",
    "abstract": "High-resolution satellite imagery has proven useful for a broad range of tasks, including measurement of global human population, local economic livelihoods, and biodiversity, among many others. Unfortunately, high-resolution imagery is both infrequently collected and expensive to purchase, making it hard to efficiently and effectively scale these downstream tasks over both time and space. We propose a new conditional pixel synthesis model that uses abundant, low-cost, low-resolution imagery to generate accurate high-resolution imagery at locations and times in which it is unavailable. We show that our model attains photo-realistic sample quality and outperforms competing baselines on a key downstream task \u2013 object counting \u2013 particularly in geographic locations where conditions on the ground are changing rapidly.",
    "authors": [
      "He, Yutong",
      "Wang, Dingjie",
      "Lai, Nicholas",
      "Zhang, William",
      "Meng, Chenlin",
      "Burke, Marshall",
      "Lobell, David",
      "Ermon, Stefano"
    ]
  },
  {
    "id": "eae15aabaa768ae4a5993a8a4f4fa6e4",
    "title": "On Memorization in Probabilistic Deep Generative Models",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/eae15aabaa768ae4a5993a8a4f4fa6e4-Paper.pdf",
    "abstract": "Recent advances in deep generative models have led to impressive results in a variety of application domains. Motivated by the possibility that deep learning models might memorize part of the input data, there have been increased efforts to understand how memorization arises. In this work, we extend a recently proposed measure of memorization for supervised learning (Feldman, 2019) to the unsupervised density estimation problem and adapt it to be more computationally efficient. Next, we present a study that demonstrates how memorization can occur in probabilistic deep generative models such as variational autoencoders. This reveals that the form of memorization to which these models are susceptible differs fundamentally from mode collapse and overfitting. Furthermore, we show that the proposed memorization score measures a phenomenon that is not captured by commonly-used nearest neighbor tests. Finally, we discuss several strategies that can be used to limit memorization in practice. Our work thus provides a framework for understanding problematic memorization in probabilistic generative models.",
    "authors": [
      "van den Burg, Gerrit",
      "Williams, Chris"
    ]
  },
  {
    "id": "eaf76caaba574ebf8e825f321c14ba29",
    "title": "You Are the Best Reviewer of Your Own Papers: An Owner-Assisted Scoring Mechanism",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/eaf76caaba574ebf8e825f321c14ba29-Paper.pdf",
    "abstract": "I consider the setting where reviewers offer very noisy scores for a number of items for the selection of high-quality ones (e.g., peer review of large conference proceedings) whereas the owner of these items knows the true underlying scores but prefers not to provide this information. To address this withholding of information, in this paper, I introduce the Isotonic Mechanism, a simple and efficient approach to improving on the imprecise raw scores by leveraging certain information that the owner is incentivized to provide. This mechanism takes as input the ranking of the items from best to worst provided by the owner, in addition to the raw scores provided by the reviewers. It reports adjusted scores for the items by solving a convex optimization problem. Under certain conditions, I show that the owner's optimal strategy is to honestly report the true ranking of the items to her best knowledge in order to maximize the expected utility. Moreover, I prove that the adjusted scores provided by this owner-assisted mechanism are indeed significantly moreaccurate than the raw scores provided by the reviewers. This paper concludes with several extensions of the Isotonic Mechanism and some refinements of the mechanism for practical considerations.",
    "authors": [
      "Su, Weijie"
    ]
  },
  {
    "id": "eb160de1de89d9058fcb0b968dbbbd68",
    "title": "Garment4D: Garment Reconstruction from Point Cloud Sequences",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/eb160de1de89d9058fcb0b968dbbbd68-Paper.pdf",
    "abstract": "Learning to reconstruct 3D garments is important for dressing 3D human bodies of different shapes in different poses. Previous works typically rely on 2D images as input, which however suffer from the scale and pose ambiguities. To circumvent the problems caused by 2D images, we propose a principled framework, Garment4D, that uses 3D point cloud sequences of dressed humans for garment reconstruction. Garment4D has three dedicated steps: sequential garments registration, canonical garment estimation, and posed garment reconstruction. The main challenges are two-fold: 1) effective 3D feature learning for fine details, and 2) capture of garment dynamics caused by the interaction between garments and the human body, especially for loose garments like skirts. To unravel these problems, we introduce a novel Proposal-Guided Hierarchical Feature Network and Iterative Graph Convolution Network, which integrate both high-level semantic features and low-level geometric features for fine details reconstruction. Furthermore, we propose a Temporal Transformer for smooth garment motions capture. Unlike non-parametric methods, the reconstructed garment meshes by our method are separable from the human body and have strong interpretability, which is desirable for downstream tasks. As the first attempt at this task, high-quality reconstruction results are qualitatively and quantitatively illustrated through extensive experiments. Codes are available at https://github.com/hongfz16/Garment4D.",
    "authors": [
      "Hong, Fangzhou",
      "Pan, Liang",
      "Cai, Zhongang",
      "Liu, Ziwei"
    ]
  },
  {
    "id": "eb1848290d5a7de9c9ccabc67fefa211",
    "title": "Fast Policy Extragradient Methods for Competitive Games with Entropy Regularization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/eb1848290d5a7de9c9ccabc67fefa211-Paper.pdf",
    "abstract": "This paper investigates the problem of computing the equilibrium of competitive games, which is often modeled as a constrained saddle-point optimization problem with probability simplex constraints. Despite recent efforts in understanding the last-iterate convergence of extragradient methods in the unconstrained setting, the theoretical underpinnings of these methods in the constrained settings, especially those using multiplicative updates, remain highly inadequate, even when the objective function is bilinear. Motivated by the algorithmic role of entropy regularization in single-agent reinforcement learning and game theory, we develop provably efficient extragradient methods to find the quantal response equilibrium (QRE)---which are solutions to zero-sum two-player matrix games with entropy regularization---at a linear rate. The proposed algorithms can be implemented in a decentralized manner, where each player executes symmetric and multiplicative updates iteratively using its own payoff without observing the opponent's actions directly.  In addition, by controlling the knob of entropy regularization, the proposed algorithms can locate an approximate Nash equilibrium of the unregularized matrix game at a sublinear rate without assuming the Nash equilibrium to be unique. Our methods also lead to efficient policy extragradient algorithms for solving entropy-regularized zero-sum Markov games at a linear rate. All of our convergence rates are nearly dimension-free, which are independent of the size of the state and action spaces up to logarithm factors, highlighting the positive role of entropy regularization for accelerating convergence.",
    "authors": [
      "Cen, Shicong",
      "Wei, Yuting",
      "Chi, Yuejie"
    ]
  },
  {
    "id": "eb55e369affa90f77dd7dc9e2cd33b16",
    "title": "Shift-Robust GNNs: Overcoming the Limitations of Localized Graph Training data",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/eb55e369affa90f77dd7dc9e2cd33b16-Paper.pdf",
    "abstract": "There has been a recent surge of interest in designing Graph Neural Networks (GNNs) for semi-supervised learning tasks. Unfortunately this work has assumed that the nodes labeled for use in training were selected uniformly at random (i.e. are an IID sample). However in many real world scenarios gathering labels for graph nodes is both expensive and inherently biased -- so this assumption can not be met. GNNs can suffer poor generalization when this occurs, by overfitting to superfluous regularities present in the training data. In this work we present a method, Shift-Robust GNN (SR-GNN), designed to account for distributional differences between biased training data and the graph's true inference distribution. SR-GNN adapts GNN models for the presence of distributional shifts between the nodes which have had labels provided for training and the rest of the dataset. We illustrate the effectiveness of SR-GNN in a variety of experiments with biased training datasets on common GNN benchmark datasets for semi-supervised learning, where we see that SR-GNN outperforms other GNN baselines by accuracy, eliminating at least (~40%) of the negative effects introduced by biased training data. On the largest dataset we consider, ogb-arxiv, we observe an 2% absolute improvement over the baseline and reduce 30% of the negative effects.",
    "authors": [
      "Zhu, Qi",
      "Ponomareva, Natalia",
      "Han, Jiawei",
      "Perozzi, Bryan"
    ]
  },
  {
    "id": "eb86d510361fc23b59f18c1bc9802cc6",
    "title": "RIM: Reliable Influence-based Active Learning on Graphs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/eb86d510361fc23b59f18c1bc9802cc6-Paper.pdf",
    "abstract": "Message passing is the core of most graph models such as Graph Convolutional Network (GCN) and Label Propagation (LP), which usually require a large number of clean labeled data to smooth out the neighborhood over the graph. However, the labeling process can be tedious, costly, and error-prone in practice. In this paper, we propose to unify active learning (AL) and message passing towards minimizing labeling costs, e.g., making use of few and unreliable labels that can be obtained cheaply. We make two contributions towards that end. First, we open up a perspective by drawing a connection between AL enforcing message passing and social influence maximization, ensuring that the selected samples effectively improve the model performance. Second, we propose an extension to the influence model that incorporates an explicit quality factor to model label noise. In this way, we derive a fundamentally new AL selection criterion for GCN and LP--reliable influence maximization (RIM)--by considering quantity and quality of influence simultaneously. Empirical studies on public datasets show that RIM significantly outperforms current AL methods in terms of accuracy and efficiency. ",
    "authors": [
      "Zhang, Wentao",
      "Wang, Yexin",
      "You, Zhenbang",
      "Cao, Meng",
      "Huang, Ping",
      "Shan, Jiulong",
      "Yang, Zhi",
      "CUI, Bin"
    ]
  },
  {
    "id": "ebb71045453f38676c40deb9864f811d",
    "title": "Dynamical Wasserstein Barycenters for Time-series Modeling",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ebb71045453f38676c40deb9864f811d-Paper.pdf",
    "abstract": "Many time series can be modeled as a sequence of segments representing high-level discrete states, such as running and walking in a human activity application. Flexible models should describe the system state and observations in stationary ``pure-state'' periods as well as transition periods between adjacent segments, such as a gradual slowdown between running and walking. However, most prior work assumes instantaneous transitions between pure discrete states. We propose a dynamical Wasserstein barycentric (DWB) model that estimates the system state over time as well as the data-generating distributions of pure states in an unsupervised manner. Our model assumes each pure state generates data from a multivariate normal distribution, and characterizes transitions between states via displacement-interpolation specified by the Wasserstein barycenter. The system state is represented by a barycentric weight vector which evolves over time via a random walk on the simplex. Parameter learning leverages the natural Riemannian geometry of Gaussian distributions under the Wasserstein distance, which leads to improved convergence speeds. Experiments on several human activity datasets show that our proposed DWB model accurately learns the generating distribution of pure states while improving state estimation for transition periods compared to the commonly used linear interpolation mixture models.",
    "authors": [
      "Cheng, Kevin",
      "Aeron, Shuchin",
      "Hughes, Michael C.",
      "Miller, Eric L"
    ]
  },
  {
    "id": "ebbdfea212e3a756a1fded7b35578525",
    "title": "RelaySum for Decentralized Deep Learning on Heterogeneous Data",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ebbdfea212e3a756a1fded7b35578525-Paper.pdf",
    "abstract": "In decentralized machine learning, workers compute model updates on their local data.Because the workers only communicate with few neighbors without central coordination, these updates propagate progressively over the network.This paradigm enables distributed training on networks without all-to-all connectivity, helping to protect data privacy as well as to reduce the communication cost of distributed training in data centers.A key challenge, primarily in decentralized deep learning, remains the handling of differences between the workers' local data distributions.To tackle this challenge, we introduce the RelaySum mechanism for information propagation in decentralized learning.RelaySum uses spanning trees to distribute information exactly uniformly across all workers with finite delays depending on the distance between nodes.In contrast, the typical gossip averaging mechanism only distributes data uniformly asymptotically while using the same communication volume per step as RelaySum.We prove that RelaySGD, based on this mechanism, is independent of data heterogeneity and scales to many workers, enabling highly accurate decentralized deep learning on heterogeneous data.",
    "authors": [
      "Vogels, Thijs",
      "He, Lie",
      "Koloskova, Anastasiia",
      "Karimireddy, Sai Praneeth",
      "Lin, Tao",
      "Stich, Sebastian U.",
      "Jaggi, Martin"
    ]
  },
  {
    "id": "ec0f40c389aeef789ce03eb814facc6c",
    "title": "Transformers Generalize DeepSets and Can be Extended to Graphs & Hypergraphs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ec0f40c389aeef789ce03eb814facc6c-Paper.pdf",
    "abstract": "We present a generalization of Transformers to any-order permutation invariant data (sets, graphs, and hypergraphs). We begin by observing that Transformers generalize DeepSets, or first-order (set-input) permutation invariant MLPs. Then, based on recently characterized higher-order invariant MLPs, we extend the concept of self-attention to higher orders and propose higher-order Transformers for order-$k$ data ($k=2$ for graphs and $k>2$ for hypergraphs). Unfortunately, higher-order Transformers turn out to have prohibitive complexity $\\mathcal{O}(n^{2k})$ to the number of input nodes $n$. To address this problem, we present sparse higher-order Transformers that have quadratic complexity to the number of input hyperedges, and further adopt the kernel attention approach to reduce the complexity to linear. In particular, we show that the sparse second-order Transformers with kernel attention are theoretically more expressive than message passing operations while having an asymptotically identical complexity. Our models achieve significant performance improvement over invariant MLPs and message-passing graph neural networks in large-scale graph regression and set-to-(hyper)graph prediction tasks. Our implementation is available at https://github.com/jw9730/hot.",
    "authors": [
      "Kim, Jinwoo",
      "Oh, Saeyoon",
      "Hong, Seunghoon"
    ]
  },
  {
    "id": "ec1f764517b7ffb52057af6df18142b7",
    "title": "No Regrets for Learning the Prior in Bandits",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ec1f764517b7ffb52057af6df18142b7-Paper.pdf",
    "abstract": "We propose AdaTS, a Thompson sampling algorithm that adapts sequentially to bandit tasks that it interacts with. The key idea in AdaTS is to adapt to an unknown task prior distribution by maintaining a distribution over its parameters. When solving a bandit task, that uncertainty is marginalized out and properly accounted for. AdaTS is a fully-Bayesian algorithm that can be implemented efficiently in several classes of bandit problems. We derive upper bounds on its Bayes regret that quantify the loss due to not knowing the task prior, and show that it is small. Our theory is supported by experiments, where AdaTS outperforms prior algorithms and works well even in challenging real-world problems.",
    "authors": [
      "Basu, Soumya",
      "Kveton, Branislav",
      "Zaheer, Manzil",
      "Szepesvari, Csaba"
    ]
  },
  {
    "id": "ec20019911a77ad39d023710be68aaa1",
    "title": "Encoding Robustness to Image Style via Adversarial Feature Perturbations",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ec20019911a77ad39d023710be68aaa1-Paper.pdf",
    "abstract": "Adversarial training is the industry standard for producing models that are robust to small adversarial perturbations.  However, machine learning practitioners need models that are robust to other kinds of changes that occur naturally, such as changes in the style or illumination of input images. Such changes in input distribution have been effectively modeled as shifts in the mean and variance of deep image features. We adapt adversarial training by directly perturbing feature statistics, rather than image pixels, to produce models that are robust to various unseen distributional shifts. We explore the relationship between these perturbations and distributional shifts by visualizing adversarial features. Our proposed method, Adversarial Batch Normalization (AdvBN), is a single network layer that generates worst-case feature perturbations during training. By fine-tuning neural networks on adversarial feature distributions, we observe improved robustness of networks to various unseen distributional shifts, including style variations and image corruptions. In addition, we show that our proposed adversarial feature perturbation can be complementary to existing image space data augmentation methods, leading to improved performance. The source code and pre-trained models are released at \\url{https://github.com/azshue/AdvBN}.",
    "authors": [
      "Shu, Manli",
      "Wu, Zuxuan",
      "Goldblum, Micah",
      "Goldstein, Tom"
    ]
  },
  {
    "id": "ec26fc2eb2b75aece19c70392dc744c2",
    "title": "Continuized Accelerations of Deterministic and Stochastic Gradient Descents, and of Gossip Algorithms",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ec26fc2eb2b75aece19c70392dc744c2-Paper.pdf",
    "abstract": "We introduce the ``continuized'' Nesterov acceleration, a close variant of Nesterov acceleration whose variables are indexed by a continuous time parameter. The two variables continuously mix following a linear ordinary differential equation and take gradient steps at random times. This continuized variant benefits from the best of the continuous and the discrete frameworks: as a continuous process, one can use differential calculus to analyze convergence and obtain analytical expressions for the parameters; but a discretization of the continuized process can be computed exactly with convergence rates similar to those of Nesterov original acceleration. We show that the discretization has the same structure as Nesterov acceleration, but with random parameters. We provide continuized Nesterov acceleration under deterministic as well as stochastic gradients, with either additive or multiplicative noise.  Finally, using our continuized framework and expressing the gossip averaging problem as the stochastic minimization of a certain energy function, we provide the first rigorous acceleration of asynchronous gossip algorithms.",
    "authors": [
      "Even, Mathieu",
      "Berthier, Rapha\u00ebl",
      "Bach, Francis",
      "Flammarion, Nicolas",
      "Hendrikx, Hadrien",
      "Gaillard, Pierre",
      "Massouli\u00e9, Laurent",
      "Taylor, Adrien"
    ]
  },
  {
    "id": "ec5aa0b7846082a2415f0902f0da88f2",
    "title": "Natural continual learning: success is a journey, not (just) a destination",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ec5aa0b7846082a2415f0902f0da88f2-Paper.pdf",
    "abstract": "Biological agents are known to learn many different tasks over the course of their lives, and to be able to revisit previous tasks and behaviors with little to no loss in performance. In contrast, artificial agents are prone to \u2018catastrophic forgetting\u2019 whereby performance on previous tasks deteriorates rapidly as new ones are acquired. This shortcoming has recently been addressed using methods that encourage parameters to stay close to those used for previous tasks. This can be done by (i) using specific parameter regularizers that map out suitable destinations in parameter space, or (ii) guiding the optimization journey by projecting gradients into subspaces that do not interfere with previous tasks. However, these methods often exhibit subpar performance in both feedforward and recurrent neural networks, with recurrent networks being of interest to the study of neural dynamics supporting biological continual learning. In this work, we propose Natural Continual Learning (NCL), a new method that unifies weight regularization and projected gradient descent. NCL uses Bayesian weight regularization to encourage good performance on all tasks at convergence and combines this with gradient projection using the prior precision, which prevents catastrophic forgetting during optimization. Our method outperforms both standard weight regularization techniques and projection based approaches when applied to continual learning problems in feedforward and recurrent networks. Finally, the trained networks evolve task-specific dynamics that are strongly preserved as new tasks are learned, similar to experimental findings in biological circuits.",
    "authors": [
      "Kao, Ta-Chu",
      "Jensen, Kristopher",
      "van de Ven, Gido",
      "Bernacchia, Alberto",
      "Hennequin, Guillaume"
    ]
  },
  {
    "id": "ec7f346604f518906d35ef0492709f78",
    "title": "Individual Privacy Accounting via a R\u00e9nyi Filter",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ec7f346604f518906d35ef0492709f78-Paper.pdf",
    "abstract": "We consider a sequential setting in which a single dataset of individuals is used to perform adaptively-chosen analyses, while ensuring that the differential privacy loss of each participant does not exceed a pre-specified privacy budget. The standard approach to this problem relies on bounding a worst-case estimate of the privacy loss over all individuals and all possible values of their data, for every single analysis. Yet, in many scenarios this approach is overly conservative, especially for \"typical\" data points which incur little privacy loss by participation in most of the analyses. In this work, we give a method for tighter privacy loss accounting based on the value of a personalized privacy loss estimate for each individual in each analysis. To implement the accounting method we design a filter for R\u00e9nyi differential privacy. A filter is a tool that ensures that the privacy parameter of a composed sequence of algorithms with adaptively-chosen privacy parameters does not exceed a pre-specified budget. Our filter is simpler and tighter than the known filter for $(\\epsilon,\\delta)$-differential privacy by Rogers et al. (2016). We apply our results to the analysis of noisy gradient descent and show that personalized accounting can be practical, easy to implement, and can only make the privacy-utility tradeoff tighter.",
    "authors": [
      "Feldman, Vitaly",
      "Zrnic, Tijana"
    ]
  },
  {
    "id": "ec8956637a99787bd197eacd77acce5e",
    "title": "Post-Training Quantization for Vision Transformer",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ec8956637a99787bd197eacd77acce5e-Paper.pdf",
    "abstract": "Recently, transformer has achieved remarkable performance on a variety of computer vision applications. Compared with mainstream convolutional neural networks, vision transformers are often of sophisticated architectures for extracting powerful feature representations, which are more difficult to be developed on mobile devices. In this paper, we present an effective post-training quantization algorithm for reducing the memory storage and computational costs of vision transformers. Basically, the quantization task can be regarded as finding the optimal low-bit quantization intervals for weights and inputs, respectively. To preserve the functionality of the attention mechanism, we introduce a ranking loss into the conventional quantization objective that aims to keep the relative order of the self-attention results after quantization. Moreover, we thoroughly analyze the relationship between quantization loss of different layers and the feature diversity, and explore a mixed-precision quantization scheme by exploiting the nuclear norm of each attention map and output feature. The effectiveness of the proposed method is verified on several benchmark models and datasets, which outperforms the state-of-the-art post-training quantization algorithms. For instance, we can obtain an 81.29% top-1 accuracy using DeiT-B model on ImageNet dataset with about 8-bit quantization. Code will be available at https://gitee.com/mindspore/models/tree/master/research/cv/VT-PTQ. ",
    "authors": [
      "Liu, Zhenhua",
      "Wang, Yunhe",
      "Han, Kai",
      "Zhang, Wei",
      "Ma, Siwei",
      "Gao, Wen"
    ]
  },
  {
    "id": "ec8ce6abb3e952a85b8551ba726a1227",
    "title": "Unsupervised Part Discovery from Contrastive Reconstruction",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ec8ce6abb3e952a85b8551ba726a1227-Paper.pdf",
    "abstract": "The goal of self-supervised visual representation learning is to learn strong, transferable image representations, with the majority of research focusing on object or scene level. On the other hand, representation learning at part level has received significantly less attention. In this paper, we propose an unsupervised approach to object part discovery and segmentation and make three contributions. First, we construct a proxy task through a set of objectives that encourages the model to learn a meaningful decomposition of the image into its parts. Secondly, prior work argues for reconstructing or clustering pre-computed features as a proxy to parts; we show empirically that this alone is unlikely to find meaningful parts; mainly because of their low resolution and the tendency of classification networks to spatially smear out information. We suggest that image reconstruction at the level of pixels can alleviate this problem, acting as a complementary cue. Lastly, we show that the standard evaluation based on keypoint regression does not correlate well with segmentation quality and thus introduce different metrics, NMI and ARI, that better characterize the decomposition of objects into parts. Our method yields semantic parts which are consistent across fine-grained but visually distinct categories, outperforming the state of the art on three benchmark datasets. Code is available at the project page: https://www.robots.ox.ac.uk/~vgg/research/unsup-parts/.",
    "authors": [
      "Choudhury, Subhabrata",
      "Laina, Iro",
      "Rupprecht, Christian",
      "Vedaldi, Andrea"
    ]
  },
  {
    "id": "ecf5631507a8aedcae34cef231aa7348",
    "title": "ASSANet: An Anisotropic Separable Set Abstraction for Efficient Point Cloud Representation Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ecf5631507a8aedcae34cef231aa7348-Paper.pdf",
    "abstract": "Access to 3D point cloud representations has been widely facilitated by LiDAR sensors embedded in various mobile devices. This has led to an emerging need for fast and accurate point cloud processing techniques. In this paper, we revisit and dive deeper into PointNet++, one of the most influential yet under-explored networks, and develop faster and more accurate variants of the model. We first present a novel Separable Set Abstraction (SA) module that disentangles the vanilla SA module used in PointNet++ into two separate learning stages: (1) learning channel correlation and (2) learning spatial correlation. The Separable SA module is significantly faster than the vanilla version, yet it achieves comparable performance.  We then introduce a new Anisotropic Reduction function into our Separable SA module and propose an Anisotropic Separable SA (ASSA) module that substantially increases the network's accuracy. We later replace the vanilla SA modules in PointNet++ with the proposed ASSA modules, and denote the modified network as ASSANet. Extensive experiments on point cloud classification, semantic segmentation, and part segmentation show that ASSANet outperforms PointNet++ and other methods, achieving much higher accuracy and faster speeds. In particular, ASSANet outperforms PointNet++ by $7.4$ mIoU on S3DIS Area 5, while maintaining $1.6 \\times $ faster inference speed on a single NVIDIA 2080Ti GPU. Our scaled ASSANet variant achieves $66.8$ mIoU and outperforms KPConv, while being more than $54 \\times$ faster.",
    "authors": [
      "Qian, Guocheng",
      "Hammoud, Hasan",
      "Li, Guohao",
      "Thabet, Ali",
      "Ghanem, Bernard"
    ]
  },
  {
    "id": "ecf9902e0f61677c8de25ae60b654669",
    "title": "An Empirical Investigation of Domain Generalization with Empirical Risk Minimizers",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ecf9902e0f61677c8de25ae60b654669-Paper.pdf",
    "abstract": "Recent work demonstrates that deep neural networks trained using Empirical Risk Minimization (ERM) can generalize under distribution shift, outperforming specialized training algorithms for domain generalization. The goal of this paper is to further understand this phenomenon. In particular, we study the extent to which the seminal domain adaptation theory of Ben-David et al. (2007) explains the performance of ERMs. Perhaps surprisingly, we find that this theory does not provide a tight explanation of the out-of-domain generalization observed across a large number of ERM models trained on three popular domain generalization datasets. This motivates us to investigate other possible measures\u2014that, however, lack theory\u2014which could explain generalization in this setting. Our investigation reveals that measures relating to the Fisher information, predictive entropy, and maximum mean discrepancy are good predictors of the out-of-distribution generalization of ERM models. We hope that our work helps galvanize the community towards building a better understanding of when deep networks trained with ERM generalize out-of-distribution.",
    "authors": [
      "Vedantam, Ramakrishna",
      "Lopez-Paz, David",
      "Schwab, David J."
    ]
  },
  {
    "id": "ed277964a8959e72a0d987e598dfbe72",
    "title": "Fair Sequential Selection Using Supervised Learning Models",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ed277964a8959e72a0d987e598dfbe72-Paper.pdf",
    "abstract": "We consider a selection problem where sequentially arrived applicants apply for a limited number of positions/jobs. At each time step, a decision maker accepts or rejects the given applicant using a pre-trained supervised learning model until all the vacant positions are filled. In this paper, we discuss whether the fairness notions (e.g., equal opportunity, statistical parity, etc.) that are commonly used in classification problems are suitable for the sequential selection problems. In particular, we show that even with a pre-trained model that satisfies the common fairness notions, the selection outcomes may still be biased against certain demographic groups. This observation implies that the fairness notions used in classification problems are not suitable for a selection problem where the applicants compete for a limited number of positions.  We introduce a new fairness notion, ``Equal Selection (ES),'' suitable for sequential selection problems and propose a post-processing approach to satisfy the ES fairness notion. We also consider a setting where the applicants have privacy concerns, and the decision maker only has access to the noisy version of sensitive attributes. In this setting, we can show that the \\textit{perfect} ES fairness can still be attained under certain conditions.",
    "authors": [
      "Khalili, Mohammad Mahdi",
      "Zhang, Xueru",
      "Abroshan, Mahed"
    ]
  },
  {
    "id": "ed46558a56a4a26b96a68738a0d28273",
    "title": "Towards Sample-efficient Overparameterized Meta-learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ed46558a56a4a26b96a68738a0d28273-Paper.pdf",
    "abstract": "An overarching goal in machine learning is to build a generalizable model with few samples. To this end, overparameterization has been the subject of immense interest to explain the generalization ability of deep nets even when the size of the dataset is smaller than that of the model. While the prior literature focuses on the classical supervised setting, this paper aims to demystify overparameterization for meta-learning. Here we have a sequence of linear-regression tasks and we ask: (1) Given earlier tasks, what is the optimal linear representation of features for a new downstream task? and (2) How many samples do we need to build this representation? This work shows that surprisingly, overparameterization arises as a natural answer to these fundamental meta-learning questions. Specifically, for (1), we first show that learning the optimal representation coincides with the problem of designing a task-aware regularization to promote inductive bias. We leverage this inductive bias to explain how the downstream task actually benefits from overparameterization, in contrast to prior works on few-shot learning. For (2), we develop a theory to explain how feature covariance can implicitly help reduce the sample complexity well below the degrees of freedom and lead to small estimation error. We then integrate these findings to obtain an overall performance guarantee for our meta-learning algorithm. Numerical experiments on real and synthetic data verify our insights on overparameterized meta-learning.",
    "authors": [
      "Sun, Yue",
      "Narang, Adhyyan",
      "Gulluk, Ibrahim",
      "Oymak, Samet",
      "Fazel, Maryam"
    ]
  },
  {
    "id": "ed519c02f134f2cdd836cba387b6a3c8",
    "title": "ScaleCert: Scalable Certified Defense against Adversarial Patches with Sparse Superficial Layers",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ed519c02f134f2cdd836cba387b6a3c8-Paper.pdf",
    "abstract": "Requests for name changes in the electronic proceedings will be accepted with no questions asked.  However name changes may cause bibliographic tracking issues.  Authors are asked to consider this carefully and discuss it with their co-authors prior to requesting a name change in the electronic proceedings.",
    "authors": [
      "Han, Husheng",
      "Xu, Kaidi",
      "Hu, Xing",
      "Chen, Xiaobing",
      "LIANG, Ling",
      "Du, Zidong",
      "Guo, Qi",
      "Wang, Yanzhi",
      "Chen, Yunji"
    ]
  },
  {
    "id": "ed519dacc89b2bead3f453b0b05a4a8b",
    "title": "Towards mental time travel: a hierarchical memory for reinforcement learning agents",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ed519dacc89b2bead3f453b0b05a4a8b-Paper.pdf",
    "abstract": "Reinforcement learning agents often forget details of the past, especially after delays or distractor tasks. Agents with common memory architectures struggle to recall and integrate across multiple timesteps of a past event, or even to recall the details of a single timestep that is followed by distractor tasks. To address these limitations, we propose a Hierarchical Chunk Attention Memory (HCAM), that helps agents to remember the past in detail. HCAM stores memories by dividing the past into chunks, and recalls by first performing high-level attention over coarse summaries of the chunks, and then performing detailed attention within only the most relevant chunks. An agent with HCAM can therefore \"mentally time-travel\"--remember past events in detail without attending to all intervening events. We show that agents with HCAM substantially outperform agents with other memory architectures at tasks requiring long-term recall, retention, or reasoning over memory. These include recalling where an object is hidden in a 3D environment, rapidly learning to navigate efficiently in a new neighborhood, and rapidly learning and retaining new words. Agents with HCAM can extrapolate to task sequences much longer than they were trained on, and can even generalize zero-shot from a meta-learning setting to maintaining knowledge across episodes. HCAM improve agent sample efficiency, generalization, and generality (by solving tasks that previously required specialized architectures). Our work is a step towards agents that can learn, interact, and adapt in complex and temporally-extended environments.",
    "authors": [
      "Lampinen, Andrew",
      "Chan, Stephanie",
      "Banino, Andrea",
      "Hill, Felix"
    ]
  },
  {
    "id": "eda80a3d5b344bc40f3bc04f65b7a357",
    "title": "Beyond Tikhonov: faster learning with self-concordant losses, via iterative regularization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/eda80a3d5b344bc40f3bc04f65b7a357-Paper.pdf",
    "abstract": "The theory of spectral filtering is a remarkable tool to understand the statistical properties of learning with kernels. For least squares, it allows to derive various regularization schemes that yield faster convergence rates of the excess risk than with Tikhonov regularization. This is typically achieved by leveraging classical assumptions called source and capacity conditions, which characterize the difficulty of the learning task. In order to understand estimators derived from other loss functions, Marteau-Ferey et al. have extended the theory of Tikhonov regularization to generalized self concordant loss functions (GSC), which contain, e.g., the logistic loss. In this paper, we go a step further and show that fast and optimal rates can be achieved for GSC by using the iterated Tikhonov regularization scheme, which is intrinsically related to the proximal point method in optimization, and overcomes the limitation of the classical Tikhonov regularization.",
    "authors": [
      "Beugnot, Gaspard",
      "Mairal, Julien",
      "Rudi, Alessandro"
    ]
  },
  {
    "id": "edb446b67d69adbfe9a21068982000c2",
    "title": "Variational Bayesian Reinforcement Learning with Regret Bounds",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/edb446b67d69adbfe9a21068982000c2-Paper.pdf",
    "abstract": "We consider the exploration-exploitation trade-off in reinforcement learning and show that an agent endowed with an exponential epistemic-risk-seeking utility function explores efficiently, as measured by regret. The state-action values induced by the exponential utility satisfy a Bellman recursion, so we can use dynamic programming to compute them.  We call the resulting algorithm K-learning (for knowledge) and the risk-seeking utility ensures that the associated state-action values (K-values) are optimistic for the expected optimal Q-values under the posterior.  The exponential utility function induces a Boltzmann exploration policy for which the 'temperature' parameter is equal to the risk-seeking parameter and is carefully controlled to yield a Bayes regret bound of $\\tilde O(L^{3/2} \\sqrt{S A T})$, where $L$ is the time horizon, $S$ is the number of states, $A$ is the number of actions, and $T$ is the total number of elapsed timesteps. We conclude with a numerical example demonstrating that K-learning is competitive with other state-of-the-art algorithms in practice.",
    "authors": [
      "O'Donoghue, Brendan"
    ]
  },
  {
    "id": "edb947f2bbceb132245fdde9c59d3f59",
    "title": "Logarithmic Regret from Sublinear Hints",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/edb947f2bbceb132245fdde9c59d3f59-Paper.pdf",
    "abstract": "We consider the online linear optimization problem, where at every step the algorithm plays a point $x_t$ in the unit ball, and suffers loss $\\langle c_t, x_t \\rangle$ for some cost vector $c_t$ that is then revealed to the algorithm. Recent work showed that if an algorithm  receives a _hint_ $h_t$ that has non-trivial correlation with $c_t$ before it plays $x_t$, then it can achieve a regret guarantee of $O(\\log T)$, improving on the bound of $\\Theta(\\sqrt{T})$ in the standard setting. In this work, we study the question of whether an algorithm really requires a hint at _every_ time step. Somewhat surprisingly, we show that an algorithm can obtain $O(\\log T)$ regret with just $O(\\sqrt{T})$ hints under a natural query model; in contrast, we also show that $o(\\sqrt{T})$ hints cannot guarantee better than $\\Omega(\\sqrt{T})$ regret. We give two applications of our result, to the well-studied setting of {\\em optimistic} regret bounds, and to the problem of online learning with abstention. ",
    "authors": [
      "Bhaskara, Aditya",
      "Cutkosky, Ashok",
      "Kumar, Ravi",
      "Purohit, Manish"
    ]
  },
  {
    "id": "edc27f139c3b4e4bb29d1cdbc45663f9",
    "title": "Independent mechanism analysis, a new concept?",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/edc27f139c3b4e4bb29d1cdbc45663f9-Paper.pdf",
    "abstract": "Independent component analysis provides a principled framework for unsupervised representation learning, with solid theory on the identifiability of the latent code that generated the data, given only observations of mixtures thereof. Unfortunately, when the mixing is nonlinear, the model is provably nonidentifiable, since statistical independence alone does not sufficiently constrain the problem. Identifiability can be recovered in settings where additional, typically observed variables are included in the generative process. We investigate an alternative path and consider instead including assumptions reflecting the principle of independent causal mechanisms exploited in the field of causality. Specifically, our approach is motivated by thinking of each source as independently influencing the mixing process. This gives rise to a framework which we term independent mechanism analysis. We provide theoretical and empirical evidence that our approach circumvents a number of nonidentifiability issues arising in nonlinear blind source separation.",
    "authors": [
      "Gresele, Luigi",
      "von K\u00fcgelgen, Julius",
      "Stimper, Vincent",
      "Sch\u00f6lkopf, Bernhard",
      "Besserve, Michel"
    ]
  },
  {
    "id": "eddea82ad2755b24c4e168c5fc2ebd40",
    "title": "Momentum Centering and Asynchronous Update for Adaptive Gradient Methods",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/eddea82ad2755b24c4e168c5fc2ebd40-Paper.pdf",
    "abstract": "We propose ACProp (Asynchronous-centering-Prop), an adaptive optimizer which combines centering of second momentum and asynchronous update (e.g. for $t$-th update, denominator uses information up to step $t-1$, while numerator uses gradient at $t$-th step).  ACProp has both strong theoretical properties and empirical performance. With the example by Reddi et al. (2018), we show that asynchronous optimizers (e.g. AdaShift, ACProp) have weaker convergence condition than synchronous optimizers (e.g. Adam, RMSProp, AdaBelief); within asynchronous optimizers, we show that centering of second momentum further weakens the convergence condition. We demonstrate that ACProp has a convergence rate of $O(\\frac{1}{\\sqrt{T}})$ for the stochastic non-convex case, which matches the oracle rate and outperforms the $O(\\frac{logT}{\\sqrt{T}})$ rate of RMSProp and Adam. We validate ACProp in extensive empirical studies: ACProp outperforms both SGD and other adaptive optimizers in image classification with CNN, and outperforms well-tuned adaptive optimizers in the training of various GAN models, reinforcement learning and transformers. To sum up, ACProp has good theoretical properties including weak convergence condition and optimal convergence rate, and strong empirical performance including good generalization like SGD and training stability like Adam. We provide the implementation at \\url{ https://github.com/juntang-zhuang/ACProp-Optimizer}.",
    "authors": [
      "Zhuang, Juntang",
      "Ding, Yifan",
      "Tang, Tommy",
      "Dvornek, Nicha",
      "Tatikonda, Sekhar C",
      "Duncan, James"
    ]
  },
  {
    "id": "ede7e2b6d13a41ddf9f4bdef84fdc737",
    "title": "Robustness via Uncertainty-aware Cycle Consistency",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ede7e2b6d13a41ddf9f4bdef84fdc737-Paper.pdf",
    "abstract": "Unpaired image-to-image translation refers to learning inter-image-domain mapping without corresponding image pairs. Existing methods learn deterministic mappings without explicitly modelling the robustness to outliers or predictive uncertainty, leading to performance degradation when encountering unseen perturbations at test time. To address this, we propose a novel probabilistic method based on Uncertainty-aware Generalized Adaptive Cycle Consistency (UGAC), which models the per-pixel residual by generalized Gaussian distribution, capable of modelling heavy-tailed distributions. We compare our model with a wide variety of state-of-the-art methods on various challenging tasks including unpaired image translation of natural images spanning autonomous driving, maps, facades, and also in the medical imaging domain consisting of MRI. Experimental results demonstrate that our method exhibits stronger robustness towards unseen perturbations in test data. Code is released here: https://github.com/ExplainableML/UncertaintyAwareCycleConsistency.",
    "authors": [
      "Upadhyay, Uddeshya",
      "Chen, Yanbei",
      "Akata, Zeynep"
    ]
  },
  {
    "id": "edea298442a67de045e88dfb6e5ea4a2",
    "title": "CBP: backpropagation with constraint on weight precision using a pseudo-Lagrange multiplier method",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/edea298442a67de045e88dfb6e5ea4a2-Paper.pdf",
    "abstract": "Backward propagation of errors (backpropagation) is a method to minimize objective functions (e.g., loss functions) of deep neural networks by identifying optimal sets of weights and biases. Imposing constraints on weight precision is often required to alleviate prohibitive workloads on hardware. Despite the remarkable success of backpropagation, the algorithm itself is not capable of considering such constraints unless additional algorithms are applied simultaneously. To address this issue, we propose the constrained backpropagation (CBP) algorithm based on the pseudo-Lagrange multiplier method to obtain the optimal set of weights that satisfy a given set of constraints. The defining characteristic of the proposed CBP algorithm is the utilization of a Lagrangian function (loss function plus constraint function) as its objective function. We considered various types of constraints \u2014 binary, ternary, one-bit shift, and two-bit shift weight constraints. As a post-training method, CBP applied to AlexNet, ResNet-18, ResNet-50, and GoogLeNet on ImageNet, which were pre-trained using the conventional backpropagation. For most cases, the proposed algorithm outperforms the state-of-the-art methods on ImageNet, e.g., 66.6\\%, 74.4\\%, and 64.0\\% top-1 accuracy for ResNet-18, ResNet-50, and GoogLeNet with binary weights, respectively. This highlights CBP as a learning algorithm to address diverse constraints with the minimal performance loss by employing appropriate constraint functions. The code for CBP is publicly available at \\url{https://github.com/dooseokjeong/CBP}.",
    "authors": [
      "Kim, Guhyun",
      "Jeong, Doo Seok"
    ]
  },
  {
    "id": "ee0e95249268b86ff2053bef214bfeda",
    "title": "On the Sample Complexity of Privately Learning Axis-Aligned Rectangles",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ee0e95249268b86ff2053bef214bfeda-Paper.pdf",
    "abstract": "We revisit the fundamental problem of learning Axis-Aligned-Rectangles over a finite grid $X^d\\subseteq\\mathbb{R}^d$ with differential privacy. Existing results show that the sample complexity of this problem is at most $\\min\\left\\{ d{\\cdot}\\log|X| \\;,\\; d^{1.5}{\\cdot}\\left(\\log^*|X| \\right)^{1.5}\\right\\}$. That is, existing constructions either require sample complexity that grows linearly with $\\log|X|$, or else it grows super linearly with the dimension $d$.  We present a novel algorithm that reduces the sample complexity to only $\\tilde{O}\\left\\{d{\\cdot}\\left(\\log^*|X|\\right)^{1.5}\\right\\}$,  attaining a dimensionality optimal dependency without requiring the sample complexity to grow with $\\log|X|$. The technique used in order to attain this improvement involves the deletion of \"exposed\" data-points on the go, in a fashion designed to avoid the cost of the adaptive composition theorems.The core of this technique may be of individual interest, introducing a new method for constructing statistically-efficient private algorithms.",
    "authors": [
      "Sadigurschi, Menachem",
      "Stemmer, Uri"
    ]
  },
  {
    "id": "ee188463935a061dee6df8bf449cb882",
    "title": "Implicit Sparse Regularization: The Impact of Depth and Early Stopping",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ee188463935a061dee6df8bf449cb882-Paper.pdf",
    "abstract": "In this paper, we study the implicit bias of gradient descent for sparse regression. We extend results on regression with quadratic parametrization, which amounts to depth-2 diagonal linear networks, to more general depth-$N$ networks, under more realistic settings of noise and correlated designs. We show that early stopping is crucial for gradient descent to converge to a sparse model, a phenomenon that we call \\emph{implicit sparse regularization}. This result is in sharp contrast to known results for noiseless and uncorrelated-design cases.   We characterize the impact of depth and early stopping and show that for a general depth parameter $N$, gradient descent with early stopping achieves minimax optimal sparse recovery with sufficiently small initialization $w_0$ and step size $\\eta$. In particular, we show that increasing depth enlarges the scale of working initialization and the early-stopping window so that this implicit sparse regularization effect is more likely to take place.",
    "authors": [
      "Li, Jiangyuan",
      "Nguyen, Thanh",
      "Hegde, Chinmay",
      "Wong, Ka Wai"
    ]
  },
  {
    "id": "ee1abc6b5f7c6acb34ad076b05d40815",
    "title": "Efficient Generalization with Distributionally Robust Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ee1abc6b5f7c6acb34ad076b05d40815-Paper.pdf",
    "abstract": "Distributionally robust learning (DRL) is increasingly seen as a viable method to train machine learning models for improved model generalization. These min-max formulations, however, are more dif\ufb01cult to solve. We provide a new stochastic gradient descent algorithm to ef\ufb01ciently solve this DRL formulation. Our approach applies gradient descent to the outer minimization formulation and estimates the gradient of the inner maximization based on a sample average approximation. The latter uses a subset of the data sampled without replacement in each iteration, progressively increasing the subset size to ensure convergence. We rigorously establish convergence to a near-optimal solution under standard regularity assumptions and, for strongly convex losses, match the best known $O(\\epsilon{ \u22121})$ rate of convergence up to a known threshold. Empirical results demonstrate the signi\ufb01cant bene\ufb01ts of our approach over previous work in improving learning for model generalization.",
    "authors": [
      "Ghosh, Soumyadip",
      "Squillante, Mark",
      "Wollega, Ebisa"
    ]
  },
  {
    "id": "ee389847678a3a9d1ce9e4ca69200d06",
    "title": "No-regret Online Learning over Riemannian Manifolds",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ee389847678a3a9d1ce9e4ca69200d06-Paper.pdf",
    "abstract": "We consider online optimization over Riemannian manifolds, where a learner attempts to minimize a sequence of time-varying loss functions defined on Riemannian manifolds. Though many Euclidean online convex optimization algorithms have been proven useful in a wide range of areas, less attention has been paid to their Riemannian counterparts. In this paper, we study Riemannian online gradient descent (R-OGD) on Hadamard manifolds for both geodesically convex and strongly geodesically convex loss functions, and Riemannian bandit algorithm (R-BAN) on Hadamard homogeneous manifolds for geodesically convex functions. We establish upper bounds on the regrets of the problem with respect to time horizon, manifold curvature, and manifold dimension. We also find a universal lower bound for the achievable regret by constructing an online convex optimization problem on Hadamard manifolds. All the obtained regret bounds match the corresponding results are provided in Euclidean spaces. Finally, some numerical experiments validate our theoretical results.",
    "authors": [
      "Wang, Xi",
      "Tu, Zhipeng",
      "Hong, Yiguang",
      "Wu, Yingyi",
      "Shi, Guodong"
    ]
  },
  {
    "id": "ee39e503b6bedf0c98c388b7e8589aca",
    "title": "Landmark-Guided Subgoal Generation in Hierarchical Reinforcement Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ee39e503b6bedf0c98c388b7e8589aca-Paper.pdf",
    "abstract": "Goal-conditioned hierarchical reinforcement learning (HRL) has shown promising results for solving complex and long-horizon RL tasks. However, the action space of high-level policy in the goal-conditioned HRL is often large, so it results in poor exploration, leading to inefficiency in training. In this paper, we present HIerarchical reinforcement learning Guided by Landmarks (HIGL), a novel framework for training a high-level policy with a reduced action space guided by landmarks, i.e., promising states to explore. The key component of HIGL is twofold: (a) sampling landmarks that are informative for exploration and (b) encouraging the high level policy to generate a subgoal towards a selected landmark. For (a), we consider two criteria: coverage of the entire visited state space (i.e., dispersion of states) and novelty of states (i.e., prediction error of a state). For (b), we select a landmark as the very first landmark in the shortest path in a graph whose nodes are landmarks. Our experiments demonstrate that our framework outperforms prior-arts across a variety of control tasks, thanks to efficient exploration guided by landmarks.",
    "authors": [
      "Kim, Junsu",
      "Seo, Younggyo",
      "Shin, Jinwoo"
    ]
  },
  {
    "id": "eeb69a3cb92300456b6a5f4162093851",
    "title": "Minimax Regret for Stochastic Shortest Path",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/eeb69a3cb92300456b6a5f4162093851-Paper.pdf",
    "abstract": "We study the Stochastic Shortest Path (SSP) problem in which an agent has to reach a goal state in minimum total expected cost. In the learning formulation of the problem, the agent has no prior knowledge about the costs and dynamics of the model. She repeatedly interacts with the model for $K$ episodes, and has to minimize her regret. In this work we show that the minimax regret for this setting is $\\widetilde O(\\sqrt{ (B_\\star^2 + B_\\star) |S| |A| K})$ where $B_\\star$ is a bound on the expected cost of the optimal policy from any state, $S$ is the state space, and $A$ is the action space. This matches the $\\Omega (\\sqrt{ B_\\star^2 |S| |A| K})$ lower bound of Rosenberg et al. [2020] for $B_\\star \\ge 1$, and improves their regret bound by a factor of $\\sqrt{|S|}$. For $B_\\star < 1$ we prove a matching lower bound of $\\Omega (\\sqrt{ B_\\star |S| |A| K})$. Our algorithm is based on a novel reduction from SSP to finite-horizon MDPs.  To that end, we provide an algorithm for the finite-horizon setting whose leading term in the regret depends polynomially on the expected cost of the optimal policy and only logarithmically on the horizon.",
    "authors": [
      "Cohen, Alon",
      "Efroni, Yonathan",
      "Mansour, Yishay",
      "Rosenberg, Aviv"
    ]
  },
  {
    "id": "eec96a7f788e88184c0e713456026f3f",
    "title": "Parametrized Quantum Policies for Reinforcement Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/eec96a7f788e88184c0e713456026f3f-Paper.pdf",
    "abstract": "With the advent of real-world quantum computing, the idea that parametrized quantum computations can be used as hypothesis families in a quantum-classical machine learning system is gaining increasing traction. Such hybrid systems have already shown the potential to tackle real-world tasks in supervised and generative learning, and recent works have established their provable advantages in special artificial tasks. Yet, in the case of reinforcement learning, which is arguably most challenging and where learning boosts would be extremely valuable, no proposal has been successful in solving even standard benchmarking tasks, nor in showing a theoretical learning advantage over classical algorithms. In this work, we achieve both. We propose a hybrid quantum-classical reinforcement learning model using very few qubits, which we show can be effectively trained to solve several standard benchmarking environments. Moreover, we demonstrate, and formally prove, the ability of parametrized quantum circuits to solve certain learning tasks that are intractable to classical models, including current state-of-art deep neural networks, under the widely-believed classical hardness of the discrete logarithm problem.",
    "authors": [
      "Jerbi, Sofiene",
      "Gyurik, Casper",
      "Marshall, Simon",
      "Briegel, Hans",
      "Dunjko, Vedran"
    ]
  },
  {
    "id": "eecca5b6365d9607ee5a9d336962c534",
    "title": "On Pathologies in KL-Regularized Reinforcement Learning from Expert Demonstrations",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/eecca5b6365d9607ee5a9d336962c534-Paper.pdf",
    "abstract": "KL-regularized reinforcement learning from expert demonstrations has proved successful in improving the sample efficiency of deep reinforcement learning algorithms, allowing them to be applied to challenging physical real-world tasks. However, we show that KL-regularized reinforcement learning with behavioral reference policies derived from expert demonstrations can suffer from pathological training dynamics that can lead to slow, unstable, and suboptimal online learning. We show empirically that the pathology occurs for commonly chosen behavioral policy classes and demonstrate its impact on sample efficiency and online policy performance. Finally, we show that the pathology can be remedied by non-parametric behavioral reference policies and that this allows KL-regularized reinforcement learning to significantly outperform state-of-the-art approaches on a variety of challenging locomotion and dexterous hand manipulation tasks.",
    "authors": [
      "Rudner, Tim G. J.",
      "Lu, Cong",
      "Osborne, Michael A",
      "Gal, Yarin",
      "Teh, Yee"
    ]
  },
  {
    "id": "ef0d3930a7b6c95bd2b32ed45989c61f",
    "title": "Conditional Generation Using Polynomial Expansions",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ef0d3930a7b6c95bd2b32ed45989c61f-Paper.pdf",
    "abstract": "Generative modeling has evolved to a notable field of machine learning. Deep polynomial neural networks (PNNs) have demonstrated impressive results in unsupervised image generation, where the task is to map an input vector (i.e., noise) to a synthesized image. However, the success of PNNs has not been replicated in conditional generation tasks, such as super-resolution. Existing PNNs focus on single-variable polynomial expansions which do not fare well to two-variable inputs, i.e., the noise variable and the conditional variable. In this work, we introduce a general framework, called CoPE, that enables a polynomial expansion of two input variables and captures their auto- and cross-correlations. We exhibit how CoPE can be trivially augmented to accept an arbitrary number of input variables. CoPE is evaluated in five tasks (class-conditional generation, inverse problems, edges-to-image translation, image-to-image translation, attribute-guided generation) involving eight datasets. The thorough evaluation suggests that CoPE can be useful for tackling diverse conditional generation tasks. The source code of CoPE is available at https://github.com/grigorisg9gr/polynomialnetsforconditionalgeneration.",
    "authors": [
      "Chrysos, Grigorios",
      "Georgopoulos, Markos",
      "Panagakis, Yannis"
    ]
  },
  {
    "id": "ef1e491a766ce3127556063d49bc2f98",
    "title": "Efficient constrained sampling via the mirror-Langevin algorithm",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ef1e491a766ce3127556063d49bc2f98-Paper.pdf",
    "abstract": "We propose a new discretization of the mirror-Langevin diffusion and give a crisp proof of its convergence. Our analysis uses relative convexity/smoothness and self-concordance, ideas which originated in convex optimization, together with a new result in optimal transport that generalizes the displacement convexity of the entropy. Unlike prior works, our result both (1) requires much weaker assumptions on the mirror map and the target distribution, and (2) has vanishing bias as the step size tends to zero. In particular, for the task of sampling from a log-concave distribution supported on a compact set, our theoretical results are significantly better than the existing guarantees.",
    "authors": [
      "Ahn, Kwangjun",
      "Chewi, Sinho"
    ]
  },
  {
    "id": "ef41d488755367316f04fc0e0e9dc9fc",
    "title": "Adaptive Online Packing-guided Search for POMDPs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ef41d488755367316f04fc0e0e9dc9fc-Paper.pdf",
    "abstract": "The partially observable Markov decision process (POMDP) provides a general framework for modeling an agent's decision process with state uncertainty, and online planning plays a pivotal role in solving it. A belief is a distribution of states representing state uncertainty. Methods for large-scale POMDP problems rely on the same idea of sampling both states and observations. That is, instead of exact belief updating, a collection of sampled states is used to approximate the belief; instead of considering all possible observations, only a set of sampled observations are considered. Inspired by this, we take one step further and propose an online planning algorithm, Adaptive Online Packing-guided Search (AdaOPS), to better approximate beliefs with adaptive particle filter technique and balance estimation bias and variance by fusing similar observation branches. Theoretically, our algorithm is guaranteed to find an $\\epsilon$-optimal policy with a high probability given enough planning time under some mild assumptions. We evaluate our algorithm on several tricky POMDP domains, and it outperforms the state-of-the-art in all of them.",
    "authors": [
      "Wu, Chenyang",
      "Yang, Guoyu",
      "Zhang, Zongzhang",
      "Yu, Yang",
      "Li, Dong",
      "Liu, Wulong",
      "Hao, Jianye"
    ]
  },
  {
    "id": "ef452c63f81d0105dd4486f775adec81",
    "title": "Turing Completeness of Bounded-Precision Recurrent Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ef452c63f81d0105dd4486f775adec81-Paper.pdf",
    "abstract": "Previous works have proved that recurrent neural networks (RNNs) are Turing-complete. However, in the proofs, the RNNs allow for neurons with unbounded precision, which is neither practical in implementation nor biologically plausible. To remove this assumption, we propose a dynamically growing memory module made of neurons of fixed precision. The memory module dynamically recruits new neurons when more memories are needed, and releases them when memories become irrelevant. We prove that a 54-neuron bounded-precision RNN with growing memory modules can simulate a Universal Turing Machine, with time complexity linear in the simulated machine's time and independent of the memory size. The result is extendable to various other stack-augmented RNNs. Furthermore, we analyze the Turing completeness of both unbounded-precision and bounded-precision RNNs, revisiting and extending the theoretical foundations of RNNs.",
    "authors": [
      "Chung, Stephen",
      "Siegelmann, Hava"
    ]
  },
  {
    "id": "ef50c335cca9f340bde656363ebd02fd",
    "title": "End-to-end Multi-modal Video Temporal Grounding",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ef50c335cca9f340bde656363ebd02fd-Paper.pdf",
    "abstract": "We address the problem of text-guided video temporal grounding, which aims to identify the time interval of a certain event based on a natural language description. Different from most existing methods that only consider RGB images as visual features, we propose a multi-modal framework to extract complementary information from videos. Specifically, we adopt RGB images for appearance, optical flow for motion, and depth maps for image structure. While RGB images provide abundant visual cues of certain events, the performance may be affected by background clutters. Therefore, we use optical flow to focus on large motion and depth maps to infer the scene configuration when the action is related to objects recognizable with their shapes. To integrate the three modalities more effectively and enable inter-modal learning, we design a dynamic fusion scheme with transformers to model the interactions between modalities. Furthermore, we apply intra-modal self-supervised learning to enhance feature representations across videos for each modality, which also facilitates multi-modal learning. We conduct extensive experiments on the Charades-STA and ActivityNet Captions datasets, and show that the proposed method performs favorably against state-of-the-art approaches.",
    "authors": [
      "Chen, Yi-Wen",
      "Tsai, Yi-Hsuan",
      "Yang, Ming-Hsuan"
    ]
  },
  {
    "id": "ef575e8837d065a1683c022d2077d342",
    "title": "How Powerful are Performance Predictors in Neural Architecture Search?",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ef575e8837d065a1683c022d2077d342-Paper.pdf",
    "abstract": "Early methods in the rapidly developing field of neural architecture search (NAS) required fully training thousands of neural networks. To reduce this extreme computational cost, dozens of techniques have since been proposed to predict the final performance of neural architectures. Despite the success of such performance prediction methods, it is not well-understood how different families of techniques compare to one another, due to the lack of an agreed-upon evaluation metric and optimization for different constraints on the initialization time and query time. In this work, we give the first large-scale study of performance predictors by analyzing 31 techniques ranging from learning curve extrapolation, to weight-sharing, to supervised learning, to zero-cost proxies. We test a number of correlation- and rank-based performance measures in a variety of settings, as well as the ability of each technique to speed up predictor-based NAS frameworks. Our results act as recommendations for the best predictors to use in different settings, and we show that certain families of predictors can be combined to achieve even better predictive power, opening up promising research directions. We release our code, featuring a library of 31 performance predictors.",
    "authors": [
      "White, Colin",
      "Zela, Arber",
      "Ru, Robin",
      "Liu, Yang",
      "Hutter, Frank"
    ]
  },
  {
    "id": "ef67f7c2d86352c2c42e19d20f881f53",
    "title": "Stylized Dialogue Generation with Multi-Pass Dual Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ef67f7c2d86352c2c42e19d20f881f53-Paper.pdf",
    "abstract": "Stylized dialogue generation, which aims to generate a given-style response for an input context, plays a vital role in intelligent dialogue systems. Considering there is no parallel data between the contexts and the responses of target style S1, existing works mainly use back translation to generate stylized synthetic data for training, where the data about context, target style S1 and an intermediate style S0 is used. However, the interaction among these texts is not fully exploited, and the pseudo contexts are not adequately modeled. To overcome the above difficulties, we propose multi-pass dual learning (MPDL), which leverages the duality among the context, response of style S1 and response of style S_0. MPDL builds mappings among the above three domains, where the context should be reconstructed by the MPDL framework, and the reconstruction error is used as the training signal. To evaluate the quality of synthetic data, we also introduce discriminators that effectively measure how a pseudo sequence matches the specific domain, and the evaluation result is used as the weight for that data. Evaluation results indicate that our method obtains significant improvement over previous baselines.",
    "authors": [
      "Li, Jinpeng",
      "Xia, Yingce",
      "Yan, Rui",
      "Sun, Hongda",
      "Zhao, Dongyan",
      "Liu, Tie-Yan"
    ]
  },
  {
    "id": "ef82567365bc6a0efb05d21837257424",
    "title": "Entropy-based adaptive Hamiltonian Monte Carlo",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ef82567365bc6a0efb05d21837257424-Paper.pdf",
    "abstract": "Hamiltonian Monte Carlo (HMC) is a popular Markov Chain Monte Carlo (MCMC) algorithm to sample from an unnormalized probability distribution. A leapfrog integrator is commonly used to implement HMC in practice, but its performance can be sensitive to the choice of mass matrix used therein. We develop a gradient-based algorithm that allows for the adaptation of the mass matrix by encouraging the leapfrog integrator to have high acceptance rates while also exploring all dimensions jointly. In contrast to previous work that adapt the hyperparameters of HMC using some form of expected squared jumping distance, the adaptation strategy suggested here aims to increase sampling efficiency by maximizing an approximation of the proposal entropy. We illustrate that using multiple gradients in the HMC proposal can be beneficial compared to a single gradient-step in Metropolis-adjusted Langevin proposals. Empirical evidence suggests that the adaptation method can outperform different versions of HMC schemes by adjusting the mass matrix to the geometry of the target distribution and by providing some control on the integration time.",
    "authors": [
      "Hirt, Marcel",
      "Titsias, Michalis",
      "Dellaportas, Petros"
    ]
  },
  {
    "id": "ef8446f35513a8d6aa2308357a268a7e",
    "title": "Continual World: A Robotic Benchmark For Continual Reinforcement Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ef8446f35513a8d6aa2308357a268a7e-Paper.pdf",
    "abstract": "Continual learning (CL) --- the ability to continuously learn, building on previously acquired knowledge --- is a natural requirement for long-lived autonomous reinforcement learning (RL) agents. While building such agents, one needs to balance opposing desiderata, such as constraints on capacity and compute, the ability to not catastrophically forget, and to exhibit positive transfer on new tasks. Understanding the right trade-off is conceptually and computationally challenging, which we argue has led the community to overly focus on catastrophic forgetting.  In response to these issues, we advocate for the need to prioritize forward transfer and propose Continual World, a benchmark consisting of realistic and meaningfully diverse robotic tasks built on top of Meta-World  as a testbed. Following an in-depth empirical evaluation of existing CL methods, we pinpoint their limitations and highlight unique algorithmic challenges in the RL setting. Our benchmark aims to provide a meaningful and computationally inexpensive challenge for the community and thus help better understand the performance of existing and future solutions. Information about the benchmark, including the open-source code, is available at https://sites.google.com/view/continualworld.",
    "authors": [
      "Wo\u0142czyk, Maciej",
      "Zaj\u0105c, Micha\u0142",
      "Pascanu, Razvan",
      "Kuci\u0144ski, \u0141ukasz",
      "Mi\u0142o\u015b, Piotr"
    ]
  },
  {
    "id": "ef8f94395be9fd78b7d0aeecf7864a03",
    "title": "Towards Best-of-All-Worlds Online Learning with Feedback Graphs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ef8f94395be9fd78b7d0aeecf7864a03-Paper.pdf",
    "abstract": "We study the online learning with feedback graphs framework introduced by Mannor and Shamir (2011), in which the feedback received by the online learner is specified by a graph $G$ over the available actions.  We develop an algorithm that simultaneously achieves regret bounds of the form: $O(\\sqrt{\\theta(G) T})$ with adversarial losses; $O(\\theta(G)\\mathrm{polylog}{T})$ with stochastic losses; and $O(\\theta(G)\\mathrm{polylog}{T} + \\sqrt{\\theta(G) C})$ with stochastic losses subject to $C$ adversarial corruptions.  Here, $\\theta(G)$ is the $clique~covering~number$ of the graph $G$.  Our algorithm is an instantiation of Follow-the-Regularized-Leader with a novel regularization that can be seen as a product of a Tsallis entropy component (inspired by Zimmert and Seldin (2019)) and a Shannon entropy component (analyzed in the corrupted stochastic case by Amir et al. (2020)), thus subtly interpolating between the two forms of entropies.  One of our key technical contributions is in establishing the convexity of this regularizer and controlling its inverse Hessian, despite its complex product structure.",
    "authors": [
      "Erez, Liad",
      "Koren, Tomer"
    ]
  },
  {
    "id": "efb76cff97aaf057654ef2f38cd77d73",
    "title": "ViTAE: Vision Transformer Advanced by Exploring Intrinsic Inductive Bias",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/efb76cff97aaf057654ef2f38cd77d73-Paper.pdf",
    "abstract": "Transformers have shown great potential in various computer vision tasks owing to their strong capability in modeling long-range dependency using the self-attention mechanism. Nevertheless, vision transformers treat an image as 1D sequence of visual tokens, lacking an intrinsic inductive bias (IB) in modeling local visual structures and dealing with scale variance. Alternatively, they require large-scale training data and longer training schedules to learn the IB implicitly. In this paper, we propose a new Vision Transformer Advanced by Exploring intrinsic IB from convolutions, i.e., ViTAE. Technically, ViTAE has several spatial pyramid reduction modules to downsample and embed the input image into tokens with rich multi-scale context by using multiple convolutions with different dilation rates. In this way, it acquires an intrinsic scale invariance IB and is able to learn robust feature representation for objects at various scales. Moreover, in each transformer layer, ViTAE has a convolution block in parallel to the multi-head self-attention module, whose features are fused and fed into the feed-forward network. Consequently, it has the intrinsic locality IB and is able to learn local features and global dependencies collaboratively. Experiments on ImageNet as well as downstream tasks prove the superiority of ViTAE over the baseline transformer and concurrent works. Source code and pretrained models will be available at https://github.com/Annbless/ViTAE.",
    "authors": [
      "Xu, Yufei",
      "ZHANG, Qiming",
      "Zhang, Jing",
      "Tao, Dacheng"
    ]
  },
  {
    "id": "efe34c4e2190e97d1adc625902822b13",
    "title": "Open Rule Induction",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/efe34c4e2190e97d1adc625902822b13-Paper.pdf",
    "abstract": "Rules have a number of desirable properties. It is easy to understand,  infer new knowledge, and communicate with other inference systems. One weakness of the previous rule induction systems is that they only find rules within a knowledge base (KB) and therefore cannot generalize to more open and complex real-world rules. Recently, the language model (LM)-based rule generation are proposed to enhance the expressive power of the rules.In this paper, we revisit the differences between KB-based rule induction and LM-based rule generation. We argue that, while KB-based methods inducted rules by discovering data commonalitiess, the current LM-based methods are learning rules from rules''. This limits these methods to only producecanned'' rules whose patterns are constrained by the annotated rules, while discarding the rich expressive power of LMs for free text.Therefore, in this paper, we propose the open rule induction problem, which aims to induce open rules utilizing the knowledge in LMs. Besides, we propose the Orion (\\underline{o}pen \\underline{r}ule \\underline{i}nducti\\underline{on}) system to automatically mine open rules from LMs without supervision of annotated rules. We conducted extensive experiments to verify the quality and quantity of the inducted open rules. Surprisingly, when applying the open rules in downstream tasks (i.e. relation extraction), these automatically inducted rules even outperformed the manually annotated rules.",
    "authors": [
      "Cui, Wanyun",
      "Chen, Xingran"
    ]
  },
  {
    "id": "eff3058117fd4cf4d4c3af12e273a40f",
    "title": "Post-Contextual-Bandit Inference",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/eff3058117fd4cf4d4c3af12e273a40f-Paper.pdf",
    "abstract": "Contextual bandit algorithms are increasingly replacing non-adaptive A/B tests in e-commerce, healthcare, and policymaking because they can both improve outcomes for study participants and increase the chance of identifying good or even best policies. To support credible inference on novel interventions at the end of the study, nonetheless, we still want to construct valid confidence intervals on average treatment effects, subgroup effects, or value of new policies. The adaptive nature of the data collected by contextual bandit algorithms, however, makes this difficult: standard estimators are no longer asymptotically normally distributed and classic confidence intervals fail to provide correct coverage. While this has been addressed in non-contextual settings by using stabilized estimators, variance stabilized estimators in the contextual setting pose unique challenges that we tackle for the first time in this paper. We propose the Contextual Adaptive Doubly Robust (CADR) estimator, a novel estimator for policy value that is asymptotically normal under contextual adaptive data collection. The main technical challenge in constructing CADR is designing adaptive and consistent conditional standard deviation estimators for stabilization. Extensive numerical experiments using 57 OpenML datasets demonstrate that confidence intervals based on CADR uniquely provide correct coverage.",
    "authors": [
      "Bibaut, Aurelien",
      "Dimakopoulou, Maria",
      "Kallus, Nathan",
      "Chambaz, Antoine",
      "van der Laan, Mark"
    ]
  },
  {
    "id": "effc299a1addb07e7089f9b269c31f2f",
    "title": "Revisiting Discriminator in GAN Compression: A Generator-discriminator Cooperative Compression Scheme",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/effc299a1addb07e7089f9b269c31f2f-Paper.pdf",
    "abstract": "Recently, a series of algorithms have been explored for GAN compression, which aims to reduce tremendous computational overhead and memory usages when deploying GANs on resource-constrained edge devices. However, most of the existing GAN compression work only focuses on how to compress the generator, while fails to take the discriminator into account. In this work, we revisit the role of discriminator in GAN compression and design a novel generator-discriminator cooperative compression scheme for GAN compression, termed GCC. Within GCC, a selective activation discriminator automatically selects and activates convolutional channels according to a local capacity constraint and a global coordination constraint, which help maintain the Nash equilibrium with the lightweight generator during the adversarial training and avoid mode collapse. The original generator and discriminator are also optimized from scratch, to play as a teacher model to progressively refine the pruned generator and the selective activation discriminator. A novel online collaborative distillation scheme is designed to take full advantage of the intermediate feature of the teacher generator and discriminator to further boost the performance of the lightweight generator. Extensive experiments on various GAN-based generation tasks demonstrate the effectiveness and generalization of GCC. Among them, GCC contributes to reducing 80% computational costs while maintains comparable performance in image translation tasks.",
    "authors": [
      "Li, Shaojie",
      "Wu, Jie",
      "Xiao, Xuefeng",
      "Chao, Fei",
      "Mao, Xudong",
      "Ji, Rongrong"
    ]
  },
  {
    "id": "f0282b5ff85e7c9c66200d780bd7e72e",
    "title": "Asymptotically Exact Error Characterization of Offline Policy Evaluation with Misspecified Linear Models",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f0282b5ff85e7c9c66200d780bd7e72e-Paper.pdf",
    "abstract": "We consider the problem of offline policy evaluation~(OPE) with Markov decision processes~(MDPs), where the goal is to estimate the utility of given decision-making policies based on static datasets. Recently, theoretical understanding of OPE has been rapidly advanced under (approximate) realizability assumptions, i.e., where the environments of interest are well approximated with the given hypothetical models. On the other hand, the OPE under unrealizability has not been well understood as much as in the realizable setting despite its importance in real-world applications.To address this issue, we study the behavior of a simple existing OPE method called the linear direct method~(DM) under the unrealizability. Consequently, we obtain an asymptotically exact characterization of the OPE error in a doubly robust form. Leveraging this result, we also establish the nonparametric consistency of the tile-coding estimators under quite mild assumptions.",
    "authors": [
      "Miyaguchi, Kohei"
    ]
  },
  {
    "id": "f03704cb51f02f80b09bffba15751691",
    "title": "Topographic VAEs learn Equivariant Capsules",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f03704cb51f02f80b09bffba15751691-Paper.pdf",
    "abstract": "In this work we seek to bridge the concepts of topographic organization and equivariance in neural networks. To accomplish this, we introduce the Topographic VAE: a novel method for efficiently training deep generative models with topographically organized latent variables. We show that such a model indeed learns to organize its activations according to salient characteristics such as digit class, width, and style on MNIST. Furthermore, through topographic organization over time (i.e. temporal coherence), we demonstrate how predefined latent space transformation operators can be encouraged for observed transformed input sequences -- a primitive form of unsupervised learned equivariance. We demonstrate that this model successfully learns sets of approximately equivariant features (i.e. \"capsules\") directly from sequences and achieves higher likelihood on correspondingly transforming test sequences. Equivariance is verified quantitatively by measuring the approximate commutativity of the inference network and the sequence transformations. Finally, we demonstrate approximate equivariance to complex transformations, expanding upon the capabilities of existing group equivariant neural networks. ",
    "authors": [
      "Keller, T. Anderson",
      "Welling, Max"
    ]
  },
  {
    "id": "f06048518ff8de2035363e00710c6a1d",
    "title": "MobILE: Model-Based Imitation Learning From Observation Alone",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f06048518ff8de2035363e00710c6a1d-Paper.pdf",
    "abstract": "This paper studies Imitation Learning from Observations alone (ILFO) where the learner is presented with expert demonstrations that consist only of states visited by an expert (without access to actions taken by the expert). We present a provably efficient model-based framework MobILE to solve the ILFO problem. MobILE involves carefully trading off exploration against imitation - this is achieved by integrating the idea of optimism in the face of uncertainty into the distribution matching imitation learning (IL) framework. We provide a unified analysis for MobILE, and demonstrate that MobILE enjoys strong performance guarantees for classes of MDP dynamics that satisfy certain well studied notions of complexity. We also show that the ILFO problem is strictly harder than the standard IL problem by reducing ILFO to a multi-armed bandit problem indicating that exploration is necessary for solving ILFO efficiently. We complement  these theoretical results with experimental simulations on benchmark OpenAI Gym tasks that indicate the efficacy of MobILE. Code for implementing the MobILE framework is available at https://github.com/rahulkidambi/MobILE-NeurIPS2021.",
    "authors": [
      "Kidambi, Rahul",
      "Chang, Jonathan",
      "Sun, Wen"
    ]
  },
  {
    "id": "f065d878ccfb4cc4f4265a4ff8bafa9a",
    "title": "Few-Round Learning for Federated Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f065d878ccfb4cc4f4265a4ff8bafa9a-Paper.pdf",
    "abstract": "In federated learning (FL), a number of distributed clients targeting the same task collaborate to train a single global model without sharing their data. The learning process typically starts from a randomly initialized or some pretrained model. In this paper, we aim at designing an initial model based on which an arbitrary group of clients can obtain a global model for its own purpose, within only a few rounds of FL. The key challenge here is that the downstream tasks for which the pretrained model will be used are generally unknown when the initial model is prepared. Our idea is to take a meta-learning approach to construct the initial model so that any group with a possibly unseen task can obtain a high-accuracy global model within only R rounds of FL. Our meta-learning itself could be done via federated learning among willing participants and is based on an episodic arrangement to mimic the R rounds of FL followed by inference in each episode. Extensive experimental results show that our method generalizes well for arbitrary groups of clients and provides large performance improvements given the same overall communication/computation resources, compared to other baselines relying on known pretraining methods.",
    "authors": [
      "Park, Younghyun",
      "Han, Dong-Jun",
      "Kim, Do-Yeon",
      "Seo, Jun",
      "Moon, Jaekyun"
    ]
  },
  {
    "id": "f076073b2082f8741a9cd07b789c77a0",
    "title": "On Path Integration of Grid Cells: Group Representation and Isotropic Scaling",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f076073b2082f8741a9cd07b789c77a0-Paper.pdf",
    "abstract": "Understanding how grid cells perform path integration calculations remains a fundamental problem. In this paper, we conduct theoretical analysis of a general representation model of path integration by grid cells, where the 2D self-position is encoded as a higher dimensional vector, and the 2D self-motion is represented by a general transformation of the vector. We identify two conditions on the transformation. One is a group representation condition that is necessary for path integration. The other is an isotropic scaling condition that ensures locally conformal embedding, so that the error in the vector representation translates conformally to the error in the 2D self-position. Then we investigate the simplest transformation, i.e., the linear transformation, uncover its explicit algebraic and geometric structure as matrix Lie group of rotation, and explore the connection between the isotropic scaling condition and a special class of hexagon grid patterns. Finally, with our optimization-based approach, we manage to learn hexagon grid patterns that share similar properties of the grid cells in the rodent brain. The learned model is capable of accurate long distance path integration. Code is available at https://github.com/ruiqigao/grid-cell-path.",
    "authors": [
      "Gao, Ruiqi",
      "Xie, Jianwen",
      "Wei, Xue-Xin",
      "Zhu, Song-Chun",
      "Wu, Ying Nian"
    ]
  },
  {
    "id": "f08b7ac8aa30a2a9ab34394e200e1a71",
    "title": "Online Convex Optimization with Continuous Switching Constraint",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f08b7ac8aa30a2a9ab34394e200e1a71-Paper.pdf",
    "abstract": "In many sequential decision making applications, the change of decision would bring an additional cost, such as the wear-and-tear cost associated with changing server status. To control the switching cost, we introduce the problem of online convex optimization with continuous switching constraint, where the goal is to achieve a small regret given a budget on the \\emph{overall} switching cost. We first investigate the hardness of the problem, and provide a lower bound of order $\\Omega(\\sqrt{T})$ when the switching cost budget $S=\\Omega(\\sqrt{T})$, and $\\Omega(\\min\\{\\frac{T}{S},T\\})$ when $S=O(\\sqrt{T})$, where $T$ is the time horizon. The essential idea is to carefully design an adaptive adversary, who can adjust the loss function according to the cumulative switching cost of the player incurred so far based on the orthogonal technique. We then develop a simple gradient-based algorithm which enjoys the minimax optimal regret bound. Finally, we show that, for strongly convex functions, the regret bound can be improved to $O(\\log T)$ for $S=\\Omega(\\log T)$, and $O(\\min\\{T/\\exp(S)+S,T\\})$ for $S=O(\\log T)$.",
    "authors": [
      "Wang, Guanghui",
      "Wan, Yuanyu",
      "Yang, Tianbao",
      "Zhang, Lijun"
    ]
  },
  {
    "id": "f0bf4a2da952528910047c31b6c2e951",
    "title": "Why Do Better Loss Functions Lead to Less Transferable Features?",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f0bf4a2da952528910047c31b6c2e951-Paper.pdf",
    "abstract": "Previous work has proposed many new loss functions and regularizers that improve test accuracy on image classification tasks. However, it is not clear whether these loss functions learn better representations for downstream tasks. This paper studies how the choice of training objective affects the transferability of the hidden representations of convolutional neural networks trained on ImageNet. We show that many objectives lead to statistically significant improvements in ImageNet accuracy over vanilla softmax cross-entropy, but the resulting fixed feature extractors transfer substantially worse to downstream tasks, and the choice of loss has little effect when networks are fully fine-tuned on the new tasks. Using centered kernel alignment to measure similarity between hidden representations of networks, we find that differences among loss functions are apparent only in the last few layers of the network. We delve deeper into representations of the penultimate layer, finding that different objectives and hyperparameter combinations lead to dramatically different levels of class separation. Representations with higher class separation obtain higher accuracy on the original task, but their features are less useful for downstream tasks. Our results suggest there exists a trade-off between learning invariant features for the original task and features relevant for transfer tasks.",
    "authors": [
      "Kornblith, Simon",
      "Chen, Ting",
      "Lee, Honglak",
      "Norouzi, Mohammad"
    ]
  },
  {
    "id": "f0e6be4ce76ccfa73c5a540d992d0756",
    "title": "Breaking the centralized barrier for cross-device federated learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f0e6be4ce76ccfa73c5a540d992d0756-Paper.pdf",
    "abstract": "Federated learning (FL) is a challenging setting for optimization due to the heterogeneity of the data across different clients which gives rise to the client drift phenomenon. In fact, obtaining an algorithm for FL which is uniformly better than simple centralized training has been a major open problem thus far. In this work, we propose a general algorithmic framework, Mime, which i) mitigates client drift and ii) adapts arbitrary centralized optimization algorithms such as momentum and Adam to the cross-device federated learning setting. Mime uses a combination of control-variates and server-level statistics (e.g. momentum) at every client-update step to ensure that each local update mimics that of the centralized method run on iid data. We prove a reduction result showing that Mime can translate the convergence of a generic algorithm in the centralized setting into convergence in the federated setting. Further, we show that when combined with momentum based variance reduction, Mime is provably faster than any centralized method--the first such result. We also perform a thorough experimental exploration of Mime's performance on real world datasets.",
    "authors": [
      "Karimireddy, Sai Praneeth",
      "Jaggi, Martin",
      "Kale, Satyen",
      "Mohri, Mehryar",
      "Reddi, Sashank",
      "Stich, Sebastian U.",
      "Suresh, Ananda Theertha"
    ]
  },
  {
    "id": "f0f07e680de407b0f12abf15bd520097",
    "title": "Adversarially robust learning for security-constrained optimal power flow",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f0f07e680de407b0f12abf15bd520097-Paper.pdf",
    "abstract": "In recent years, the ML community has seen surges of interest in both adversarially robust learning and implicit layers, but connections between these two areas have seldom been explored. In this work, we combine innovations from these areas to tackle the problem of N-k security-constrained optimal power flow (SCOPF). N-k SCOPF is a core problem for the operation of electrical grids, and aims to schedule power generation in a manner that is robust to potentially $k$ simultaneous equipment outages. Inspired by methods in adversarially robust training, we frame N-k SCOPF as a minimax optimization problem -- viewing power generation settings as adjustable parameters and equipment outages as (adversarial) attacks -- and solve this problem via gradient-based techniques. The loss function of this minimax problem involves resolving implicit equations representing grid physics and operational decisions, which we differentiate through via the implicit function theorem. We demonstrate the efficacy of our framework in solving N-3 SCOPF, which has traditionally been considered as prohibitively expensive to solve given that the problem size depends combinatorially on the number of potential outages.",
    "authors": [
      "Donti, Priya",
      "Agarwal, Aayushya",
      "Bedmutha, Neeraj Vijay",
      "Pileggi, Larry",
      "Kolter, J. Zico"
    ]
  },
  {
    "id": "f0f6cc51dacebe556699ccb45e2d43a8",
    "title": "Learning a Single Neuron with Bias Using Gradient Descent",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f0f6cc51dacebe556699ccb45e2d43a8-Paper.pdf",
    "abstract": "We theoretically study the fundamental problem of learning a single neuron with a bias term ($\\mathbf{x}\\mapsto \\sigma(\\langle\\mathbf{w},\\mathbf{x}\\rangle + b)$) in the realizable setting with the ReLU activation, using gradient descent. Perhaps surprisingly, we show that this is a significantly different and more challenging problem than the bias-less case (which was the focus of previous works on single neurons), both in terms of the optimization geometry as well as the ability of gradient methods to succeed in some scenarios. We provide a detailed study of this problem, characterizing the critical points of the objective, demonstrating failure cases, and providing positive convergence guarantees under different sets of assumptions. To prove our results, we develop some tools which may be of independent interest, and improve previous results on learning single neurons. ",
    "authors": [
      "Vardi, Gal",
      "Yehudai, Gilad",
      "Shamir, Ohad"
    ]
  },
  {
    "id": "f0f800c92d191d736c4411f3b3f8ef4a",
    "title": "Making a (Counterfactual) Difference One Rationale at a Time",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f0f800c92d191d736c4411f3b3f8ef4a-Paper.pdf",
    "abstract": "Rationales, snippets of extracted text that explain an inference, have emerged as a popular framework for interpretable natural language processing (NLP). Rationale models typically consist of two cooperating modules: a selector and a classifier with the goal of maximizing the mutual information (MMI) between the \"selected\" text and the document label. Despite their promises, MMI-based methods often pick up on spurious text patterns and result in models with nonsensical behaviors. In this work, we investigate whether counterfactual data augmentation (CDA), without human assistance, can improve the performance of the selector by lowering the mutual information between spurious signals and the document label. Our counterfactuals are produced in an unsupervised fashion using class-dependent generative models. From an information theoretic lens, we derive properties of the unaugmented dataset for which our CDA approach would succeed. The effectiveness of CDA is empirically evaluated by comparing against several baselines including an improved MMI-based rationale schema on two multi-aspect datasets. Our results show that CDA produces rationales that better capture the signal of interest.",
    "authors": [
      "Plyler, Mitchell",
      "Green, Michael",
      "Chi, Min"
    ]
  },
  {
    "id": "f0fcf351df4eb6786e9bb6fc4e2dee02",
    "title": "3D Siamese Voxel-to-BEV Tracker for Sparse Point Clouds",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f0fcf351df4eb6786e9bb6fc4e2dee02-Paper.pdf",
    "abstract": "3D object tracking in point clouds is still a challenging problem due to the sparsity of LiDAR points in dynamic environments. In this work, we propose a Siamese voxel-to-BEV tracker, which can significantly improve the tracking performance in sparse 3D point clouds. Specifically, it consists of a Siamese shape-aware feature learning network and a voxel-to-BEV target localization network. The Siamese shape-aware feature learning network can capture 3D shape information of the object to learn the discriminative features of the object so that the potential target from the background in sparse point clouds can be identified. To this end, we first perform template feature embedding to embed the template's feature into the potential target and then generate a dense 3D shape to characterize the shape information of the potential target. For localizing the tracked target, the voxel-to-BEV target localization network regresses the target's 2D center and the z-axis center from the dense bird's eye view (BEV) feature map in an anchor-free manner. Concretely, we compress the voxelized point cloud along z-axis through max pooling to obtain a dense BEV feature map, where the regression of the 2D center and the z-axis center can be performed more effectively. Extensive evaluation on the KITTI tracking dataset shows that our method significantly outperforms the current state-of-the-art methods by a large margin. Code is available at https://github.com/fpthink/V2B.",
    "authors": [
      "Hui, Le",
      "Wang, Lingpeng",
      "Cheng, Mingmei",
      "Xie, Jin",
      "Yang, Jian"
    ]
  },
  {
    "id": "f1404c2624fa7f2507ba04fd9dfc5fb1",
    "title": "Stateful Strategic Regression",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f1404c2624fa7f2507ba04fd9dfc5fb1-Paper.pdf",
    "abstract": "Automated decision-making tools increasingly assess individuals to determine if they qualify for high-stakes opportunities. A recent line of research investigates how strategic agents may respond to such scoring tools to receive favorable assessments. While prior work has focused on the short-term strategic interactions between a decision-making institution (modeled as a principal) and individual decision-subjects (modeled as agents), we investigate interactions spanning multiple time-steps. In particular, we consider settings in which the agent's effort investment today can accumulate over time in the form of an internal state - impacting both his future rewards and that of the principal. We characterize the Stackelberg equilibrium of the resulting game and provide novel algorithms for computing it. Our analysis reveals several intriguing insights about the role of multiple interactions in shaping the game's outcome: First, we establish that in our stateful setting, the class of all linear assessment policies remains as powerful as the larger class of all monotonic assessment policies. While recovering the principal's optimal policy requires solving a non-convex optimization problem, we provide polynomial-time algorithms for recovering both the principal and agent's optimal policies under common assumptions about the process by which effort investments convert to observable features. Most importantly, we show that with multiple rounds of interaction at her disposal, the principal is more effective at incentivizing the agent to accumulate effort in her desired direction. Our work addresses several critical gaps in the growing literature on the societal impacts of automated decision-making - by focusing on longer time horizons and accounting for the compounding nature of decisions individuals receive over time. ",
    "authors": [
      "Harris, Keegan",
      "Heidari, Hoda",
      "Wu, Steven Z."
    ]
  },
  {
    "id": "f1507aba9fc82ffa7cc7373c58f8a613",
    "title": "Self-Attention Between Datapoints: Going Beyond Individual Input-Output Pairs in Deep Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f1507aba9fc82ffa7cc7373c58f8a613-Paper.pdf",
    "abstract": "We challenge a common assumption underlying most supervised deep learning: that a model makes a prediction depending only on its parameters and the features of a single input. To this end, we introduce a general-purpose deep learning architecture that takes as input the entire dataset instead of processing one datapoint at a time. Our approach uses self-attention to reason about relationships between datapoints explicitly, which can be seen as realizing non-parametric models using parametric attention mechanisms. However, unlike conventional non-parametric models, we let the model learn end-to-end from the data how to make use of other datapoints for prediction. Empirically, our models solve cross-datapoint lookup and complex reasoning tasks unsolvable by traditional deep learning models. We show highly competitive results on tabular data, early results on CIFAR-10, and give insight into how the model makes use of the interactions between points.",
    "authors": [
      "Kossen, Jannik",
      "Band, Neil",
      "Lyle, Clare",
      "Gomez, Aidan N.",
      "Rainforth, Thomas",
      "Gal, Yarin"
    ]
  },
  {
    "id": "f1676935f9304b97d59b0738289d2e22",
    "title": "Your head is there to move you around: Goal-driven models of the primate dorsal pathway",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f1676935f9304b97d59b0738289d2e22-Paper.pdf",
    "abstract": "Neurons in the dorsal visual pathway of the mammalian brain are selective for motion stimuli, with the complexity of stimulus representations increasing along the hierarchy. This progression is similar to that of the ventral visual pathway, which is well characterized by artificial neural networks (ANNs) optimized for object recognition. In contrast, there are no image-computable models of the dorsal stream with comparable explanatory power. We hypothesized that the properties of dorsal stream neurons could be explained by a simple learning objective: the need for an organism to orient itself during self-motion. To test this hypothesis, we trained a 3D ResNet to predict an agent's self-motion parameters from visual stimuli in a simulated environment. We found that the responses in this network accounted well for the selectivity of neurons in a large database of single-neuron recordings from the dorsal visual stream of non-human primates. In contrast, ANNs trained on an action recognition dataset through supervised or self-supervised learning  could not explain responses in the dorsal stream, despite also being trained on naturalistic videos with moving objects. These results demonstrate that an ecologically relevant cost function can account for dorsal stream properties in the primate brain.",
    "authors": [
      "Mineault, Patrick",
      "Bakhtiari, Shahab",
      "Richards, Blake",
      "Pack, Christopher"
    ]
  },
  {
    "id": "f18224a1adfb7b3dbff668c9b655a35a",
    "title": "Achieving Rotational Invariance with Bessel-Convolutional Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f18224a1adfb7b3dbff668c9b655a35a-Paper.pdf",
    "abstract": "For many applications in image analysis, learning models that are invariant to translations and rotations is paramount. This is the case, for example, in medical imaging where the objects of interest can appear at arbitrary positions, with arbitrary orientations. As of today, Convolutional Neural Networks (CNN) are one of the most powerful tools for image analysis. They achieve, thanks to convolutions, an invariance with respect to translations. In this work, we present a new type of convolutional layer that takes advantage of Bessel functions, well known in physics, to build Bessel-CNNs (B-CNNs) that are invariant to all the continuous set of possible rotation angles by design.",
    "authors": [
      "Delchevalerie, Valentin",
      "Bibal, Adrien",
      "Fr\u00e9nay, Beno\u00eet",
      "Mayer, Alexandre"
    ]
  },
  {
    "id": "f187a23c3ee681ef6913f31fd6d6446b",
    "title": "Unsupervised Domain Adaptation with Dynamics-Aware Rewards in Reinforcement Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f187a23c3ee681ef6913f31fd6d6446b-Paper.pdf",
    "abstract": "Unsupervised reinforcement learning aims to acquire skills without prior goal representations, where an agent automatically explores an open-ended environment to represent goals and learn the goal-conditioned policy. However, this procedure is often time-consuming, limiting the rollout in some potentially expensive target environments. The intuitive approach of training in another interaction-rich environment disrupts the reproducibility of trained skills in the target environment due to the dynamics shifts and thus inhibits direct transferring. Assuming free access to a source environment, we propose an unsupervised domain adaptation method to identify and acquire skills across dynamics. Particularly, we introduce a KL regularized objective to encourage emergence of skills, rewarding the agent for both discovering skills and aligning its behaviors respecting dynamics shifts. This suggests that both dynamics (source and target) shape the reward to facilitate the learning of adaptive skills. We also conduct empirical experiments to demonstrate that our method can effectively learn skills that can be smoothly deployed in target. ",
    "authors": [
      "Liu, Jinxin",
      "Shen, Hao",
      "Wang, Donglin",
      "Kang, Yachen",
      "Tian, Qiangxing"
    ]
  },
  {
    "id": "f18a6d1cde4b205199de8729a6637b42",
    "title": "GraphFormers: GNN-nested Transformers for Representation Learning on Textual Graph",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f18a6d1cde4b205199de8729a6637b42-Paper.pdf",
    "abstract": "The representation learning on textual graph is to generate low-dimensional embeddings for the nodes based on the individual textual features and the neighbourhood information. Recent breakthroughs on pretrained language models and graph neural networks push forward the development of corresponding techniques. The existing works mainly rely on the cascaded model architecture: the textual features of nodes are independently encoded by language models at first; the textual embeddings are aggregated by graph neural networks afterwards. However, the above architecture is limited due to the independent modeling of textual features. In this work, we propose GraphFormers, where layerwise GNN components are nested alongside the transformer blocks of language models. With the proposed architecture, the text encoding and the graph aggregation are fused into an iterative workflow, making each node's semantic accurately comprehended from the global perspective. In addition, a progressive learning strategy is introduced, where the model is successively trained on manipulated data and original data to reinforce its capability of integrating information on graph. Extensive evaluations are conducted on three large-scale benchmark datasets, where GraphFormers outperform the SOTA baselines with comparable running efficiency. The source code is released at https://github.com/microsoft/GraphFormers .",
    "authors": [
      "Yang, Junhan",
      "Liu, Zheng",
      "Xiao, Shitao",
      "Li, Chaozhuo",
      "Lian, Defu",
      "Agrawal, Sanjay",
      "Singh, Amit",
      "Sun, Guangzhong",
      "Xie, Xing"
    ]
  },
  {
    "id": "f197002b9a0853eca5e046d9ca4663d5",
    "title": "A Universal Law of Robustness via Isoperimetry",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f197002b9a0853eca5e046d9ca4663d5-Paper.pdf",
    "abstract": "Classically, data interpolation with a parametrized model class is possible as long as the number of parameters is larger than the number of equations to be satisfied. A puzzling phenomenon in the current practice of deep learning is that models are trained with many more parameters than what this classical theory would suggest. We propose a theoretical explanation for this phenomenon. We prove that for a broad class of data distributions and model classes, overparametrization is {\\em necessary} if one wants to interpolate the data {\\em smoothly}. Namely we show that {\\em smooth} interpolation requires $d$ times more parameters than mere interpolation, where $d$ is the ambient data dimension. We prove this universal law of robustness for any smoothly parametrized function class with polynomial size weights, and any covariate distribution verifying isoperimetry. In the case of two-layers neural networks and Gaussian covariates, this law was conjectured in prior work by Bubeck, Li and Nagaraj. We also give an interpretation of our result as an improved generalization bound for model classes consisting of smooth functions.",
    "authors": [
      "Bubeck, Sebastien",
      "Sellke, Mark"
    ]
  },
  {
    "id": "f19c44d068fecac1d6d13a80df4f8e96",
    "title": "On Contrastive Representations of Stochastic Processes",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f19c44d068fecac1d6d13a80df4f8e96-Paper.pdf",
    "abstract": "Learning representations of stochastic processes is an emerging problem in machine learning with applications from meta-learning to physical object models to time series. Typical methods rely on exact reconstruction of observations, but this approach breaks down as observations become high-dimensional or noise distributions become complex. To address this, we propose a unifying framework for learning contrastive representations of stochastic processes (CReSP) that does away with exact reconstruction. We dissect potential use cases for stochastic process representations, and propose methods that accommodate each. Empirically, we show that our methods are effective for learning representations of periodic functions, 3D objects and dynamical processes. Our methods tolerate noisy high-dimensional observations better than traditional approaches, and the learned representations transfer to a range of downstream tasks.",
    "authors": [
      "Mathieu, Emile",
      "Foster, Adam",
      "Teh, Yee"
    ]
  },
  {
    "id": "f19fec2f129fbdba76493451275c883a",
    "title": "A Domain-Shrinking based Bayesian Optimization Algorithm with Order-Optimal Regret Performance",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f19fec2f129fbdba76493451275c883a-Paper.pdf",
    "abstract": "We consider sequential optimization of an unknown function in a reproducing kernel Hilbert space. We propose a Gaussian process-based algorithm and establish its order-optimal regret performance (up to a poly-logarithmic factor). This is the first GP-based algorithm with an order-optimal regret guarantee. The proposed algorithm is rooted in the methodology of domain shrinking realized through a sequence of tree-based region pruning and refining to concentrate queries in increasingly smaller high-performing regions of the function domain. The search for high-performing regions is localized and guided by an iterative estimation of the optimal function value to ensure both learning efficiency and computational efficiency. Compared with the prevailing GP-UCB family of algorithms, the proposed algorithm reduces computational complexity by a factor of $O(T^{2d-1})$ (where $T$ is the time horizon and $d$ the dimension of the function domain).",
    "authors": [
      "Salgia, Sudeep",
      "Vakili, Sattar",
      "Zhao, Qing"
    ]
  },
  {
    "id": "f1b0775946bc0329b35b823b86eeb5f5",
    "title": "Scalars are universal: Equivariant machine learning, structured like classical physics",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f1b0775946bc0329b35b823b86eeb5f5-Paper.pdf",
    "abstract": "There has been enormous progress in the last few years in designing  neural networks that respect the fundamental symmetries and coordinate freedoms of physical law. Some of these frameworks make use of irreducible representations, some make use of high-order tensor objects, and some apply symmetry-enforcing constraints. Different physical laws obey different combinations of fundamental symmetries, but a large fraction (possibly all) of classical physics is equivariant to translation, rotation, reflection (parity), boost (relativity), and permutations. Here we show that it is simple to parameterize universally approximating polynomial functions that are equivariant under these symmetries, or under the Euclidean, Lorentz, and Poincar\u00e9 groups, at any dimensionality $d$. The key observation is that nonlinear O($d$)-equivariant (and related-group-equivariant) functions can be universally expressed in terms of a lightweight collection of scalars---scalar products and scalar contractions of the scalar, vector, and tensor inputs. We complement our theory with numerical examples that show that the scalar-based method is simple, efficient, and scalable. ",
    "authors": [
      "Villar, Soledad",
      "Hogg, David W",
      "Storey-Fisher, Kate",
      "Yao, Weichi",
      "Blum-Smith, Ben"
    ]
  },
  {
    "id": "f1b6f2857fb6d44dd73c7041e0aa0f19",
    "title": "Unsupervised Object-Level Representation Learning from Scene Images",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f1b6f2857fb6d44dd73c7041e0aa0f19-Paper.pdf",
    "abstract": "Contrastive self-supervised learning has largely narrowed the gap to supervised pre-training on ImageNet. However, its success highly relies on the object-centric priors of ImageNet, i.e., different augmented views of the same image correspond to the same object. Such a heavily curated constraint becomes immediately infeasible when pre-trained on more complex scene images with many objects. To overcome this limitation, we introduce Object-level Representation Learning (ORL), a new self-supervised learning framework towards scene images. Our key insight is to leverage image-level self-supervised pre-training as the prior to discover object-level semantic correspondence, thus realizing object-level representation learning from scene images. Extensive experiments on COCO show that ORL significantly improves the performance of self-supervised learning on scene images, even surpassing supervised ImageNet pre-training on several downstream tasks. Furthermore, ORL improves the downstream performance when more unlabeled scene images are available, demonstrating its great potential of harnessing unlabeled data in the wild. We hope our approach can motivate future research on more general-purpose unsupervised representation learning from scene data.",
    "authors": [
      "Xie, Jiahao",
      "Zhan, Xiaohang",
      "Liu, Ziwei",
      "Ong, Yew Soon",
      "Loy, Chen Change"
    ]
  },
  {
    "id": "f1c1592588411002af340cbaedd6fc33",
    "title": "Do Transformers Really Perform Badly for Graph Representation?",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f1c1592588411002af340cbaedd6fc33-Paper.pdf",
    "abstract": "The Transformer architecture has become a dominant choice in many domains, such as natural language processing and computer vision. Yet, it has not achieved competitive performance on popular leaderboards of graph-level prediction compared to mainstream GNN variants. Therefore, it remains a mystery how Transformers could perform well for graph representation learning. In this paper, we solve this mystery by presenting Graphormer, which is built upon the standard Transformer architecture, and could attain excellent results on a broad range of graph representation learning tasks, especially on the recent OGB Large-Scale Challenge. Our key insight to utilizing Transformer in the graph is the necessity of effectively encoding the structural information of a graph into the model. To this end, we propose several simple yet effective structural encoding methods to help Graphormer better model graph-structured data. Besides, we mathematically characterize the expressive power of Graphormer and exhibit that with our ways of encoding the structural information of graphs, many popular GNN variants could be covered as the special cases of Graphormer. The code and models of Graphormer will be made publicly available at \\url{https://github.com/Microsoft/Graphormer}.",
    "authors": [
      "Ying, Chengxuan",
      "Cai, Tianle",
      "Luo, Shengjie",
      "Zheng, Shuxin",
      "Ke, Guolin",
      "He, Di",
      "Shen, Yanming",
      "Liu, Tie-Yan"
    ]
  },
  {
    "id": "f1e709e6aef16ba2f0cd6c7e4f52b9b6",
    "title": "Powerpropagation: A sparsity inducing weight reparameterisation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f1e709e6aef16ba2f0cd6c7e4f52b9b6-Paper.pdf",
    "abstract": "The training of sparse neural networks is becoming an increasingly important tool for reducing the computational footprint of models at training and evaluation, as well enabling the effective scaling up of models. Whereas much work over the years has been dedicated to specialised pruning techniques, little attention has been paid to the inherent effect of gradient based training on model sparsity. Inthis work, we introduce Powerpropagation, a new weight-parameterisation for neural networks that leads to inherently sparse models. Exploiting the behaviour of gradient descent, our method gives rise to weight updates exhibiting a \u201crich get richer\u201d dynamic, leaving low-magnitude parameters largely unaffected by learning. Models trained in this manner exhibit similar performance, but have a distributionwith markedly higher density at zero, allowing more parameters to be pruned safely. Powerpropagation is general, intuitive, cheap and straight-forward to implement and can readily be combined with various other techniques. To highlight its versatility, we explore it in two very different settings: Firstly, following a recent line of work, we investigate its effect on sparse training for resource-constrained settings. Here, we combine Powerpropagation with a traditional weight-pruning technique as well as recent state-of-the-art sparse-to-sparse algorithms, showing superior performance on the ImageNet benchmark. Secondly, we advocate the useof sparsity in overcoming catastrophic forgetting, where compressed representations allow accommodating a large number of tasks at fixed model capacity. In all cases our reparameterisation considerably increases the efficacy of the off-the-shelf methods.",
    "authors": [
      "Schwarz, Jonathan",
      "Jayakumar, Siddhant",
      "Pascanu, Razvan",
      "Latham, Peter E",
      "Teh, Yee"
    ]
  },
  {
    "id": "f22e4747da1aa27e363d86d40ff442fe",
    "title": "Stronger NAS with Weaker Predictors",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f22e4747da1aa27e363d86d40ff442fe-Paper.pdf",
    "abstract": "Neural Architecture Search (NAS) often trains and evaluates a large number of architectures. Recent predictor-based NAS approaches attempt to alleviate such heavy computation costs with two key steps: sampling some architecture-performance pairs and fitting a proxy accuracy predictor. Given limited samples, these predictors, however, are far from accurate to locate top architectures due to the difficulty of fitting the huge search space. This paper reflects on a simple yet crucial question: if our final goal is to find the best architecture, do we really need to model the whole space well?. We propose a paradigm shift from fitting the whole architecture space using one strong predictor, to progressively fitting a search path towards the high-performance sub-space through a set of weaker predictors. As a key property of the weak predictors, their probabilities of sampling better architectures keep increasing. Hence we only sample a few well-performed architectures guided by the previously learned predictor and estimate a new better weak predictor. This embarrassingly easy framework, dubbed WeakNAS, produces coarse-to-fine iteration to gradually refine the ranking of sampling space. Extensive experiments demonstrate that WeakNAS costs fewer samples to find top-performance architectures on NAS-Bench-101 and NAS-Bench-201. Compared to state-of-the-art (SOTA) predictor-based NAS methods, WeakNAS outperforms all with notable margins, e.g., requiring at least 7.5x less samples to find global optimal on NAS-Bench-101. WeakNAS can also absorb their ideas to boost performance more. Further, WeakNAS strikes the new SOTA result of 81.3% in the ImageNet MobileNet Search Space. The code is available at: https://github.com/VITA-Group/WeakNAS.",
    "authors": [
      "Wu, Junru",
      "Dai, Xiyang",
      "Chen, Dongdong",
      "Chen, Yinpeng",
      "Liu, Mengchen",
      "Yu, Ye",
      "Wang, Zhangyang",
      "Liu, Zicheng",
      "Chen, Mei",
      "Yuan, Lu"
    ]
  },
  {
    "id": "f23d125da1e29e34c552f448610ff25f",
    "title": "Convolutional Normalization: Improving Deep Convolutional Network Robustness and Training",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f23d125da1e29e34c552f448610ff25f-Paper.pdf",
    "abstract": "Normalization techniques have become a basic component in modern convolutional neural networks (ConvNets). In particular, many recent works demonstrate that promoting the orthogonality of the weights helps train deep models and improve robustness. For ConvNets, most existing methods are based on penalizing or normalizing weight matrices derived from concatenating or flattening the convolutional kernels. These methods often destroy or ignore the benign convolutional structure of the kernels; therefore, they are often expensive or impractical for deep ConvNets. In contrast, we introduce a simple and efficient ``Convolutional Normalization'' (ConvNorm) method that can fully exploit the convolutional structure in the Fourier domain and serve as a simple plug-and-play module to be conveniently incorporated into any ConvNets. Our method is inspired by recent work on preconditioning methods for convolutional sparse coding and can effectively promote each layer's channel-wise isometry. Furthermore, we show that our ConvNorm can reduce the layerwise spectral norm of the weight matrices and hence improve the Lipschitzness of the network, leading to easier training and improved robustness for deep ConvNets. Applied to classification under noise corruptions and generative adversarial network (GAN), we show that the ConvNorm improves the robustness of common ConvNets such as ResNet and the performance of GAN. We verify our findings via numerical experiments on CIFAR and ImageNet. Our implementation is available online at \\url{https://github.com/shengliu66/ConvNorm}.",
    "authors": [
      "Liu, Sheng",
      "Li, Xiao",
      "Zhai, Yuexiang",
      "You, Chong",
      "Zhu, Zhihui",
      "Fernandez-Granda, Carlos",
      "Qu, Qing"
    ]
  },
  {
    "id": "f24ad6f72d6cc4cb51464f2b29ab69d3",
    "title": "Nearly-Tight and Oblivious Algorithms for Explainable Clustering",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f24ad6f72d6cc4cb51464f2b29ab69d3-Paper.pdf",
    "abstract": "We study the problem of explainable clustering in the setting first formalized by Dasgupta, Frost, Moshkovitz, and Rashtchian (ICML 2020). A $k$-clustering is said to be explainable if it is given by a decision tree where each internal node splits data points with a threshold cut in a single dimension (feature), and each of the $k$ leaves corresponds to a cluster. We give an algorithm that outputs an explainable clustering that loses at most a factor of $O(\\log^2 k)$ compared to an optimal (not necessarily explainable) clustering for the $k$-medians objective, and a factor of $O(k \\log^2 k)$ for the $k$-means objective. This improves over the previous best upper bounds of $O(k)$ and $O(k^2)$, respectively, and nearly matches the previous $\\Omega(\\log k)$ lower bound for $k$-medians and our new $\\Omega(k)$ lower bound for $k$-means. The algorithm is remarkably simple. In particular, given an initial not necessarily explainable clustering in $\\mathbb{R}^d$, it is oblivious to the data points and runs in time $O(dk \\log^2 k)$, independent of the number of data points $n$. Our upper and lower bounds also generalize to objectives given by higher $\\ell_p$-norms.",
    "authors": [
      "Gamlath, Buddhima",
      "Jia, Xinrui",
      "Polak, Adam",
      "Svensson, Ola"
    ]
  },
  {
    "id": "f26df67e8110ee2b44923db775e3e47f",
    "title": "Deep Networks Provably Classify Data on Curves",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f26df67e8110ee2b44923db775e3e47f-Paper.pdf",
    "abstract": "Data with low-dimensional nonlinear structure are ubiquitous in engineering and scientific problems. We study a model problem with such structure---a binary classification task that uses a deep fully-connected neural network to classify data drawn from two disjoint smooth curves on the unit sphere. Aside from mild regularity conditions, we place no restrictions on the configuration of the curves. We prove that when (i) the network depth is large relative to certain geometric properties that set the difficulty of the problem and (ii) the network width and number of samples is polynomial in the depth, randomly-initialized gradient descent quickly learns to correctly classify all points on the two curves with high probability. To our knowledge, this is the first generalization guarantee for deep networks with nonlinear data that depends only on intrinsic data properties. Our analysis proceeds by a reduction to dynamics in the neural tangent kernel (NTK) regime, where the network depth plays the role of a fitting resource in solving the classification problem. In particular, via fine-grained control of the decay properties of the NTK, we demonstrate that when the network is sufficiently deep, the NTK can be locally approximated by a translationally invariant operator on the manifolds and stably inverted over smooth functions, which guarantees convergence and generalization. ",
    "authors": [
      "Wang, Tingran",
      "Buchanan, Sam",
      "Gilboa, Dar",
      "Wright, John"
    ]
  },
  {
    "id": "f29a179746902e331572c483c45e5086",
    "title": "COMBO: Conservative Offline Model-Based Policy Optimization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f29a179746902e331572c483c45e5086-Paper.pdf",
    "abstract": "Model-based reinforcement learning (RL) algorithms, which learn a dynamics model from logged experience and perform conservative planning under the learned model, have emerged as a promising paradigm for offline reinforcement learning (offline RL). However, practical variants of such model-based algorithms rely on explicit uncertainty quantification for incorporating conservatism. Uncertainty estimation with complex models, such as deep neural networks, can be difficult and unreliable. We empirically find that uncertainty estimation is not accurate and leads to poor performance in certain scenarios in offline model-based RL. We overcome this limitation by developing a new model-based offline RL algorithm, COMBO, that trains a value function using both the offline dataset and data generated using rollouts under the model while also additionally regularizing the value function on out-of-support state-action tuples generated via model rollouts. This results in a conservative estimate of the value function for out-of-support state-action tuples, without requiring explicit uncertainty estimation. Theoretically, we show that COMBO satisfies a policy improvement guarantee in the offline setting. Through extensive experiments, we find that COMBO attains greater performance compared to prior offline RL on problems that demand generalization to related but previously unseen tasks, and also consistently matches or outperforms prior offline RL methods on widely studied offline RL benchmarks, including image-based tasks.",
    "authors": [
      "Yu, Tianhe",
      "Kumar, Aviral",
      "Rafailov, Rafael",
      "Rajeswaran, Aravind",
      "Levine, Sergey",
      "Finn, Chelsea"
    ]
  },
  {
    "id": "f2b4053221961416d47d497814a8064f",
    "title": "Time-series Generation by Contrastive Imitation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f2b4053221961416d47d497814a8064f-Paper.pdf",
    "abstract": "Consider learning a generative model for time-series data. The sequential setting poses a unique challenge: Not only should the generator capture the conditional dynamics of (stepwise) transitions, but its open-loop rollouts should also preserve the joint distribution of (multi-step) trajectories. On one hand, autoregressive models trained by MLE allow learning and computing explicit transition distributions, but suffer from compounding error during rollouts. On the other hand, adversarial models based on GAN training alleviate such exposure bias, but transitions are implicit and hard to assess. In this work, we study a generative framework that seeks to combine the strengths of both: Motivated by a moment-matching objective to mitigate compounding error, we optimize a local (but forward-looking) transition policy, where the reinforcement signal is provided by a global (but stepwise-decomposable) energy model trained by contrastive estimation. At training, the two components are learned cooperatively, avoiding the instabilities typical of adversarial objectives. At inference, the learned policy serves as the generator for iterative sampling, and the learned energy serves as a trajectory-level measure for evaluating sample quality. By expressly training a policy to imitate sequential behavior of time-series features in a dataset, this approach embodies \"generation by imitation\". Theoretically, we illustrate the correctness of this formulation and the consistency of the algorithm. Empirically, we evaluate its ability to generate predictively useful samples from real-world datasets, verifying that it performs at the standard of existing benchmarks.",
    "authors": [
      "Jarrett, Daniel",
      "Bica, Ioana",
      "van der Schaar, Mihaela"
    ]
  },
  {
    "id": "f2b5e92f61b6de923b063588ee6e7c48",
    "title": "Differentially Private Sampling from Distributions",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f2b5e92f61b6de923b063588ee6e7c48-Paper.pdf",
    "abstract": "We initiate an investigation of  private sampling from distributions. Given a dataset with $n$ independent observations from an unknown distribution $P$, a sampling algorithm must output a single observation from a distribution that is close in total variation distance to $P$ while satisfying differential privacy. Sampling abstracts the goal of generating small amounts of realistic-looking data. We provide tight upper and lower bounds for the dataset size needed for this task for three natural families of distributions: arbitrary distributions on $\\{1,\\ldots ,k\\}$, arbitrary product distributions on $\\{0,1\\}^d$, and product distributions on on $\\{0,1\\}^d$ with bias in each coordinate bounded away from 0 and 1. We demonstrate that, in some parameter regimes, private sampling requires asymptotically fewer observations than learning a description of $P$ nonprivately; in other regimes, however, private sampling proves to be as difficult as private learning. Notably, for some classes of distributions, the overhead in the number of observations needed for private learning compared to non-private learning is completely captured by the number of observations needed for private sampling.",
    "authors": [
      "Raskhodnikova, Sofya",
      "Sivakumar, Satchit",
      "Smith, Adam",
      "Swanberg, Marika"
    ]
  },
  {
    "id": "f2c3b258e9cd8ba16e18f319b3c88c66",
    "title": "On the Expected Complexity of Maxout Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f2c3b258e9cd8ba16e18f319b3c88c66-Paper.pdf",
    "abstract": "Learning with neural networks relies on the complexity of their representable functions, but more importantly, their particular assignment of typical parameters to functions of different complexity. Taking the number of activation regions as a complexity measure, recent works have shown that the practical complexity of deep ReLU networks is often far from the theoretical maximum. In this work, we show that this phenomenon also occurs in networks with maxout (multi-argument) activation functions and when considering the decision boundaries in classification tasks. We also show that the parameter space has a multitude of full-dimensional regions with widely different complexity, and obtain nontrivial lower bounds on the expected complexity. Finally, we investigate different parameter initialization procedures and show that they can increase the speed of convergence in training. ",
    "authors": [
      "Tseran, Hanna",
      "Montufar, Guido F."
    ]
  },
  {
    "id": "f31b20466ae89669f9741e047487eb37",
    "title": "Cross-view Geo-localization with Layer-to-Layer Transformer",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f31b20466ae89669f9741e047487eb37-Paper.pdf",
    "abstract": "In this work, we address the problem of cross-view geo-localization, which estimates the geospatial location of a street view image by matching it with a database of geo-tagged aerial images. The cross-view matching task is extremely challenging due to drastic appearance and geometry differences across views. Unlike existing methods that predominantly fall back on CNN, here we devise a novel layer-to-layer Transformer (L2LTR) that utilizes the properties of self-attention in Transformer to model global dependencies, thus significantly decreasing visual ambiguities in cross-view geo-localization. We also exploit the positional encoding of the Transformer to help the L2LTR understand and correspond geometric configurations between ground and aerial images. Compared to state-of-the-art methods that impose strong assumptions on geometry knowledge, the L2LTR flexibly learns the positional embeddings through the training objective. It hence becomes more practical in many real-world scenarios. Although Transformer is well suited to our task, its vanilla self-attention mechanism independently interacts within image patches in each layer, which overlooks correlations between layers. Instead, this paper proposes a simple yet effective self-cross attention mechanism to improve the quality of learned representations. Self-cross attention models global dependencies between adjacent layers and creates short paths for effective information flow. As a result, the proposed self-cross attention leads to more stable training, improves the generalization ability, and prevents the learned intermediate features from being overly similar. Extensive experiments demonstrate that our L2LTR performs favorably against state-of-the-art methods on standard, fine-grained, and cross-dataset cross-view geo-localization tasks. The code is available online.",
    "authors": [
      "Yang, Hongji",
      "Lu, Xiufan",
      "Zhu, Yingying"
    ]
  },
  {
    "id": "f337d999d9ad116a7b4f3d409fcc6480",
    "title": "TAAC: Temporally Abstract Actor-Critic for Continuous Control",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f337d999d9ad116a7b4f3d409fcc6480-Paper.pdf",
    "abstract": "We present temporally abstract actor-critic (TAAC), a simple but effective off-policy RL algorithm that incorporates closed-loop temporal abstraction into the actor-critic framework. TAAC adds a second-stage binary policy to choose between the previous action and a new action output by an actor. Crucially, its \"act-or-repeat\" decision hinges on the actually sampled action instead of the expected behavior of the actor. This post-acting switching scheme let the overall policy make more informed decisions. TAAC has two important features: a) persistent exploration, and b) a new compare-through Q operator for multi-step TD backup, specially tailored to the action repetition scenario. We demonstrate TAAC's advantages over several strong baselines across 14 continuous control tasks. Our surprising finding reveals that while achieving top performance, TAAC is able to \"mine\" a significant number of repeated actions with the trained policy even on continuous tasks whose problem structures on the surface seem to repel action repetition. This suggests that aside from encouraging persistent exploration, action repetition can find its place in a good policy behavior. Code is available at https://github.com/hnyu/taac.",
    "authors": [
      "Yu, Haonan",
      "Xu, Wei",
      "Zhang, Haichao"
    ]
  },
  {
    "id": "f33ba15effa5c10e873bf3842afb46a6",
    "title": "Learning Robust Hierarchical Patterns of Human Brain across Many fMRI Studies",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f33ba15effa5c10e873bf3842afb46a6-Paper.pdf",
    "abstract": "Multi-site fMRI studies face the challenge that the pooling introduces systematic non-biological site-specific variance due to hardware, software, and environment. In this paper, we propose to reduce site-specific variance in the estimation of hierarchical Sparsity Connectivity Patterns (hSCPs) in fMRI data via a simple yet effective matrix factorization while preserving biologically relevant variations. Our method leverages unsupervised adversarial learning to improve the reproducibility of the components. Experiments on simulated datasets display that the proposed method can estimate components with higher accuracy and reproducibility, while preserving age-related variation on a multi-center clinical data set. ",
    "authors": [
      "Sahoo, Dushyant",
      "Davatzikos, Christos"
    ]
  },
  {
    "id": "f3507289cfdc8c9ae93f4098111a13f9",
    "title": "Global Convergence  to Local Minmax Equilibrium in Classes of Nonconvex Zero-Sum Games",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f3507289cfdc8c9ae93f4098111a13f9-Paper.pdf",
    "abstract": "We study gradient descent-ascent learning dynamics with timescale separation ($\\tau$-GDA) in unconstrained continuous action zero-sum games where the minimizing player faces a nonconvex optimization problem and the maximizing player optimizes a Polyak-Lojasiewicz (PL) or strongly-concave (SC) objective. In contrast to past work on gradient-based learning in nonconvex-PL/SC zero-sum games, we assess convergence in relation to natural game-theoretic equilibria instead of only notions of stationarity. In pursuit of this goal, we prove that the only locally stable points of the $\\tau$-GDA continuous-time limiting system correspond to strict local minmax equilibria in each class of games. For these classes of games, we exploit timescale separation to construct a potential function that when combined with the stability characterization and an asymptotic saddle avoidance result gives a global asymptotic almost-sure convergence guarantee for the discrete-time gradient descent-ascent update to a set of the strict local minmax equilibrium. Moreover, we provide convergence rates for the gradient descent-ascent dynamics with timescale separation to approximate stationary points.",
    "authors": [
      "Fiez, Tanner",
      "Ratliff, Lillian",
      "Mazumdar, Eric",
      "Faulkner, Evan",
      "Narang, Adhyyan"
    ]
  },
  {
    "id": "f3a4ff4839c56a5f460c88cce3666a2b",
    "title": "Bandit Quickest Changepoint Detection",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f3a4ff4839c56a5f460c88cce3666a2b-Paper.pdf",
    "abstract": "Many industrial and security applications employ a suite of sensors for detecting abrupt changes in temporal behavior patterns. These abrupt changes typically manifest locally, rendering only a small subset of sensors informative. Continuous monitoring of every sensor can be expensive due to resource constraints, and serves as a motivation for the bandit quickest changepoint detection problem, where sensing actions (or sensors) are sequentially chosen, and only measurements corresponding to chosen actions are observed. We derive an information-theoretic lower bound on the detection delay for a general class of finitely parameterized probability distributions. We then propose a computationally efficient online sensing scheme, which seamlessly balances the need for exploration of different sensing options with exploitation of querying informative actions. We derive expected delay bounds for the proposed scheme and show that these bounds match our information-theoretic lower bounds at low false alarm rates, establishing optimality of the proposed method. We then perform a number of experiments on synthetic and real datasets demonstrating the effectiveness of our proposed method.",
    "authors": [
      "Gopalan, Aditya",
      "Lakshminarayanan, Braghadeesh",
      "Saligrama, Venkatesh"
    ]
  },
  {
    "id": "f3b7e5d3eb074cde5b76e26bc0fb5776",
    "title": "Can multi-label classification networks know what they don\u2019t know?",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f3b7e5d3eb074cde5b76e26bc0fb5776-Paper.pdf",
    "abstract": "Estimating out-of-distribution (OOD) uncertainty is a major challenge for safely deploying machine learning models in the open-world environment. Improved methods for OOD detection in multi-class classification have emerged, while OOD detection methods for multi-label classification remain underexplored and use rudimentary techniques. We propose JointEnergy, a simple and effective method, which estimates the OOD indicator scores by aggregating label-wise energy scores from multiple labels. We show that JointEnergy can be mathematically interpreted from a joint likelihood perspective. Our results show consistent improvement over previous methods that are based on the maximum-valued scores, which fail to capture joint information from multiple labels. We demonstrate the effectiveness of our method on three common multi-label classification benchmarks, including MS-COCO, PASCAL-VOC, and NUS-WIDE. We show that JointEnergy can reduce the FPR95 by up to 10.05% compared to the previous best baseline, establishing state-of-the-art performance. ",
    "authors": [
      "Wang, Haoran",
      "Liu, Weitang",
      "Bocchieri, Alex",
      "Li, Yixuan"
    ]
  },
  {
    "id": "f3bd5ad57c8389a8a1a541a76be463bf",
    "title": "Balanced Chamfer Distance as a Comprehensive Metric for Point Cloud Completion",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f3bd5ad57c8389a8a1a541a76be463bf-Paper.pdf",
    "abstract": "Chamfer Distance (CD) and Earth Mover\u2019s Distance (EMD) are two broadly adopted metrics for measuring the similarity between two point sets. However, CD is usually insensitive to mismatched local density, and EMD is usually dominated by global distribution while overlooks the fidelity of detailed structures. Besides, their unbounded value range induces a heavy influence from the outliers. These defects prevent them from providing a consistent evaluation. To tackle these problems, we propose a new similarity measure named Density-aware Chamfer Distance (DCD). It is derived from CD and benefits from several desirable properties: 1) it can detect disparity of density distributions and is thus a more intensive measure of similarity compared to CD; 2) it is stricter with detailed structures and significantly more computationally efficient than EMD; 3) the bounded value range encourages a more stable and reasonable evaluation over the whole test set. We adopt DCD to evaluate the point cloud completion task, where experimental results show that DCD pays attention to both the overall structure and local geometric details and provides a more reliable evaluation even when CD and EMD contradict each other. We can also use DCD as the training loss, which outperforms the same model trained with CD loss on all three metrics. In addition, we propose a novel point discriminator module that estimates the priority for another guided down-sampling step, and it achieves noticeable improvements under DCD together with competitive results for both CD and EMD. We hope our work could pave the way for a more comprehensive and practical point cloud similarity evaluation. Our code will be available at https://github.com/wutong16/DensityawareChamfer_Distance.",
    "authors": [
      "Wu, Tong",
      "Pan, Liang",
      "Zhang, Junzhe",
      "WANG, Tai",
      "Liu, Ziwei",
      "Lin, Dahua"
    ]
  },
  {
    "id": "f3d9de86462c28781cbe5c47ef22c3e5",
    "title": "Optimal Gradient-based Algorithms for Non-concave Bandit Optimization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f3d9de86462c28781cbe5c47ef22c3e5-Paper.pdf",
    "abstract": "Bandit problems with linear or concave reward have been extensively studied, but relatively few works have studied bandits with non-concave reward. This work considers a large family of bandit problems where the unknown underlying reward function is non-concave, including the low-rank generalized linear bandit problems and two-layer neural network with polynomial activation bandit problem.For the low-rank generalized linear bandit problem, we provide a minimax-optimal algorithm in the dimension, refuting both conjectures in \\cite{lu2021low,jun2019bilinear}. Our algorithms are based on a unified zeroth-order optimization paradigm that applies in great generality and attains optimal rates in several structured polynomial settings (in the dimension). We further demonstrate the applicability of our algorithms in RL in the generative model setting, resulting in improved sample complexity over prior approaches.Finally, we show that the standard optimistic algorithms (e.g., UCB) are sub-optimal by dimension factors. In the neural net setting (with polynomial activation functions) with noiseless reward, we provide a bandit algorithm with sample complexity equal to the intrinsic algebraic dimension. Again, we show that optimistic approaches have worse sample complexity, polynomial in the extrinsic dimension (which could be exponentially worse in the polynomial degree).",
    "authors": [
      "Huang, Baihe",
      "Huang, Kaixuan",
      "Kakade, Sham",
      "Lee, Jason D.",
      "Lei, Qi",
      "Wang, Runzhe",
      "Yang, Jiaqi"
    ]
  },
  {
    "id": "f3e0eb8f4ae5f3afd35b5e4b6e5a2d78",
    "title": "On Optimal Interpolation in Linear Regression",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f3e0eb8f4ae5f3afd35b5e4b6e5a2d78-Paper.pdf",
    "abstract": "Understanding when and why interpolating methods generalize well has recently been a topic of interest in statistical learning theory. However, systematically connecting interpolating methods to achievable notions of optimality has only received partial attention. In this paper, we ask the question of what is the optimal way to interpolate in linear regression using functions that are linear in the response variable (as the case for the Bayes optimal estimator in ridge regression) and depend on the data, the population covariance of the data, the signal-to-noise ratio and the covariance of the prior for the signal, but do not depend on the value of the signal itself nor the noise vector in the training data. We provide a closed-form expression for the interpolator that achieves this notion of optimality and show that it can be derived as the limit of preconditioned gradient descent with a specific initialization. We identify a regime where the minimum-norm interpolator provably generalizes arbitrarily worse than the optimal response-linear achievable interpolator that we introduce, and validate with numerical experiments that the notion of optimality we consider can be achieved by interpolating methods that only use the training data as input in the case of an isotropic prior. Finally, we extend the notion of optimal response-linear interpolation to random features regression under a linear data-generating model.",
    "authors": [
      "Oravkin, Eduard",
      "Rebeschini, Patrick"
    ]
  },
  {
    "id": "f3f1b7fc5a8779a9e618e1f23a7b7860",
    "title": "Differentiable Optimization of Generalized Nondecomposable Functions using Linear Programs",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f3f1b7fc5a8779a9e618e1f23a7b7860-Paper.pdf",
    "abstract": "We propose a framework which makes it feasible to directly train deep neural networks with respect to popular families of task-specific non-decomposable performance measures such as AUC, multi-class AUC, $F$-measure and others. A common feature of the optimization model that emerges from these tasks is that it involves solving a Linear Programs (LP) during training where representations learned by upstream layers characterize the constraints or the feasible set. The constraint matrix is not only large but the constraints are also modified at each iteration. We show how adopting a set of ingenious ideas proposed by Mangasarian for 1-norm SVMs -- which advocates for solving LPs with a generalized Newton method -- provides a simple and effective solution that can be run on the GPU. In particular, this strategy needs little unrolling, which makes it more efficient during backward pass. Further, even when the constraint matrix is too large to fit on the GPU memory (say large minibatch settings), we show that running the Newton method in a lower dimensional space yields accurate gradients for training, by utilizing a statistical concept called {\\em sufficient}  dimension reduction. While a number of specialized algorithms have been proposed for the models that we describe here, our module turns out to be applicable without any  specific adjustments or relaxations. We describe each use case, study its properties and demonstrate the efficacy of the approach over alternatives which use surrogate lower bounds and often, specialized optimization schemes. Frequently, we achieve superior computational behavior and performance improvements on common datasets used in the literature. ",
    "authors": [
      "Meng, Zihang",
      "Mukherjee, Lopamudra",
      "Wu, Yichao",
      "Singh, Vikas",
      "Ravi, Sathya"
    ]
  },
  {
    "id": "f3f1fa1e4348bfbebdeee8c80a04c3b9",
    "title": "Towards Understanding Cooperative Multi-Agent Q-Learning with Value Factorization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f3f1fa1e4348bfbebdeee8c80a04c3b9-Paper.pdf",
    "abstract": "Value factorization is a popular and promising approach to scaling up multi-agent reinforcement learning in cooperative settings, which balances the learning scalability and the representational capacity of value functions. However, the theoretical understanding of such methods is limited. In this paper, we formalize a multi-agent fitted Q-iteration framework for analyzing factorized multi-agent Q-learning. Based on this framework, we investigate linear value factorization and reveal that multi-agent Q-learning with this simple decomposition implicitly realizes a powerful counterfactual credit assignment, but may not converge in some settings. Through further analysis, we find that on-policy training or richer joint value function classes can improve its local or global convergence properties, respectively. Finally, to support our theoretical implications in practical realization, we conduct an empirical analysis of state-of-the-art deep multi-agent Q-learning algorithms on didactic examples and a broad set of StarCraft II unit micromanagement tasks.",
    "authors": [
      "Wang, Jianhao",
      "Ren, Zhizhou",
      "Han, Beining",
      "Ye, Jianing",
      "Zhang, Chongjie"
    ]
  },
  {
    "id": "f40723ed94042ea9ea36bfb5ad4157b2",
    "title": "Margin-Independent Online Multiclass Learning via Convex Geometry",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f40723ed94042ea9ea36bfb5ad4157b2-Paper.pdf",
    "abstract": "We consider the problem of multi-class classification, where a stream of adversarially chosen queries arrive and must be assigned a label online. Unlike traditional bounds which seek to minimize the misclassification rate, we minimize the total distance from each query to the region corresponding to its assigned label. When the true labels are determined via a nearest neighbor partition -- i.e. the label of a point is given by which of $k$ centers it is closest to in Euclidean distance -- we show that one can achieve a loss that is independent of the total number of queries. We complement this result by showing that learning general convex sets requires an almost linear loss per query. Our results build off of regret guarantees for the problem of contextual search. In addition, we develop a novel reduction technique from multiclass classification to binary classification which may be of independent interest. ",
    "authors": [
      "Guruganesh, Guru",
      "Liu, Allen",
      "Schneider, Jon",
      "Wang, Joshua"
    ]
  },
  {
    "id": "f4334c131c781e2a6f0a5e34814c8147",
    "title": "STEP: Out-of-Distribution Detection in the Presence of Limited In-Distribution Labeled Data",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f4334c131c781e2a6f0a5e34814c8147-Paper.pdf",
    "abstract": "Existing semi-supervised learning (SSL) studies typically assume that unlabeled and test data are drawn from the same distribution as labeled data. However, in many real-world applications, it is desirable to have SSL algorithms that not only classify the samples drawn from the same distribution of labeled data but also detect out-of-distribution (OOD) samples drawn from an unknown distribution. In this paper, we study a setting called semi-supervised OOD detection. Two main challenges compared with previous OOD detection settings are i) the lack of labeled data and in-distribution data; ii) OOD samples could be unseen during training. Efforts on this direction remain limited. In this paper, we present an approach STEP significantly improving OOD detection performance by introducing a new technique: Structure-Keep Unzipping. It learns a new representation space in which OOD samples could be separated well. An efficient optimization algorithm is derived to solve the objective. Comprehensive experiments across various OOD detection benchmarks clearly show that our STEP approach outperforms other methods by a large margin and achieves remarkable detection performance on several benchmarks. ",
    "authors": [
      "Zhou, Zhi",
      "Guo, Lan-Zhe",
      "Cheng, Zhanzhan",
      "Li, Yu-Feng",
      "Pu, Shiliang"
    ]
  },
  {
    "id": "f44ec26e2ac3f1ab8c2472d4b1c2ea86",
    "title": "Renyi Differential Privacy of The Subsampled Shuffle Model In Distributed Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f44ec26e2ac3f1ab8c2472d4b1c2ea86-Paper.pdf",
    "abstract": "We study privacy in a distributed learning framework, where clients collaboratively build a learning model iteratively throughinteractions with a server from whom we need privacy. Motivated by stochastic optimization and the federated learning (FL) paradigm, we focus on the case where a small fraction of data samples are randomly sub-sampled in each round to participate in the learning process, which also enables privacy amplification.  To obtain even stronger local privacy guarantees, we study this in the shuffle privacy model, where each client randomizes its response using a local differentially private (LDP) mechanism and the server only receives a random permutation (shuffle) of the clients' responses without theirassociation to each client. The principal result of this paper is a privacy-optimization performance trade-off for discrete randomization mechanisms in this sub-sampled shuffle privacy model. This is enabledthrough a new theoretical technique to analyze the Renyi Differential Privacy (RDP) of the sub-sampled shuffle model.  We numerically demonstrate that, for important regimes, with composition our boundyields significant improvement in privacy guarantee over the state-of-the-art approximate Differential Privacy (DP) guarantee (with strong composition) for sub-sampled shuffled models. We also demonstrate numerically significant improvement in privacy-learning performance operating point using real data sets. Despite these advances, an open question is to bridge the gap between lower and upper privacy bounds in our RDP analysis.",
    "authors": [
      "Girgis, Antonious",
      "Data, Deepesh",
      "Diggavi, Suhas"
    ]
  },
  {
    "id": "f45a1078feb35de77d26b3f7a52ef502",
    "title": "Gradient-based Editing of Memory Examples for Online Task-free Continual Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f45a1078feb35de77d26b3f7a52ef502-Paper.pdf",
    "abstract": "We explore task-free continual learning (CL), in which a model is trained to avoid catastrophic forgetting in the absence of explicit task boundaries or identities. Among many efforts on task-free CL, a notable family of approaches are memory-based that store and replay a subset of training examples. However, the utility of stored seen examples may diminish over time since CL models are continually updated. Here, we propose Gradient based Memory EDiting (GMED), a framework for editing stored examples in continuous input space via gradient updates, in order to create more \"challenging\" examples for replay. GMED-edited examples remain similar to their unedited forms, but can yield increased loss in the upcoming model updates, thereby making the future replays more effective in overcoming catastrophic forgetting. By construction, GMED can be seamlessly applied in conjunction with other memory-based CL algorithms to bring further improvement. Experiments validate the effectiveness of GMED, and our best method significantly outperforms baselines and previous state-of-the-art on five out of six datasets. ",
    "authors": [
      "Jin, Xisen",
      "Sadhu, Arka",
      "Du, Junyi",
      "Ren, Xiang"
    ]
  },
  {
    "id": "f45cc474bff52cb1b2268a2f94a2abcf",
    "title": "Tailoring: encoding inductive biases by optimizing unsupervised objectives at prediction time",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f45cc474bff52cb1b2268a2f94a2abcf-Paper.pdf",
    "abstract": "From CNNs to attention mechanisms, encoding inductive biases into neural networks has been a fruitful source of improvement in machine learning. Adding auxiliary losses to the main objective function is a general way of encoding biases that can help networks learn better representations. However, since auxiliary losses are minimized only on training data, they suffer from the same generalization gap as regular task losses. Moreover, by adding a term to the loss function, the model optimizes a different objective than the one we care about. In this work we address both problems: first, we take inspiration from transductive learning and note that after receiving an input but before making a prediction, we can fine-tune our networks on any unsupervised loss. We call this process tailoring, because we customize the model to each input to ensure our prediction satisfies the inductive bias. Second, we formulate meta-tailoring, a nested optimization similar to that in meta-learning, and train our models to perform well on the task objective after adapting them using an unsupervised loss. The advantages of tailoring and meta-tailoring are discussed theoretically and demonstrated empirically on a diverse set of examples.",
    "authors": [
      "Alet, Ferran",
      "Bauza, Maria",
      "Kawaguchi, Kenji",
      "Kuru, Nurullah Giray",
      "Lozano-P\u00e9rez, Tom\u00e1s",
      "Kaelbling, Leslie"
    ]
  },
  {
    "id": "f4661398cb1a3abd3ffe58600bf11322",
    "title": "Implicit Bias of SGD for Diagonal Linear Networks: a Provable Benefit of Stochasticity",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f4661398cb1a3abd3ffe58600bf11322-Paper.pdf",
    "abstract": "Understanding the implicit bias of training algorithms is of crucial importance in order to explain the success of overparametrised neural networks. In this paper, we study the dynamics of stochastic gradient descent over diagonal linear networks through its continuous time version, namely stochastic gradient flow. We explicitly characterise the solution chosen by the stochastic flow and prove that it always enjoys better generalisation properties than that of gradient flow.Quite surprisingly, we show that the convergence speed of the training loss controls the magnitude of the biasing effect: the slower the convergence, the better the bias. To fully complete our analysis, we provide convergence guarantees for the dynamics. We also give experimental results which support our theoretical claims. Our findings highlight the fact that structured noise can induce better generalisation and they help explain the greater performances of stochastic gradient  descent over gradient descent observed in practice.",
    "authors": [
      "Pesme, Scott",
      "Pillaud-Vivien, Loucas",
      "Flammarion, Nicolas"
    ]
  },
  {
    "id": "f48c04ffab49ff0e5d1176244fdfb65c",
    "title": "Iterative Teacher-Aware Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f48c04ffab49ff0e5d1176244fdfb65c-Paper.pdf",
    "abstract": "In human pedagogy, teachers and students can interact adaptively to maximize communication efficiency. The teacher adjusts her teaching method for different students, and the student, after getting familiar with the teacher\u2019s instruction mechanism, can infer the teacher\u2019s intention to learn faster. Recently, the benefits of integrating this cooperative pedagogy into machine concept learning in discrete spaces have been proved by multiple works. However, how cooperative pedagogy can facilitate machine parameter learning hasn\u2019t been thoroughly studied. In this paper, we propose a gradient optimization based teacher-aware learner who can incorporate teacher\u2019s cooperative intention into the likelihood function and learn provably faster compared with the naive learning algorithms used in previous machine teaching works. We give theoretical proof that the iterative teacher-aware learning (ITAL) process leads to local and global improvements. We then validate our algorithms with extensive experiments on various tasks including regression, classification, and inverse reinforcement learning using synthetic and real data. We also show the advantage of modeling teacher-awareness when agents are learning from human teachers.",
    "authors": [
      "Yuan, Luyao",
      "Zhou, Dongruo",
      "Shen, Junhong",
      "Gao, Jingdong",
      "Chen, Jeffrey L",
      "Gu, Quanquan",
      "Wu, Ying Nian",
      "Zhu, Song-Chun"
    ]
  },
  {
    "id": "f490d0af974fedf90cb0f1edce8e3dd5",
    "title": "Clockwork Variational Autoencoders",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f490d0af974fedf90cb0f1edce8e3dd5-Paper.pdf",
    "abstract": "Deep learning has enabled algorithms to generate realistic images. However, accurately predicting long video sequences requires understanding long-term dependencies and remains an open challenge. While existing video prediction models succeed at generating sharp images, they tend to fail at accurately predicting far into the future. We introduce the Clockwork VAE (CW-VAE), a video prediction model that leverages a hierarchy of latent sequences, where higher levels tick at slower intervals. We demonstrate the benefits of both hierarchical latents and temporal abstraction on 4 diverse video prediction datasets with sequences of up to 1000 frames, where CW-VAE outperforms top video prediction models. Additionally, we propose a Minecraft benchmark for long-term video prediction. We conduct several experiments to gain insights into CW-VAE and confirm that slower levels learn to represent objects that change more slowly in the video, and faster levels learn to represent faster objects.",
    "authors": [
      "Saxena, Vaibhav",
      "Ba, Jimmy",
      "Hafner, Danijar"
    ]
  },
  {
    "id": "f4e369c0a468d3aeeda0593ba90b5e55",
    "title": "How Does it Sound?",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f4e369c0a468d3aeeda0593ba90b5e55-Paper.pdf",
    "abstract": "One of the primary purposes of video is to capture people and their unique activities. It is often the case that the experience of watching the video can be enhanced by adding a musical soundtrack that is in-sync with the rhythmic features of these activities. How would this soundtrack sound? Such a problem is challenging since little is known about capturing the rhythmic nature of free body movements. In this work, we explore this problem and propose a novel system, called `RhythmicNet', which takes as an input a video which includes human movements and generates a soundtrack for it. RhythmicNet works directly with human movements by extracting skeleton keypoints and implements a sequence of models which translate the keypoints to rhythmic sounds.RhythmicNet follows the natural process of music improvisation which includes the prescription of streams of the beat, the rhythm and the melody. In particular, RhythmicNet first infers the music beat and the style pattern from body keypoints per each frame to produce rhythm. Next, it implements a transformer-based model to generate the hits of drum instruments and implements a U-net based model to generate the velocity and the offsets of the instruments. Additional types of instruments are added to the soundtrack by further conditioning on the generated drum sounds. We evaluate RhythmicNet on large scale datasets of videos that include body movements with inherit sound association, such as dance, as well as 'in the wild' internet videos of various movements and actions. We show that the method can generate plausible music that aligns well with different types of human movements.",
    "authors": [
      "Su, Kun",
      "Liu, Xiulong",
      "Shlizerman, Eli"
    ]
  },
  {
    "id": "f4f6dce2f3a0f9dada0c2b5b66452017",
    "title": "Stabilizing Dynamical Systems via Policy Gradient Methods",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f4f6dce2f3a0f9dada0c2b5b66452017-Paper.pdf",
    "abstract": "Stabilizing an unknown control system is one of the most fundamental problems in control systems engineering.  In this paper, we provide a simple, model-free algorithm for stabilizing fully observed dynamical systems.  While model-free methods have become increasingly popular in practice due to their simplicity and flexibility, stabilization via direct policy search has received surprisingly little attention. Our algorithm proceeds by solving a series of discounted LQR problems, where the discount factor is gradually increased. We prove that this method efficiently recovers a stabilizing controller for linear systems, and for smooth, nonlinear systems within a neighborhood of their equilibria. Our approach overcomes a significant limitation of prior work, namely the need for a pre-given stabilizing control policy. We empirically evaluate the effectiveness of our approach on common control benchmarks. ",
    "authors": [
      "Perdomo, Juan",
      "Umenberger, Jack",
      "Simchowitz, Max"
    ]
  },
  {
    "id": "f51338d736f95dd42427296047067694",
    "title": "Language models enable zero-shot prediction of the effects of mutations on protein function",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f51338d736f95dd42427296047067694-Paper.pdf",
    "abstract": "Modeling the effect of sequence variation on function is a fundamental problem for understanding and designing proteins. Since evolution encodes information about function into patterns in protein sequences, unsupervised models of variant effects can be learned from sequence data. The approach to date has been to fit a model to a family of related sequences. The conventional setting is limited, since a new model must be trained for each prediction task. We show that using only zero-shot inference, without any supervision from experimental data or additional training, protein language models capture the functional effects of sequence variation, performing at state-of-the-art.",
    "authors": [
      "Meier, Joshua",
      "Rao, Roshan",
      "Verkuil, Robert",
      "Liu, Jason",
      "Sercu, Tom",
      "Rives, Alex"
    ]
  },
  {
    "id": "f514cec81cb148559cf475e7426eed5e",
    "title": "Deep Reinforcement Learning at the Edge of the Statistical Precipice",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f514cec81cb148559cf475e7426eed5e-Paper.pdf",
    "abstract": "Deep reinforcement learning (RL) algorithms are predominantly evaluated by comparing their relative performance on a large suite of tasks. Most published results on deep RL benchmarks compare point estimates of aggregate performance such as mean and median scores across tasks, ignoring the statistical uncertainty implied by the use of a finite number of training runs. Beginning with the Arcade Learning Environment (ALE), the shift towards computationally-demanding benchmarks has led to the practice of evaluating only a small number of runs per task, exacerbating the statistical uncertainty in point estimates. In this paper, we argue that reliable evaluation in the few run deep RL regime cannot ignore the uncertainty in results without running the risk of slowing down progress in the field. We illustrate this point using a case study on the Atari 100k benchmark, where we find substantial discrepancies between conclusions drawn from point estimates alone versus a more thorough statistical analysis. With the aim of increasing the field's confidence in reported results with a handful of runs, we advocate for reporting interval estimates of aggregate performance and propose performance profiles to account for the variability in results, as well as present more robust and efficient aggregate metrics, such as interquartile mean scores, to achieve small uncertainty in results. Using such statistical tools, we scrutinize performance evaluations of existing algorithms on other widely used RL benchmarks including the ALE, Procgen, and the DeepMind Control Suite, again revealing discrepancies in prior comparisons. Our findings call for a change in how we evaluate performance in deep RL, for which we present a more rigorous evaluation methodology, accompanied with an open-source library rliable, to prevent unreliable results from stagnating the field. This work received an outstanding paper award at NeurIPS 2021.",
    "authors": [
      "Agarwal, Rishabh",
      "Schwarzer, Max",
      "Castro, Pablo Samuel",
      "Courville, Aaron C.",
      "Bellemare, Marc"
    ]
  },
  {
    "id": "f56de5ef149cf0aedcc8f4797031e229",
    "title": "DRONE: Data-aware Low-rank Compression for Large NLP Models",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f56de5ef149cf0aedcc8f4797031e229-Paper.pdf",
    "abstract": "The representations learned by large-scale NLP models such as BERT have been widely used in various tasks. However, the increasing model size of the pre-trained models also brings efficiency challenges, including inference speed and model size when deploying models on mobile devices. Specifically, most operations in BERT consist of matrix multiplications. These matrices are not low-rank and thus canonical matrix decomposition could not find an efficient approximation. In this paper, we observe that the learned representation of each layer lies in a low-dimensional space. Based on this observation, we propose DRONE (data-aware low-rank compression), a provably optimal low-rank decomposition of weight matrices, which has a simple closed form solution that can be efficiently computed. DRONE can be applied to both fully connected and self-attention layers appearing in the BERT model. In addition to compressing standard models, out method can also be used on distilled BERT models to further improve compression rate. Experimental results show that DRONE is able to improve both model size and inference speed with limited loss in accuracy. Specifically, DRONE alone achieves 1.92x speedup on the MRPC task with only 1.5% loss in accuracy, and when DRONE is combined with distillation, it further achieves over 12.3x speedup on various natural language inference tasks.",
    "authors": [
      "Chen, Patrick",
      "Yu, Hsiang-Fu",
      "Dhillon, Inderjit",
      "Hsieh, Cho-Jui"
    ]
  },
  {
    "id": "f5ac21cd0ef1b88e9848571aeb53551a",
    "title": "DSelect-k: Differentiable Selection in the Mixture of Experts with Applications to Multi-Task Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f5ac21cd0ef1b88e9848571aeb53551a-Paper.pdf",
    "abstract": "The Mixture-of-Experts (MoE) architecture is showing promising results in improving parameter sharing in multi-task learning (MTL) and in scaling high-capacity neural networks. State-of-the-art MoE models use a trainable \"sparse gate'\" to select a subset of the experts for each input example. While conceptually appealing, existing sparse gates, such as Top-k, are not smooth. The lack of smoothness can lead to convergence and statistical performance issues when training with gradient-based methods. In this paper, we develop DSelect-k: a continuously differentiable and sparse gate for MoE, based on a novel binary encoding formulation. The gate can be trained using first-order methods, such as stochastic gradient descent, and offers explicit control over the number of experts to select. We demonstrate the effectiveness of DSelect-k on both synthetic and real MTL datasets with up to 128 tasks. Our experiments indicate that DSelect-k can achieve statistically significant improvements in prediction and expert selection over popular MoE gates. Notably, on a real-world, large-scale recommender system, DSelect-k achieves over 22% improvement in predictive performance compared to Top-k. We provide an open-source implementation of DSelect-k.",
    "authors": [
      "Hazimeh, Hussein",
      "Zhao, Zhe",
      "Chowdhery, Aakanksha",
      "Sathiamoorthy, Maheswaran",
      "Chen, Yihua",
      "Mazumder, Rahul",
      "Hong, Lichan",
      "Chi, Ed"
    ]
  },
  {
    "id": "f5bf0ba0a17ef18f9607774722f5698c",
    "title": "Mind the Gap: Assessing Temporal Generalization in Neural Language Models",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f5bf0ba0a17ef18f9607774722f5698c-Paper.pdf",
    "abstract": "Our world is open-ended, non-stationary, and constantly evolving; thus what we talk about and how we talk about it change over time. This inherent dynamic nature of language contrasts with the current static language modelling paradigm, which trains and evaluates models on utterances from overlapping time periods. Despite impressive recent progress, we demonstrate that Transformer-XL language models perform worse in the realistic setup of predicting future utterances from beyond their training period, and that model performance becomes increasingly worse with time. We find that, while increasing model size alone\u2014a key driver behind recent progress\u2014does not solve this problem, having models that continually update their knowledge with new information can indeed mitigate this performance degradation over time. Hence, given the compilation of ever-larger language modelling datasets, combined with the growing list of language-model-based NLP applications that require up-to-date factual knowledge about the world, we argue that now is the right time to rethink the static way in which we currently train and evaluate our language models, and develop adaptive language models that can remain up-to-date with respect to our ever-changing and non-stationary world. We publicly release our dynamic, streaming language modelling benchmarks for WMT and arXiv to facilitate language model evaluation that takes temporal dynamics into account.",
    "authors": [
      "Lazaridou, Angeliki",
      "Kuncoro, Adhi",
      "Gribovskaya, Elena",
      "Agrawal, Devang",
      "Liska, Adam",
      "Terzi, Tayfun",
      "Gimenez, Mai",
      "de Masson d'Autume, Cyprien",
      "Kocisky, Tomas",
      "Ruder, Sebastian",
      "Yogatama, Dani",
      "Cao, Kris",
      "Young, Susannah",
      "Blunsom, Phil"
    ]
  },
  {
    "id": "f5c3dd7514bf620a1b85450d2ae374b1",
    "title": "Heavy Tails in SGD and Compressibility of Overparametrized Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f5c3dd7514bf620a1b85450d2ae374b1-Paper.pdf",
    "abstract": "Neural network compression techniques have become increasingly popular as they can drastically reduce the storage and computation requirements for very large networks. Recent empirical studies have illustrated that even simple pruning strategies can be surprisingly effective, and several theoretical studies have shown that compressible networks (in specific senses) should achieve a low generalization error. Yet, a theoretical characterization of the underlying causes that make the networks amenable to such simple compression schemes is still missing. In this study, focusing our attention on stochastic gradient descent (SGD), our main contribution is to link compressibility to two recently established properties of SGD: (i) as the network size goes to infinity, the system can converge to a mean-field limit, where the network weights behave independently [DBDF\u015e20], (ii) for a large step-size/batch-size ratio, the SGD iterates can converge to a heavy-tailed stationary distribution  [HM20, G\u015eZ21]. Assuming that both of these phenomena occur simultaneously, we prove that the networks are guaranteed to be '$\\ell_p$-compressible', and the compression errors of different pruning techniques (magnitude, singular value, or node pruning) become arbitrarily small as the network size increases. We further prove generalization bounds adapted to our theoretical framework, which are consistent with the observation that the generalization error will be lower for more compressible networks. Our theory and numerical study on various neural networks show that large step-size/batch-size ratios introduce heavy tails, which, in combination with overparametrization, result in compressibility.",
    "authors": [
      "Barsbey, Melih",
      "Sefidgaran, Milad",
      "Erdogdu, Murat A.",
      "Richard, Ga\u00ebl",
      "Simsekli, Umut"
    ]
  },
  {
    "id": "f5cfbc876972bd0d031c8abc37344c28",
    "title": "Targeted Neural Dynamical Modeling",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f5cfbc876972bd0d031c8abc37344c28-Paper.pdf",
    "abstract": "Latent dynamics models have emerged as powerful tools for modeling and interpreting neural population activity. Recently, there has been a focus on incorporating simultaneously measured behaviour into these models to further disentangle sources of neural variability in their latent space. These approaches, however, are limited in their ability to capture the underlying neural dynamics (e.g. linear) and in their ability to relate the learned dynamics back to the observed behaviour (e.g. no time lag). To this end, we introduce Targeted Neural Dynamical Modeling (TNDM), a nonlinear state-space model that jointly models the neural activity and external behavioural variables. TNDM decomposes neural dynamics into behaviourally relevant and behaviourally irrelevant dynamics; the relevant dynamics are used to reconstruct the behaviour through a flexible linear decoder and both sets of dynamics are used to reconstruct the neural activity through a linear decoder with no time lag. We implement TNDM as a sequential variational autoencoder and validate it on simulated recordings and recordings taken from the premotor and motor cortex of a monkey performing a center-out reaching task. We show that TNDM is able to learn low-dimensional latent dynamics that are highly predictive of behaviour without sacrificing its fit to the neural data.",
    "authors": [
      "Hurwitz, Cole",
      "Srivastava, Akash",
      "Xu, Kai",
      "Jude, Justin",
      "Perich, Matthew",
      "Miller, Lee",
      "Hennig, Matthias"
    ]
  },
  {
    "id": "f5deaeeae1538fb6c45901d524ee2f98",
    "title": "Exploiting the Intrinsic Neighborhood Structure for Source-free Domain Adaptation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f5deaeeae1538fb6c45901d524ee2f98-Paper.pdf",
    "abstract": "Domain adaptation (DA) aims to alleviate the domain shift between source domain and target domain. Most DA methods require access to the source data, but often that is not possible (e.g. due to data privacy or intellectual property). In this paper, we address the challenging source-free domain adaptation (SFDA) problem, where the source pretrained model is adapted to the target domain in the absence of source data. Our method is based on the observation that target data, which might no longer align with the source domain classifier, still forms clear clusters. We capture this intrinsic structure by defining local affinity of the target data, and encourage label consistency among data with high local affinity. We observe that higher affinity should be assigned to reciprocal neighbors, and propose a self regularization loss to decrease the negative impact of noisy neighbors. Furthermore, to aggregate information with more context, we consider expanded neighborhoods with small affinity values. In the experimental results we verify that the inherent structure of the target features is an important source of information for domain adaptation. We demonstrate that this local structure can be efficiently captured by considering the local neighbors, the reciprocal neighbors, and the expanded neighborhood. Finally, we achieve state-of-the-art performance on several 2D image and 3D point cloud recognition datasets. Code is available in https://github.com/Albert0147/SFDA_neighbors.",
    "authors": [
      "Yang, Shiqi",
      "wang, yaxing",
      "van de Weijer, Joost",
      "Herranz, Luis",
      "Jui, Shangling"
    ]
  },
  {
    "id": "f5e62af885293cf4d511ceef31e61c80",
    "title": "Learning with Noisy Correspondence for Cross-modal Matching",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f5e62af885293cf4d511ceef31e61c80-Paper.pdf",
    "abstract": "Cross-modal matching, which aims to establish the correspondence between two different modalities, is fundamental to a variety of tasks such as cross-modal retrieval and vision-and-language understanding. Although a huge number of cross-modal matching methods have been proposed and achieved remarkable progress in recent years, almost all of these methods implicitly assume that the multimodal training data are correctly aligned. In practice, however, such an assumption is extremely expensive even impossible to satisfy. Based on this observation, we reveal and study a latent and challenging direction in cross-modal matching, named noisy correspondence, which could be regarded as a new paradigm of noisy labels. Different from the traditional noisy labels which mainly refer to the errors in category labels, our noisy correspondence refers to the mismatch paired samples. To solve this new problem, we propose a novel method for learning with noisy correspondence, named Noisy Correspondence Rectifier (NCR). In brief, NCR divides the data into clean and noisy partitions based on the memorization effect of neural networks and then rectifies the correspondence via an adaptive prediction model in a co-teaching manner. To verify the effectiveness of our method, we conduct experiments by using the image-text matching as a showcase. Extensive experiments on Flickr30K, MS-COCO, and Conceptual Captions verify the effectiveness of our method. The code could be accessed from www.pengxi.me .",
    "authors": [
      "Huang, Zhenyu",
      "Niu, Guocheng",
      "Liu, Xiao",
      "Ding, Wenbiao",
      "Xiao, Xinyan",
      "Wu, Hua",
      "Peng, Xi"
    ]
  },
  {
    "id": "f5e647292cc4e1064968ca62bebe7e47",
    "title": "Offline Reinforcement Learning with Reverse Model-based Imagination",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f5e647292cc4e1064968ca62bebe7e47-Paper.pdf",
    "abstract": "In offline reinforcement learning (offline RL), one of the main challenges is to deal with the distributional shift between the learning policy and the given dataset. To address this problem,  recent offline RL methods attempt to introduce conservatism bias to encourage learning in high-confidence areas. Model-free approaches directly encode such bias into policy or value function learning using conservative regularizations or special network structures, but their constrained policy search limits the generalization beyond the offline dataset. Model-based approaches learn forward dynamics models with conservatism quantifications and then generate imaginary trajectories to extend the offline datasets. However, due to limited samples in offline datasets, conservatism quantifications often suffer from overgeneralization in out-of-support regions. The unreliable conservative measures will mislead forward model-based imaginations to undesired areas, leading to overaggressive behaviors. To encourage more conservatism, we propose a novel model-based offline RL framework, called Reverse Offline Model-based Imagination (ROMI). We learn a reverse dynamics model in conjunction with a novel reverse policy,  which can generate rollouts leading to the target goal states within the offline dataset. These reverse imaginations provide informed data augmentation for model-free policy learning and enable conservative generalization beyond the offline dataset. ROMI can effectively combine with off-the-shelf model-free algorithms to enable model-based generalization with proper conservatism. Empirical results show that our method can generate more conservative behaviors and achieve state-of-the-art performance on offline RL benchmark tasks.",
    "authors": [
      "Wang, Jianhao",
      "Li, Wenzhe",
      "Jiang, Haozhe",
      "Zhu, Guangxiang",
      "Li, Siyuan",
      "Zhang, Chongjie"
    ]
  },
  {
    "id": "f6185f0ef02dcaec414a3171cd01c697",
    "title": "Parameter Prediction for Unseen Deep Architectures",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f6185f0ef02dcaec414a3171cd01c697-Paper.pdf",
    "abstract": "Deep learning has been successful in automating the design of features in machine learning pipelines. However, the algorithms optimizing neural network parameters remain largely hand-designed and computationally inefficient. We study if we can use deep learning to directly predict these parameters by exploiting the past knowledge of training other networks. We introduce a large-scale dataset of diverse computational graphs of neural architectures - DeepNets-1M - and use it to explore parameter prediction on CIFAR-10 and ImageNet. By leveraging advances in graph neural networks, we propose a hypernetwork that can predict performant parameters in a single forward pass taking a fraction of a second, even on a CPU. The proposed model achieves surprisingly good performance on unseen and diverse networks. For example, it is able to predict all 24 million parameters of a ResNet-50 achieving a 60% accuracy on CIFAR-10. On ImageNet, top-5 accuracy of some of our networks approaches 50%. Our task along with the model and results can potentially lead to a new, more computationally efficient paradigm of training networks. Our model also learns a strong representation of neural architectures enabling their analysis.",
    "authors": [
      "Knyazev, Boris",
      "Drozdzal, Michal",
      "Taylor, Graham W.",
      "Romero Soriano, Adriana"
    ]
  },
  {
    "id": "f621585df244e9596dc70a39b579efb1",
    "title": "FMMformer: Efficient and Flexible Transformer via Decomposed Near-field and Far-field Attention",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f621585df244e9596dc70a39b579efb1-Paper.pdf",
    "abstract": "We propose FMMformers, a class of efficient and flexible transformers inspired by the celebrated fast multipole method (FMM) for accelerating interacting particle simulation. FMM decomposes particle-particle interaction into near-field and far-field components and then performs direct and coarse-grained computation, respectively. Similarly, FMMformers decompose the attention into near-field and far-field attention, modeling the near-field attention by a banded matrix and the far-field attention by a low-rank matrix. Computing the attention matrix for FMMformers requires linear complexity in computational time and memory footprint with respect to the sequence length. In contrast, standard transformers suffer from quadratic complexity. We analyze and validate the advantage of FMMformers over the standard transformer on the Long Range Arena and language modeling benchmarks. FMMformers can even outperform the standard transformer in terms of accuracy by a significant margin. For instance, FMMformers achieve an average classification accuracy of $60.74\\%$ over the five Long Range Arena tasks, which is significantly better than the standard transformer's average accuracy of $58.70\\%$.",
    "authors": [
      "Nguyen, Tan",
      "Suliafu, Vai",
      "Osher, Stanley",
      "Chen, Long",
      "Wang, Bao"
    ]
  },
  {
    "id": "f65854da4622c1f1ad4ffeb361d7703c",
    "title": "Square Root Principal Component Pursuit: Tuning-Free Noisy Robust Matrix Recovery",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f65854da4622c1f1ad4ffeb361d7703c-Paper.pdf",
    "abstract": "We propose a new framework -- Square Root Principal Component Pursuit -- for low-rank matrix recovery from observations corrupted with noise and outliers. Inspired by the square root Lasso, this new formulation does not require prior knowledge of the noise level. We show that a single, universal choice of the regularization parameter suffices to achieve reconstruction error proportional to the (a priori unknown) noise level. In comparison, previous formulations such as stable PCP rely on noise-dependent parameters to achieve similar performance, and are therefore challenging to deploy in applications where the noise level is unknown. We validate the effectiveness of our new method through experiments on simulated and real datasets. Our simulations corroborate the claim that a universal choice of the regularization parameter yields near optimal performance across a range of noise levels, indicating that the proposed method outperforms the (somewhat loose) bound proved here. ",
    "authors": [
      "Zhang, Junhui",
      "Yan, Jingkai",
      "Wright, John"
    ]
  },
  {
    "id": "f6a673f09493afcd8b129a0bcf1cd5bc",
    "title": "Neural Bellman-Ford Networks: A General Graph Neural Network Framework for Link Prediction",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f6a673f09493afcd8b129a0bcf1cd5bc-Paper.pdf",
    "abstract": "Link prediction is a very fundamental task on graphs. Inspired by traditional path-based methods, in this paper we propose a general and flexible representation learning framework based on paths for link prediction. Specifically, we define the representation of a pair of nodes as the generalized sum of all path representations, with each path representation as the generalized product of the edge representations in the path. Motivated by the Bellman-Ford algorithm for solving the shortest path problem, we show that the proposed path formulation can be efficiently solved by the generalized Bellman-Ford algorithm. To further improve the capacity of the path formulation, we propose the Neural Bellman-Ford Network (NBFNet), a general graph neural network framework that solves the path formulation with learned operators in the generalized Bellman-Ford algorithm. The NBFNet parameterizes the generalized Bellman-Ford algorithm with 3 neural components, namely Indicator, Message and Aggregate functions, which corresponds to the boundary condition, multiplication operator, and summation operator respectively. The NBFNet covers many traditional path-based methods, and can be applied to both homogeneous graphs and multi-relational graphs (e.g., knowledge graphs) in both transductive and inductive settings. Experiments on both homogeneous graphs and knowledge graphs show that the proposed NBFNet outperforms existing methods by a large margin in both transductive and inductive settings, achieving new state-of-the-art results.",
    "authors": [
      "Zhu, Zhaocheng",
      "Zhang, Zuobai",
      "Xhonneux, Louis-Pascal",
      "Tang, Jian"
    ]
  },
  {
    "id": "f6b5f8c32c65fee991049a55dc97d1ce",
    "title": "CorticalFlow: A Diffeomorphic Mesh Transformer Network for Cortical Surface Reconstruction",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f6b5f8c32c65fee991049a55dc97d1ce-Paper.pdf",
    "abstract": "In this paper, we introduce CorticalFlow, a new geometric deep-learning model that, given a 3-dimensional image, learns to deform a reference template towards a targeted object. To conserve the template mesh\u2019s topological properties, we train our model over a set of diffeomorphic transformations. This new implementation of a flow Ordinary Differential Equation (ODE) framework benefits from a small GPU memory footprint, allowing the generation of surfaces with several hundred thousand vertices. To reduce topological errors introduced by its discrete resolution, we derive numeric conditions which improve the manifoldness of the predicted triangle mesh. To exhibit the utility of CorticalFlow, we demonstrate its performance for the challenging task of brain cortical surface reconstruction. In contrast to the current state-of-the-art, CorticalFlow produces superior surfaces while reducing the computation time from nine and a half minutes to one second. More significantly, CorticalFlow enforces the generation of anatomically plausible surfaces; the absence of which has been a major impediment restricting the clinical relevance of such surface reconstruction methods.",
    "authors": [
      "Lebrat, Leo",
      "Santa Cruz, Rodrigo",
      "de Gournay, Frederic",
      "Fu, Darren",
      "Bourgeat, Pierrick",
      "Fripp, Jurgen",
      "Fookes, Clinton",
      "Salvado, Olivier"
    ]
  },
  {
    "id": "f6b6d2a114a9644419dc8d2315f22401",
    "title": "Bridging the Gap Between Practice and PAC-Bayes Theory in Few-Shot Meta-Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f6b6d2a114a9644419dc8d2315f22401-Paper.pdf",
    "abstract": "Despite recent advances in its theoretical understanding, there still remains a significant gap in the ability of existing PAC-Bayesian theories on meta-learning to explain performance improvements in the few-shot learning setting, where the number of training examples in the target tasks is severely limited. This gap originates from an assumption in the existing theories which supposes that the number of training examples in the observed tasks and the number of training examples in the target tasks follow the same distribution, an assumption that rarely holds in practice. By relaxing this assumption, we develop two PAC-Bayesian bounds tailored for the few-shot learning setting and show that two existing meta-learning algorithms (MAML and Reptile) can be derived from our bounds, thereby bridging the gap between practice and PAC-Bayesian theories. Furthermore, we derive a new computationally-efficient PACMAML algorithm, and show it outperforms existing meta-learning algorithms on several few-shot benchmark datasets.",
    "authors": [
      "Ding, Nan",
      "Chen, Xi",
      "Levinboim, Tomer",
      "Goodman, Sebastian",
      "Soricut, Radu"
    ]
  },
  {
    "id": "f6c2a0c4b566bc99d596e58638e342b0",
    "title": "SLOE: A Faster Method for Statistical Inference in High-Dimensional Logistic Regression",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f6c2a0c4b566bc99d596e58638e342b0-Paper.pdf",
    "abstract": "Logistic regression remains one of the most widely used tools in applied statistics, machine learning and data science. However, in moderately high-dimensional problems, where the number of features $d$ is a non-negligible fraction of the sample size $n$, the logistic regression maximum likelihood estimator (MLE), and statistical procedures based the large-sample approximation of its distribution, behave poorly. Recently, Sur and Cand\u00e8s (2019) showed that these issues can be corrected by applying a new approximation of the MLE's sampling distribution in this high-dimensional regime. Unfortunately, these corrections are difficult to implement in practice, because they require an estimate of the \\emph{signal strength}, which is a function of the underlying parameters $\\beta$ of the logistic regression. To address this issue, we propose SLOE, a fast and straightforward approach to estimate the signal strength in logistic regression. The key insight of SLOE is that the Sur and Cand\u00e8s (2019) correction can be reparameterized in terms of the corrupted signal strength, which is only a function of the estimated parameters $\\widehat \\beta$. We propose an estimator for this quantity, prove that it is consistent in the relevant high-dimensional regime, and show that dimensionality correction using SLOE is accurate in finite samples. Compared to the existing ProbeFrontier heuristic, SLOE is conceptually simpler and orders of magnitude faster, making it suitable for routine use. We demonstrate the importance of routine dimensionality correction in the Heart Disease dataset from the UCI repository, and a genomics application using data from the UK Biobank.",
    "authors": [
      "Yadlowsky, Steve",
      "Yun, Taedong",
      "McLean, Cory Y",
      "D'Amour, Alexander"
    ]
  },
  {
    "id": "f6f154417c4665861583f9b9c4afafa2",
    "title": "ELLA: Exploration through Learned Language Abstraction",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f6f154417c4665861583f9b9c4afafa2-Paper.pdf",
    "abstract": "Building agents capable of understanding language instructions is critical to effective and robust human-AI collaboration. Recent work focuses on training these agents via reinforcement learning in environments with synthetic language; however, instructions often define long-horizon, sparse-reward tasks, and learning policies requires many episodes of experience. We introduce ELLA: Exploration through Learned Language Abstraction, a reward shaping approach geared towards boosting sample efficiency in sparse reward environments by correlating high-level instructions with simpler low-level constituents. ELLA has two key elements: 1) A termination classifier that identifies when agents complete low-level instructions, and 2) A relevance classifier that correlates low-level instructions with success on high-level tasks. We learn the termination classifier offline from pairs of instructions and terminal states. Notably, in departure from prior work in language and abstraction, we learn the relevance classifier online, without relying on an explicit decomposition of high-level instructions to low-level instructions. On a suite of complex BabyAI environments with varying instruction complexities and reward sparsity, ELLA shows gains in sample efficiency relative to language-based shaping and traditional RL methods.",
    "authors": [
      "Mirchandani, Suvir",
      "Karamcheti, Siddharth",
      "Sadigh, Dorsa"
    ]
  },
  {
    "id": "f702defbc67edb455949f46babab0c18",
    "title": "Learning Distilled Collaboration Graph for Multi-Agent Perception",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f702defbc67edb455949f46babab0c18-Paper.pdf",
    "abstract": "To promote better performance-bandwidth trade-off for multi-agent perception, we propose a novel distilled collaboration graph (DiscoGraph) to model trainable, pose-aware, and adaptive collaboration among agents. Our key novelties lie in two aspects. First, we propose a teacher-student framework to train DiscoGraph via knowledge distillation. The teacher model employs an early collaboration with holistic-view inputs; the student model is based on intermediate collaboration with single-view inputs. Our framework trains DiscoGraph by constraining post-collaboration feature maps in the student model to match the correspondences in the teacher model. Second, we propose a matrix-valued edge weight in DiscoGraph. In such a matrix, each element reflects the inter-agent attention at a specific spatial region, allowing an agent to adaptively highlight the informative regions. During inference, we only need to use the student model named as the distilled collaboration network (DiscoNet). Attributed to the teacher-student framework, multiple agents with the shared DiscoNet could collaboratively approach the performance of a hypothetical teacher model with a holistic view. Our approach is validated on V2X-Sim 1.0, a large-scale multi-agent perception dataset that we synthesized using CARLA and SUMO co-simulation. Our quantitative and qualitative experiments in multi-agent 3D object detection show that DiscoNet could not only achieve a better performance-bandwidth trade-off than the state-of-the-art collaborative perception methods, but also bring more straightforward design rationale. Our code is available on https://github.com/ai4ce/DiscoNet.",
    "authors": [
      "Li, Yiming",
      "Ren, Shunli",
      "Wu, Pengxiang",
      "Chen, Siheng",
      "Feng, Chen",
      "Zhang, Wenjun"
    ]
  },
  {
    "id": "f740c8d9c193f16d8a07d3a8a751d13f",
    "title": "Federated-EM with heterogeneity mitigation and variance reduction",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f740c8d9c193f16d8a07d3a8a751d13f-Paper.pdf",
    "abstract": "The Expectation Maximization (EM) algorithm is the default algorithm for inference in latent variable models. As in any other field of machine learning, applications of latent variable models to very large datasets make the use of advanced parallel and distributed architecture mandatory. This paper introduces FedEM, which is the first extension of the EM algorithm to the federated learning context. FedEM is  a new communication efficient method, which handles partial participation of local devices, and is robust to  heterogeneous distribution of the datasets. To alleviate the communication bottleneck, FedEM compresses appropriately defined complete data sufficient statistics. We also develop and analyze an extension of FedEM to further incorporate a variance reduction scheme. In all cases, we derive finite-time complexity bounds for smooth non-convex problems.  Numerical results are presented to support our theoretical findings, as well as an application to federated missing values imputation for biodiversity monitoring.",
    "authors": [
      "Dieuleveut, Aymeric",
      "Fort, Gersende",
      "Moulines, Eric",
      "Robin, Genevi\u00e8ve"
    ]
  },
  {
    "id": "f754186469a933256d7d64095e963594",
    "title": "On the Role of Optimization in Double Descent: A Least Squares Study",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f754186469a933256d7d64095e963594-Paper.pdf",
    "abstract": "Empirically it has been observed that the performance of deep neural networks steadily improves with increased model size, contradicting the classical view on overfitting and generalization. Recently, the double descent phenomenon has been proposed to reconcile this observation with theory, suggesting that the test error has a second descent when the model becomes sufficiently overparameterized, as the model size itself acts as an implicit regularizer. In this paper we add to the growing body of work in this space, providing a careful study of learning dynamics as a function of model size for the least squares scenario. We show an excess risk bound for the gradient descent solution of the least squares objective. The bound depends on the smallest non-zero eigenvalue of the sample covariance matrix of the input features, via a functional form that has the double descent behaviour. This gives a new perspective on the double descent curves reported in the literature, as our analysis of the excess risk allows to decouple the effect of optimization and generalization error. In particular, we find that in the case of noiseless regression, double descent is explained solely by optimization-related quantities, which was missed in studies focusing on the Moore-Penrose pseudoinverse solution. We believe that our derivation provides an alternative view compared to existing works, shedding some light on a possible cause of this phenomenon, at least in the considered least squares setting. We empirically explore if our predictions hold for neural networks, in particular whether the spectrum of the sample covariance of features at intermediary hidden layers has a similar behaviour as the one predicted by our derivations in the least squares setting.",
    "authors": [
      "Kuzborskij, Ilja",
      "Szepesvari, Csaba",
      "Rivasplata, Omar",
      "Rannen-Triki, Amal",
      "Pascanu, Razvan"
    ]
  },
  {
    "id": "f7664060cc52bc6f3d620bcedc94a4b6",
    "title": "Neural Architecture Dilation for Adversarial Robustness",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f7664060cc52bc6f3d620bcedc94a4b6-Paper.pdf",
    "abstract": "With the tremendous advances in the architecture and scale of convolutional neural networks (CNNs) over the past few decades, they can easily reach or even exceed the performance of humans in certain tasks. However, a recently discovered shortcoming of CNNs is that they are vulnerable to adversarial attacks. Although the adversarial robustness of CNNs can be improved by adversarial training, there is a trade-off between standard accuracy and adversarial robustness. From the neural architecture perspective, this paper aims to improve the adversarial robustness of the backbone CNNs that have a satisfactory accuracy. Under a minimal computational overhead, the introduction of a dilation architecture is expected to be friendly with the standard performance of the backbone CNN while pursuing adversarial robustness. Theoretical analyses on the standard and adversarial error bounds naturally motivate the proposed neural architecture dilation algorithm. Experimental results on real-world datasets and benchmark neural networks demonstrate the effectiveness of the proposed algorithm to balance the accuracy and adversarial robustness.",
    "authors": [
      "Li, Yanxi",
      "Yang, Zhaohui",
      "Wang, Yunhe",
      "Xu, Chang"
    ]
  },
  {
    "id": "f770b62bc8f42a0b66751fe636fc6eb0",
    "title": "Clustering Effect of Adversarial Robust Models",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f770b62bc8f42a0b66751fe636fc6eb0-Paper.pdf",
    "abstract": "Adversarial robustness has received increasing attention along with the study of adversarial examples. So far, existing works show that robust models not only obtain robustness against various adversarial attacks but also boost the performance in some downstream tasks. However, the underlying mechanism of adversarial robustness is still not clear. In this paper, we interpret adversarial robustness from the perspective of linear components, and find that there exist some statistical properties for comprehensively robust models. Specifically, robust models show obvious hierarchical clustering effect on their linearized sub-networks, when removing or replacing all non-linear components (e.g., batch normalization, maximum pooling, or activation layers). Based on these observations, we propose a novel understanding of adversarial robustness and apply it on more tasks including domain adaption and robustness boosting. Experimental evaluations demonstrate the rationality and superiority of our proposed clustering strategy. Our code is available at https://github.com/bymavis/AdvWeightNeurIPS2021.",
    "authors": [
      "Bai, Yang",
      "Yan, Xin",
      "Jiang, Yong",
      "Xia, Shu-Tao",
      "Wang, Yisen"
    ]
  },
  {
    "id": "f78688fb6a5507413ade54a230355acd",
    "title": "On the Cryptographic Hardness of Learning Single Periodic Neurons",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f78688fb6a5507413ade54a230355acd-Paper.pdf",
    "abstract": "We show a simple reduction which demonstrates the cryptographic hardness of learning a single periodic neuron over isotropic Gaussian distributions in the presence of noise. More precisely, our reduction shows that any polynomial-time algorithm (not necessarily gradient-based) for learning such functions under small noise implies a polynomial-time quantum algorithm for solving worst-case lattice problems, whose hardness form the foundation of lattice-based cryptography. Our core hard family of functions, which are well-approximated by one-layer neural networks, take the general form of a univariate periodic function applied to an affine projection of the data. These functions have appeared in previous seminal works which demonstrate their hardness against gradient-based (Shamir'18), and Statistical Query (SQ) algorithms (Song et al.'17). We show that if (polynomially) small noise is added to the labels, the intractability of learning these functions applies to all polynomial-time algorithms, beyond gradient-based and SQ algorithms, under the aforementioned cryptographic assumptions. Moreover, we demonstrate the necessity of noise in the hardness result by designing a polynomial-time algorithm for learning certain families of such functions under exponentially small adversarial noise. Our proposed algorithm is not a gradient-based or an SQ algorithm, but is rather based on the celebrated Lenstra-Lenstra-Lov\\'asz (LLL) lattice basis reduction algorithm. Furthermore, in the absence of noise, this algorithm can be directly applied to solve CLWE detection (Bruna et al.'21) and phase retrieval with an optimal sample complexity of $d+1$ samples. In the former case, this improves upon the quadratic-in-$d$ sample complexity required in (Bruna et al.'21).",
    "authors": [
      "Song, Min Jae",
      "Zadik, Ilias",
      "Bruna, Joan"
    ]
  },
  {
    "id": "f7ac67a9aa8d255282de7d11391e1b69",
    "title": "PCA Initialization for Approximate Message Passing in Rotationally Invariant Models",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f7ac67a9aa8d255282de7d11391e1b69-Paper.pdf",
    "abstract": "We study the problem of estimating a rank-1 signal in the presence of rotationally invariant noise--a class of perturbations more general than Gaussian noise.  Principal Component Analysis (PCA) provides a natural estimator, and sharp results on its performance have been obtained in the high-dimensional regime. Recently, an Approximate Message Passing (AMP) algorithm has been proposed as an alternative estimator with the potential to improve the accuracy of PCA. However, the existing analysis of AMP requires an initialization that is both correlated with the signal and independent of the noise, which is often unrealistic in practice. In this work, we combine the two methods, and propose to initialize AMP with PCA. Our main result is a rigorous asymptotic characterization of the performance of this estimator. Both the AMP algorithm and its analysis differ from those previously derived in the Gaussian setting: at every iteration, our AMP algorithm requires a specific term to account for PCA initialization, while in the Gaussian case, PCA initialization affects only the first iteration of AMP. The proof is based on a two-phase artificial AMP that first approximates the PCA estimator and then mimics the true AMP. Our numerical simulations show an excellent agreement between AMP results and theoretical predictions, and suggest an interesting open direction on achieving Bayes-optimal performance.",
    "authors": [
      "Mondelli, Marco",
      "Venkataramanan, Ramji"
    ]
  },
  {
    "id": "f7b027d45fd7484f6d0833823b98907e",
    "title": "Automatic and Harmless  Regularization  with Constrained and Lexicographic Optimization: A Dynamic Barrier Approach",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f7b027d45fd7484f6d0833823b98907e-Paper.pdf",
    "abstract": "Many machine learning tasks have to make a trade-off between two loss functions, typically the main data-fitness loss and an auxiliary loss. The most widely used approach is to optimize the linear combination of the objectives, which, however, requires manual tuning of the combination coefficient and is theoretically unsuitable for non-convex functions. In this work, we consider constrained optimization as a more principled approach for trading off two losses, with a special emphasis on lexicographic optimization, a degenerated limit of constrained optimization which optimizes a secondary loss inside the optimal set of the main loss. We propose a dynamic barrier gradient descent algorithm which provides a unified solution of both constrained and lexicographic optimization. We establish the convergence of the method for general non-convex functions. ",
    "authors": [
      "Gong, Chengyue",
      "Liu, Xingchao",
      "Liu, Qiang"
    ]
  },
  {
    "id": "f7b6bc883be91f56eb248d72de4d2847",
    "title": "Corruption Robust Active Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f7b6bc883be91f56eb248d72de4d2847-Paper.pdf",
    "abstract": "We conduct theoretical studies on streaming-based active learning for binary classification under unknown adversarial label corruptions. In this setting, every time before the learner observes a sample, the adversary decides whether to corrupt the label ornot. First, we show that, in a benign corruption setting (which includes the misspecification setting as a special case),with a slight enlargement on the hypothesis elimination threshold, the classical RobustCAL framework can (surprisingly) achieve nearly the same label complexity guarantee as in the non-corrupted setting. However, this algorithm can fail in the general corruption setting. To resolve this drawback, we propose a new algorithm which is provably correct without any assumptions on the presence of corruptions. Furthermore, this algorithm enjoys the minimax label complexity in the non-corrupted setting (which is achieved by RobustCAL) and only requires $\\tilde{\\mathcal{O}}(C_{\\mathrm{total}})$ additional labels in the corrupted setting to achieve $\\mathcal{O}(\\varepsilon + \\frac{C_{\\mathrm{total}}}{n})$, where $\\varepsilon$ is the target accuracy, $C_{\\mathrm{total}}$ is the total number of corruptions and $n$ is the total number of unlabeled samples.",
    "authors": [
      "Chen, Yifang",
      "Du, Simon S.",
      "Jamieson, Kevin G."
    ]
  },
  {
    "id": "f7cfdde9db36af8e0d9a6d123d5c385e",
    "title": "Metadata-based Multi-Task Bandits with Bayesian Hierarchical Models",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f7cfdde9db36af8e0d9a6d123d5c385e-Paper.pdf",
    "abstract": "How to explore efficiently is a central problem in multi-armed bandits. In this paper, we introduce the metadata-based multi-task bandit problem, where the agent needs to solve a large number of related multi-armed bandit tasks and can leverage some task-specific features (i.e., metadata) to share knowledge across tasks. As a general framework, we propose to capture task relations through the lens of Bayesian hierarchical models, upon which a Thompson sampling algorithm is designed to efficiently learn task relations, share information, and minimize the cumulative regrets. Two concrete examples for Gaussian bandits and Bernoulli bandits are carefully analyzed. The Bayes regret for Gaussian bandits clearly demonstrates the benefits of information sharing with our algorithm. The proposed method is further supported by extensive experiments. ",
    "authors": [
      "Wan, Runzhe",
      "Ge, Lin",
      "Song, Rui"
    ]
  },
  {
    "id": "f7e2b2b75b04175610e5a00c1e221ebb",
    "title": "Program Synthesis Guided Reinforcement Learning for Partially Observed Environments",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f7e2b2b75b04175610e5a00c1e221ebb-Paper.pdf",
    "abstract": "A key challenge for reinforcement learning is solving long-horizon planning problems. Recent work has leveraged programs to guide reinforcement learning in these settings. However, these approaches impose a high manual burden on the user since they must provide a guiding program for every new task. Partially observed environments further complicate the programming task because the program must implement a strategy that correctly, and ideally optimally, handles every possible configuration of the hidden regions of the environment. We propose a new approach, model predictive program synthesis (MPPS), that uses program synthesis to automatically generate the guiding programs. It trains a generative model to predict the unobserved portions of the world, and then synthesizes a program based on samples from this model in a way that is robust to its uncertainty. In our experiments, we show that our approach significantly outperforms non-program-guided approaches on a set of challenging benchmarks, including a 2D Minecraft-inspired environment where the agent must complete a complex sequence of subtasks to achieve its goal, and achieves a similar performance as using handcrafted programs to guide the agent. Our results demonstrate that our approach can obtain the benefits of program-guided reinforcement learning without requiring the user to provide a new guiding program for every new task.",
    "authors": [
      "Yang, Yichen",
      "Inala, Jeevana Priya",
      "Bastani, Osbert",
      "Pu, Yewen",
      "Solar-Lezama, Armando",
      "Rinard, Martin"
    ]
  },
  {
    "id": "f7fbc4bafcc80cbf690acbef25f2ce1c",
    "title": "Robust Allocations with Diversity Constraints",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f7fbc4bafcc80cbf690acbef25f2ce1c-Paper.pdf",
    "abstract": "We consider the problem of allocating divisible items among multiple agents, and consider the setting where any agent is allowed to introduce {\\emph diversity constraints} on the items they are allocated. We motivate this via settings where the items themselves correspond to user ad slots or task workers with attributes such as race and gender on which the principal seeks to achieve demographic parity. We consider the following question: When an agent expresses diversity constraints into an allocation rule, is the allocation of other agents hurt significantly? If this happens, the cost of introducing such constraints is disproportionately borne by agents who do not benefit from diversity. We codify this via two desiderata capturing {\\em robustness}. These are {\\emph no negative externality} -- other agents are not hurt -- and {\\emph monotonicity} -- the agent enforcing the constraint does not see a large increase in value. We show in a formal sense that the Nash Welfare rule that maximizes product of agent values is {\\emph uniquely} positioned to be robust when diversity constraints are introduced, while almost all other natural allocation rules fail this criterion. We also show that the guarantees achieved by Nash Welfare are nearly optimal within a widely studied class of allocation rules. We finally perform an empirical simulation on real-world data that models ad allocations to show that this gap between Nash Welfare and other rules persists in the wild.",
    "authors": [
      "Shen, Zeyu",
      "Gelauff, Lodewijk",
      "Goel, Ashish",
      "Korolova, Aleksandra",
      "Munagala, Kamesh"
    ]
  },
  {
    "id": "f80ebff16ccaa9b48a0224d7c489cef4",
    "title": "Activation Sharing with Asymmetric Paths Solves Weight Transport Problem without Bidirectional Connection",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f80ebff16ccaa9b48a0224d7c489cef4-Paper.pdf",
    "abstract": "One of the reasons why it is difficult for the brain to perform backpropagation (BP) is the weight transport problem, which argues forward and feedback neurons cannot share the same synaptic weights during learning in biological neural networks. Recently proposed algorithms address the weight transport problem while providing good performance similar to BP in large-scale networks. However, they require bidirectional connections between the forward and feedback neurons to train their weights, which is observed to be rare in the biological brain. In this work, we propose an Activation Sharing algorithm that removes the need for bidirectional connections between the two types of neurons. In this algorithm, hidden layer outputs (activations) are shared across multiple layers during weight updates. By applying this learning rule to both forward and feedback networks, we solve the weight transport problem without the constraint of bidirectional connections, also achieving good performance even on deep convolutional neural networks for various datasets. In addition, our algorithm could significantly reduce memory access overhead when implemented in hardware.",
    "authors": [
      "Woo, Sunghyeon",
      "Park, Jeongwoo",
      "Hong, Jiwoo",
      "Jeon, Dongsuk"
    ]
  },
  {
    "id": "f8417d04a0a2d5e1fb5c5253a365643c",
    "title": "BlendGAN: Implicitly GAN Blending for Arbitrary Stylized Face Generation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f8417d04a0a2d5e1fb5c5253a365643c-Paper.pdf",
    "abstract": "Generative Adversarial Networks (GANs) have made a dramatic leap in high-fidelity image synthesis and stylized face generation. Recently, a layer-swapping mechanism has been developed to improve the stylization performance. However, this method is incapable of fitting arbitrary styles in a single model and requires hundreds of style-consistent training images for each style. To address the above issues, we propose BlendGAN for arbitrary stylized face generation by leveraging a flexible blending strategy and a generic artistic dataset. Specifically, we first train a self-supervised style encoder on the generic artistic dataset to extract the representations of arbitrary styles. In addition, a weighted blending module (WBM) is proposed to blend face and style representations implicitly and control the arbitrary stylization effect. By doing so, BlendGAN can gracefully fit arbitrary styles in a unified model while avoiding case-by-case preparation of style-consistent training images. To this end, we also present a novel large-scale artistic face dataset AAHQ. Extensive experiments demonstrate that BlendGAN outperforms state-of-the-art methods in terms of visual quality and style diversity for both latent-guided and reference-guided stylized face synthesis.",
    "authors": [
      "Liu, Mingcong",
      "Li, Qiang",
      "Qin, Zekui",
      "Zhang, Guoxin",
      "Wan, Pengfei",
      "Zheng, Wen"
    ]
  },
  {
    "id": "f8580959e35cb0934479bb007fb241c2",
    "title": "Differentially Private Model Personalization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f8580959e35cb0934479bb007fb241c2-Paper.pdf",
    "abstract": "We study personalization of supervised learning with user-level differential privacy. Consider a setting with many users, each of whom has a training data set drawn from their own distribution $P_i$. Assuming some shared structure among the problems $P_i$, can users collectively learn the shared structure---and solve their tasks better than they could individually---while preserving the privacy of their data? We formulate this question using joint, user-level differential privacy---that is, we control what is leaked about each user's entire data set. We provide algorithms that exploit popular non-private approaches in this domain like the Almost-No-Inner-Loop (ANIL) method, and give strong user-level privacy guarantees for our general approach. When the problems $P_i$ are linear regression problems with each user's regression vector lying in a common, unknown low-dimensional subspace, we show that our efficient algorithms satisfy nearly optimal estimation error guarantees. We also establish a general, information-theoretic upper bound via an exponential mechanism-based algorithm.",
    "authors": [
      "Jain, Prateek",
      "Rush, John",
      "Smith, Adam",
      "Song, Shuang",
      "Guha Thakurta, Abhradeep"
    ]
  },
  {
    "id": "f862d13454fd267baa5fedfffb200567",
    "title": "Rates of Estimation of Optimal Transport Maps using Plug-in Estimators via  Barycentric Projections",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f862d13454fd267baa5fedfffb200567-Paper.pdf",
    "abstract": "Optimal transport maps between two probability distributions $\\mu$ and $\\nu$ on $\\R^d$ have found extensive applications in both machine learning and statistics. In practice, these maps need to be estimated from data sampled according to $\\mu$ and $\\nu$. Plug-in estimators are perhaps most popular in estimating transport  maps in the field of computational optimal transport. In this paper, we provide a comprehensive analysis of the rates of convergences for general plug-in estimators defined via barycentric projections. Our main contribution is a new stability estimate for barycentric projections which proceeds under minimal smoothness assumptions and can be used to analyze general plug-in estimators. We illustrate the usefulness of this stability estimate by first providing rates of convergence for the natural discrete-discrete and semi-discrete estimators of  optimal transport maps. We then use the same stability estimate to show that, under additional smoothness assumptions of Besov type or Sobolev type, wavelet based or kernel smoothed plug-in estimators respectively speed up the rates of convergence and significantly mitigate the curse of dimensionality suffered by the natural discrete-discrete/semi-discrete estimators. As a by-product of our analysis, we also obtain faster rates of convergence for plug-in estimators of $W_2(\\mu,\\nu)$, the Wasserstein distance between $\\mu$ and $\\nu$, under the aforementioned smoothness assumptions, thereby complementing recent results in Chizat et al. (2020). Finally, we illustrate the applicability of our results in obtaining rates of convergence for Wasserstein barycenters between two probability distributions and obtaining asymptotic detection thresholds for some recent optimal-transport based tests of independence. ",
    "authors": [
      "DEB, NABARUN",
      "Ghosal, Promit",
      "Sen, Bodhisattva"
    ]
  },
  {
    "id": "f86890095c957e9b949d11d15f0d0cd5",
    "title": "Robust Generalization despite Distribution Shift via Minimum Discriminating Information",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f86890095c957e9b949d11d15f0d0cd5-Paper.pdf",
    "abstract": "Training models that perform well under distribution shifts is a central challenge in machine learning. In this paper, we introduce a modeling framework where, in addition to training data, we have partial structural knowledge of the shifted test distribution. We employ the principle of minimum discriminating information to embed the available prior knowledge, and use distributionally robust optimization to account for uncertainty due to the limited samples. By leveraging large deviation results, we obtain explicit generalization bounds with respect to the unknown shifted distribution. Lastly, we demonstrate the versatility of our framework by demonstrating it on two rather distinct applications: (1) training classifiers on systematically biased data and (2) off-policy evaluation in Markov Decision Processes.",
    "authors": [
      "Sutter, Tobias",
      "Krause, Andreas",
      "Kuhn, Daniel"
    ]
  },
  {
    "id": "f8905bd3df64ace64a68e154ba72f24c",
    "title": "Soft Calibration Objectives for Neural Networks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f8905bd3df64ace64a68e154ba72f24c-Paper.pdf",
    "abstract": "Optimal decision making requires that classifiers produce uncertainty estimates consistent with their empirical accuracy. However, deep neural networks are often under- or over-confident in their predictions. Consequently, methods have been developed to improve the calibration of their predictive uncertainty both during training and post-hoc. In this work, we propose differentiable losses to improve calibration based on a soft (continuous) version of the binning operation underlying popular calibration-error estimators. When incorporated into training, these soft calibration losses achieve state-of-the-art single-model ECE across multiple datasets with less than 1% decrease in accuracy. For instance, we observe an 82% reduction in ECE (70% relative to the post-hoc rescaled ECE) in exchange for a 0.7% relative decrease in accuracy relative to the cross entropy baseline on CIFAR-100.When incorporated post-training, the soft-binning-based calibration error objective improves upon temperature scaling, a popular recalibration method.  Overall, experiments across losses and datasets demonstrate that using calibration-sensitive procedures yield better uncertainty estimates under dataset shift than the standard practice of using a cross entropy loss and post-hoc recalibration methods.",
    "authors": [
      "Karandikar, Archit",
      "Cain, Nicholas",
      "Tran, Dustin",
      "Lakshminarayanan, Balaji",
      "Shlens, Jonathon",
      "Mozer, Michael C.",
      "Roelofs, Becca"
    ]
  },
  {
    "id": "f89394c979b34a25cc4ff8e11234fbfb",
    "title": "Distributional Gradient Matching for Learning Uncertain Neural Dynamics Models",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f89394c979b34a25cc4ff8e11234fbfb-Paper.pdf",
    "abstract": "Differential equations in general and neural ODEs in particular are an essential technique in continuous-time system identification. While many deterministic learning algorithms have been designed based on numerical integration via the adjoint method, many downstream tasks such as active learning, exploration in reinforcement learning, robust control, or filtering require accurate estimates of predictive uncertainties. In this work, we propose a novel approach towards estimating epistemically uncertain neural ODEs, avoiding the numerical integration bottleneck. Instead of modeling uncertainty in the ODE parameters, we directly model  uncertainties in the state space. Our algorithm distributional gradient matching (DGM) jointly trains a smoother and a dynamics model and matches their gradients via minimizing a Wasserstein loss. Our experiments show that, compared to traditional approximate inference methods based on numerical integration, our approach is faster to train, faster at predicting previously unseen trajectories, and in the context of neural ODEs, significantly more accurate.",
    "authors": [
      "Treven, Lenart",
      "Wenk, Philippe",
      "Dorfler, Florian",
      "Krause, Andreas"
    ]
  },
  {
    "id": "f8b7aa3a0d349d9562b424160ad18612",
    "title": "Shaping embodied agent behavior with activity-context priors from egocentric video",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f8b7aa3a0d349d9562b424160ad18612-Paper.pdf",
    "abstract": "Complex physical tasks entail a sequence of object interactions, each with its own preconditions -- which can be difficult for robotic agents to learn efficiently solely through their own experience. We introduce an approach to discover activity-context priors from in-the-wild egocentric video captured with human worn cameras. For a given object, an activity-context prior represents the set of other compatible objects that are required for activities to succeed (e.g., a knife and cutting board brought together with a tomato are conducive to cutting). We encode our video-based prior as an auxiliary reward function that encourages an agent to bring compatible objects together before attempting an interaction. In this way, our model translates everyday human experience into embodied agent skills. We demonstrate our idea using egocentric EPIC-Kitchens video of people performing unscripted kitchen activities to benefit virtual household robotic agents performing various complex tasks in AI2-iTHOR, significantly accelerating agent learning. ",
    "authors": [
      "Nagarajan, Tushar",
      "Grauman, Kristen"
    ]
  },
  {
    "id": "f8e6ba1db0f3c4054afec1684ba8fb26",
    "title": "Adjusting for Autocorrelated Errors in Neural Networks for Time Series",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f8e6ba1db0f3c4054afec1684ba8fb26-Paper.pdf",
    "abstract": "An increasing body of research focuses on using neural networks to model time series. A common assumption in training neural networks via maximum likelihood estimation on time series is that the errors across time steps are uncorrelated. However, errors are actually autocorrelated in many cases due to the temporality of the data, which makes such maximum likelihood estimations inaccurate. In this paper, in order to adjust for autocorrelated errors, we propose to learn the autocorrelation coefficient jointly with the model parameters. In our experiments, we verify the effectiveness of our approach on time series forecasting. Results across a wide range of real-world datasets with various state-of-the-art models show that our method enhances performance in almost all cases. Based on these results, we suggest empirical critical values to determine the severity of autocorrelated errors. We also analyze several aspects of our method to demonstrate its advantages. Finally, other time series tasks are also considered to validate that our method is not restricted to only forecasting.",
    "authors": [
      "Sun, Fan-Keng",
      "Lang, Chris",
      "Boning, Duane"
    ]
  },
  {
    "id": "f92586a25bb3145facd64ab20fd554ff",
    "title": "A Geometric Analysis of Neural Collapse with Unconstrained Features",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f92586a25bb3145facd64ab20fd554ff-Paper.pdf",
    "abstract": "We provide the first global optimization landscape analysis of Neural Collapse -- an intriguing empirical phenomenon that arises in the last-layer classifiers and features of neural networks during the terminal phase of training. As recently reported by Papyan et al., this phenomenon implies that (i) the class means and the last-layer classifiers all collapse to the vertices of a Simplex Equiangular Tight Frame (ETF) up to scaling, and (ii) cross-example within-class variability of last-layer activations collapses to zero. We study the problem based on a simplified unconstrained feature model, which isolates the topmost layers from the classifier of the neural network. In this context, we show that the classical cross-entropy loss with weight decay has a benign global landscape, in the sense that the only global minimizers are the Simplex ETFs while all other critical points are strict saddles whose Hessian exhibit negative curvature directions. Our analysis of the simplified model not only explains what kind of features are learned in the last layer, but also shows why they can be efficiently optimized, matching the empirical observations in practical deep network architectures. These findings provide important practical implications. As an example, our experiments demonstrate that one may set the feature dimension equal to the number of classes and fix the last-layer classifier to be a Simplex ETF for network training, which reduces memory cost by over 20% on ResNet18 without sacrificing the generalization performance. The source code is available at https://github.com/tding1/Neural-Collapse.",
    "authors": [
      "Zhu, Zhihui",
      "Ding, Tianyu",
      "Zhou, Jinxin",
      "Li, Xiao",
      "You, Chong",
      "Sulam, Jeremias",
      "Qu, Qing"
    ]
  },
  {
    "id": "f95ec3de395b4bce25b39ef6138da871",
    "title": "NeRS: Neural Reflectance Surfaces for Sparse-view 3D Reconstruction in the Wild",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/f95ec3de395b4bce25b39ef6138da871-Paper.pdf",
    "abstract": "Recent history has seen a tremendous growth of work exploring implicit representations of geometry and radiance, popularized through Neural Radiance Fields (NeRF).  Such works are fundamentally based on a (implicit) {\\em volumetric} representation of occupancy, allowing them to model diverse scene structure including translucent objects and atmospheric obscurants. But because the vast majority of real-world scenes are composed of well-defined surfaces, we introduce a {\\em surface} analog of such implicit models called Neural Reflectance Surfaces (NeRS). NeRS learns a neural shape representation of a closed surface that is diffeomorphic to a sphere, guaranteeing water-tight reconstructions. Even more importantly, surface parameterizations allow NeRS to learn (neural) bidirectional surface reflectance functions (BRDFs) that factorize view-dependent appearance into environmental illumination, diffuse color (albedo), and specular \u201cshininess.\u201d Finally, rather than illustrating our results on synthetic scenes or controlled in-the-lab capture, we assemble a novel dataset of multi-view images from online marketplaces for selling goods. Such \u201cin-the-wild\u201d multi-view image sets pose a number of challenges, including a small number of views with unknown/rough camera estimates. We demonstrate that surface-based neural reconstructions enable learning from such data, outperforming volumetric neural rendering-based reconstructions. We hope that NeRS serves as a first step toward building scalable, high-quality libraries of real-world shape, materials, and illumination.",
    "authors": [
      "Zhang, Jason",
      "Yang, Gengshan",
      "Tulsiani, Shubham",
      "Ramanan, Deva"
    ]
  },
  {
    "id": "fa14d4fe2f19414de3ebd9f63d5c0169",
    "title": "Unleashing the Power of Contrastive Self-Supervised Visual Models via Contrast-Regularized Fine-Tuning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fa14d4fe2f19414de3ebd9f63d5c0169-Paper.pdf",
    "abstract": "Contrastive self-supervised learning (CSL) has attracted increasing attention for model pre-training via unlabeled data. The resulted CSL models provide instance-discriminative visual features that are uniformly scattered in the feature space.  During deployment, the common practice is to directly fine-tune CSL models with cross-entropy, which however may not be the best strategy in practice. Although cross-entropy tends to separate inter-class features, the resulting models still have limited capability for reducing intra-class feature scattering that exists in CSL models. In this paper, we investigate whether applying contrastive learning to fine-tuning would bring further benefits, and analytically find that optimizing the contrastive loss benefits both discriminative representation learning and model optimization during fine-tuning. Inspired by these findings, we propose Contrast-regularized tuning (Core-tuning), a new approach for fine-tuning CSL models. Instead of simply adding the contrastive loss to the objective of fine-tuning, Core-tuning further applies a novel hard pair mining strategy for more effective contrastive fine-tuning, as well as smoothing the decision boundary to better exploit the learned discriminative feature space. Extensive experiments on image classification and semantic segmentation verify the effectiveness of Core-tuning. ",
    "authors": [
      "Zhang, Yifan",
      "Hooi, Bryan",
      "Hu, Dapeng",
      "Liang, Jian",
      "Feng, Jiashi"
    ]
  },
  {
    "id": "fa246d0262c3925617b0c72bb20eeb1d",
    "title": "Discovery of Options via Meta-Learned Subgoals",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fa246d0262c3925617b0c72bb20eeb1d-Paper.pdf",
    "abstract": "Temporal abstractions in the form of options have been shown to help reinforcement learning (RL) agents learn faster. However, despite prior work on this topic, the problem of discovering options through interaction with an environment remains a challenge. In this paper, we introduce a novel meta-gradient approach for discovering useful options in multi-task RL environments. Our approach is based on a manager-worker decomposition of the RL agent, in which a manager maximises rewards from the environment by learning a task-dependent policy over both a set of task-independent discovered-options and primitive actions. The option-reward and termination functions that define a subgoal for each option are parameterised as neural networks and trained via meta-gradients to maximise their usefulness. Empirical analysis on gridworld and DeepMind Lab tasks show that: (1) our approach can discover meaningful and diverse temporally-extended options in multi-task RL domains, (2) the discovered options are frequently used by the agent while learning to solve the training tasks, and (3) that the discovered options help a randomly initialised manager learn faster in completely new tasks.",
    "authors": [
      "Veeriah, Vivek",
      "Zahavy, Tom",
      "Hessel, Matteo",
      "Xu, Zhongwen",
      "Oh, Junhyuk",
      "Kemaev, Iurii",
      "van Hasselt, Hado P.",
      "Silver, David",
      "Singh, Satinder"
    ]
  },
  {
    "id": "fa6c94460e902005a0b660266190c8ba",
    "title": "Near-Optimal Lower Bounds For Convex Optimization For All Orders of Smoothness",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fa6c94460e902005a0b660266190c8ba-Paper.pdf",
    "abstract": "We study the complexity of optimizing highly smooth convex functions. For a positive integer $p$, we want to find an $\\epsilon$-approximate minimum of a convex function $f$, given oracle access to the function and its first $p$ derivatives, assuming that the $p$th derivative of $f$ is Lipschitz. Recently, three independent research groups (Jiang et al., PLMR 2019; Gasnikov et al., PLMR 2019; Bubeck et al., PLMR 2019) developed a new algorithm that solves this problem with $\\widetilde{O}\\left(1/\\epsilon^{\\frac{2}{3p+1}}\\right)$ oracle calls for constant $p$. This is known to be optimal (up to log factors) for deterministic algorithms, but known lower bounds for randomized algorithms do not match this bound. We prove a new lower bound that matches this bound (up to log factors), and holds not only for randomized algorithms, but also for quantum algorithms.",
    "authors": [
      "Garg, Ankit",
      "Kothari, Robin",
      "Netrapalli, Praneeth",
      "Sherif, Suhail"
    ]
  },
  {
    "id": "fa7cdfad1a5aaf8370ebeda47a1ff1c3",
    "title": "Topology-Imbalance Learning for Semi-Supervised Node Classification",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fa7cdfad1a5aaf8370ebeda47a1ff1c3-Paper.pdf",
    "abstract": "The class imbalance problem, as an important issue in learning node representations, has drawn increasing attention from the community. Although the imbalance considered by existing studies roots from the unequal quantity of labeled examples in different classes (quantity imbalance), we argue that graph data expose a unique source of imbalance from the asymmetric topological properties of the labeled nodes, i.e., labeled nodes are not equal in terms of their structural role in the graph (topology imbalance). In this work, we first probe the previously unknown topology-imbalance issue, including its characteristics, causes, and threats to semisupervised node classification learning. We then provide a unified view to jointly analyzing the quantity- and topology- imbalance issues by considering the node influence shift phenomenon with the Label Propagation algorithm. In light of our analysis, we devise an influence conflict detection\u2013based metric Totoro to measure the degree of graph topology imbalance and propose a model-agnostic method ReNode to address the topology-imbalance issue by re-weighting the influence of labeled nodes adaptively based on their relative positions to class boundaries. Systematic experiments demonstrate the effectiveness and generalizability of our method in relieving topology-imbalance issue and promoting semi-supervised node classification. The further analysis unveils varied sensitivity of different graph neural networks (GNNs) to topology imbalance, which may serve as a new perspective in evaluating GNN architectures.",
    "authors": [
      "Chen, Deli",
      "Lin, Yankai",
      "Zhao, Guangxiang",
      "Ren, Xuancheng",
      "Li, Peng",
      "Zhou, Jie",
      "Sun, Xu"
    ]
  },
  {
    "id": "fa84632d742f2729dc32ce8cb5d49733",
    "title": "Gradient Inversion with Generative Image Prior",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fa84632d742f2729dc32ce8cb5d49733-Paper.pdf",
    "abstract": "Federated Learning (FL) is a distributed learning framework, in which the local data never leaves clients\u2019 devices to preserve privacy, and the server trains models on the data via accessing only the gradients of those local data. Without further privacy mechanisms such as differential privacy, this leaves the system vulnerable against an attacker who inverts those gradients to reveal clients\u2019 sensitive data. However, a gradient is often insufficient to reconstruct the user data without any prior knowledge. By exploiting a generative model pretrained on the data distribution, we demonstrate that data privacy can be easily breached. Further, when such prior knowledge is unavailable, we investigate the possibility of learning the prior from a sequence of gradients seen in the process of FL training. We experimentally show that the prior in a form of generative model is learnable from iterative interactions in FL. Our findings demonstrate that additional mechanisms are necessary to prevent privacy leakage in FL.",
    "authors": [
      "Jeon, Jinwoo",
      "Kim, jaechang",
      "Lee, Kangwook",
      "Oh, Sewoong",
      "Ok, Jungseul"
    ]
  },
  {
    "id": "fac7fead96dafceaf80c1daffeae82a4",
    "title": "Beta-CROWN: Efficient Bound Propagation with Per-neuron Split Constraints for Neural Network Robustness Verification",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fac7fead96dafceaf80c1daffeae82a4-Paper.pdf",
    "abstract": "Bound propagation based incomplete neural network verifiers such as CROWN are very efficient and can significantly accelerate branch-and-bound (BaB) based complete verification of neural networks. However, bound propagation cannot fully handle the neuron split constraints introduced by BaB commonly handled by expensive linear programming (LP) solvers, leading to loose bounds and hurting verification efficiency. In this work, we develop $\\beta$-CROWN, a new bound propagation based method that can fully encode neuron splits via optimizable parameters $\\beta$ constructed from either primal or dual space. When jointly optimized in intermediate layers, $\\beta$-CROWN generally produces better bounds than typical LP verifiers with neuron split constraints, while being as efficient and parallelizable as CROWN on GPUs. Applied to complete robustness verification benchmarks, $\\beta$-CROWN with BaB is up to three orders of magnitude faster than LP-based BaB methods, and is notably faster than all existing approaches while producing lower timeout rates. By terminating BaB early, our method can also be used for efficient incomplete verification.  We consistently achieve higher verified accuracy in many settings compared to powerful incomplete verifiers, including those based on convex barrier breaking techniques. Compared to the typically tightest but very costly semidefinite programming (SDP) based incomplete verifiers, we obtain higher verified accuracy with three orders of magnitudes less verification time. Our algorithm empowered the $\\alpha,\\!\\beta$-CROWN (alpha-beta-CROWN) verifier, the winning tool in VNN-COMP 2021. Our code is available at http://PaperCode.cc/BetaCROWN.",
    "authors": [
      "Wang, Shiqi",
      "Zhang, Huan",
      "Xu, Kaidi",
      "Lin, Xue",
      "Jana, Suman",
      "Hsieh, Cho-Jui",
      "Kolter, J. Zico"
    ]
  },
  {
    "id": "faf02b2358de8933f480a146f4d2d98e",
    "title": "Autobahn: Automorphism-based Graph Neural Nets",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/faf02b2358de8933f480a146f4d2d98e-Paper.pdf",
    "abstract": "We introduce Automorphism-based graph neural networks (Autobahn), a new family of graph neural networks. In an Autobahn, we decompose the graph into a collection of subgraphs and apply local convolutions that are equivariant to each subgraph's automorphism group. Specific choices of local neighborhoods and subgraphs recover existing architectures such as message passing neural networks. Our formalism also encompasses novel architectures: as an example, we introduce a graph neural network that decomposes the graph into paths and cycles. The resulting convolutions reflect the natural way that parts of the graph can transform, preserving the intuitive meaning of convolution without sacrificing global permutation equivariance. We validate our approach by applying Autobahn to molecular graphs, where it achieves results competitive with state-of-the-art message passing algorithms.",
    "authors": [
      "Thiede, Erik",
      "Zhou, Wenda",
      "Kondor, Risi"
    ]
  },
  {
    "id": "fb4c48608ce8825b558ccf07169a3421",
    "title": "Data Augmentation Can Improve Robustness",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fb4c48608ce8825b558ccf07169a3421-Paper.pdf",
    "abstract": "Adversarial training suffers from robust overfitting, a phenomenon where the robust test accuracy starts to decrease during training. In this paper, we focus on reducing robust overfitting by using common data augmentation schemes. We demonstrate that, contrary to previous findings, when combined with model weight averaging, data augmentation can significantly boost robust accuracy. Furthermore, we compare various augmentations techniques and observe that spatial composition techniques work the best for adversarial training. Finally, we evaluate our approach on CIFAR-10 against $\\ell_\\infty$ and $\\ell_2$ norm-bounded perturbations of size $\\epsilon = 8/255$ and $\\epsilon = 128/255$, respectively. We show large absolute improvements of +2.93% and +2.16% in robust accuracy compared to previous state-of-the-art methods. In particular, against $\\ell_\\infty$ norm-bounded perturbations of size $\\epsilon = 8/255$, our model reaches 60.07% robust accuracy without using any external data.  We also achieve a significant performance boost with this approach while using other architectures and datasets such as CIFAR-100, SVHN and TinyImageNet.",
    "authors": [
      "Rebuffi, Sylvestre-Alvise",
      "Gowal, Sven",
      "Calian, Dan Andrei",
      "Stimberg, Florian",
      "Wiles, Olivia",
      "Mann, Timothy A"
    ]
  },
  {
    "id": "fb4c835feb0a65cc39739320d7a51c02",
    "title": "Deep Explicit Duration Switching Models for Time Series",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fb4c835feb0a65cc39739320d7a51c02-Paper.pdf",
    "abstract": "Many complex time series can be effectively subdivided into distinct regimes that exhibit persistent dynamics. Discovering the switching behavior and the statistical patterns in these regimes is important for understanding the underlying dynamical system. We propose the Recurrent Explicit Duration Switching Dynamical System (RED-SDS), a flexible model that is capable of identifying both state- and time-dependent switching dynamics. State-dependent switching is enabled by a recurrent state-to-switch connection and an explicit duration count variable is used to improve the time-dependent switching behavior. We demonstrate how to perform efficient inference using a hybrid algorithm that approximates the posterior of the continuous states via an inference network and performs exact inference for the discrete switches and counts. The model is trained by maximizing a Monte Carlo lower bound of the marginal log-likelihood that can be computed efficiently as a byproduct of the inference routine. Empirical results on multiple datasets demonstrate that RED-SDS achieves  considerable improvement in time series segmentation and competitive forecasting performance against the state of the art. ",
    "authors": [
      "Ansari, Abdul Fatir",
      "Benidis, Konstantinos",
      "Kurle, Richard",
      "Turkmen, Ali Caner",
      "Soh, Harold",
      "Smola, Alexander J.",
      "Wang, Bernie",
      "Januschowski, Tim"
    ]
  },
  {
    "id": "fb508ef074ee78a0e58c68be06d8a2eb",
    "title": "Shared Independent Component Analysis for Multi-Subject Neuroimaging",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fb508ef074ee78a0e58c68be06d8a2eb-Paper.pdf",
    "abstract": "We consider shared response modeling, a multi-view learning problem where one wants to identify common components from multiple datasets or views. We introduce Shared Independent Component Analysis (ShICA) that models eachview as a linear transform of shared independent components contaminated by additive Gaussian noise. We show that this model is identifiable if the components are either non-Gaussian or have enough diversity in noise variances. We then show that in some cases multi-set canonical correlation analysis can recover the correct unmixing matrices, but that even a small amount of sampling noise makes Multiset CCA fail. To solve this problem, we propose to use joint diagonalization after Multiset CCA, leading to a new approach called ShICA-J. We show via simulations that ShICA-J leads to improved results while being very fast to fit. While ShICA-J is based on second-order statistics, we further propose to leverage non-Gaussianity of the components using a maximum-likelihood method, ShICA-ML, that is both more accurate and more costly. Further, ShICA comes with a principled method for shared components estimation. Finally, we provide empirical evidence on fMRI and MEG datasets that ShICA yields more accurate estimation of the componentsthan alternatives.",
    "authors": [
      "Richard, Hugo",
      "Ablin, Pierre",
      "Thirion, Bertrand",
      "Gramfort, Alexandre",
      "Hyvarinen, Aapo"
    ]
  },
  {
    "id": "fb60d411a5c5b72b2e7d3527cfc84fd0",
    "title": "Shape from Blur: Recovering Textured 3D Shape and Motion of Fast Moving Objects",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fb60d411a5c5b72b2e7d3527cfc84fd0-Paper.pdf",
    "abstract": "We address the novel task of jointly reconstructing the 3D shape, texture, and motion of an object from a single motion-blurred image. While previous approaches address the deblurring problem only in the 2D image domain, our proposed rigorous modeling of all object properties in the 3D domain enables the correct description of arbitrary object motion. This leads to significantly better image decomposition and sharper deblurring results. We model the observed appearance of a motion-blurred object as a combination of the background and a 3D object with constant translation and rotation. Our method minimizes a loss on reconstructing the input image via differentiable rendering with suitable regularizers. This enables estimating the textured 3D mesh of the blurred object with high fidelity. Our method substantially outperforms competing approaches on several benchmarks for fast moving objects deblurring. Qualitative results show that the reconstructed 3D mesh generates high-quality temporal super-resolution and novel views of the deblurred object.",
    "authors": [
      "Rozumnyi, Denys",
      "Oswald, Martin R.",
      "Ferrari, Vittorio",
      "Pollefeys, Marc"
    ]
  },
  {
    "id": "fb647ca6672b0930e9d00dc384d8b16f",
    "title": "Batched Thompson Sampling",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fb647ca6672b0930e9d00dc384d8b16f-Paper.pdf",
    "abstract": "We introduce a novel anytime batched Thompson sampling policy for multi-armed bandits where the agent observes the rewards of her actions and adjusts her policy only at the end of a small number of batches. We show that this policy simultaneously achieves a problem dependent regret of order $O(\\log(T))$ and a minimax regret of order $O(\\sqrt{T\\log(T)})$  while the number of batches can be bounded by $O(\\log(T))$ independent of the problem instance over a time horizon $T$. We also prove that in expectation the instance dependent batch complexity of our policy is of order $O(\\log\\log(T))$. These results indicate that Thompson sampling performs competitively with recently proposed algorithms for the batched setting, which optimize the batch structure for a given  time horizon $T$ and prioritize exploration in the beginning of the experiment to eliminate suboptimal actions. Unlike these algorithms, the batched Thompson sampling algorithm we propose is an anytime policy, i.e. it operates without the knowledge of the time horizon $T$, and  as such it is the only anytime algorithm that achieves optimal regret with $O(\\log\\log(T))$ expected batch complexity. This is achieved through a dynamic batching strategy, which uses the agents estimates to adaptively increase the batch duration. ",
    "authors": [
      "Kalkanli, Cem",
      "Ozgur, Ayfer"
    ]
  },
  {
    "id": "fc03d48253286a798f5116ec00e99b2b",
    "title": "Delayed Gradient Averaging: Tolerate the Communication Latency for Federated Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fc03d48253286a798f5116ec00e99b2b-Paper.pdf",
    "abstract": "Federated Learning is an emerging direction in distributed machine learning that en-ables jointly training a model without sharing the data. Since the data is distributed across many edge devices through wireless / long-distance connections, federated learning suffers from inevitable high communication latency. However, the latency issues are undermined in the current literature [15] and existing approaches suchas FedAvg [27] become less efficient when the latency increases.  To over comethe problem, we propose \\textbf{D}elayed \\textbf{G}radient \\textbf{A}veraging (DGA), which delays the averaging step to improve efficiency and allows local computation in parallel tocommunication. We theoretically prove that DGA attains a similar convergence rate as FedAvg, and empirically show that our algorithm can tolerate high network latency without compromising accuracy. Specifically, we benchmark the training speed on various vision (CIFAR, ImageNet) and language tasks (Shakespeare),with both IID and non-IID partitions, and show DGA can bring 2.55$\\times$ to 4.07$\\times$ speedup. Moreover, we built a 16-node Raspberry Pi cluster and show that DGA can consistently speed up real-world federated learning applications.",
    "authors": [
      "Zhu, Ligeng",
      "Lin, Hongzhou",
      "Lu, Yao",
      "Lin, Yujun",
      "Han, Song"
    ]
  },
  {
    "id": "fc1a36821b02abbd2503fd949bfc9131",
    "title": "Focal Attention for Long-Range Interactions in Vision Transformers",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fc1a36821b02abbd2503fd949bfc9131-Paper.pdf",
    "abstract": "Recently, Vision Transformer and its variants have shown great promise on various computer vision tasks. The ability to capture local and global visual dependencies through self-attention is the key to its success. But it also brings challenges due to quadratic computational overhead, especially for the high-resolution vision tasks(e.g., object detection). Many recent works have attempted to reduce the cost and improve model performance by applying either coarse-grained global attention or fine-grained local attention. However, both approaches cripple the modeling power of the original self-attention mechanism of multi-layer Transformers, leading to sub-optimal solutions.  In this paper, we present focal attention, a new attention mechanism that incorporates both fine-grained local and coarse-grained global interactions.  In this new mechanism, each token attends its closest surrounding tokens at the fine granularity and the tokens far away at a coarse granularity and thus can capture both short- and long-range visual dependencies efficiently and effectively. With focal attention, we propose a new variant of Vision Transformer models, called Focal Transformers, which achieve superior performance over the state-of-the-art (SoTA) Vision Transformers on a range of public image classification and object detection benchmarks.  In particular, our Focal Transformer models with a moderate size of 51.1M and a large size of 89.8M achieve 83.6% and 84.0%Top-1 accuracy, respectively, on ImageNet classification at 224\u00d7224.  When employed as the backbones, Focal Transformers achieve consistent and substantial improvements over the current SoTA Swin Transformers [44] across 6 different object detection methods.  Our largest Focal Transformer yields58.7/59.0boxmAPs and50.9/51.3mask mAPs on COCO mini-val/test-dev, and55.4mIoU onADE20K for semantic segmentation, creating new SoTA on three of the most challenging computer vision tasks. ",
    "authors": [
      "Yang, Jianwei",
      "Li, Chunyuan",
      "Zhang, Pengchuan",
      "Dai, Xiyang",
      "Xiao, Bin",
      "Yuan, Lu",
      "Gao, Jianfeng"
    ]
  },
  {
    "id": "fc2e6a440b94f64831840137698021e1",
    "title": "Scalable and Stable Surrogates for Flexible Classifiers with Fairness Constraints",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fc2e6a440b94f64831840137698021e1-Paper.pdf",
    "abstract": "We investigate how fairness relaxations scale to flexible classifiers like deep neural networks for images and text. We analyze an easy-to-use and robust way of imposing fairness constraints when training, and through this framework prove that some prior fairness surrogates exhibit degeneracies for non-convex models.  We resolve these problems via three new surrogates: an adaptive data re-weighting, and two smooth upper-bounds that are provably more robust than some previous methods. Our surrogates perform comparably to the state-of-the-art on low-dimensional fairness benchmarks, while achieving superior accuracy and stability for more complex computer vision and natural language processing tasks. ",
    "authors": [
      "Bendekgey, Henry C",
      "Sudderth, Erik"
    ]
  },
  {
    "id": "fc394e9935fbd62c8aedc372464e1965",
    "title": "Residual Pathway Priors for Soft Equivariance Constraints",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fc394e9935fbd62c8aedc372464e1965-Paper.pdf",
    "abstract": "Models such as convolutional neural networks restrict the hypothesis space to a set of functions satisfying equivariance constraints, and improve generalization in problems by capturing relevant symmetries. However, symmetries are often only partially respected, preventing models with restriction biases from fitting the data. We introduce Residual Pathway Priors (RPPs) as a method for converting hard architectural constraints into soft priors, guiding models towards structured solutions while retaining the ability to capture additional complexity. RPPs are resilient to approximate or misspecified symmetries, and are as effective as fully constrained models even when symmetries are exact. We show that RPPs provide compelling performance on both model-free and model-based reinforcement learning problems, where contact forces and directional rewards violate the assumptions of equivariant networks. Finally, we demonstrate that RPPs have broad applicability, including dynamical systems, regression, and classification.",
    "authors": [
      "Finzi, Marc",
      "Benton, Gregory",
      "Wilson, Andrew G."
    ]
  },
  {
    "id": "fc3cf452d3da8402bebb765225ce8c0e",
    "title": "Optimal Algorithms for Stochastic Contextual Preference Bandits ",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fc3cf452d3da8402bebb765225ce8c0e-Paper.pdf",
    "abstract": "We consider the problem of preference bandits in the contextual setting. At each round, the learner is presented with a context set of $K$ items, chosen randomly from a potentially infinite set of arms $\\mathcal D \\subseteq \\mathbf R^d$. However, unlike classical contextual bandits, our framework only allows the learner to receive feedback in terms of item preferences: At each round, the learner is allowed to play a subset of size $q$ (any $q \\in \\{2,\\ldots,K\\}$) upon which only a (noisy) winner of the subset is revealed. Yet, same as the classical setup, the goal is still to compete against the best context arm at each round. The problem is relevant in various online decision-making scenarios, including recommender systems, information retrieval, tournament ranking--typically any application where it's easier to elicit the items' relative strength instead of their absolute scores. To the best of our knowledge, this work is the first to consider preference-based stochastic contextual bandits for potentially infinite decision spaces. We start with presenting two algorithms for the special case of pairwise preferences $(q=2)$: The first algorithm is simple and easy to implement with an $\\tilde O(d\\sqrt{T})$ regret guarantee, while the second algorithm is shown to achieve the optimal $\\tilde O(\\sqrt{dT})$ regret, as follows from our $\\Omega(\\sqrt {dT})$ matching lower bound analysis. We then proceed to analyze the problem for any general $q$-subsetwise preferences ($q \\ge 2$), where surprisingly, our lower bound proves the fundamental performance limit to be $\\Omega(\\sqrt{d T})$ yet again, independent of the subsetsize $q$. Following this, we propose a matching upper bound algorithm justifying the tightness of our results. This implies having access to subsetwise preferences does not help in faster information aggregation for our feedback model. All the results are corroborated empirically against existing baselines.",
    "authors": [
      "Saha, Aadirupa"
    ]
  },
  {
    "id": "fc95fa5740ba01a870cfa52f671fe1e4",
    "title": "Tight High Probability Bounds for Linear Stochastic Approximation with Fixed Stepsize",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fc95fa5740ba01a870cfa52f671fe1e4-Paper.pdf",
    "abstract": "This paper provides a non-asymptotic analysis of linear stochastic approximation (LSA) algorithms with fixed stepsize. This family of methods arises in many machine learning tasks and is used to obtain approximate solutions of a linear system $\\bar{A}\\theta = \\bar{b}$ for which $\\bar{A}$ and $\\bar{b}$ can only be accessed through random estimates $\\{({\\bf A}_n, {\\bf b}_n): n \\in \\mathbb{N}^*\\}$.  Our analysis is based on new results regarding moments and high probability bounds for products of matrices which are shown to be tight. We derive high probability bounds on the performance of LSA under weaker conditions on the sequence $\\{({\\bf A}_n, {\\bf b}_n): n \\in \\mathbb{N}^*\\}$ than previous works. However, in contrast, we establish polynomial concentration bounds with order depending on the stepsize. We show that our conclusions cannot be improved  without additional assumptions on the sequence of random matrices $\\{{\\bf A}_n: n \\in \\mathbb{N}^*\\}$, and in particular that no Gaussian or exponential high probability bounds can hold.  Finally, we pay a particular attention to establishing  bounds with sharp order with respect to the number of iterations and the stepsize and  whose leading terms contain the covariance matrices appearing in the central limit theorems.",
    "authors": [
      "Durmus, Alain",
      "Moulines, Eric",
      "Naumov, Alexey",
      "Samsonov, Sergey",
      "Scaman, Kevin",
      "Wai, Hoi-To"
    ]
  },
  {
    "id": "fc9e62695def29ccdb9eb3fed5b4c8c8",
    "title": "Learning Large Neighborhood Search Policy for Integer Programming",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fc9e62695def29ccdb9eb3fed5b4c8c8-Paper.pdf",
    "abstract": "We propose a deep reinforcement learning (RL) method to learn large neighborhood search (LNS) policy for integer programming (IP). The RL policy is trained as the destroy operator to select a subset of variables at each step, which is reoptimized by an IP solver as the repair operator. However, the combinatorial number of variable subsets prevents direct application of typical RL algorithms. To tackle this challenge, we represent all subsets by factorizing them into binary decisions on each variable. We then design a neural network to learn policies for each variable in parallel, trained by a customized actor-critic algorithm. We evaluate the proposed method on four representative IP problems. Results show that it can find better solutions than SCIP in much less time, and significantly outperform other LNS baselines with the same runtime. Moreover, these advantages notably persist when the policies generalize to larger problems. Further experiments with Gurobi also reveal that our method can outperform this state-of-the-art commercial solver within the same time limit.",
    "authors": [
      "Wu, Yaoxin",
      "Song, Wen",
      "Cao, Zhiguang",
      "Zhang, Jie"
    ]
  },
  {
    "id": "fcdf698a5d673435e0a5a6f9ffea05ca",
    "title": "Dynamic Trace Estimation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fcdf698a5d673435e0a5a6f9ffea05ca-Paper.pdf",
    "abstract": "We study a dynamic version of the implicit trace estimation problem. Given access to an oracle for computing matrix-vector multiplications with a dynamically changing matrix A, our goal is to maintain an accurate approximation to A's trace using as few multiplications as possible. We present a practical algorithm for solving this problem and prove that, in a natural setting, its complexity is quadratically better than the standard solution of repeatedly applying Hutchinson's stochastic trace estimator. We also provide an improved algorithm assuming additional common assumptions on A's dynamic updates. We support our theory with empirical results, showing significant computational improvements on three applications in machine learning and network science: tracking moments of the Hessian spectral density during neural network optimization, counting triangles and estimating natural connectivity in a dynamically changing graph.",
    "authors": [
      "Dharangutte, Prathamesh",
      "Musco, Christopher"
    ]
  },
  {
    "id": "fd00d3474e495e7b6d5f9f575b2d7ec4",
    "title": "Provable Representation Learning for Imitation with Contrastive Fourier Features",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fd00d3474e495e7b6d5f9f575b2d7ec4-Paper.pdf",
    "abstract": "In imitation learning, it is common to learn a behavior policy to match an unknown target policy via max-likelihood training on a collected set of target demonstrations. In this work, we consider using offline experience datasets -- potentially far from the target distribution -- to learn low-dimensional state representations that provably accelerate the sample-efficiency of downstream imitation learning. A central challenge in this setting is that the unknown target policy itself may not exhibit low-dimensional behavior, and so there is a potential for the representation learning objective to alias states in which the target policy acts differently. Circumventing this challenge, we derive a representation learning objective that provides an upper bound on the performance difference between the target policy and a low-dimensional policy trained with max-likelihood, and this bound is tight regardless of whether the target policy itself exhibits low-dimensional structure. Moving to the practicality of our method, we show that our objective can be implemented as contrastive learning, in which the transition dynamics are approximated by either an implicit energy-based model or, in some special cases, an implicit linear model with representations given by random Fourier features. Experiments on both tabular environments and high-dimensional Atari games provide quantitative evidence for the practical benefits of our proposed objective.",
    "authors": [
      "Nachum, Ofir",
      "Yang, Mengjiao"
    ]
  },
  {
    "id": "fd06b8ea02fe5b1c2496fe1700e9d16c",
    "title": "MICo: Improved representations via sampling-based state similarity for Markov decision processes",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fd06b8ea02fe5b1c2496fe1700e9d16c-Paper.pdf",
    "abstract": "We present a new behavioural distance over the state space of a Markov decision process, and demonstrate the use of this distance as an effective means of shaping the learnt representations of deep reinforcement learning agents. While existing notions of state similarity are typically difficult to learn at scale due to high computational cost and lack of sample-based algorithms, our newly-proposed distance addresses both of these issues. In addition to providing detailed theoretical analyses, we provide empirical evidence that learning this distance alongside the value function yields structured and informative representations, including strong results on the Arcade Learning Environment benchmark.",
    "authors": [
      "Castro, Pablo Samuel",
      "Kastner, Tyler",
      "Panangaden, Prakash",
      "Rowland, Mark"
    ]
  },
  {
    "id": "fd0a5a5e367a0955d81278062ef37429",
    "title": "Counterfactual Explanations in Sequential Decision Making Under Uncertainty",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fd0a5a5e367a0955d81278062ef37429-Paper.pdf",
    "abstract": "Methods to find counterfactual explanations have predominantly focused on one-step decision making processes. In this work, we initiate the development of methods to find counterfactual explanations for decision making processes in which multiple, dependent actions are taken sequentially over time. We start by formally characterizing a sequence of actions and states using finite horizon Markov decision processes and the Gumbel-Max structural causal model. Building upon this characterization, we formally state the problem of finding counterfactual explanations for sequential decision making processes. In our problem formulation, the counterfactual explanation specifies an alternative sequence of actions differing in at most k actions from the observed sequence that could have led the observed process realization to a better outcome. Then, we introduce a polynomial time algorithm based on dynamic programming to build a counterfactual policy that is guaranteed to always provide the optimal counterfactual explanation on every possible realization of the counterfactual environment dynamics. We validate our algorithm using both synthetic and real data from cognitive behavioral therapy and show that the counterfactual explanations our algorithm finds can provide valuable insights to enhance sequential decision making under uncertainty.",
    "authors": [
      "Tsirtsis, Stratis",
      "De, Abir",
      "Rodriguez, Manuel"
    ]
  },
  {
    "id": "fd2c5e4680d9a01dba3aada5ece22270",
    "title": "Streaming Linear System Identification with Reverse Experience Replay",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fd2c5e4680d9a01dba3aada5ece22270-Paper.pdf",
    "abstract": "We consider the problem of estimating a linear time-invariant (LTI) dynamical system from a single trajectory via streaming algorithms, which is encountered in several applications including reinforcement learning (RL) and time-series analysis. While the LTI system estimation problem is well-studied in the {\\em offline} setting, the practically important streaming/online setting has received little attention. Standard streaming methods like stochastic gradient descent (SGD) are unlikely to work since streaming points can be highly correlated. In this work, we propose a novel streaming algorithm, SGD with Reverse Experience Replay (SGD-RER), that is inspired by the experience replay (ER)  technique popular in the RL literature. SGD-RER divides data into small buffers and runs SGD backwards on the data stored in the individual buffers. We show that this algorithm exactly deconstructs the dependency structure and obtains information theoretically optimal guarantees for both parameter error and prediction error. Thus, we provide the first -- to the best of our knowledge -- optimal SGD-style algorithm for the classical problem of linear system identification with a first order oracle. Furthermore, SGD-RER can be applied to more general settings like sparse LTI identification with known sparsity pattern, and  non-linear dynamical systems. Our work demonstrates that the knowledge of data dependency structure can aid us in designing statistically and computationally efficient algorithms which can ``decorrelate'' streaming samples. ",
    "authors": [
      "Kowshik, Suhas",
      "Nagaraj, Dheeraj",
      "Jain, Prateek",
      "Netrapalli, Praneeth"
    ]
  },
  {
    "id": "fd45ebc1e1d76bc1fe0ba933e60e9957",
    "title": "SmoothMix: Training Confidence-calibrated Smoothed Classifiers for Certified Robustness",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fd45ebc1e1d76bc1fe0ba933e60e9957-Paper.pdf",
    "abstract": "Randomized smoothing is currently a state-of-the-art method to construct a certifiably robust classifier from neural networks against $\\ell_2$-adversarial perturbations. Under the paradigm, the robustness of a classifier is aligned with the prediction confidence, i.e., the higher confidence from a smoothed classifier implies the better robustness. This motivates us to rethink the fundamental trade-off between accuracy and robustness in terms of calibrating confidences of a smoothed classifier. In this paper, we propose a simple training scheme, coined SmoothMix, to control the robustness of smoothed classifiers via self-mixup: it trains on convex combinations of samples along the direction of adversarial perturbation for each input. The proposed procedure effectively identifies over-confident, near off-class samples as a cause of limited robustness in case of smoothed classifiers, and offers an intuitive way to adaptively set a new decision boundary between these samples for better robustness. Our experimental results demonstrate that the proposed method can significantly improve the certified $\\ell_2$-robustness of smoothed classifiers compared to existing state-of-the-art robust training methods.",
    "authors": [
      "Jeong, Jongheon",
      "Park, Sejun",
      "Kim, Minkyu",
      "Lee, Heung-Chang",
      "Kim, Do-Guk",
      "Shin, Jinwoo"
    ]
  },
  {
    "id": "fd9dd764a6f1d73f4340d570804eacc4",
    "title": "Action-guided 3D Human Motion Prediction",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fd9dd764a6f1d73f4340d570804eacc4-Paper.pdf",
    "abstract": "The ability of forecasting future human motion is important for human-machine interaction systems to understand human behaviors and make interaction. In this work, we focus on developing models to predict future human motion from past observed video frames. Motivated by the observation that human motion is closely related to the action being performed, we propose to explore action context to guide motion prediction. Specifically, we construct an action-specific memory bank to store representative motion dynamics for each action category, and design a query-read process to retrieve some motion dynamics from the memory bank. The retrieved dynamics are consistent with the action depicted in the observed video frames and serve as a strong prior knowledge to guide motion prediction. We further formulate an action constraint loss to ensure the global semantic consistency of the predicted motion. Extensive experiments demonstrate the effectiveness of the proposed approach, and we achieve state-of-the-art performance on 3D human motion prediction.",
    "authors": [
      "Sun, Jiangxin",
      "Lin, Zihang",
      "Han, Xintong",
      "Hu, Jian-Fang",
      "Xu, Jia",
      "Zheng, Wei-Shi"
    ]
  },
  {
    "id": "fdb55ce855129e05da8374059cc82728",
    "title": "Meta-Learning the Search Distribution of Black-Box Random Search Based Adversarial Attacks",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fdb55ce855129e05da8374059cc82728-Paper.pdf",
    "abstract": "Adversarial attacks based on randomized search schemes have obtained state-of-the-art results in black-box robustness evaluation recently. However, as we demonstrate in this work, their efficiency in different query budget regimes depends on manual design and heuristic tuning of the underlying proposal distributions. We study how this issue can be addressed by adapting the proposal distribution online based on the information obtained during the attack. We consider Square Attack, which is a state-of-the-art score-based black-box attack, and demonstrate how its performance can be improved by a learned controller that adjusts the parameters of the proposal distribution online during the attack. We train the controller using gradient-based end-to-end training on a CIFAR10 model with white box access. We demonstrate that plugging the learned controller into the attack consistently improves its black-box robustness estimate in different query regimes by up to 20% for a wide range of different models with black-box access. We further show that the learned adaptation principle transfers well to the other data distributions such as CIFAR100 or ImageNet and to the targeted attack setting. ",
    "authors": [
      "Yatsura, Maksym",
      "Metzen, Jan",
      "Hein, Matthias"
    ]
  },
  {
    "id": "fdc42b6b0ee16a2f866281508ef56730",
    "title": "Validating the Lottery Ticket Hypothesis with Inertial Manifold Theory",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fdc42b6b0ee16a2f866281508ef56730-Paper.pdf",
    "abstract": "Despite achieving remarkable efficiency, traditional network pruning techniques often follow manually-crafted heuristics to generate pruned sparse networks. Such heuristic pruning strategies are hard to guarantee that the pruned networks achieve test accuracy comparable to the original dense ones. Recent works have empirically identified and verified the Lottery Ticket Hypothesis (LTH): a randomly-initialized dense neural network contains an extremely sparse subnetwork, which can be trained to achieve similar accuracy to the former. Due to the lack of theoretical evidence, they often need to run multiple rounds of expensive training and pruning over the original large networks to discover the sparse subnetworks with low accuracy loss. By leveraging dynamical systems theory and inertial manifold theory, this work theoretically verifies the validity of the LTH. We explore the possibility of theoretically lossless pruning as well as one-time pruning, compared with existing neural network pruning and LTH techniques. We reformulate the neural network optimization problem as a gradient dynamical system and reduce this high-dimensional system onto inertial manifolds to obtain a low-dimensional system regarding pruned subnetworks. We demonstrate the precondition and existence of pruned subnetworks and prune the original networks in terms of the gap in their spectrum that make the subnetworks have the smallest dimensions.",
    "authors": [
      "Zhang, Zeru",
      "Jin, Jiayin",
      "Zhang, Zijie",
      "Zhou, Yang",
      "Zhao, Xin",
      "Ren, Jiaxiang",
      "Liu, Ji",
      "Wu, Lingfei",
      "Jin, Ruoming",
      "Dou, Dejing"
    ]
  },
  {
    "id": "fdda6e957f1e5ee2f3b311fe4f145ae1",
    "title": "Are My Deep Learning Systems Fair? An Empirical Study of Fixed-Seed Training",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fdda6e957f1e5ee2f3b311fe4f145ae1-Paper.pdf",
    "abstract": "Deep learning (DL) systems have been gaining popularity in critical tasks such as credit evaluation and crime prediction. Such systems demand fairness. Recent work shows that DL software implementations introduce variance: identical DL training runs (i.e., identical network, data, configuration, software, and hardware) with a fixed seed produce different models. Such variance could make DL models and networks violate fairness compliance laws, resulting in negative social impact. In this paper, we conduct the first empirical study to quantify the impact of software implementation on the fairness and its variance of DL systems. Our study of 22 mitigation techniques and five baselines reveals up to 12.6% fairness variance across identical training runs with identical seeds. In addition, most debiasing algorithms have a negative impact on the model such as reducing model accuracy, increasing fairness variance, or increasing accuracy variance. Our literature survey shows that while fairness is gaining popularity in artificial intelligence (AI) related conferences, only 34.4% of the papers use multiple identical training runs to evaluate their approach, raising concerns about their results\u2019 validity. We call for better fairness evaluation and testing protocols to improve fairness and fairness variance of DL systems as well as DL research validity and reproducibility at large.",
    "authors": [
      "Qian, Shangshu",
      "Pham, Viet Hung",
      "Lutellier, Thibaud",
      "Hu, Zeou",
      "Kim, Jungwon",
      "Tan, Lin",
      "Yu, Yaoliang",
      "Chen, Jiahao",
      "Shah, Sameena"
    ]
  },
  {
    "id": "fde9264cf376fffe2ee4ddf4a988880d",
    "title": "Rectangular Flows for Manifold Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fde9264cf376fffe2ee4ddf4a988880d-Paper.pdf",
    "abstract": "Normalizing flows are invertible neural networks with tractable change-of-volume terms, which allow optimization of their parameters to be efficiently performed via maximum likelihood. However, data of interest are typically assumed to live in some (often unknown) low-dimensional manifold embedded in a high-dimensional ambient space. The result is a modelling mismatch since -- by construction -- the invertibility requirement implies high-dimensional support of the learned distribution. Injective flows, mappings from low- to high-dimensional spaces, aim to fix this discrepancy by learning distributions on manifolds, but the resulting volume-change term becomes more challenging to evaluate. Current approaches either avoid computing this term entirely using various heuristics, or assume the manifold is known beforehand and therefore are not widely applicable. Instead, we propose two methods to tractably calculate the gradient of this term with respect to the parameters of the model, relying on careful use of automatic differentiation and techniques from numerical linear algebra. Both approaches perform end-to-end nonlinear manifold learning and density estimation for data projected onto this manifold. We study the trade-offs between our proposed methods, empirically verify that we outperform approaches ignoring the volume-change term by more accurately learning manifolds and the corresponding distributions on them, and show promising results on out-of-distribution detection. Our code is available at https://github.com/layer6ai-labs/rectangular-flows.",
    "authors": [
      "Caterini, Anthony L.",
      "Loaiza-Ganem, Gabriel",
      "Pleiss, Geoff",
      "Cunningham, John P."
    ]
  },
  {
    "id": "fe04e05fbe48920b8ba90bea2ddfe60b",
    "title": "On the Generative Utility of Cyclic Conditionals",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fe04e05fbe48920b8ba90bea2ddfe60b-Paper.pdf",
    "abstract": "We study whether and how can we model a joint distribution $p(x,z)$ using two conditional models $p(x|z)$ and $q(z|x)$ that form a cycle. This is motivated by the observation that deep generative models, in addition to a likelihood model $p(x|z)$, often also use an inference model $q(z|x)$ for extracting representation, but they rely on a usually uninformative prior distribution $p(z)$ to define a joint distribution, which may render problems like posterior collapse and manifold mismatch. To explore the possibility to model a joint distribution using only $p(x|z)$ and $q(z|x)$, we study their compatibility and determinacy, corresponding to the existence and uniqueness of a joint distribution whose conditional distributions coincide with them. We develop a general theory for operable equivalence criteria for compatibility, and sufficient conditions for determinacy. Based on the theory, we propose a novel generative modeling framework CyGen that only uses the two cyclic conditional models. We develop methods to achieve compatibility and determinacy, and to use the conditional models to fit and generate data. With the prior constraint removed, CyGen better fits data and captures more representative features, supported by both synthetic and real-world experiments.",
    "authors": [
      "Liu, Chang",
      "Tang, Haoyue",
      "Qin, Tao",
      "Wang, Jintao",
      "Liu, Tie-Yan"
    ]
  },
  {
    "id": "fe1f9c70bdf347497e1a01b6c486bdb9",
    "title": "Structural Credit Assignment in Neural Networks using Reinforcement Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fe1f9c70bdf347497e1a01b6c486bdb9-Paper.pdf",
    "abstract": "Structural credit assignment in neural networks is a long-standing problem, with a variety of alternatives to backpropagation proposed to allow for local training of nodes. One of the early strategies was to treat each node as an agent and use a reinforcement learning method called REINFORCE to update each node locally with only a global reward signal. In this work, we revisit this approach and investigate if we can leverage other reinforcement learning approaches to improve learning. We first formalize training a neural network as a finite-horizon reinforcement learning problem and discuss how this facilitates using ideas from reinforcement learning like off-policy learning. We show that the standard on-policy REINFORCE approach, even with a variety of variance reduction approaches, learns suboptimal solutions. We introduce an off-policy approach, to facilitate reasoning about the greedy action for other agents and help overcome stochasticity in other agents. We conclude by showing that these networks of agents can be more robust to correlated samples when learning online.",
    "authors": [
      "Gupta, Dhawal",
      "Mihucz, Gabor",
      "Schlegel, Matthew",
      "Kostas, James",
      "Thomas, Philip S.",
      "White, Martha"
    ]
  },
  {
    "id": "fe2b421b8b5f0e7c355ace66a9fe0206",
    "title": "A Near-Optimal Algorithm for Stochastic Bilevel Optimization via Double-Momentum",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fe2b421b8b5f0e7c355ace66a9fe0206-Paper.pdf",
    "abstract": "This paper proposes a new algorithm -- the  \\underline{S}ingle-timescale Do\\underline{u}ble-momentum \\underline{St}ochastic \\underline{A}pprox\\underline{i}matio\\underline{n} (SUSTAIN) -- for tackling stochastic unconstrained bilevel optimization problems. We focus on bilevel problems where the lower level subproblem is strongly-convex and the upper level objective function is smooth. Unlike prior works which rely on \\emph{two-timescale} or \\emph{double loop} techniques, we design a stochastic momentum-assisted gradient estimator for both the upper and lower level updates. The latter allows us to control the error in the stochastic gradient updates due to inaccurate solution to both subproblems. If the upper objective function is smooth but possibly non-convex, we show that {SUSTAIN}~requires $O(\\epsilon^{-3/2})$  iterations (each using $O(1)$ samples) to find an $\\epsilon$-stationary solution. The $\\epsilon$-stationary solution is defined as the point whose squared norm of the gradient of the outer function is less than or equal to $\\epsilon$.  The total number of stochastic gradient samples required for the upper and lower level objective functions matches the best-known complexity for single-level stochastic gradient algorithms. We also analyze the case when the upper level objective function is strongly-convex. ",
    "authors": [
      "Khanduri, Prashant",
      "Zeng, Siliang",
      "Hong, Mingyi",
      "Wai, Hoi-To",
      "Wang, Zhaoran",
      "Yang, Zhuoran"
    ]
  },
  {
    "id": "fe2d010308a6b3799a3d9c728ee74244",
    "title": "Generalized Jensen-Shannon Divergence Loss for Learning with Noisy Labels",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fe2d010308a6b3799a3d9c728ee74244-Paper.pdf",
    "abstract": "Prior works have found it beneficial to combine provably noise-robust loss functions e.g., mean absolute error (MAE) with standard categorical loss function e.g. cross entropy (CE) to improve their learnability. Here, we propose to use Jensen-Shannon divergence as a noise-robust loss function and show that it interestingly interpolate between CE and MAE with a controllable mixing parameter. Furthermore, we make a crucial observation that CE exhibit lower consistency around noisy data points. Based on this observation, we adopt a generalized version of the Jensen-Shannon divergence for multiple distributions to encourage consistency around data points. Using this loss function, we show state-of-the-art results on both synthetic (CIFAR), and real-world (e.g., WebVision) noise with varying noise rates.",
    "authors": [
      "Englesson, Erik",
      "Azizpour, Hossein"
    ]
  },
  {
    "id": "fe5e7cb609bdbe6d62449d61849c38b0",
    "title": "Continual Learning via Local Module Composition",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fe5e7cb609bdbe6d62449d61849c38b0-Paper.pdf",
    "abstract": "Modularity is a compelling solution to continual learning (CL), the problem of modeling sequences of related tasks. Learning and then composing modules to solve different tasks provides an abstraction to address the principal challenges of CL including catastrophic forgetting, backward and forward transfer across tasks, and sub-linear model growth. We introduce local module composition (LMC), an approach to modular CL where each module is provided a local structural component that estimates a module\u2019s relevance to the input. Dynamic module composition is performed layer-wise based on local relevance scores. We demonstrate that agnosticity to task identities (IDs) arises from (local) structural learning that is module-specific as opposed to the task- and/or model-specific as in previous works, making LMC applicable to more CL settings compared to previous works. In addition, LMC also tracks statistics about the input distribution and adds new modules when outlier samples are detected. In the first set of experiments, LMC performs favorably compared to existing methods on the recent Continual Transfer-learning Benchmark without requiring task identities. In another study, we show that the locality of structural learning allows LMC to interpolate to related but unseen tasks (OOD), as well as to compose modular networks trained independently on different task sequences into a third modular network without any fine-tuning. Finally, in search for limitations of LMC we study it on more challenging sequences of 30 and 100 tasks, demonstrating that local module selection becomes much more challenging in presence of a large number of candidate modules. In this setting best performing LMC spawns much fewer modules compared to an oracle based baseline, however, it reaches a lower overall accuracy. The codebase is available under https://github.com/oleksost/LMC. ",
    "authors": [
      "Ostapenko, Oleksiy",
      "Rodriguez, Pau",
      "Caccia, Massimo",
      "Charlin, Laurent"
    ]
  },
  {
    "id": "fe73f687e5bc5280214e0486b273a5f9",
    "title": "Model-Based Episodic Memory Induces Dynamic Hybrid Controls",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fe73f687e5bc5280214e0486b273a5f9-Paper.pdf",
    "abstract": "Episodic control enables sample efficiency in reinforcement learning by recalling past experiences from an episodic memory. We propose a new model-based episodic memory of trajectories addressing current limitations of episodic control. Our memory estimates trajectory values, guiding the agent towards good policies. Built upon the memory, we construct a complementary learning model via a dynamic hybrid control unifying model-based, episodic and habitual learning into a single architecture. Experiments demonstrate that our model allows significantly faster and better learning than other strong reinforcement learning agents across a variety of environments including stochastic and non-Markovian settings.",
    "authors": [
      "Le, Hung",
      "Karimpanal George, Thommen",
      "Abdolshah, Majid",
      "Tran, Truyen",
      "Venkatesh, Svetha"
    ]
  },
  {
    "id": "fe7ee8fc1959cc7214fa21c4840dff0a",
    "title": "FedDR \u2013 Randomized Douglas-Rachford Splitting Algorithms for Nonconvex Federated Composite Optimization",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fe7ee8fc1959cc7214fa21c4840dff0a-Paper.pdf",
    "abstract": "We develop two new algorithms, called, FedDR and asyncFedDR, for solving a fundamental nonconvex composite optimization problem in federated learning. Our algorithms rely on a novel combination between a nonconvex Douglas-Rachford splitting method, randomized block-coordinate strategies, and asynchronous im- plementation. They can also handle convex regularizers. Unlike recent methods in the literature, e.g., FedSplit and FedPD, our algorithms update only a subset of users at each communication round, and possibly in an asynchronous manner, making them more practical. These new algorithms can handle statistical and sys- tem heterogeneity, which are the two main challenges in federated learning, while achieving the best known communication complexity. In fact, our new algorithms match the communication complexity lower bound up to a constant factor under standard assumptions. Our numerical experiments illustrate the advantages of our methods over existing algorithms on synthetic and real datasets.",
    "authors": [
      "Tran Dinh, Quoc",
      "Pham, Nhan H",
      "Phan, Dzung",
      "Nguyen, Lam"
    ]
  },
  {
    "id": "fe87435d12ef7642af67d9bc82a8b3cd",
    "title": "Adversarial Examples Make Strong Poisons",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fe87435d12ef7642af67d9bc82a8b3cd-Paper.pdf",
    "abstract": "The adversarial machine learning literature is largely partitioned into evasion attacks on testing data and poisoning attacks on training data.  In this work, we show that adversarial examples, originally intended for attacking pre-trained models, are even more effective for data poisoning than recent methods designed specifically for poisoning. In fact, adversarial examples with labels re-assigned by the crafting network remain effective for training, suggesting that adversarial examples contain useful semantic content, just with the \"wrong\" labels (according to a network, but not a human). Our method, adversarial poisoning, is substantially more effective than existing poisoning methods for secure dataset release, and we release a poisoned version of ImageNet, ImageNet-P, to encourage research into the strength of this form of data obfuscation.",
    "authors": [
      "Fowl, Liam",
      "Goldblum, Micah",
      "Chiang, Ping-yeh",
      "Geiping, Jonas",
      "Czaja, Wojciech",
      "Goldstein, Tom"
    ]
  },
  {
    "id": "fea9c11c4ad9a395a636ed944a28b51a",
    "title": "Coresets for Decision Trees of Signals",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fea9c11c4ad9a395a636ed944a28b51a-Paper.pdf",
    "abstract": "A $k$-decision tree $t$ (or $k$-tree) is a recursive partition of a matrix (2D-signal) into $k\\geq 1$ block matrices (axis-parallel rectangles, leaves) where each rectangle is assigned a real label. Its regression or classification loss to a given matrix $D$ of $N$ entries (labels) is the sum of squared differences over every label in $D$ and its assigned label by $t$.Given an error parameter $\\varepsilon\\in(0,1)$, a $(k,\\varepsilon)$-coreset $C$ of $D$ is a small summarization that provably approximates this loss to \\emph{every} such tree, up to a multiplicative factor of $1\\pm\\varepsilon$. In particular, the optimal $k$-tree of $C$ is a $(1+\\varepsilon)$-approximation to the optimal $k$-tree of $D$.We provide the first algorithm that outputs such a $(k,\\varepsilon)$-coreset for \\emph{every} such matrix $D$. The size $|C|$ of the coreset is polynomial in $k\\log(N)/\\varepsilon$, and its construction takes $O(Nk)$ time.This is by forging a link between decision trees from machine learning -- to partition trees in computational geometry. Experimental results on \\texttt{sklearn} and \\texttt{lightGBM} show that applying our coresets on real-world data-sets boosts the computation time of random forests and their parameter tuning by up to x$10$, while keeping similar accuracy. Full open source code is provided.",
    "authors": [
      "Jubran, Ibrahim",
      "Sanches Shayda, Ernesto Evgeniy",
      "Newman, Ilan I",
      "Feldman, Dan"
    ]
  },
  {
    "id": "feade1d2047977cd0cefdafc40175a99",
    "title": "Local plasticity rules can learn deep representations using self-supervised contrastive predictions",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/feade1d2047977cd0cefdafc40175a99-Paper.pdf",
    "abstract": "Learning in the brain is poorly understood and learning rules that respect biological constraints, yet yield deep hierarchical representations, are still unknown. Here, we propose a learning rule that takes inspiration from neuroscience and recent advances in self-supervised deep learning. Learning minimizes a simple layer-specific loss function and does not need to back-propagate error signals within or between layers. Instead, weight updates follow a local, Hebbian, learning rule that only depends on pre- and post-synaptic neuronal activity, predictive dendritic input and widely broadcasted modulation factors which are identical for large groups of neurons. The learning rule applies contrastive predictive learning to a causal, biological setting using saccades (i.e. rapid shifts in gaze direction). We find that networks trained with this self-supervised and local rule build deep hierarchical representations of images, speech and video. ",
    "authors": [
      "Illing, Bernd",
      "Ventura, Jean",
      "Bellec, Guillaume",
      "Gerstner, Wulfram"
    ]
  },
  {
    "id": "fecf2c550171d3195c879d115440ae45",
    "title": "MobTCast: Leveraging Auxiliary Trajectory Forecasting for Human Mobility Prediction",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/fecf2c550171d3195c879d115440ae45-Paper.pdf",
    "abstract": "Human mobility prediction is a core functionality in many location-based services and applications. However, due to the sparsity of mobility data, it is not an easy task to predict future POIs (place-of-interests) that are going to be visited. In this paper, we propose MobTCast, a Transformer-based context-aware network for mobility prediction. Specifically, we explore the influence of four types of context in mobility prediction: temporal, semantic, social, and geographical contexts. We first design a base mobility feature extractor using the Transformer architecture, which takes both the history POI sequence and the semantic information as input. It handles both the temporal and semantic contexts. Based on the base extractor and the social connections of a user, we employ a self-attention module to model the influence of the social context. Furthermore, unlike existing methods, we introduce a location prediction branch in MobTCast as an auxiliary task to model the geographical context and predict the next location. Intuitively, the geographical distance between the location of the predicted POI and the predicted location from the auxiliary branch should be as close as possible. To reflect this relation, we design a consistency loss to further improve the POI prediction performance. In our experimental results, MobTCast outperforms other state-of-the-art next POI prediction methods. Our approach illustrates the value of including different types of context in next POI prediction.",
    "authors": [
      "Xue, Hao",
      "Salim, Flora",
      "Ren, Yongli",
      "Oliver, Nuria"
    ]
  },
  {
    "id": "ff1418e8cc993fe8abcfe3ce2003e5c5",
    "title": "Early Convolutions Help Transformers See Better",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ff1418e8cc993fe8abcfe3ce2003e5c5-Paper.pdf",
    "abstract": "Vision transformer (ViT) models exhibit substandard optimizability. In particular, they are sensitive to the choice of optimizer (AdamW vs. SGD), optimizer hyperparameters, and training schedule length. In comparison, modern convolutional neural networks are easier to optimize. Why is this the case? In this work, we conjecture that the issue lies with the patchify stem of ViT models, which is implemented by a stride-p p\u00d7p convolution (p = 16 by default) applied to the input image. This large-kernel plus large-stride convolution runs counter to typical design choices of convolutional layers in neural networks. To test whether this atypical design choice causes an issue, we analyze the optimization behavior of ViT models with their original patchify stem versus a simple counterpart where we replace the ViT stem by a small number of stacked stride-two 3\u00d73 convolutions. While the vast majority of computation in the two ViT designs is identical, we find that this small change in early visual processing results in markedly different training behavior in terms of the sensitivity to optimization settings as well as the final model accuracy. Using a convolutional stem in ViT dramatically increases optimization stability and also improves peak performance (by \u223c1-2% top-1 accuracy on ImageNet-1k), while maintaining flops and runtime. The improvement can be observed across the wide spectrum of model complexities (from 1G to 36G flops) and dataset scales (from ImageNet-1k to ImageNet-21k). These findings lead us to recommend using a standard, lightweight convolutional stem for ViT models in this regime as a more robust architectural choice compared to the original ViT model design.",
    "authors": [
      "Xiao, Tete",
      "Singh, Mannat",
      "Mintun, Eric",
      "Darrell, Trevor",
      "Dollar, Piotr",
      "Girshick, Ross"
    ]
  },
  {
    "id": "ff1ced3097ccf17c1e67506cdad9ac95",
    "title": "Error Compensated Distributed SGD Can Be Accelerated",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ff1ced3097ccf17c1e67506cdad9ac95-Paper.pdf",
    "abstract": "Gradient compression is a recent and increasingly popular technique for reducing the communication cost in distributed training of large-scale machine learning models. In this work we focus on developing efficient distributed methods that can work for any compressor satisfying a certain contraction property, which includes both unbiased (after appropriate scaling) and biased compressors such as RandK and TopK. Applied naively, gradient compression introduces errors that either slow down convergence or lead to divergence. A popular technique designed to tackle this issue is error compensation/error feedback. Due to the difficulties associated with analyzing biased compressors, it is not known whether gradient compression with error compensation can be combined with acceleration. In this work, we show for the first time that error compensated gradient compression methods can be accelerated. In particular, we propose and study the error compensated loopless Katyusha method, and establish an accelerated linear convergence rate under standard assumptions. We show through numerical experiments that the proposed method converges with substantially fewer communication rounds than previous error compensated algorithms.",
    "authors": [
      "Qian, Xun",
      "Richtarik, Peter",
      "Zhang, Tong"
    ]
  },
  {
    "id": "ff1e68e74c6b16a1a7b5d958b95e120c",
    "title": "InfoGCL: Information-Aware Graph Contrastive Learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ff1e68e74c6b16a1a7b5d958b95e120c-Paper.pdf",
    "abstract": "Various graph contrastive learning models have been proposed to improve the performance of tasks on graph datasets in recent years. While effective and prevalent, these models are usually carefully customized. In particular, despite all recent work create two contrastive views, they differ in a variety of view augmentations, architectures, and objectives. It remains an open question how to build your graph contrastive learning model from scratch for particular graph tasks and datasets. In this work, we aim to fill this gap by studying how graph information is transformed and transferred during the contrastive learning process, and proposing an information-aware graph contrastive learning framework called InfoGCL. The key to the success of the proposed framework is to follow the Information Bottleneck principle to reduce the mutual information between contrastive parts while keeping task-relevant information intact at both the levels of the individual module and the entire framework so that the information loss during graph representation learning can be minimized. We show for the first time that all recent graph contrastive learning methods can be unified by our framework. Based on theoretical and empirical analysis on benchmark graph datasets, we show that InfoGCL achieves state-of-the-art performance in the settings of both graph classification and node classification tasks.",
    "authors": [
      "Xu, Dongkuan",
      "Cheng, Wei",
      "Luo, Dongsheng",
      "Chen, Haifeng",
      "Zhang, Xiang"
    ]
  },
  {
    "id": "ff49cc40a8890e6a60f40ff3026d2730",
    "title": "Meta-Learning for Relative Density-Ratio Estimation",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ff49cc40a8890e6a60f40ff3026d2730-Paper.pdf",
    "abstract": "The ratio of two probability densities, called a density-ratio, is a vital quantity in machine learning. In particular, a relative density-ratio, which is a bounded extension of the density-ratio, has received much attention due to its stability and has been used in various applications such as outlier detection and dataset comparison. Existing methods for (relative) density-ratio estimation (DRE) require many instances from both densities. However, sufficient instances are often unavailable in practice. In this paper, we propose a meta-learning method for relative DRE, which estimates the relative density-ratio from a few instances by using knowledge in related datasets. Specifically, given two datasets that consist of a few instances, our model extracts the datasets' information by using neural networks and uses it to obtain instance embeddings appropriate for the relative DRE. We model the relative density-ratio by a linear model on the embedded space, whose global optimum solution can be obtained as a closed-form solution. The closed-form solution enables fast and effective adaptation to a few instances, and its differentiability enables us to train our model such that the expected test error for relative DRE can be explicitly minimized after adapting to a few instances. We empirically demonstrate the effectiveness of the proposed method by using three problems: relative DRE, dataset comparison, and outlier detection.",
    "authors": [
      "Kumagai, Atsutoshi",
      "Iwata, Tomoharu",
      "Fujiwara, Yasuhiro"
    ]
  },
  {
    "id": "ff4d5fbbafdf976cfdc032e3bde78de5",
    "title": "Overcoming the curse of dimensionality with Laplacian regularization in semi-supervised learning",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ff4d5fbbafdf976cfdc032e3bde78de5-Paper.pdf",
    "abstract": "As annotations of data can be scarce in large-scale practical problems, leveraging unlabelled examples is one of the most important aspects of machine learning. This is the aim of semi-supervised learning. To benefit from the access to unlabelled data, it is natural to diffuse smoothly knowledge of labelled data to unlabelled one. This induces to the use of Laplacian regularization. Yet, current implementations of Laplacian regularization suffer from several drawbacks, notably the well-known curse of dimensionality. In this paper, we design a new class of algorithms overcoming this issue, unveiling a large body of spectral filtering methods. Additionally, we provide a statistical analysis showing that our estimators exhibit desirable behaviors. They are implemented through (reproducing) kernel methods, for which we provide realistic computational guidelines in order to make our method usable with large amounts of data.  ",
    "authors": [
      "Cabannes, Vivien",
      "Pillaud-Vivien, Loucas",
      "Bach, Francis",
      "Rudi, Alessandro"
    ]
  },
  {
    "id": "ff8c1a3bd0c441439a0a081e560c85fc",
    "title": "Unlabeled Principal Component Analysis",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ff8c1a3bd0c441439a0a081e560c85fc-Paper.pdf",
    "abstract": "We introduce robust principal component analysis from a data matrix in which the entries of its columns have been corrupted by permutations, termed Unlabeled Principal Component Analysis (UPCA). Using algebraic geometry, we establish that UPCA is a well-defined algebraic problem in the sense that the only matrices of minimal rank that agree with the given data are row-permutations of the ground-truth matrix, arising as the unique solutions of a polynomial system of equations. Further, we propose an efficient two-stage algorithmic pipeline for UPCA suitable for the practically relevant case where only a fraction of the data have been permuted. Stage-I employs outlier-robust PCA methods to estimate the ground-truth column-space. Equipped with the column-space, Stage-II applies recent methods for unlabeled sensing to restore the permuted data. Experiments on synthetic data, face images, educational and medical records reveal the potential of UPCA for applications such as data privatization and record linkage.",
    "authors": [
      "Yao, Yunzhen",
      "Peng, Liangzu",
      "Tsakiris, Manolis"
    ]
  },
  {
    "id": "ffa4eb0e32349ae57f7a0ee8c7cd7c11",
    "title": "Causal-BALD: Deep Bayesian Active Learning of Outcomes to Infer Treatment-Effects from Observational Data",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ffa4eb0e32349ae57f7a0ee8c7cd7c11-Paper.pdf",
    "abstract": "Estimating personalized treatment effects from high-dimensional observational data is essential in situations where experimental designs are infeasible, unethical, or expensive. Existing approaches rely on fitting deep models on outcomes observed for treated and control populations. However, when measuring individual outcomes is costly, as is the case of a tumor biopsy, a sample-efficient strategy for acquiring each result is required. Deep Bayesian active learning provides a framework for efficient data acquisition by selecting points with high uncertainty. However, existing methods bias training data acquisition towards regions of non-overlapping support between the treated and control populations. These are not sample-efficient because the treatment effect is not identifiable in such regions. We introduce causal, Bayesian acquisition functions grounded in information theory that bias data acquisition towards regions with overlapping support to maximize sample efficiency for learning personalized treatment effects. We demonstrate the performance of the proposed acquisition strategies on synthetic and semi-synthetic datasets IHDP and CMNIST and their extensions, which aim to simulate common dataset biases and pathologies.",
    "authors": [
      "Jesson, Andrew",
      "Tigas, Panagiotis",
      "van Amersfoort, Joost",
      "Kirsch, Andreas",
      "Shalit, Uri",
      "Gal, Yarin"
    ]
  },
  {
    "id": "ffbd6cbb019a1413183c8d08f2929307",
    "title": "Scalable Rule-Based Representation Learning for Interpretable Classification",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ffbd6cbb019a1413183c8d08f2929307-Paper.pdf",
    "abstract": "Rule-based models, e.g., decision trees, are widely used in scenarios demanding high model interpretability for their transparent inner structures and good model expressivity. However, rule-based models are hard to optimize, especially on large data sets, due to their discrete parameters and structures. Ensemble methods and fuzzy/soft rules are commonly used to improve performance, but they sacrifice the model interpretability. To obtain both good scalability and interpretability, we propose a new classifier, named Rule-based Representation Learner (RRL), that automatically learns interpretable non-fuzzy rules for data representation and classification. To train the non-differentiable RRL effectively, we project it to a continuous space and propose a novel training method, called Gradient Grafting, that can directly optimize the discrete model using gradient descent. An improved design of logical activation functions is also devised to increase the scalability of RRL and enable it to discretize the continuous features end-to-end. Exhaustive experiments on nine small and four large data sets show that RRL outperforms the competitive interpretable approaches and can be easily adjusted to obtain a trade-off between classification accuracy and model complexity for different scenarios. Our code is available at: https://github.com/12wang3/rrl.",
    "authors": [
      "Wang, Zhuo",
      "Zhang, Wei",
      "Liu, Ning",
      "Wang, Jianyong"
    ]
  },
  {
    "id": "ffc58105bf6f8a91aba0fa2d99e6f106",
    "title": "Bridging Non Co-occurrence with Unlabeled In-the-wild Data for Incremental Object Detection",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ffc58105bf6f8a91aba0fa2d99e6f106-Paper.pdf",
    "abstract": "Deep networks have shown remarkable results in the task of object detection. However, their performance suffers critical drops when they are subsequently trained on novel classes without any sample from the base classes originally used to train the model. This phenomenon is known as catastrophic forgetting. Recently, several incremental learning methods are proposed to mitigate catastrophic forgetting for object detection. Despite the effectiveness, these methods require co-occurrence of the unlabeled base classes in the training data of the novel classes. This requirement is impractical in many real-world settings since the base classes do not necessarily co-occur with the novel classes. In view of this limitation, we consider a more practical setting of complete absence of co-occurrence of the base and novel classes for the object detection task. We propose the use of unlabeled in-the-wild data to bridge the non co-occurrence caused by the missing base classes during the training of additional novel classes. To this end, we introduce a blind sampling strategy based on the responses of the base-class model and pre-trained novel-class model to select a smaller relevant dataset from the large in-the-wild dataset for incremental learning. We then design a dual-teacher distillation framework to transfer the knowledge distilled from the base- and novel-class teacher models to the student model using the sampled in-the-wild data. Experimental results on the PASCAL VOC and MS COCO datasets show that our proposed method significantly outperforms other state-of-the-art class-incremental object detection methods when there is no co-occurrence between the base and novel classes during training. ",
    "authors": [
      "DONG, NA",
      "Zhang, Yongqiang",
      "Ding, Mingli",
      "Lee, Gim Hee"
    ]
  },
  {
    "id": "ffeed84c7cb1ae7bf4ec4bd78275bb98",
    "title": "A Regression Approach to Learning-Augmented Online Algorithms",
    "year": "2021-12-06",
    "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/ffeed84c7cb1ae7bf4ec4bd78275bb98-Paper.pdf",
    "abstract": "The emerging field of learning-augmented online algorithms uses ML techniques to predict future input parameters and thereby improve the performance of online algorithms. Since these parameters are, in general, real-valued functions, a natural approach is to use regression techniques to make these predictions. We introduce this approach in this paper, and explore it in the context of a general online search framework that captures classic problems like (generalized) ski rental, bin packing, minimum makespan scheduling, etc. We show nearly tight bounds on the sample complexity of this regression problem, and extend our results to the agnostic setting. From a technical standpoint, we show that the key is to incorporate online optimization benchmarks in the design of the loss function for the regression problem, thereby diverging from the use of off-the-shelf regression tools with standard bounds on statistical error.",
    "authors": [
      "Anand, Keerti",
      "Ge, Rong",
      "Kumar, Amit",
      "Panigrahi, Debmalya"
    ]
  }
]